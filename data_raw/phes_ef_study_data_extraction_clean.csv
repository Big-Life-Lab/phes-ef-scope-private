...1,covidence_num,study_id,source_title,extracted_source_title,publication_year,corresponding_author_name,corresponding_author_email,corresponding_author_country,article_objective,study_design_type,surv_system_type,surv_country,eval_framework_used,other_eval_framework_details,framework_section_01_name,framework_section_01_description,framework_section_01_eval_methodology,framework_section_01_meas_consid,framework_section_01_notes,framework_section_02_name,framework_section_02_description,framework_section_02_eval_methodology,framework_section_02_meas_consid,framework_section_02_notes,framework_section_03_name,framework_section_03_description,framework_section_03_eval_methodology,framework_section_03_meas_consid,framework_section_03_notes,framework_section_04_name,framework_section_04_description,framework_section_04_eval_methodology,framework_section_04_meas_consid,framework_section_04_notes,framework_section_05_name,framework_section_05_description,framework_section_05_eval_methodology,framework_section_05_meas_consid,framework_section_05_notes,framework_section_06_name,framework_section_06_description,framework_section_06_eval_methodology,framework_section_06_meas_consid,framework_section_06_notes,framework_section_07_name,framework_section_07_description,framework_section_07_eval_methodology,framework_section_07_meas_consid,framework_section_07_notes,framework_section_08_name,framework_section_08_description,framework_section_08_eval_methodology,framework_section_08_meas_consid,framework_section_08_notes,framework_section_09_name,framework_section_09_description,framework_section_09_eval_methodology,framework_section_09_meas_consid,framework_section_09_notes,public_health_objective_01,public_health_objective_02,public_health_objective_03,public_health_objective_04,public_health_objective_05,public_health_objective_06,public_health_objective_07,public_health_objective_08,public_health_objective_09,public_health_objective_10,wastewater_objective_01,wastewater_objective_02,wastewater_objective_03,one_health_objective_01,one_health_objective_02,one_health_objective_03,one_health_objective_04,other_objective_01,other_objective_02,other_objective_03,other_objective_04,other_objective_05,other_objective_06,surv_objective_notes,eval_stakeholders,stakeholder_01_eval_involved,stakeholder_01_eval_recommended,stakeholder_01_tool_devel_involved,stakeholder_01_notes,stakeholder_02_eval_involved,stakeholder_02_eval_recommended,stakeholder_02_tool_devel_involved,stakeholder_02_notes,stakeholder_03_eval_involved,stakeholder_03_eval_recommended,stakeholder_03_tool_devel_involved,stakeholder_03_notes,stakeholder_04_eval_involved,stakeholder_04_eval_recommended,stakeholder_04_tool_devel_involved,stakeholder_04_notes,stakeholder_05_eval_involved,stakeholder_05_eval_recommended,stakeholder_05_tool_devel_involved,stakeholder_05_notes,stakeholder_06_eval_involved,stakeholder_06_eval_recommended,stakeholder_06_tool_devel_involved,stakeholder_06_notes,stakeholder_07_eval_involved,stakeholder_07_eval_recommended,stakeholder_07_tool_devel_involved,stakeholder_07_notes,stakeholder_08_eval_involved,stakeholder_08_eval_recommended,stakeholder_08_tool_devel_involved,stakeholder_08_notes,stakeholder_09_eval_involved,stakeholder_09_eval_recommended,stakeholder_09_tool_devel_involved,stakeholder_09_notes,stakeholders_data_use_meas,domain_01_name,domain_01_def,domain_01_notes,domain_02_name,domain_02_def,domain_02_notes,domain_03_name,domain_03_def,domain_03_notes,domain_04_name,domain_04_def,domain_04_notes,domain_05_name,domain_05_def,domain_05_notes,domain_06_name,domain_06_def,domain_06_notes,domain_07_name,domain_07_def,domain_07_notes,domain_08_name,domain_08_def,domain_08_notes,acceptability_def,acceptability_eval_methods,acceptability_meas_consid,acceptability_eval_criteria,availability_def,availability_eval_methods,availability_meas_consid,availability_eval_criteria,coherence_def,coherence_eval_methods,coherence_meas_consid,coherence_eval_criteria,completeness_def,completeness_eval_methods,completeness_meas_consid,completeness_eval_criteria,compliance_def,compliance_eval_methods,compliance_meas_consid,compliance_eval_criteria,consistency_over_time_def,consistency_over_time_eval_methods,consistency_over_time_meas_consid,consistency_over_time_eval_criteria,cost_effectiveness_ratio_def,cost_effectiveness_ratio_eval_methods,cost_effectiveness_ratio_meas_consid,cost_effectiveness_ratio_eval_criteria,cost_effectiveness_def,cost_effectiveness_eval_methods,cost_effectiveness_meas_consid,cost_effectiveness_eval_criteria,cost_def,cost_eval_methods,cost_meas_consid,cost_eval_criteria,data_quality_def,data_quality_eval_methods,data_quality_meas_consid,data_quality_eval_criteria,effectiveness_def,effectiveness_eval_methods,effectiveness_meas_consid,effectiveness_eval_criteria,efficacy_def,efficacy_eval_methods,efficacy_meas_consid,efficacy_eval_criteria,efficiency_def,efficiency_eval_methods,efficiency_meas_consid,efficiency_eval_criteria,feasibility_def,feasibility_eval_methods,feasibility_meas_consid,feasibility_eval_criteria,flexibility_def,flexibility_eval_methods,flexibility_meas_consid,flexibility_eval_criteria,intergration_def,intergration_eval_methods,intergration_meas_consid,intergration_eval_criteria,interoperability_def,interoperability_eval_methods,interoperability_meas_consid,interoperability_eval_criteria,likelihood_ratio_pos_def,likelihood_ratio_pos_eval_methods,likelihood_ratio_pos_meas_consid,likelihood_ratio_pos_eval_criteria,npv_def,npv_eval_methods,npv_meas_consid,npv_eval_criteria,portability_def,portability_eval_methods,portability_meas_consid,portability_eval_criteria,ppv_def,ppv_eval_methods,ppv_meas_consid,ppv_eval_criteria,reliability_def,reliability_eval_methods,reliability_meas_consid,reliability_eval_criteria,representativeness_def,representativeness_eval_methods,representativeness_meas_consid,representativeness_eval_criteria,security_def,security_eval_methods,security_meas_consid,security_eval_criteria,sensitivity_def,sensitivity_eval_methods,sensitivity_meas_consid,sensitivity_eval_criteria,simplicity_def,simplicity_eval_methods,simplicity_meas_consid,simplicity_eval_criteria,specificity_def,specificity_eval_methods,specificity_meas_consid,specificity_eval_criteria,stability_def,stability_eval_methods,stability_meas_consid,stability_eval_criteria,standards_use_def,standards_use_eval_methods,standards_use_meas_consid,standards_use_eval_criteria,timeliness_def,timeliness_eval_methods,timeliness_meas_consid,timeliness_eval_criteria,usefulness_def,usefulness_eval_methods,usefulness_meas_consid,usefulness_eval_criteria,validity_def,validity_eval_methods,validity_meas_consid,validity_eval_criteria,addl_theme_01_def,addl_theme_01_eval_methods,addl_theme_01_meas_consid,addl_theme_01_eval_criteria,addl_theme_02_def,addl_theme_02_eval_methods,addl_theme_02_meas_consid,addl_theme_02_eval_criteria,addl_theme_03_def,addl_theme_03_eval_methods,addl_theme_03_meas_consid,addl_theme_03_eval_criteria,addl_theme_04_def,addl_theme_04_eval_methods,addl_theme_04_meas_consid,addl_theme_04_eval_criteria,addl_theme_05_def,addl_theme_05_eval_methods,addl_theme_05_meas_consid,addl_theme_05_eval_criteria,addl_theme_06_def,addl_theme_06_eval_methods,addl_theme_06_meas_consid,addl_theme_06_eval_criteria,addl_theme_07_def,addl_theme_07_eval_methods,addl_theme_07_meas_consid,addl_theme_07_eval_criteria,addl_theme_08_def,addl_theme_08_eval_methods,addl_theme_08_meas_consid,addl_theme_08_eval_criteria,addl_theme_09_def,addl_theme_09_eval_methods,addl_theme_09_meas_consid,addl_theme_09_eval_criteria,addl_theme_10_def,addl_theme_10_eval_methods,addl_theme_10_meas_consid,addl_theme_10_eval_criteria,addl_theme_11_def,addl_theme_11_eval_methods,addl_theme_11_meas_consid,addl_theme_11_eval_criteria,addl_theme_12_def,addl_theme_12_eval_methods,addl_theme_12_meas_consid,addl_theme_12_eval_criteria,addl_theme_13_def,addl_theme_13_eval_methods,addl_theme_13_meas_consid,addl_theme_13_eval_criteria,addl_theme_14_def,addl_theme_14_eval_methods,addl_theme_14_meas_consid,addl_theme_14_eval_criteria,addl_theme_15_def,addl_theme_15_eval_methods,addl_theme_15_meas_consid,addl_theme_15_eval_criteria,addl_theme_16_def,addl_theme_16_eval_methods,addl_theme_16_meas_consid,addl_theme_16_eval_criteria,addl_theme_17_def,addl_theme_17_eval_methods,addl_theme_17_meas_consid,addl_theme_17_eval_criteria,addl_theme_18_def,addl_theme_18_eval_methods,addl_theme_18_meas_consid,addl_theme_18_eval_criteria,addl_theme_19_def,addl_theme_19_eval_methods,addl_theme_19_meas_consid,addl_theme_19_eval_criteria,addl_theme_20_def,addl_theme_20_eval_methods,addl_theme_20_meas_consid,addl_theme_20_eval_criteria,addl_theme_21_def,addl_theme_21_eval_methods,addl_theme_21_meas_consid,addl_theme_21_eval_criteria,addl_theme_22_def,addl_theme_22_eval_methods,addl_theme_22_meas_consid,addl_theme_22_eval_criteria,addl_theme_23_def,addl_theme_23_eval_methods,addl_theme_23_meas_consid,addl_theme_23_eval_criteria,addl_theme_24_def,addl_theme_24_eval_methods,addl_theme_24_meas_consid,addl_theme_24_eval_criteria,addl_theme_25_def,addl_theme_25_eval_methods,addl_theme_25_meas_consid,addl_theme_25_eval_criteria,addl_theme_26_def,addl_theme_26_eval_methods,addl_theme_26_meas_consid,addl_theme_26_eval_criteria,addl_theme_27_def,addl_theme_27_eval_methods,addl_theme_27_meas_consid,addl_theme_27_eval_criteria,addl_theme_28_def,addl_theme_28_eval_methods,addl_theme_28_meas_consid,addl_theme_28_eval_criteria,addl_theme_29_def,addl_theme_29_eval_methods,addl_theme_29_meas_consid,addl_theme_29_eval_criteria,addl_theme_30_def,addl_theme_30_eval_methods,addl_theme_30_meas_consid,addl_theme_30_eval_criteria,addl_theme_31_def,addl_theme_31_eval_methods,addl_theme_31_meas_consid,addl_theme_31_eval_criteria,addl_theme_32_def,addl_theme_32_eval_methods,addl_theme_32_meas_consid,addl_theme_32_eval_criteria,addl_theme_33_def,addl_theme_33_eval_methods,addl_theme_33_meas_consid,addl_theme_33_eval_criteria,addl_theme_34_def,addl_theme_34_eval_methods,addl_theme_34_meas_consid,addl_theme_34_eval_criteria,addl_theme_35_def,addl_theme_35_eval_methods,addl_theme_35_meas_consid,addl_theme_35_eval_criteria,addl_theme_36_def,addl_theme_36_eval_methods,addl_theme_36_meas_consid,addl_theme_36_eval_criteria,addl_theme_37_def,addl_theme_37_eval_methods,addl_theme_37_meas_consid,addl_theme_37_eval_criteria,addl_theme_38_def,addl_theme_38_eval_methods,addl_theme_38_meas_consid,addl_theme_38_eval_criteria,addl_theme_39_def,addl_theme_39_eval_methods,addl_theme_39_meas_consid,addl_theme_39_eval_criteria,addl_theme_40_def,addl_theme_40_eval_methods,addl_theme_40_meas_consid,addl_theme_40_eval_criteria,eval_methodology_strengths_limitations,wbs_gaps_opportunities,pandemic_eval_consid,relevant_sources_for_review,extraction_addl_comments,N/A
Zotero Citation Key,Covidence #,Study ID,Title,1. What is the title of the identified source?,2. What year was the work published?,3. What is the name of the corresponding author? If the corresponding author is not specified use first author's details.,4. What is the email address of the corresponding author? If the corresponding author is not specified use first author's details.,5. What country is listed in the primary affiliation of the corresponding author?,6. What is the objective of the article? Please provide a short description of what the article is about,"7. What type of work is described? Assess this based on your evaluation of study design, not based on what the labelling of the article states.",8. What type of surveillance system is discussed?,9. In what country is the described surveillance system located?,"10. What framework or guidance document, if any, was used to evaluate surveillance systems(s)?","11. If you selected ""other"", please provide the source title along with the organization or first author and year of publication below. If this does not apply, please write ""N/A"".",12.1 Framework Section,12.1  Definition or Description,12. Evaluation Methodology,12.1 Measurement Considerations,12.1 Additional Notes,12.2 Framework Section,12.3 Definition or Description,12.2 Evaluation Methodology,12.2 Measurement Considerations,12.2 Additional Notes,12.3 Framework Section,12.3 Definition or Description2,12.3 Evaluation Methodology,12.3 Measurement Considerations,12.3 Additional Notes,12.4 Framework Section,12.4 Definition or Description,12.4 Evaluation Methodology,12.4 Measurement Considerations,12.4 Additional Notes,12.5 Framework Section,12.5 Definition or Description,12.5 Evaluation Methodology,12.5 Measurement Considerations,12.5 Additional Notes,12.6 Framework Section,12.6 Definition or Description,12.6 Evaluation Methodology,12.6 Measurement Considerations,12.6 Additional Notes,12.7 Framework Section,12.7 Definition or Description,12.7 Evaluation Methodology,12.7 Measurement Considerations,12.7 Additional Notes,12.8 Framework Section,12.8 Definition or Description,12.8 Evaluation Methodology,12.8 Measurement Considerations,12.8 Additional Notes,12.9 Framework Section,12.9 Definition or Description,12.9 Evaluation Methodology,12.9 Measurement Considerations,12.9 Additional Notes,13. Public Health Objective 1,13. Public Health Objective 2,13. Public Health Objective 3,13. Public Health Objective 4,13. Public Health Objective 5,13. Public Health Objective 6,13. Public Health Objective 7,13. Public Health Objective 8,13. Public Health Objective 9,13. Public Health Objective 10,13. Wastewater Objective 1,13. Wastewater Objective 2,13. Wastewater Objective 3,13. One Health Objective 1,13. One Health Objective 2,13. One Health Objective 3,13. One Health Objective 4,13. Other Objective 1,13. Other Objective 2,13. Other Objective 3,13. Other Objective 4,13. Other Objective 5,13. Other Objective 6,"14. Please list any additional notes related to the objectives of the identified surveillance system. If none, please write ""N/A"".","15.	What stakeholders were involved in the evaluation of the surveillance system or are recommended to be involved in the evaluation of a surveillance system (e.g., industry, researchers, societies, etc.)? :",Stakeholder 1 Involved in the evaluation of the surveillance system,15. Stakeholder 1 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 1 Involved in the development of the evaluation tool,15. Stakeholder 1 Notes,15. 15. Stakeholder 2 Involved in the evaluation of the surveillance system,15. 15. Stakeholder 2 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 2 Involved in the development of the evaluation tool,15. Stakeholder 2 Notes,15. Stakeholder 3 Involved in the evaluation of the surveillance system,15. Stakeholder 3 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 3 Involved in the development of the evaluation tool,15. Stakeholder 3 Notes,15. Stakeholder 4 Involved in the evaluation of the surveillance system,15. Stakeholder 4 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 4 Involved in the development of the evaluation tool,15. Stakeholder 4 Notes,15. Stakeholder 5 Involved in the evaluation of the surveillance system,15. Stakeholder 5 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 5 Involved in the development of the evaluation tool,15. Stakeholder 5 Notes,15. Stakeholder 6 Involved in the evaluation of the surveillance system,15. Stakeholder 6 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 6 Involved in the development of the evaluation tool,15. Stakeholder 6 Notes,15. Stakeholder 7 Involved in the evaluation of the surveillance system,15. Stakeholder 7 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 7 Involved in the development of the evaluation tool,15. Stakeholder 7 Notes,15. Stakeholder 8 Involved in the evaluation of the surveillance system,15. Stakeholder 8 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 8 Involved in the development of the evaluation tool,15. Stakeholder 8 Notes,15. Stakeholder 9 Involved in the evaluation of the surveillance system,15. Stakeholder 9 Recommended to be involved in the evaluation of the surveillance system,15. Stakeholder 9 Involved in the development of the evaluation tool,15. Stakeholder 9 Notes,"16. Were any methods mentioned for the measurement of use of surveillance data by stakeholders? If not, please write ""none provided"".",17. Domain 1 Name,17. Domain 1 Definition or Description,17. Domain 1 Notes,17. Domain 2 Name,17. Domain 2 Definition or Description,17. Domain 2 Notes,17. Domain 3 Name,17. Domain 3 Definition or Description,17. Domain 3 Notes,17. Domain 4 Name,17. Domain 4 Definition or Description,17. Domain 4 Notes,17. Domain 5 Name,17. Domain 5 Definition or Description,17. Domain 5 Notes,17. Domain 6 Name,17. Domain 6 Definition or Description,17. Domain 6 Notes,17. Domain 7 Name,17. Domain 7 Definition or Description,17. Domain 7 Notes,17. Domain 8 Name,17. Domain 8 Definition or Description,17. Domain 8 Notes,18. Acceptability Definition,18. Acceptability Evaluation Methods,18. Acceptability Measurement Considerations,18. Acceptability Evaluation Criteria,18. Availability (Stability) Definition,18. Availability (Stability) Evaluation Methods,18. Availability (Stability) Measurement Considerations,18. Availability (Stability) Evaluation Criteria,18. Coherence Definition,18. Coherence Evaluation Methods,18. Coherence Measurement Considerations,18. Coherence Evaluation Criteria,18. Completeness Definition,18. Completeness Evaluation Methods,18. Completeness Measurement Considerations,18. Completeness Evaluation Criteria,18. Compliance Definition,18. Compliance Evaluation Methods,18. Compliance Measurement Considerations,18. Compliance Evaluation Criteria,18. Consistency over time Definition,18. Consistency over time Evaluation Methods,18. Consistency over time Measurement Considerations,18. Consistency over time Evaluation Criteria,18. Cost-Effectiveness Ratio Definition,18. Cost-Effectiveness Ratio Evaluation Methods,18. Cost-Effectiveness Ratio Measurement Considerations,18. Cost-Effectiveness Ratio Evaluation Criteria,18. Cost-Effectiveness Definition,18. Cost-Effectiveness Evaluation Methods,18. Cost-Effectiveness Measurement Considerations,18. Cost-Effectiveness Evaluation Criteria,18. Cost Definition,18. Cost Evaluation Methods,18. Cost Measurement Considerations,18. Cost Evaluation Criteria,18. Data Quality Definition,18. Data Quality Evaluation Methods,18. Data Quality Measurement Considerations,18. Data Quality Evaluation Criteria,18. Effectiveness Definition,18. Effectiveness Evaluation Methods,18. Effectiveness Measurement Considerations,18. Effectiveness Evaluation Criteria,18. Efficacy Definition,18. Efficacy Evaluation Methods,18. Efficacy Measurement Considerations,18. Efficacy Evaluation Criteria,18. Efficiency Definition,18. Efficiency Evaluation Methods,18. Efficiency Measurement considerations,18. Efficiency Evaluation Criteria,18. Feasibility Definition,18. Feasibility Evaluation Methods,18. Feasibility Measurement Considerations,18. Feasibility Evaluation Criteria,18. Flexibility Definition,18. Flexibility Evaluation Methods,18. Flexibility Measurement Considerations,18. Flexibility Evaluation Criteria,18. Integration Definition,18. Integration Evaluation Methods,18. Integration Measurement Considerations,18. Integration Evaluation Criteria,18. Interoperability Definition,18. Interoperability Evaluation Methods,18. Interoperability Measurement Considerations,18. Interoperability Evaluation Criteria,18. Likelihood Ration of a Positive Test Definition,18. Likelihood Ration of a Positive Test Evaluation Methods,18. Likelihood Ration of a Positive Test Measurement Considerations,18. Likelihood Ration of a Positive Test Evaluation Criteria,18. Negative predictive value (NPV) Definition,18. Negative predictive value (NPV) Evaluation Methods,18. Negative predictive value (NPV) Measurement Considerations,18. Negative predictive value (NPV) Evaluation Criteria,18. Portability Definition,18. Portability Evaluation Methods,18. Portability Measurement Considerations,18. Portability Evaluation Criteria,18. Predictive Value Positive (PVP) Definition,18. Predictive Value Positive (PVP) Evaluation Methods,18. Predictive Value Positive (PVP) Measurement Considerations,18. Predictive Value Positive (PVP) Evaluation Criteria,18. Reliability (Stability) Definition,18. Reliability (Stability) Evaluation Methods,18. Reliability (Stability) Measurement Considerations,18. Reliability (Stability) Evaluation Criteria,18. Representativeness Definition,18. Representativeness Evaluation Methods,18. Representativeness Measurement Considerations,18. Representativeness Evaluation Criteria,18. Security Definition,18. Security Evaluation Methods,18. Security Measurement Considerations,18. Security Evaluation Criteria,18. Sensitivity Definition,18. Sensitivity Evaluation Methods,18. Sensitivity Measurement Considerations,18. Sensitivity Evaluation Criteria,18. Simplicity Definition,18. Simplicity Evaluation Methods,18. Simplicity Measurement Considerations,18. Simplicity Evaluation Criteria,18. Specificity Definition,18. Specificity Evaluation Methods,18. Specificity Measurement Considerations,18. Specificity Evaluation Criteria,18. Stability Definition,18. Stability Evaluation Methods,18. Stability Measurement Considerations,18. Stability Evaluation Criteria,18. Standards Use Definition,18. Standards Use Evaluation Methods,18. Standards Use Measurement Considerations,18. Standards Use Evaluation Criteria,18. Timeliness Definition,18. Timeliness Evaluation Methods,18. Timeliness Measurement Considerations,18. Timeliness Evaluation Criteria,18. Usefulness Definition,18. Usefulness Evaluation Methods,18. Usefulness Measurement Considerations,18. Usefulness Evaluation Criteria,18. Validity (Data Quality) Definition,18. Validity (Data Quality) Evaluation Methods,18. Validity (Data Quality) Measurement Considerations,18. Validity (Data Quality) Evaluation Criteria,18. Additional Theme 1 Definition,18. Additional Theme 1 Evaluation Methods,18. Additional Theme 1 Measurement Considerations,18. Additional Theme 1 Evaluation Criteria,18. Additional Theme 2 Definition,18. Additional Theme 2 Evaluation Methods,18. Additional Theme 2 Measurement Considerations,18. Additional Theme 2 Evaluation Criteria,18. Additional Theme 3 Definition,18. Additional Theme 3 Evaluation Methods,18. Additional Theme 3 Measurement Considerations,18. Additional Theme 3 Evaluation Criteria,18. Additional Theme 4 Definition,18. Additional Theme 4 Evaluation Methods,18. Additional Theme 4 Measurement Considerations,18. Additional Theme 4 Evaluation Criteria,18. Additional Theme 5 Definition,18. Additional Theme 5 Evaluation Methods,18. Additional Theme 5 Measurement Considerations,18. Additional Theme 5 Evaluation Criteria,18. Additional Theme 6 Definition,18. Additional Theme 6 Evaluation Methods,18. Additional Theme 6 Measurement Considerations,18. Additional Theme 6 Evaluation Criteria,18. Additional Theme 7 Definition,18. Additional Theme 7 Evaluation Methods,18. Additional Theme 7 Measurement Considerations,18. Additional Theme 7 Evaluation Criteria,18. Additional Theme 8 Definition,18. Additional Theme 8 Evaluation Methods,18. Additional Theme 8 Measurement Considerations,18. Additional Theme 8 Evaluation Criteria,18. Additional Theme 9 Definition,18. Additional Theme 9 Evaluation Methods,18. Additional Theme 9 Measurement Considerations,18. Additional Theme 9 Evaluation Criteria,18. Additional Theme 10 Definition,18. Additional Theme 10 Evaluation Methods,18. Additional Theme 10 Measurement Considerations,18. Additional Theme 10 Evaluation Criteria,18. Additional Theme 11 Definition,18. Additional Theme 11 Evaluation Methods,18. Additional Theme 11 Measurement Considerations,18. Additional Theme 11 Evaluation Criteria,18. Additional Theme 12 Definition,18. Additional Theme 12 Evaluation Methods,18. Additional Theme 12 Measurement Considerations,18. Additional Theme 12 Evaluation Criteria,18. Additional Theme 13 Definition,18. Additional Theme 13 Evaluation Methods,18. Additional Theme 13 Measurement Considerations,18. Additional Theme 13 Evaluation Criteria,18. Additional Theme 14 Definition,18. Additional Theme 14 Evaluation Methods,18. Additional Theme 14 Measurement Considerations,18. Additional Theme 14 Evaluation Criteria,18. Additional Theme 15 Definition,18. Additional Theme 15 Evaluation Methods,18. Additional Theme 15 Measurement Considerations,18. Additional Theme 15 Evaluation Criteria,18. Additional Theme 16 Definition,18. Additional Theme 16 Evaluation Methods,18. Additional Theme 16 Measurement Considerations,18. Additional Theme 16 Evaluation Criteria,18. Additional Theme 17 Definition,18. Additional Theme 17 Evaluation Methods,18. Additional Theme 17 Measurement Considerations,18. Additional Theme 17 Evaluation Criteria,18. Additional Theme 18 Definition,18. Additional Theme 18 Evaluation Methods,18. Additional Theme 18 Measurement Considerations,18. Additional Theme 18 Evaluation Criteria,18. Additional Theme 19 Definition,18. Additional Theme 19 Evaluation Methods,18. Additional Theme 19 Measurement Considerations,18. Additional Theme 19 Evaluation Criteria,18. Additional Theme 20 Definition,18. Additional Theme 20 Evaluation Methods,18. Additional Theme 20 Measurement Considerations,18. Additional Theme 20 Evaluation Criteria,18. Additional Theme 21 Definition,18. Additional Theme 21 Evaluation Methods,18. Additional Theme 21 Measurement Considerations,18. Additional Theme 21 Evaluation Criteria,18. Additional Theme 22 Definition,18. Additional Theme 22 Evaluation Methods,18. Additional Theme 22 Measurement Considerations,18. Additional Theme 22 Evaluation Criteria,18. Additional Theme 23 Definition,18. Additional Theme 23 Evaluation Methods,18. Additional Theme 23 Measurement Considerations,18. Additional Theme 23 Evaluation Criteria,18. Additional Theme 24 Definition,18. Additional Theme 24 Evaluation Methods,18. Additional Theme 24 Measurement Considerations,18. Additional Theme 24 Evaluation Criteria,18. Additional Theme 25 Definition,18. Additional Theme 25 Evaluation Methods,18. Additional Theme 25 Measurement Considerations,18. Additional Theme 25 Evaluation Criteria,18. Additional Theme 26 Definition,18. Additional Theme 26 Evaluation Methods,18. Additional Theme 26 Measurement Considerations,18. Additional Theme 26 Evaluation Criteria,18. Additional Theme 27 Definition,18. Additional Theme 27 Evaluation Methods,18. Additional Theme 27 Measurement Considerations,18. Additional Theme 27 Evaluation Criteria,18. Additional Theme 28 Definition,18. Additional Theme 28 Evaluation Methods,18. Additional Theme 28 Measurement Considerations,18. Additional Theme 28 Evaluation Criteria,18. Additional Theme 29 Definition,18. Additional Theme 29 Evaluation Methods,18. Additional Theme 29 Measurement Considerations,18. Additional Theme 29 Evaluation Criteria,18. Additional Theme 30 Definition,18. Additional Theme 30 Evaluation Methods,18. Additional Theme 30 Measurement Considerations,18. Additional Theme 30 Evaluation Criteria,18. Additional Theme 31 Definition,18. Additional Theme 31 Evaluation Methods,18. Additional Theme 31 Measurement Considerations,18. Additional Theme 31 Evaluation Criteria,18. Additional Theme 32 Definition,18. Additional Theme 32 Evaluation Methods,18. Additional Theme 32 Measurement Considerations,18. Additional Theme 32 Evaluation Criteria,18. Additional Theme 33 Definition,18. Additional Theme 33 Evaluation Methods,18. Additional Theme 33 Measurement Considerations,18. Additional Theme 33 Evaluation Criteria,18. Additional Theme 34 Definition,18. Additional Theme 34 Evaluation Methods,18. Additional Theme 34 Measurement Considerations,18. Additional Theme 34 Evaluation Criteria,18. Additional Theme 35 Definition,18. Additional Theme 35 Evaluation Methods,18. Additional Theme 35 Measurement Considerations,18. Additional Theme 35 Evaluation Criteria,18. Additional Theme 36 Definition,18. Additional Theme 36 Evaluation Methods,18. Additional Theme 36 Measurement Considerations,18. Additional Theme 36 Evaluation Criteria,18. Additional Theme 37 Definition,18. Additional Theme 37 Evaluation Methods,18. Additional Theme 37 Measurement Considerations,18. Additional Theme 37 Evaluation Criteria,18. Additional Theme 38 Definition,18. Additional Theme 38 Evaluation Methods,18. Additional Theme 38 Measurement Considerations,18. Additional Theme 38 Evaluation Criteria,18. Additional Theme 39 Definition,18. Additional Theme 39 Evaluation Methods,18. Additional Theme 39 Measurement Considerations,18. Additional Theme 39 Evaluation Criteria,18. Additional Theme 40 Definition,18. Additional Theme 40 Evaluation Methods,18. Additional Theme 40 Measurement Considerations,18. Additional Theme 40 Evaluation Criteria,"19.	Were any strengths and/or limitations of evaluation methodologies provided? If so, please list them below.",20. Were any gaps and/or opportunities identified for performing wastewater-based surveillance as a public health tool?,21. Were any pandemic-specific considerations mentioned for the evaluation of surveillance systems?,22. Please provide any relevant sources from the source article that should be identified for the scoping review.,"23.	Please note any additional comments below. If none, please write ""N/A"".",
GuidelinesEvaluatingSurveillance1988,13368,Klaucke 1988,Guidelines for evaluating surveillance systems.,Guidelines for Evaluating Surveillance Systems,1988,Douglas N. Klaucke,unknown,not reported,Guidelines for evaluating epidemiologic surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,"A. Describe the public health importance of the health event. The following are the three most important categories to consider: 1. Total number of cases, incidence, and prevalence; 2. Indices of severity such as the mortality rate and the case-fatality ratio; 3. Preventability","The public health importance of a health event and the need to have that health event under surveillance can be described in several ways. Health events that affect many people or require large expenditures of resources clearly have public health importance. However, health events that affect relatively few persons may also be important, especially if the events cluster in time and place--e.g., a limited outbreak of a severe disease. At other times, public concerns may focus attention on a particular health event, creating or heightening the sense of importance. Diseases that are now rare because of successful control measures may be perceived as ""unimportant,"" but their level of importance should be assessed in light of their potential to re-emerge. Finally, the public health importance of a health event is influenced by its preventability.","Describe the public health importance of the health event.
Parameters for measuring the importance of a health event--and, therefore, the surveillance system with which it is monitored--include:
1.Total number of cases, incidence, and prevalence
2. Indices of severity, e.g., the case-fatality ratio
3. Mortality rate
4. An index of lost productivity, e.g., bed-disability days
5. An index of premature mortality, e.g., years of potential life lost (YPLL)
6. Medical costs
7. Preventability","These measures of importance do not take into account the effect of existing control measures. For example, the number of cases of vaccine-preventable illness has declined following the implementation of school immunization laws, and the public health importance of these diseases would be underestimated by case counts alone. In such instances, it may be possible to estimate the number of cases that would be expected in the absence of control programs (1). Preventability can be defined at several levels--from preventing the occurrence of disease (primary prevention); through early detection and intervention with the aim of reversing, halting, or at least retarding the progress of a condition (secondary prevention); to minimizing the effects of disease and disability among those already ill (tertiary prevention). From the perspective of surveillance, preventability reflects the potential for effective public health intervention at any of these levels. Attempts have been made to quantify the public health importance of various diseases and health conditions. Dean et al. describe such an approach using a score that takes into account age-specific mortality and morbidity rates as well as healthcare costs (2).",N/A,"B. Describe the system to be evaluated.
1. List the objectives of the system.
2. Describe the health event(s) under surveillance. State the case definition for each health event.
3. Draw a flow chart of the system.
4. Describe the components and operation of the system.
a. What is the population under surveillance?
b. What is the period of time of the data collection?
c. What information is collected?
d. Who provides the surveillance information?
e. How is the information transferred?
f. How is the information stored?
g. Who analyzes the data?
h. How are the data analyzed and how often?
i. How often are reports disseminated? 
j. To whom are reports distributed? 
k. How are the reports distributed?",Not provided,"Objectives may include detecting or monitoring outbreaks, monitoring trends, identifying contacts and administering prophylaxis, enrolling case-patients in a study, and generating hypotheses about etiology.
The objectives of the system define a framework for evaluating the specific components.
The next task is to describe the components of a surveillance system. This can be done by answering the following questions:
a. What is the population under surveillance?
b. What is the period of time of the data collection?
c. What information is collected?
d. Who provides the surveillance information? What is the data source?
e. How is the information transferred?
f. How is the information stored?
g. Who analyzes the data?
h. How are the data analyzed, and how often?
i. Are there preliminary and final tabulations, analyses, and reports? 
j. How often are reports disseminated? 
k. To whom are reports distributed? 
l. How are the reports distributed?

It is often useful to list the discrete steps in the processing of the health-event reports by the system, and then to depict these steps in a flow chart (Figure 1)",N/A,N/A,C. Indicate the level of usefulness by describing actions taken as a result of the data from the surveillance system. Characterize the entities that have used the data to make decisions and take actions. List other anticipated uses of the data.,"A surveillance system is useful if it contributes to the prevention and control of adverse health events, including an improved understanding of the public health implications of such events. A surveillance system can also be useful if it helps to determine that an adverse health event previously thought to be unimportant is actually important.","1. Describe the actions that have been taken as a result of the data from the surveillance system.
2. Describe who has used the data to make decisions and take actions.
3. List other anticipated uses of the data

An assessment of the usefulness of a surveillance system should begin with a review of the objectives of the system and should consider the dependence of policy decisions and control measures on surveillance. Depending on the objectives of a particular surveillance system, the system may be considered useful if it satisfactorily addresses at least one of the following questions. Does the system:
a. Detect trends signaling changes in the occurrence of disease?
b. Detect epidemics?
c. Provide estimates of the magnitude of morbidity and mortality related to the health problem under surveillance?
d. Stimulate epidemiologic research likely to lead to control or prevention?
e. Identify risk factors associated with disease occurrence?
f. Permit assessment of the effects of control measures?
g. Lead to improved clinical practice by the health-care providers who are the constituents of the surveillance system?

","Usefulness may be affected by all the attributes of surveillance. Increased sensitivity may afford a greater opportunity for identifying epidemics and understanding the natural course of an adverse health event in a community. Improved timeliness allows control and prevention activities to be initiated earlier. Increased predictive value positive enables public health officials to focus on productive activities. A representative surveillance system will better characterize the epidemiologic characteristics of a health event in a defined population. Systems that are simple, flexible, and acceptable also tend to be more useful",N/A,"D. Evaluate the system for each of the following attributes:
1. Simplicity
2. Flexibility
3. Acceptability
4. Sensitivity
5. Predictive value positive
6. Representativeness
7. Timeliness",Provided in table for question 20.,Provided in table for question 20.,Provided in table for question 20.,N/A,E. Describe the resources used to operate the system (direct costs).,"This document covers only the resources directly required to operate a surveillance system. These are sometimes referred to as Pdirect costsP' and include the personnel and financial resources expended in collecting, processing, analyzing, and disseminating the surveillance data","Describe the resources that are used to operate the system (direct costs).

In estimating these resources consider the following:
a. Personnel requirements A first step is to estimate the time it takes to operate the system (e.g., person-time expended per year of operation). If desired, these measures can be converted to dollar estimates by multiplying the person-time by appropriate salary and benefit figures.
b. Other resources These may include the cost of travel, training, supplies, equipment, and services (e.g., mail, telephone, and computer time). The application of these resources at all levels of the public health system--from the local health-care provider to municipal, county, state, and Federal health agencies--should be considered.
The costs of surveillance systems from two studies are illustrated in Tables 2 and 3 below (7,13).","This approach to assessment of resources includes only those personnel and material resources required for the operation of surveillance and excludes a broader definition of costs that might be considered in a more comprehensive evaluation. Estimating the overall costs of a surveillance system can be a complex process. The estimates may include the estimation of a) indirect costs, such as follow-up laboratory tests or treatment incurred as a result of surveillance; b) costs of secondary data sources (e.g., vital statistics or survey data); and c) costs averted (benefits) by surveillance.

Costs are often judged relative to benefits, but few evaluations of surveillance systems are likely to include a formal cost-benefit analysis, and such analyses are beyond the scope of this document. Estimating benefits (e.g., savings resulting from preventing morbidity through surveillance data) may be possible in some instances, although this approach does not take into account the full spectrum of benefits that may result from surveillance systems. More realistically, costs should be judged with respect to the objectives and usefulness of a surveillance system. 

Examples of resource estimation for surveillance systems operated in Vermont and Kentucky follow.
Vermont example (7)
Two methods of collecting surveillance data in Vermont have been compared. The PpassiveP' system was already in place and consisted of unsolicited reports of notifiable diseases to the district offices or state health department. The PactiveP' system was implemented in a probability sample of physician practices. Each week, a health department employee called these practitioners to solicit reports of selected notifiable diseases. In comparing the two systems an attempt was made to estimate their costs. The estimates of resources
directly applied to the surveillance systems are shown in Table 2. 

Kentucky example (13)
Another example is provided by an assessment of the costs of a surveillance system involving the active solicitation of case reports of type A hepatitis in Kentucky. Table 3 summarizes the costs of this system. The resources that went into the direct operation of the system were for personnel and telephone and were estimated as $3,764 and $535, respectively. This system found nine more cases than would have been found through the passive surveillance system, and an estimated seven hepatitis cases were prevented through prophylaxis of the contacts of the nine case-patients",N/A,"F. List your conclusions and recommendations. State whether the system is meeting its objectives, and address the need to continue and/or modify the surveillance system",List your conclusions and recommendations. These should state whether the system is addressing an important public health problem and is meeting its objectives. Recommendations should address the continuation and/or modification of the surveillance system.,N/A,"The attributes and costs of a surveillance system are interdependent. Before recommending changes in a system, interactions among the attributes and costs should be considered to ensure that benefits resulting from strengthening one attribute do not adversely affect another attribute.

Efforts to increase sensitivity, PVP, timeliness, and representativeness tend to increase the cost of a surveillance system, although savings in efficiency with automation may offset some of these costs (12).

As sensitivity and PVP approach 100%, a surveillance system is more likely to be representative of the population being monitored. However, as sensitivity increases, PVP may decrease. Efforts to increase sensitivity and PVP tend to make a surveillance system more complex--potentially decreasing its acceptability, timeliness, and flexibility. For example, a study comparing health-department-initiated (active) surveillance and provider-initiated (passive) surveillance did not improve timeliness, despite increased sensitivity (8)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"This may be partially addressed by the ""Acceptability"" theme list in the table for question 20.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Acceptability reflects the willingness of individuals and organizations to participate in the surveillance system.,"In terms of evaluating a surveillance system, acceptability refers to the willingness to use the system by: a) persons outside the sponsoring agency, e.g., those who are asked to do something for the system and b) persons in the sponsoring agency that operates the system. To assess acceptability, one must consider the points of interaction between the system and its participants (Figure 1), including persons with the condition and those reporting cases.

Quantitative indicators of acceptability include:
a. Subject or agency participation rates
b. If participation is high, how quickly it was achieved
c. Interview completion rates and question refusal rates (if the system involves interviews with subjects)
d. Completeness of report forms
e. Physician, laboratory, or hospital/facility reporting rates
f. Timeliness of reporting Some of these measures may be obtained from a review of surveillance report forms, while others would require special studies or surveys.","Acceptability is a largely subjective attribute that encompasses the willingness of persons on whom the system depends to provide accurate, consistent, complete, and timely data. Some factors influencing the acceptability of a particular system are:
a. The public health importance of the health event
b. Recognition by the system of the individual's contribution
c. Responsiveness of the system to suggestions or comments
d. Time burden relative to available time
e. Federal and state legislative restrictions on data collection and assurance of confidentiality
f. Federal and state legislative requirements for reporting",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Efforts to increase sensitivity, PVP, timeliness, and representativeness tend to increase the cost of a surveillance system, although savings in efficiency with automation may offset some of these costs (12).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"A flexible surveillance system can adapt to changing information needs or operating conditions with little additional cost in time, personnel, or allocated funds. Flexible systems can accommodate, for example, new diseases and health conditions, changes in case definitions, and variations in reporting sources.","Flexibility is probably best judged retrospectively, by observing how a system responded to a new demand. For example, when acquired immunodeficiency syndrome (AIDS) emerged in 1981, the existing notifiable disease reporting system of state health departments was used to report cases, and AIDSsurveillance has adapted to rapidly advancing knowledge about the disease, its diagnosis, and its risk factors. Another example is the capacity of the gonorrhea surveillance system to accommodate special surveillance for penicillinase-producing Neisseria gonorrhoeae.","Unless efforts have been made to adapt a system to another disease, it may be difficult to assess the flexibility of that system. In the absence of practical experience, one can look at the design and workings of a system. Generally, simpler systems will be more flexible--fewer components will need to be modified when adapting the system for use with another disease",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Predictive value positive (PVP) is the proportion of persons identified as having cases who actually do have the condition under surveillance (5). In Table 1 this is represented by A/(A+B).,"In assessing PVP, primary emphasis is placed on the confirmation of cases reported through the surveillance system. Its effect on the use of public health resources can be considered on two levels. At the level of an individual case, PVP affects the amount of resources used for case investigations. For example, in some states every reported case of type A hepatitis is promptly investigated by a public health nurse, and family members at risk are referred for prophylactic treatment with immune globulin. A surveillance system with low PVP--and therefore frequent ""false-positive"" case reports--would lead to wasted resources.

The other level is that of detection of epidemics. A high rate of erroneous case reports may trigger an inappropriate outbreak investigation. Therefore, the proportion of epidemics identified by the surveillance system that are true epidemics is needed to assess this attribute.

Calculating the PVP may require that records be kept of all interventions initiated because of information obtained from the surveillance system. A record of the number of case investigations done and the proportion of persons who actually had the condition under surveillance would allow the calculation of the PVP at the level of case detection. Personnel activity reports, travel records, and telephone logbooks may all be useful in estimating the PVP at the epidemic detection level.","PVP is important because a low value means that a) non-cases are being investigated and b) epidemics may be mistakenly identified. PFalse-positiveP' reports may lead to unnecessary intervention, and falsely detected PepidemicsP' may lead to costly investigations and undue concern in the community. A surveillance system with high PVP will lead to fewer wild-goose chases and wasted resources.

An example of a surveillance evaluation that examined PVP was reported by Barker et al. They reviewed hospital charts to determine the proportion of persons admitted with a diagnosis of stroke who had the diagnosis confirmed (6). Of 1,604 patients admitted to seven acute-care hospitals with a stroke-related
diagnosis, 903 (PVP = 56%) were subsequently confirmed to have had strokes.

The PVP for a health event is closely related to the clarity and specificity of the case definition. Good communication between the persons who report cases and the receiving agency also can improve PVP.

The PVP reflects the sensitivity and specificity of the case definition and the prevalence of the condition in the population (Table 1). The PVP increases with increasing specificity and prevalence.",N/A,N/A,N/A,N/A,N/A,A surveillance system that is representative accurately describes a) the occurrence of a health event over time and b) its distribution in the population by place and person.,"Representativeness is assessed by comparing the characteristics of reported events to all such actual events. Although the latter information is generally not known, some judgment of the representativeness of surveillance data is possible, based on knowledge of:
a. Characteristics of the population--e.g., age, socioeconomic status, geographic location (5);
b. Natural history of the condition--e.g., latency period, mode of transmission, fatal outcome;
c. Prevailing medical practices--e.g., sites performing diagnostic tests, physician-referral patterns (7,8);
d. Multiple sources of data--e.g., mortality rates for comparison with incidence data, laboratory reports for comparison with physician reports. Representativeness can be examined through special studies that seek to identify a probability sample of all cases.

Quality of data is an important part of representativeness. Much of the discussion in this document focuses on the identification and classification of cases. However, most surveillance systems rely on more than simple case counts. Information commonly collected includes the demographic characteristics of affected persons, details about the health event, and notification of the presence or absence of potential risk factors.
The quality and usefulness and representativeness of this information depends on its completeness and validity.

Quality of data is influenced by the clarity of surveillance forms, the quality of training and supervision of persons who complete surveillance forms, and the care exercised in data management. A review of these facets of a surveillance system provides an indirect measure of quality of data. Examining the percentage of unknown or blank responses to items on surveillance forms or questionnaires is straightforward.Assessing the reliability and validity of responses would require such special studies as chart reviews or re-interviews of respondents.","In order to generalize findings from surveillance data to the population at large, the data from a surveillance system should reflect the population characteristics that are important to the goals and objectives of that system. These characteristics generally relate to time, place, and person. An important result of evaluating the representativeness of a surveillance system is the identification of population subgroups that may be systematically excluded from the reporting system. This process allows appropriate modification of data collection and more accurate projection of incidence of the health event in the target population.

For example, an evaluation of reporting of hepatitis in a county in Washington State suggested that cases of type B hepatitis were under-reported among homosexual males and that cases of type non A-non B hepatitis were under-reported among persons given blood transfusions. The importance of these risk factors as contributors to the occurrence of these diseases was apparently underestimated by the selective under-reporting of certain types of hepatitis cases (9).

Errors and bias can make their way into a surveillance system at any stage. Because surveillance data are used to identify high-risk groups, to target interventions, and to evaluate interventions, it is important to be aware of the strengths and limitations of the information in the system.

So far the discussion of attributes has been aimed at the information collected for cases, but in many surveillance systems morbidity and mortality rates are calculated. The denominators for these rate calculations are often obtained from a completely separate data system maintained by another agency, e.g., the Bureau of the Census. Thought should be given to the comparability of categories (e.g., race, age, residence) on which the numerators and denominators of rate calculations are based.",N/A,N/A,N/A,N/A,N/A,"The sensitivity of a surveillance system can be considered on two levels. First, at the level of case reporting, the proportion of cases of a disease or health condition detected by the surveillance system can be evaluated. In Table 1 this is represented by A/(A+C). Second, the system can be evaluated for its ability to detect epidemics (3).","The sensitivity of a surveillance system is affected by the likelihood that:
a. Persons with certain diseases or health conditions seek medical care;
b. The diseases or conditions will be diagnosed, reflecting the skill of care providers and the sensitivity of diagnostic tests; and
c. The case will be reported to the system, given the diagnosis. These three conditions can be extended by analogy to surveillance systems that do not fit the traditional disease care-provider model. For example, the sensitivity of a telephone-based surveillance system of morbidity or risk factors is affected by:
a. The number of people who have telephones, who are at home when the call is placed, and who agree to participate;
b. The ability of persons to understand the questions and correctly identify their status; and
c. The willingness of respondents to report their status. The extent to which these questions are explored depends on the system and on the resources available for the evaluation. The measurement of sensitivity in a surveillance system requires a) the validation of information collected by the system and b) the collection of information external to the system to determine the frequency of the condition in a community (4). From a practical standpoint, the primary emphasis in assessing sensitivity--assuming that most reported cases are correctly classified--is to estimate the proportion of the total number of cases in the community being detected by the system","A surveillance system that does not have high sensitivity can still be useful in monitoring trends, as long as the sensitivity remains reasonably constant. Questions concerning sensitivity in surveillance systems most commonly arise when changes in disease occurrence are noted. Changes in sensitivity can be precipitated by such events as heightened awareness of a disease, introduction of new diagnostic tests, and changes in the method of conducting surveillance. A search for such surveillance ""artifacts"" is often an initial step in outbreak investigations.

As sensitivity and PVP approach 100%, a surveillance system is more likely to be representative of the population being monitored. However, as sensitivity increases, PVP may decrease. Efforts to increase sensitivity and PVP tend to make a surveillance system more complex--potentially decreasing its acceptability, timeliness, and flexibility. For example, a study comparing health-department-initiated (active) surveillance and provider-initiated (passive) surveillance did not improve timeliness, despite increased sensitivity (8)",N/A,The simplicity of a surveillance system refers to both its structure and ease of operation. Surveillance systems should be as simple as possible while still meeting their objectives.,"A chart describing the flow of information and the lines of response in a surveillance system can help assess the simplicity or complexity of a surveillance system. A flow chart for a generic surveillance system is illustrated in Figure 1.

The following measures might be considered in evaluating the simplicity of a system:
a. Amount and type of information necessary to establish the diagnosis
b. Number and type of reporting sources
c. Method(s) of transmitting case information/data
d. Number of organizations involved in receiving case reports
e. Staff training requirements
f. Type and extent of data analysis
g. Number and type of users of compiled case information
h. Method of distributing reports or case information to these users
i. Time spent with the following tasks:
1. Maintaining the system
2. Collecting case information
3. Transmitting case information
4. Analyzing case information
5. Preparing and disseminating surveillance reports","It may be useful to think of the simplicity of a surveillance system from two perspectives: the design of the system and the size of the system. An example of a system that is simple in design is one whose case definition is easy to apply and in which the person identifying the case will also be the one analyzing and using the information. A more complex system might involve some of the following:
a. Special laboratory tests to confirm the case
b. Telephone contact or a home visit by a public health nurse to collect detailed information
c. Multiple levels of reporting (e.g., with the Notifiable Diseases Reporting System, case reports may start with the doctor who makes the diagnosis and pass through county and state health departments before going to the Centers for Disease Control) Simplicity is closely related to timeliness and will affect the amount of resources that are required to operate the system",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Timeliness reflects the speed or delay between steps in a surveillance system.,"The major steps in a surveillance system are shown in Figure 2. The time interval linking any two of the steps in this figure can be examined. The interval usually considered first is the amount of time between the onset of an adverse health event and the report of the event to the public health agency responsible for instituting control and prevention measures. Another aspect of timeliness is the time required for the identification of trends, outbreaks, or the effect of control measures. With acute diseases, the onset of symptoms is usually used. Sometimes the date of exposure is used. With chronic diseases, it may be more useful to look at elapsed time from diagnosis rather than to estimate an onset date.","The timeliness of a surveillance system should be evaluated in terms of availability of information for disease control--either for immediate control efforts or for long-term program planning.

For example, a study of a surveillance system for Shigella infections indicated that the typical case of shigellosis was brought to the attention of health officials 11 days after onset of symptoms--a period sufficient for the occurrence of secondary and tertiary transmission. This suggests that the level of timeliness was not satisfactory for effective disease control (10). In contrast, when there is a long period oflatency between exposure and appearance of disease, the rapid identification of cases of illness may not be as important as the rapid availability of exposure data to provide a basis for interrupting and preventing exposures that lead to disease. In another time frame, surveillance data are being used by public health agencies to track progress toward the 1990 Objectives for the Nation and to plan for the Year 2000 Objectives.

The need for rapidity of response in a surveillance system depends on the nature of the public health problem under surveillance and the objectives of that system. Recently, computer technology has been integrated into surveillance systems and may promote timeliness (11,12)
",N/A,"A surveillance system is useful if it contributes to the prevention and control of adverse health events, including an improved understanding of the public health implications of such events. A surveillance system can also be useful if it helps to determine that an adverse health event previously thought to be unimportant is actually important.","An assessment of the usefulness of a surveillance system should begin with a review of the objectives of the system and should consider the dependence of policy decisions and control measures on surveillance.
Depending on the objectives of a particular surveillance system, the system may be considered useful if it satisfactorily addresses at least one of the following questions. Does the system:
Detect trends signaling changes in the occurrence of disease?
Detect epidemics?
Provide estimates of the magnitude of morbidity and mortality related to the health problem under surveillance?
Stimulate epidemiologic research likely to lead to control or prevention?
Identify risk factors associated with disease occurrence?
Permit assessment of the effects of control measures?
Lead to improved clinical practice by the health-care providers who are the constituents of the surveillance system?","Usefulness may be affected by all the attributes of surveillance. Increased sensitivity may afford a greater opportunity for identifying epidemics and understanding the natural course of an adverse health event in a community. Improved timeliness allows control and prevention activities to be initiated earlier. Increased predictive value positive enables public health officials to focus on productive activities. A representative surveillance system will better characterize the epidemiologic characteristics of a health event in a defined population. Systems that are simple, flexible, and acceptable also tend to be more useful.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,
aenishaenslinEvaluatingIntegrationOne2021,5801,Aenishaenslin 2021,Evaluating the integration of One Health in surveillance systems for antimicrobial use and resistance: a conceptual framework.,Evaluating the Integration of One Health in Surveillance Systems for Antimicrobial Use and Resistance: A Conceptual Framework,2021,Cécile Aenishaenslin,cecile.aenishaenslin@umontreal.ca,Canada,Development of an evaluation framework to assess the level of One Health integration in AMR/AMU surveillance systems (ISSE framework),"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,Canada,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Level 1: Integration of a OH Approach,"-Nature of Integration 
-Relevance to Objectives 
-Organization and Governance","-Describes what aspects are integrated into the Surveillance system
-Explores how OH Integration contributes to achieving Surveillance Objectives
-Examines how collaboration and Integration are organized among collaborators and organizations","What is integrated into the surveillance systems?
How is OH integration contributing to achieving the surveillance objective?
How is the integration between the collaborators organized and operationalized?","The ISSE framework was developed to be comprehensive, but evaluators can choose to focus on one or two evaluation levels depending on their needs, rather than on all five evaluation levels. For example, we suggest focusing on evaluation levels 1 and 2 in the first 3-5 years of implementation for new or recently integrated surveillance systems. More will be learned about the added value of the OH surveillance for AMU and AMR globally once multiple case studies are completed, as it will allow to explore the relationship between the higher level of OH integration (at Levels 1 and 2) and surveillance outcomes (at Levels 3 to 5).",Level 2: Production of OH Information and Expertise,"-OH Team Performance

-OH Network of Stakeholders
-Capacity to Produce OH Information","-Assesses the performance of the interdisciplinary OH team responsible for integrating information
-Evaluates the representation and contributions of stakeholders united by the surveillance system
-Examines the system's ability to generate up-to-date OH information on Antimicrobial Use (AMU) and Antimicrobial Resistance (AMR)",N/A,"The ISSE framework was developed to be comprehensive, but evaluators can choose to focus on one or two evaluation levels depending on their needs, rather than on all five evaluation levels. For example, we suggest focusing on evaluation levels 1 and 2 in the first 3-5 years of implementation for new or recently integrated surveillance systems. More will be learned about the added value of the OH surveillance for AMU and AMR globally once multiple case studies are completed, as it will allow to explore the relationship between the higher level of OH integration (at Levels 1 and 2) and surveillance outcomes (at Levels 3 to 5).",Level 3: Generation of Actionable Knowledge,"-detection and Explanation of Trends
-Knowledge Translation","-Assesses the system's capacity to detect and explain trends in AMR circulating between humans, animals, and the environment.
-Evaluates the system's ability to translate and transfer OH information to relevant stakeholders, making it actionable",N/A,"The ISSE framework was developed to be comprehensive, but evaluators can choose to focus on one or two evaluation levels depending on their needs, rather than on all five evaluation levels. For example, we suggest focusing on valuation levels 1 and 2 in the first 3-5 years of implementation for new or recently integrated surveillance systems. More will be learned about the added value of the OH surveillance for AMU and AMR globally once multiple case studies are completed, as it will allow to explore the relationship between the higher level of OH integration (at Levels 1 and 2) and surveillance outcomes (at Levels 3 to 5).",Level 4: Influence on Decision-Making,"-Contribution to Decisions

-End-User Surveys: 
","-Evaluates how Knowledge generated by the system is used for decision-making, interventions, policy changes, and individual behaviors.
-Quantifies ways in which Knowledge is used and Assesses the perceived influence of the Surveillance system on Decisions",N/A,"The ISSE framework was developed to be comprehensive, but evaluators can choose to focus on one or two evaluation levels depending on their needs, rather than on all five evaluation levels. For example, we suggest focusing on evaluation levels 1 and 2 in the first 3-5 years of implementation for new or recently integrated surveillance systems. More will be learned about the added value of the OH surveillance for AMU and AMR globally once multiple case studies are completed, as it will allow to explore the relationship between the higher level of OH integration (at Levels 1 and 2) and surveillance outcomes (at Levels 3 to 5).",Level 5: Contribution to Desirable Outcomes,"-Impacts of OH Integration

-Economic Efficiency","-Evaluates the Impacts of Decisions attributed to OH Integration, including reductions in AMU and AMR and their consequences on human, animal, and ecosystem health.
-Considers conducting a cost-benefit analysis to assess the Economic Efficiency of the OH mitigation system",Methods for evaluating the impacts of OH integration into surveillance systems will differ depending on the types of impacts that need to be evaluated.,"The ISSE framework was developed to be comprehensive, but evaluators can choose to focus on one or two evaluation levels depending on their needs, rather than on all five evaluation levels. For example, we suggest focusing on evaluation levels 1 and 2 in the first 3-5 years of implementation for new or recently integrated surveillance systems. More will be learned about the added value of the OH surveillance for AMU and AMR globally once multiple case studies are completed, as it will allow to explore the relationship between the higher level of OH integration (at Levels 1 and 2) and surveillance outcomes (at Levels 3 to 5).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,To evaluate the integration of OH in surveillance systems for AMR and AMU,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The evaluation of the surveillance system is structured into five levels, each focusing on different aspects of its integration, performance, and impact. Each level represents a progressive evaluation stage, from assessing integration to measuring real-world impacts, providing a comprehensive framework for evaluating the effectiveness and contributions of the OH-integrated surveillance system.",N/A,N/A,N/A,Team members from CIPARS,Employees of the PHAC with more than 75% of their task being part of the activities for CIPARS for more than 5 years. An email invitation to participate was sent to the team members of CIPARS who meet the inclusion criteria. Interested members were then invited to sign the consent form prior to participating in the FGD.,N/A,N/A,End-users of CIPARS,"The end-users of CIPARS were selected using the following criteria: Active end-users of the knowledge and/or data produced by CIPARS for more than 5 years. A list of 653 end-users compiled by the team of CIPARS was used to identify the end-users who could provide a diverse set of perspectives across different areas of expertise (human and animal health) and organizations in Canada (public, private, non-profit, provincial, and federal). An invitation letter and the information and consent form were sent through email to a subgroup of 17
potential participants selected by the CIPARS.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Survey questions: What are the challenges of using information from an integrated surveillance system for AMR?,Activities,Domains are from the logic model.,N/A,Outputs,Domains are from the logic model.,N/A,Immediate outcomes,Domains are from the logic model.,N/A,Intermediate outcomes,Domains are from the logic model.,N/A,Ultimate outcomes,Domains are from the logic model.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Integration of a OH Approach: not provided,"Description of the elements that are integrated in the surveillance system (Focus groups or individual interviews).

Evaluation of the relevance and rationale of the integration with regards to surveillance objectives (Focus groups or individual interviews).

Evaluation of the governance and multi-sectoral collaboration in the system (Focus groups or individual interviews, complementary tools). 

Overall evaluation of the level of integration (Semi-quantitative measurement scale, complementary tools).",N/A,"What is the nature of OH integration in the surveillance system?

How is the oH integration contributing to the surveillance objective?

How is organized and operationalized OH integration with collaborating organizations?

What is the level of OH integration in the surveillance design?",Production of OH Information and Expertise: not provided,"Evaluation of the performance of surveillance team in coherence with a OH approach (External or self-evaluation of the team).  
Evaluation of the performance of the network of stakeholders in coherence with a OH approach (Qualitative assessment; social network analysis).  
How well does the system produce OH information (Qualitative assessment; complementary tools).",N/A,"How effective i the OH surveillance team?; 
How effective is the OH network?; 
How well does the system produce OH information?;",Generation of Actionable Knowledge: not provided,"Evaluation of the capacity of the system to detect and explain trends and correlations between AMR trends in animal and humans (Qualitative assessment; complementary tools); 
Evaluation of the capacity of the system to transfer new knowledge to all relevant stakeholders (End-users survey).",N/A,"How does the system contribute to detect and explain trends and correlations in AMU and AMR circulating in human, animals and the environment?; How well does the system contribute to transfer new knowledge to stakeholder and increase their awareness?",Influence on Decision-Making: not provided,Evaluation of how the surveillance information is used by different stakeholders and of which decisions have been influenced by the system (End-users survey and individuals interviews with end-users).,N/A,How does OH knowledge produced by the system is used for decision-making?,Contribution to Desirable Outcomes: not provided,"Evaluation of the impacts of the decisions that the system has influence. Impacts on the levels of AMU and AMR in animals, humans and ecosystems, and associated impacts on animals and human health should be considered (Epidemiological modelling). Evaluation of the effectiveness or cost-benefits of the system (surveillance + resulting decisions) (Cost-benefit analysis or related economic evaluation methods).",N/A,"What are the health impacts of the system-related decisions on humans, animals and ecosystems?; 
What are the economic impacts of the system?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"ISSE framework was developed in partnership with CIPARS and may better reflect the evaluation needs of a mature, highly integrated surveillance system for AMU and AMR, than the evaluation needs of more recent, or less integrated surveillance systems.",N/A,N/A,"13. Aenishaenslin C, Hasler B, Ravel A, Parmley J, Stark K, Buckeridge D. Evidence needed for antimicrobial resistance surveillance systems. Bull World Health Organ. (2019) 97:283-9. doi: 10.2471/BLT.18.218917 
20. CoEval-AMR. Convergence in Evaluation Frameworks for Integrated Surveillance of Antimicrobial Resistance and Antimicrobial Use: The CoEval- AMR Network. (2020). Available online at: https://coevalamr.fp7-risksur.eu/ network (accessed June 25, 2020). 
21. Bordier M, Delavenne C, Nguyen DTT, Goutard FL, Hendrikx P. One health surveillance: a matrix to evaluate multisectoral collaboration. Front Vet Sci. (2019) 6:109. doi: 10.3389/fvets.2019.00109 
22. Ruegg SR, Nielsen LR, Buttigieg SC, Santa M, Aragrande M, Canali M, et al. A systems approach to evaluate one health initiatives. Front Vet Sci. (2018) 5:23. doi: 10.3389/fvets.2018.00023 
23. USAID. One Health OH-APP. (2020). Available online at: https://www. onehealthapp.org/about (accessed June 26, 2020). 
24. FAO. ATLASS: FAO Assessment Tool for Laboratories and AMR Surveillance Systems. (2020). Available online at: http://www.fao.org/antimicrobial-resistance/resources/tools/fao-atlass/en/ (accessed June 26, 2020). 
25. Hendrikx P, Gay E, Chazel M, Moutou F, Danan C, Richomme C, et al. OASIS: an assessment tool of epidemiological surveillance systems in animal health and food safety. Epidemiol Infect. (2011) 139:1486-96. doi: 10.1017/S0950268811000161 
26. Drewe JA, Hoinville LJ, Cook AJC, Floyd T, Gunn G, Stark KDC. SERVAL: a new framework for the evaluation of animal health surveillance. Transbound Emerg Dis. (2015) 62:33-45. doi: 10.1111/tbed.12063 
27. RiskSur. RISKSUR Tools for Surveillance Design and Evaluation. (2020). Available online at: https://www.fp7 risksur.eu/results/tools (accessed June 26, 2020). 
28. Muellner P, Stark KD, Watts J. Surveillance Evaluation Framework (SurF). (2016). Available online at: https://www.mpi.govt.nz/dmsdocument/18091/ direct (accessed March 4, 2021). 
29. FAO. Piloting the Progressive Management Pathway for Antimicrobial Resistance. (2019). Available online at: http://www.fao.org/europe/events/ detail-events/en/c/1197882/ (accessed June 26, 2020). 
30. WHO. Joint External Evaluation tool (2nd Edition). (2018). Available online at: https://extranet.who.int/sph/joint-external evaluation-tool-2nd- edition (accessed June 26, 2020). 
31. International Office of Epizootics, World Health Organization. Handbook for the Assessment of Capacities at the Human-Animal Interface: Global Capacities, Alert and Response. (2015). Available online at: http://apps.who. int/iris/bitstream/10665/181594/1/9789241549325_eng.pdf?ua=1 (accessed June 26, 2020). 
32. OIE. OIE Tool for the Evaluation of Performance of Veterinary Services. (2013). Available online at: https://www.oie.int/fileadmin/vademecum/eng/PDF_ WORD_Vademecum/SERVICES_VETERINAIRES_FINAL/Slide%2011/EN/ A_%20PVS%20Tool_Final_Edition%202013.pdf (accessed March 4, 2021). 
35. Babo Martins S, Rushton J, Stark KDC. Economic assessment of zoonoses surveillance in a one health context: a conceptual framework. Zoonoses Public Health. (2016) 63:386-95. doi: 10.1111/zph.12239 
42. Queenan K, Hasler B, Rushton J. A one health approach to antimicrobial resistance surveillance: is there a business case for it? Int J Antimicrob Agents. (2016) 48:422-7. doi: 10.1016/j.ijantimicag.2016.06.014","Consequently, surveillance systems for AMR should integrate the surveillance of AMU and resistance in microorganisms circulating in humans, in animals, and in the environment (8, 9).

The following 12 tools were included: [1] Evaluation of collaboration for surveillance (EcoSurTool) (21), [2] Network for the Evaluation of OH Framework (NEOH) (22), [3] OH Assessment for Planning and Performance (OH-APP) (23), [4] The FAO Assessment Tool for Laboratory and AMR Surveillance Systems (ATLASS) (24), [5] Outil d'Analyse des Systèmes de Surveillance (OASIS) (25), [6] SuRveillance EVALuation framework (SERVAL) (26), [7] SurvTools (27), [8] Surveillance Evaluation Framework (SurF) (28), [9] The FAO Progressive Management Pathway for AMR (PMP-AMR) (29), [10] Joint External Evaluation tool (Second edition) (JEE) (30), [11] International Health Regulation core capacity monitoring framework (IHR) (31), and [12] The OIE Tool for the Evaluation of Performance of Veterinary Services (PVS) (32) (Table 4).


Tool (Reference)
 Year of publication
General purpose 
Levels of evaluation

ECoSur (21)
 2019
 Evaluation tool for the organization, functioning, and functionalities of collaboration taking place in a multisectoral surveillance system.
1

NEOH (22)
 2018
 Tool to assess the extent to which the six aspects of knowledge integration are implemented in an initiative or a surveillance system, including thinking, planning, transdisciplinary working, sharing, learning, and systemic organization.
1, and parts of 2 and 4

OH-APP (23)
 2018
 Tool to assess the maturity of multisectoral coordination mechanism and to provide data for decision-making that would enhance the organizational capacity and OH performance.
Parts of 1

ATLASS (24)
 2016
 Tool developed by FAO to help identify targets to improve the national AMR surveillance systems in the food and agriculture sectors.
Parts of 1, 2, 3 and 4

OASIS (25)
 2011
 Tool for the evaluation of surveillance systems in animal health, food safety, and plant health.
 Parts of 2, 3, and 5

SERVAL (26)
 2015
 Evaluation framework for the comprehensive evaluation of single surveillance components (activities) or the entire surveillance programs.
Parts of 2, 3, and 5

SurvTool (27)
 2018
 Surveillance evaluation tools and framework for providing step-by-step guidance for the evaluation of surveillance (all sectors).
Parts of 2, 3, and 5

SurF (28)
 2016
 Surveillance evaluation tools and framework for the animal, plant, environment, and marine sectors.
 Parts of 2, 3, and 5

PMP-AMR (29)
 2019
 Tool developed by the FAO to provide guidance to countries for developing and operationalizing their multi-sector OH National Action Plans on AMR through a stepwise approach.
Parts of 2, 3, and 4
JEE (30)
 2018
 Tool developed by the WHO to establish country-specific status and progress in achieving the targets defined by the International Health Regulations (IHR).
Parts of 2, 3, and 5

IHR (31)
 2015
 Tool developed for the assessment of capacities at the human-animal interface in the IHR Monitoring Framework.
Parts of 1, 2, and 3

PVS (32)
 2013
 Tool developed by Organization for Animal Health (OIE) for the evaluation of the application of its standards and guidelines.
Parts of 2 and 3",
albaliComparativePerformanceEvaluation2023,23,Albali 2023,Comparative Performance Evaluation of the Public Health Surveillance Systems in 6 Gulf Cooperation Countries: Cross-sectional Study.,Comparative Performance Evaluation of the Public Health Surveillance Systems in 6 Gulf Cooperation Countries: Cross-sectional Study,2023,Nawaf Albali,nawaf.albali@gmail.com,Saudi Arabia,Comparative performance evaluation of public health surveillance systems,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",a. Public Health,"The six Gulf Cooperation Council (GCC) nations: the United Arab Emirates (UAE), Bahrain, Saudi Arabia, Oman, Qatar, and Kuwai.",b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001); c. Framework for Evaluating Public Health Surveillance Systems for Early Detection of Outbreaks; Recommendations from the CDC Working Group (CDC 2004),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Country representative (epidemiologist or public health professional),N/A,"The questions were constructed by 3 experts with experience in the establishment and assessment of surveillance systems, and content validity was determined by a panel of 5 epidemiologists, public health professionals, and preventive medicine specialists.
The questionnaire was validated by 2 representatives from GCC member countries.",ESS: Inclusion criteria mandated that the country representative must be an epidemiologist or a public health professional with >5 years of experience in managing national-level surveillance systems.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"CDC 2001 [i.e., ""Acceptability reflects the willingness of persons and organizations to participate in the surveillance system""]","3 indicators ofacceptability including the completion rates of entered forms,the associated laboratory completion rates, and the completionrates of hospitals and primary health centers","5-point Likert scale (1=strongly disagree, 2=disagree, 3=neutral, 4=agree, and 5=strongly agree), with a higher score representing better performance on the assessed attribute",Our surveillance system has high completion rates; Our surveillance system has high laboratory reporting rates; Our surveillance system has high hospital or PHCa reporting rates,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The data quality reflects the completeness and validity of the data recorded in each country's public health surveillance system.,"3 indicators of data quality in their respective country including the accuracy of the data entered, presence of standardized methods for data entry, and internal validity of the surveillance system's data","5-point Likert scale (1=strongly disagree, 2=disagree, 3=neutral, 4=agree, and 5=strongly agree), with a higher score representing better performance on the assessed attribute","The entered data in our surveillance system is accurate 

Our surveillance system has standardized methods for data entry

Our surveillance system can measure what it intends to measure",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Flexibility alludes to the system's ability to handle new health-related events and case definition revisions and its ease of integration with other systems.,"3 indicators including the ability to respond quickly to a newdemand, such as diseases and risk factors; the ability to respond quickly to emerging and re-emerging pandemics; and the ability to detect events other than notifiable diseases, such as food poisoning, chemical poisoning, and environmental events","5-point Likert scale (1=strongly disagree, 2=disagree, 3=neutral, 4=agree, and 5=strongly agree), with a higher score representing better performance on the assessed attribute","Our surveillance system allows us to respond quickly to a new demand, that is, diseases, risk factors etc.

Our surveillance system allows us to respond quickly for emerging or re-emerging pandemics

Our surveillance system can detect events other than notifiable diseases, such as food poisoning, chemical poisoning, environmental events, etc.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001,N/A,N/A,"Our surveillance system can correctly detect a high proportion of disease cases

Our surveillance system can correctly detect new epidemics or outbreaks

The proportion of reported cases that are true cases in our surveillance system is high

The proportion of reported epidemics that are true epidemics in our surveillance system is high",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Timeliness refers to the rapid availability of sufficient data to enable public health authorities to take appropriate actions.,"Two indicators were developed and assessed for timeliness, including the system's ability to rapidly generate data for immediate disease control and long-term program planning","5-point Likert scale (1=strongly disagree, 2=disagree, 3=neutral, 4=agree, and 5=strongly agree), with a higher score representing better performance on the assessed attribute","Our surveillance system is able to generate data for immediate disease control

Our surveillance system is able to generate data for long-term program planning",CDC 2001,"10 indicators of usefulness was deemed useful if it could produce estimates of morbidity and mortality rates, identify high-risk populations and the social determinants of fatalities, generate actionable reports and insights instantly, permit the evaluation of the impact of preventive and control programs, anticipate trends and outcomes using artificial intelligence (AI) and machine learning models, and stimulate research.","5-point Likert scale (1=strongly disagree, 2=disagree, 3=neutral, 4=agree, and 5=strongly agree), with a higher score representing better performance on the assessed attribute","The system provides estimates of morbidity related to the health-related event under surveillance

The system provides estimates of mortality related to the health-related event under surveillance

The system enables us to identify high-risk populations 

The system enables us to plan the resources needed for prevention and control

The system enables us to update and develop national policy strategy

The system enables us to assess the impact of any prevention and control intervention

The system can generate actionable reports and insights immediately about health-related events under surveillance

The system can detect trends that signal changes in the occurrence of all health-related events under surveillance

The system can predict trends and outcomes using artificial intelligence and machine learning models

The system data stimulate research intended for prevention or control

",N/A,N/A,N/A,N/A,Sensitivity and PVP,"4 indicators of sensitivity and predictive values as proxies for the actual calculation. Indicators included the system's ability to correctly detect a high proportion of disease cases and new epidemics or outbreaks, the proportion of reported cases that are true cases, and the proportion of reported epidemics that are true epidemics.","5-point Likert scale (1=strongly disagree, 2=disagree, 3=neutral, 4=agree, and 5=strongly agree), with a higher score representing better performance on the assessed attribute",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Self-reported questionnaires, however, have the potential to introduce bias, especially with regard to delicate issues such as the usefulness and quality of the system's data. To better understand the research question and guarantee that the conclusions are grounded in participants'views and experiences, we suggest conducting a mixed methods evaluation approach, including qualitative research, to evaluate GCC surveillance systems.

Potential lessons should be leveraged from countries with high scores, especially in using emerging technologies such as machine learning, AI, and real-time analytics.",N/A,"Use of emerging technologies such as machine learning, AI, and real-time analytics are recommended.",N/A,There may be an error in the criteria extracted for simplicity as the indicator descriptions did not fully align with the indicators in Table 3.,
amatoEvaluationPilotWastewater2023,2775,Amato 2023,"Evaluation of the Pilot Wastewater Surveillance for SARS-CoV-2 in Norway, June 2022 - March 2023","Evaluation of the pilot wastewater surveillance for SARS-CoV-2 in Norway, June 2022 - March 2023",2023,Ettore Amato,ettore.amato@fhi.no,Norway,Formal evaluation of SARS-CoV-2 surveillance system in Norway,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",c. Wastewater,Norway,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001); f. Data Quality Monitoring and Surveillance System Evaluation - A Handbook of Methods and Applications (ECDC 2014),Data quality monitoring and surveillance system evaluation (ECDC 2014),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Describe trends of virus circulation, including its variants in the population over time and space",Provide an early detection of change in infection trends in the population compared to other national COVID-19 surveillance systems and indicators,"Detect and monitor emerging variants of public health relevance
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Contact persons from participating wastewater treatment plants,Wastewater treatment plants,N/A,N/A,Municipal doctors from the 5 participating municipalities,Local public health authorities,N/A,N/A,The Directorate of Health and the Norwegian Institute of Public Health,National public health authorities and experts on infection control and preparedness,N/A,N/A,The Norwegian Environment Agency,National authority responsible for wastewater legislation and environmental monitoring,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The extent to which end-users and stakeholders were willing to participate in the pilot WS and in the future,A questionnaire was developed and sent to involved stakeholders and participants of the pilot WS in February 2023,"Willingness to continue contributing to the WWS system, taking into account their available resources and capacity.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The ability of the system to adapt to changes over time being able to be scaled up, scaled down or expand if necessary",N/A,The system was flexible to the extent that the number of sampling locations and sampling frequency can be scaled up and down when needed,"During the operational period of the pilot, we were able to test the ability to scale down, which proceeded without major challenges. Scaling up requires that the treatment plants and the laboratory have sufficient capacity. Feedback from operators of the treatment plants suggested that capacity-related challenges may arise for several of them if there is a need for upscaling. Shortages of personnel, logistics and time pressure were mentioned as the biggest possible challenge. Different end-users expressed interest in using the WWS system to monitor other pathogens in addition to SARS-CoV-2 in the future",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The proportion of the population covered by the WS. The concordance between the geographical area covered by the WS and the geographical unit for clinical surveillance considered for other indicators is evaluated,N/A,"The selected 12 wastewater treatment plants included in the pilot's first phase (June-November 2022) covered approximately 30% of the Norwegian population. The scaled down phase of the pilot (December 2022-March 2023) included only five wastewater treatment plants with a coverage of around 25% of the population. We have simulated a further scale down of the pilot including only Oslo municipality and the airport area with a coverage of around 22%. The trend analysis considering these three scale down situations showed that the national trend is similar in all scenarios, but the results were less reliable at the local level.",N/A,N/A,N/A,N/A,N/A,The proportion of waves of infection or new virus variants that are captured by the WS system,"Comparing with clinical indicators (such as registered COVID-19 cases, hospitalizations, and ICU admissions), all waves were captured by the WS system, indicating that the system had a similar sensitivity compared to other surveillance systems both at national and local level (Figure 1 and 2).","1. Weekly level of SARS-CoV-2 RNA detected in wastewater in Norway compared with clinical indicators for COVID-19. SARS-CoV-2 RNA levels in wastewater are population-weighted and PMMoV-normalized. Note: the wastewater data are based on results of samples taken at selected locations, while the clinical indicators are based on data from national registries.
2. Weekly concentration of SARS-CoV-2 RNA in wastewater compared to weekly registered cases expressed as incidence per 10,000 inhabitants. SARS-CoV-2 RNA levels in wastewater are population-weighted and PMMoV-normalized. Note: the wastewater data are based on results of samples taken at selected locations, while the data on registered cases are based on national registries.
","While mutational PCR screening was performed by the contract laboratory and reported for the entire study period, reporting of sequencing results started only at a late stage (week 47). Overall, mutational PCR screening results showed concordance with the signals generated from the clinical variants surveillance. However, the PCR screening method did not have sufficient discriminatory power to detect and identify specific variants over time. Preliminary sequencing data, both real-time and retrospective data (Supplementary Figures S3), suggest that signals of new key-mutations and changes in variant distribution from the WS system preceded signals from clinical variant surveillance approximately by 1-2 weeks. However, additional data would be needed to conduct a proper evaluation of the WS systems' real-time performance in terms of sensitivity, specificity, and timeliness for new variants of public health relevance","The structure/organization of the system and its ease of operation, including logistics from sampling to reporting of results",N/A,N/A,N/A,The system's ability to avoid false warnings about new waves of infection or new virus variants (false positives),"Compared to the Beredt C19 clinical indicators, we observed that the WS system gave signals of temporary fluctuations over the weeks that were not otherwise captured. These fluctuations made the interpretation of the wastewater signals challenging, since it was unclear in a real-time situation whether a weekly increased value represented a real increase or was a consequence of random fluctuations, or measurement errors which could occur at different stages of the process from sampling to final result",N/A,"While mutational PCR screening was performed by the contract laboratory and reported for the entire study period, reporting of sequencing results started only at a late stage (week 47). Overall, mutational PCR screening results showed concordance with the signals generated from the clinical variants surveillance. However, the PCR screening method did not have sufficient discriminatory power to detect and identify specific variants over time. Preliminary sequencing data, both real-time and retrospective data (Supplementary Figures S3), suggest that signals of new key-mutations and changes in variant distribution from the WS system preceded signals from clinical variant surveillance approximately by 1-2 weeks. However, additional data would be needed to conduct a proper evaluation of the WS systems' real-time performance in terms of sensitivity, specificity, and timeliness for new variants of public health relevance",The ability to collect samples and produce results without deviation or failure.,N/A,The system showed stability in terms of delivering regular results for assessment of national trends.,"Deviations could occur for several reasons and at different stages in the WWS system. The most important reasons we have registered were: (i) sampling, such as lack of capacity to take samples, which sometimes resulted in one sample per week instead of two. Capacity challenges were often linked to holiday closures and public holidays, (ii) logistics such as delays and deviations in connection with the collection and transport of samples, and (iii) analysis deviations such as inhibition of the PCR analysis",N/A,N/A,N/A,N/A,The ability of the WS to deliver timely results and to provide an early warning signal compared to other surveillance systems.,The results provided by the WS system correlated with clinical indicators related to this wave but did not give an early signal of downward trend compared to registered clinical cases,N/A,N/A,"The extent to which the system has benefited the end-users and led to specific public health actions, either in the form of assessments or measures","A questionnaire was developed and sent to involved stakeholders and participants of the pilot WS in February 2023 (Section A, Supplementary information). The questions were adapted to each end-user category and covered topics such as cooperation, communication, future areas of use and surveillance attributes. The information was collected, aggregated, and analysed based on feedback received. Experiences form NIPH's project eam and experts were also collected to describe the pilot wastewater system and its technical performance.","Questions for the Directorate of Health 3. Have you benefited from the results of NIPH's pilot for wastewater surveillance of SARSCoV-2? In what way? What do you think the results can be used for in the future? (Describe briefly)
4. How do you consider the usefulness of the wastewater surveillance compared to other indicators used in the national monitoring of SARS-CoV-2? (Describe briefly)
5. From a public health perspective, do you have any thoughts about future areas of use for wastewater surveillance? (Describe briefly)
6. What do you think will be the most important prerequisites for wastewater surveillance to be used as a national preparedness tool in dealing with future epidemics and health threats? (Describe briefly)
Questions for Norwegian Institute of Public Health:
3. Have the results of the SARS-CoV-2 wastewater surveillance pilot been useful? In what way? (Describe briefly)
4. Seen from a national surveillance perspective, will there be a need for wastewater surveillance beyond March 2023? Yes  No  Unsure 
4.1.If yes, at what level and what do you think the results can be used for in the future? (Describe briefly)
5. Have the results been communicated in an understandable way? Do you have suggestions for improvements in the way we present the results? (Describe briefly)
6. What do you think are the most important limitations of the results from the wastewater surveillance? (Describe briefly)
7. How do you assess the usefulness of the wastewater surveillance compared to other indicators used in the national surveillance of SARS-CoV-2? (Describe briefly)
8. Are there other parts of the surveillance that can be scaled down in the future if we continue with wastewater surveillance? (Describe briefly)
9. If the project had started earlier during the pandemic, do you think the results would have had an impact on NIPH's risk assessments and advice regarding measures? (Describe briefly)
10. From a public health perspective, do you have any thoughts about future areas of use for wastewater surveillance? If the surveillance is to be extended to other agents, which ones do you think should have the highest priority and why? (Describe briefly)
11. What do you think will be the most important prerequisites for wastewater surveillance to be used as a national preparedness tool in addressing future epidemics and health threats? (Describe briefly)
","In what way have the results been used in your municipality?

Have the results from the wastewater surveillance been useful to you?

Do you know of any specific measures or assessments that have followed from the results of the wastewater surveillance?

What type of information would be useful to know about the wastewater surveillance besides the information you have received?

Based on experiences from the test project, do you think that you would have benefited from the results of the project if the wastewater surveillance would have been started earlier in the pandemic, i.e., before June 2022

Have you benefited from the results of NIPH's pilot for wastewater surveillance of SARS-CoV-2? In what way? 

What do you think the results can be used for in the future?
How do you consider the usefulness of the wastewater surveillance compared to other indicators used in the national monitoring of SARS-CoV-2?

From a public health perspective, do you have any thoughts about future areas of use for wastewater surveillance?

What do you think will be the most important prerequisites for wastewater surveillance to be used as a national preparedness tool in dealing with future epidemics and health threats?

How do you consider the usefulness of the wastewater surveillance compared to other indicators used in the national monitoring of SARS-CoV-2?

3. Have the results of the SARS-CoV-2 wastewater surveillance pilot been useful? In what way? (Describe briefly)
4. Seen from a national surveillance perspective, will there be a need for wastewater surveillance beyond March 2023? Yes  No  Unsure 
4.1. If yes, at what level and what do you think the results can be used for in the future? (Describe briefly)
5. Have the results been communicated in an understandable way? Do you have suggestions for improvements in the way we present the results? (Describe briefly)
6. What do you think are the most important limitations of the results from the wastewater surveillance? (Describe briefly)
7. How do you assess the usefulness of the wastewater surveillance compared to other indicators used in the national surveillance of SARS-CoV-2? (Describe briefly)
8. Are there other parts of the surveillance that can be scaled down in the future if we continue with wastewater surveillance? (Describe briefly)
9. If the project had started earlier during the pandemic, do you think the results would have had an impact on NIPH's risk assessments and advice regarding measures? (Describe briefly)
10. From a public health perspective, do you have any thoughts about future areas of use for wastewater surveillance? If the surveillance is to be extended to other agents, which ones do you think should have the highest priority and why? (Describe briefly) 
11. What do you think will be the most important prerequisites for wastewater surveillance to be used as a national preparedness tool in addressing future epidemics and health threats? (Describe briefly)",N/A,N/A,N/A,N/A,COMMUNICATION - The ability of the system to deliver information and data in a clear and distinct manner,N/A,"All end-users and stakeholders reported that the results were clearly presented and the content sufficient for their needs. As additional feedback, end-users suggested adding more information on virus variants and proposed to include an indicator of the burden on the primary healthcare service, together with the hospital's admission figures. End-users of the system at municipal level suggested that direct reporting to the municipal contact person was the preferred channel for communicating and accessing results rather than visiting the NIPH's website to check the published reports. The frequency of reporting, once per week, was considered adequate during the study period","Which of the following information channels do you use to keep yourself updated on the results of the wastewater surveillance?If you have to choose, through which of the channels mentioned above do you prefer to receive results from the wastewater surveillance? 

Which parts of the results did you find most interesting and relevant to the task you are responsible for? 

Do you think the results were understandable and sufficient for the tasks you are responsible for? If no, what do you think could have been done better/differently? 

Is there anything you are missing in the results reports you have received from NIPH? 

Are you satisfied with how frequently you have received results report from NIPH? 

Are there any other actors/units in your municipality that you think would benefit from being involved in the project and/or receiving results reports?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Statistical Analysis: Hindered by the absence of a reliable 'gold standard' indicator for disease incidence.
Timing of Pilot: Pilot started during a new wave of infections, preventing assessment of the system's early warning capabilities.
Survey Questions: Limited depth due to concerns about response rates, with a focus on end-users and stakeholders.
Cost-Benefit Analysis: Not conducted due to the need for a different study design and evaluation method, outside the study's scope.
Laboratory Testing: Outsourcing of laboratory testing under specific contract requirements prevented evaluation of testing capacity in an upscaling scenario.
Variant Sequencing Analysis: Operational only in the last weeks of the pilot, limiting the evaluation of sensitivity, specificity, and timeliness for variant surveillance.
Scope and Setting: Evaluation limited to pilot settings, excluding experiences from smaller municipalities.
Routine Sampling and Analysis Procedures: Acknowledgment that adjustments to these factors could impact the performance of the WWS system and surveillance attributes.","To improve the quality and efficiency of the WWS system, we would recommend to standardise and validate methods for assessing trends of new waves or virus variants, evaluate the WWS system for sensitivity, specificity and timeliness for variants using a longer surveillance operational period, identify the causes of trend fluctuation to minimise the challenges in the interpretation of WWS signals, and conduct prevalence studies in the population to calibrate WWS data and improve the interpretation of data","Although the system proved to be simple, flexible, acceptable, and stable by end-users and stakeholders during the pilot phase, some resource-related challenges might arise in a possible upscale scenario. In addition, environment and health sectors could be separated institutionally in many countries, highlighting the importance of cross-sectoral collaborations and agreements. These challenges are relevant when establishing or implementing WWS systems, particularly in high demand situations (e.g., during the acute phase of a pandemic).
Standardised analytical methods used for WWS and a harmonised approach for surveillance evaluations would be useful to compare the results, performance and added value of WWS in different countries, different settings and in different phases of a pandemic/epidemic","1. Environmental surveillance for SARS-CoV-2 to complement public health surveillance - Interim Guidance. World Health Organization; 2022

15. ECDC. Data quality monitoring and surveillance system evaluation2014. Available from: https://www.ecdc.europa.eu/sites/default/files/media/en/publications/Publications/Data-quality-monitoring-surveillance system-evaluation-Sept-2014.pdf","Additional evaluation criteria:

3. How has the collaboration with the laboratory and those who collect the samples worked? 
Is there anything that could have been done better? (Describe briefly) 
4. How has the collaboration with NIPH worked? Is there something that you have missed or that could have been done better? (Describe briefly)
5. What capacity do you have to continue with sampling for this type of surveillance in the future, beyond the test period? (Describe briefly)
6. What will be the biggest challenges for you related to continuing with sampling for this type of purpose? (Describe briefly)


5. Do you know whether your municipality has been involved in previous projects where wastewater has been used to map information about the health status of the inhabitants of your municipality?
6. If yes, what type of mapping? 

19. How did you experience the collaboration with NIPH in connection with the project, do you have any suggestions for something that could have been better? (Describe briefly)

20. Would you be willing to continue participating in the wastewater surveillance if extended beyond the test period, i.e., after March 2023? Yes No  Unsure 
21. Are there any challenges to participating from your side and, if so, what are the biggest obstacles? (Describe briefly)
22. Which other diseases/health threats do you think will be most relevant to include in wastewater-based surveillance in the future, and which will have the highest relevance for you? (Please explain why)",
anonymousUpdatedGuidelinesEvaluating2001,5578,Anonymous 2001,Updated guidelines for evaluating public health surveillance systems,Updated Guidelines for Evaluating Public Health Surveillance Systems,2001,Centers for Disease Control and Prevention,unknown,United States of America,Guidelines for evaluating public health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Task A. Engage the Stakeholders in the Evaluation,N/A,N/A,N/A,N/A,Task B. Describe the Surveillance System to be Evaluated,N/A,"Describe the public health importance of the health-related event under surveillance.

Describe the purpose and operation of the system.

Describe the resources used to operate the system","To construct a balanced and reliable description of the system, multiple sources of information might be needed. The description of the system can be improved by consulting with a variety of persons involved with the system and by checking reported descriptions of the system against direct observation",N/A,B.1. Describe the Public Health Importance of the Health-Related Event Under Surveillance,"The public health importance of a health-related event and the need to have that event under surveillance can be described in several ways. Health-related events that affect many persons or that require large expenditures of resources are of public health importance. However, health-related events that affect few persons might also be important, especially if the events cluster in time and place (e.g., a limited outbreak of a severe disease). In other instances, public concerns might focus attention on a particular health-related event, creating or heightening the importance of an evaluation. Diseases that are now rare because of successful control measures might be perceived as unimportant, but their level of importance should be assessed as a possible sentinel health-related event or for their potential to reemerge. Finally, the public health importance of a health-related event is influenced by its level of preventability (10 ).","Parameters for measuring the importance of a health-related event—and therefore the public health surveillance system with which it is monitored—can include (7 )
* indices of frequency (e.g., the total number of cases and/or deaths; incidence rates, prevalence, and/or mortality rates); and summary measures of population health status (e.g., quality-adjusted life years [QALYS]);
* indices of severity (e.g., bed-disability days, case-fatality ratio, and hospitalization rates and/or disability rates);
* disparities or inequities associated with the health-related event;
* costs associated with the health-related event;
* preventability (10 );
* potential clinical course in the absence of an intervention (e.g., vaccinations) (11,12 ); and
* public interest",N/A,N/A,B.2. Describe the Purpose and Operation of the Surveillance System,N/A,"Methods for describing the operation of the public health surveillance system include
* List the purpose and objectives of the system.
* Describe the planned uses of the data from the system.
* Describe the health-related event under surveillance, including the case definition for each specific condition.Cite any legal authority for the data collection.
* Describe where in the organization(s) the system resides, including the context (e.g., the political, administrative, geographic, or social climate) in which the system evaluation will be done.
* Describe the level of integration with other systems, if appropriate.
* Draw a flow chart of the system.
* Describe the components of the system. For example
— What is the population under surveillance?
— What is the period of time of the data collection?
— What data are collected and how are they collected?
— What are the reporting sources of data for the system?
— How are the system's data managed (e.g., the transfer, entry, editing, storage, and back up of data)? Does the system comply with applicable standards for data formats and coding schemes? If not, why?
— How are the system's data analyzed and disseminated?
— What policies and procedures are in place to ensure patient privacy, data confidentiality, and system security? What is the policy and procedure for releasing data? Do these procedures comply with applicable federal and state statutes and regulations? If not, why?
— Does the system comply with an applicable records management program?
For example, are the system's records properly archived and/or disposed of?",N/A,See FIGURE 1. Simplified flow chart for a generic surveillance system,B.3. Describe the Resources Used to Operate the Surveillance System,"In this report, the methods for assessing resources cover only those resources directly required to operate a public health surveillance system. These resources are sometimes referred to as ""direct costs"" and include the personnel and financial resources expended in operating the system.","In describing these resources consider the following:
* Funding source(s): Specify the source of funding for the surveillance system. In the United States, public health surveillance often results from a collaboration among federal, state, and local governments.
* Personnel requirements: Estimate the time it takes to operate the system, including the collection, editing, analysis, and dissemination of data (e.g., person-time expended per year of operation). These measures can be converted to dollar estimates by multiplying the person-time by appropriate salary and benefit costs.
* Other resources: Determine the cost of other resources, including travel, training, supplies, computer and other equipment, and related services (e.g., mail, telephone, computer support, Internet connections, laboratory support, and hardware and software maintenance).","When appropriate, the description of the system's resources should consider all levels of the public health system, from the local health-care provider to municipal, county, state, and federal health agencies.

This approach to assessing resources includes only those personnel and material resources required for the operation of surveillance and excludes a broader definition of costs that might be considered in a more comprehensive evaluation. For example, the assessment of resources could include the estimation of indirect costs (e.g., follow-up laboratory tests) and costs of secondary data sources (e.g., vital statistics or survey data).

The assessment of the system's operational resources should not be done in isolation of the program or initiative that relies on the public health surveillance system. A more formal economic evaluation of the system (i.e., judging costs relative to benefits) could be included with the resource description. Estimating the effect of the system on decision making, treatment, care, prevention, education, and/or research might be possible (35,36 ). For some surveillance systems, however, a more realistic approach would be to judge costs based on the objectives and usefulness of the system.",N/A,Task C. Focus the Evaluation Design,The direction and process of the evaluation must be focused to ensure that time and resources are used as efficiently as possible.,"Focusing the evaluation design for a public health surveillance system involves
* determining the specific purpose of the evaluation (e.g., a change in practice);
* identifying stakeholders (Task A) who will receive the findings and recommendations of the evaluation (i.e., the intended users);
* considering what will be done with the information generated from the evaluation (i.e., the intended uses);
*specifying the questions that will be answered by the evaluation; and
* determining standards for assessing the performance of the system","An effective evaluation design is contingent upon a) its specific purpose being understood by all of the stakeholders in the evaluation and b) persons who need to know the findings and recommendations of the design being committed to using the information generated from it. In addition, when multiple stakeholders are involved, agreements that clarify roles and responsibilities might need to be established among those who are implementing the evaluation.

Standards for assessing how the public health surveillance system performs establish what the system must accomplish to be considered successful in meeting its objectives. These standards specify, for example, what levels of usefulness and simplicity are relevant for the system, given its objectives. Approaches to setting useful standards for assessing the system's performance include a review of current scientific literature on the health-related event under surveillance and/or consultation with appropriate specialists, including users of the data.",N/A,Task D. Gather Credible Evidence Regarding the Performance of the Surveillance System,N/A,N/A,N/A,N/A,"Task E. Justify and State Conclusions, and Make Recommendations","Conclusions from the evaluation can be justified through appropriate analysis, synthesis, interpretation, and judgement of the gathered evidence regarding the performance of the public health surveillance system (Task D). Because the stakeholders (Task A) must agree that the conclusions are justified before they will use findings from the evaluation with confidence, the gathered evidence should be linked to their relevant standards for assessing the system's performance (Task C). In addition, the conclusions should state whether the surveillance system is addressing an important public health problem (Task B.1) and is meeting its objectives (Task B.2).

Recommendations should address the modification and/or continuation of the public health surveillance system. Before recommending modifications to a system, the evaluation should consider the interdependence of the system's costs (Task B.3) and attributes (Task D.2). Strengthening one system attribute could adversely affect another attribute of a higher priority. Efforts to improve sensitivity, PVP, representativeness, timeliness, and stability can increase the cost of a surveillance system, although savings in efficiency with computer technology (e.g., electronic reporting) might offset some of these costs. As sensitivity and PVP approach 100%, a surveillance system is more likely to be representative of the population with the event under surveillance.
However, as sensitivity increases, PVP might decrease. Efforts to increase sensitivity and PVP might increase the complexity of a surveillance system — potentially decreasing its acceptability, timeliness, and flexibility. In a study comparing health-department-initiated (active) surveillance and provider-initiated (passive) surveillance, for example, the active surveillance did not improve timeliness, despite increased sensitivity (61 ). In addition, the recommendations can address concerns about ethical obligations in operating the system (74 ).

In some instances, conclusions from the evaluation indicate that the most appropriate recommendation is to discontinue the public health surveillance system; however, this type of recommendation should be considered carefully before it is issued. The cost of renewing a system that has been discontinued could be substantially greater than the cost of aintaining it. The stakeholders in the evaluation should consider relevant public health and other consequences of discontinuing a surveillance system.",N/A,N/A,N/A,Task F. Ensure Use of Evaluation Findings and Share Lessons Learned,"Deliberate effort is needed to ensure that the findings from a public health surveillance system evaluation are used and disseminated appropriately. When the evaluation design is focused (Task C), the stakeholders (Task A) can comment on decisions that might affect the likelihood of gathering credible evidence regarding the system's performance. During the implementation of the evaluation (Tasks D and E), considering how potential findings (particularly negative findings) could affect decisions made about the surveillance system might be necessary. When conclusions from the evaluation and recommendations are made (Task E), follow-up might be necessary to remind intended users of their planned uses and to prevent lessons learned from becoming lost or ignored.

Strategies for communicating the findings from the evaluation and recommendations should be tailored to relevant audiences, including persons who provided data used for the evaluation. In the public health community, for example, a formal written report or oral presentation might be important but not necessarily the only means of communicating findings and recommendations from the evaluation to relevant audiences. Several examples of formal written reports of surveillance evaluations have been included in peer-reviewed journals (51,53,57,59,75 ).",N/A,N/A,N/A,Guide immediate action for cases of public health importance,"Measure the burden of a disease (or other health-related event), including changes in related factors, the identification of populations at high risk, and the identification of new or emerging health concerns","Monitor trends in the burden of a disease (or other health-related event), including the detection of epidemics (outbreaks) and pandemics","Guide the planning, implementation, and evaluation of programs to prevent and control disease, injury, or adverse exposure",Evaluate public policy,Detect changes in health practices and the effects of these changes,Prioritize the allocation of health resource,Describe the clinical course of disease,Provide a basis for epidemiologic research,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Data disseminated by a public health surveillance system can be used for immediate public health action, program planning and evaluation, and formulating research hypotheses.",N/A,N/A,N/A,Public health practitioners,"Stakeholders can provide input to ensure that the evaluation of a public health surveillance system addresses appropriate questions and assesses pertinent attributes and that its findings will be acceptable and useful. In that context, we define stakeholders as those persons or organizations who use data for the promotion of healthy lifestyles and the prevention and control of disease, injury, or adverse exposure.",N/A,N/A,Health-care providers,N/A,N/A,N/A,Data providers and users,N/A,N/A,N/A,Representatives of affected communities,N/A,N/A,N/A,"Governments at the local, state, and federal levels",N/A,N/A,N/A,Professional and private nonprofit organizations,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"We define stakeholders as those persons or organizations who use data for the promotion of healthy lifestyles and the prevention and control of disease, injury, or adverse exposure.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,[CDC 2001] Acceptability reflects the willingness of persons and organizations to participate in the surveillance system,"Acceptability refers to the willingness of persons in the sponsoring agency that operates the system and persons outside the sponsoring agency (e.g., persons who are asked to report data) to use the system. To assess acceptability, the points of interaction between the system and its participants must be considered (Figure 1), including persons with the health-related event and those reporting cases. 
Quantitative measures of acceptability can include: 
* subject or agency participation rate (if it is high, how quickly it was achieved); 
* interview completion rates and question refusal rates (if the system involves interviews); 
* completeness of report forms; 
* physician, laboratory, or hospital/facility reporting rate; and 
* timeliness of data reporting. Some of these measures might be obtained from a review of surveillance report forms, whereas others would require special studies or surveys.","Acceptability is a largely subjective attribute that encompasses the willingness of persons on whom the public health surveillance system depends to provide accurate, consistent, complete, and timely data. Some factors influencing the acceptability of a particular system are: 
* the public health importance of the health-related event; 
* acknowledgment by the system of the person's contribution; 
* dissemination of aggregate data back to reporting sources and interested parties; 
* responsiveness of the system to suggestions or comments; 
* burden on time relative to available time; 
* ease and cost of data reporting; 
* federal and state statutory assurance of privacy and confidentiality; 
* the ability of the system to protect privacy and confidentiality; 
* federal and state statute requirements for data collection and case reporting; and 
* participation from the community in which the system operates.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001,"Examining the percentage of ""unknown"" or ""blank"" responses to items on surveillance forms is a straightforward and easy measure of data quality. Data of high quality will have low percentages of such responses. However, a full assessment of the completeness and validity of the system's data might require a special study.
Data values recorded in the surveillance system can be compared to ""true"" values through, for example, a review of sampled data (40 ), a special record linkage (41 ), or patient interview (42 ). In addition, the calculation of sensitivity (Task D.2.e) and predictive value positive (Task D.2.f) for the system's data fields might be useful in assessing data quality.
Quality of data is influenced by the performance of the screening and diagnostic tests (i.e., the case definition) for the health-related event, the clarity of hardcopy or electronic surveillance forms, the quality of training and supervision of persons who complete these surveillance forms, and the care exercised in data management. A review of these facets of a public health surveillance system provides an indirect measure of data quality.","Most surveillance systems rely on more than simple case counts. Data commonly collected include the demographic characteristics of affected persons, details about the health-related event, and the presence or absence of potential risk factors. The quality of these data depends on their completeness and validity.
The acceptability (see Task D.2.d) and representativeness (Task D.2.g) of a public health surveillance system are related to data quality. With data of high quality, the system can be accepted by those who participate in it. In addition, the system can accurately represent the health-related event under surveillance.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001,"Flexibility is probably best evaluated retrospectively by observing how a system has responded to a new demand. An important characteristic of CDC's Behavioral Risk Factor Surveillance System (BRFSS) is its flexibility (39 ). Conducted in collaboration with state health departments, BRFSS is an ongoing sample survey that gathers and reports state-level prevalence data on health behaviors related to the leading preventable causes of death as well as data on preventive health practices. The system permits states to add questions of their own design to the BRFSS questionnaire but is uniform enough to allow state-to-state comparisons for certain questions. These state-specific questions can address emergent and locally important health concerns.
In addition, states can stratify their BRFSS samples to estimate prevalence data for regions or counties within their respective states.","Unless efforts have been made to adapt the public health surveillance system to another disease (or other health-related event), a revised case definition, additional data sources, new information technology, or changes in funding, assessing the flexibility of that system might be difficult. In the absence of practical experience, the design and workings of a system can be examined. Simpler systems might be more flexible (i.e., fewer components will need to be modified when adapting the system for a change in information needs or operating conditions)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001,"The assessment of sensitivity and of PVP provide different perspectives regarding how well the system is operating. Depending on the objectives of the public health surveillance system, assessing PVP whenever sensitivity has been assessed might be necessary (47-50,53 ). In this report, PVP is represented by A/(A+B) (Table 3).

In assessing PVP, primary emphasis is placed on the confirmation of cases reported through the surveillance system. The effect of PVP on the use of public health resources can be considered on two levels. At the level of case detection, PVP affects the amount of resources used for case investigations. For example, in some states, every reported case of type A hepatitis is promptly investigated by a public health nurse, and contacts at risk are referred for prophylactic treatment. A surveillance system with low PVP, and therefore frequent ""false-positive"" case reports, would lead to misdirected resources.

At the level of outbreak (or epidemic) detection, a high rate of erroneous case reports might trigger an inappropriate outbreak investigation. Therefore, the proportion of epidemics identified by the surveillance system that are true epidemics can be used to assess this attribute.

Calculating the PVP might require that records be kept of investigations prompted by information obtained from the public health surveillance system. At the level of case detection, a record of the number of case investigations completed and the proportion of reported persons who actually had the health-related event under surveillance would allow the calculation of the PVP. At the level of outbreak detection, the review of personnel activity reports, travel records, and telephone logbooks might enable the assessment of PVP. For some surveillance systems, however, a review of data external to the system (e.g., medical records) might be necessary to confirm cases to calculate PVP. Examples of data sources used to assess the PVP of health information or public health surveillance systems include medical records (48,57 ), registries (49,58 ), and death certificates (59 ).

To assess the PVP of the system adequately, calculating more than one measurement of the attribute might be necessary. For example, PVP could be determined for the system's data fields, for each data source or combinations of data sources (48 ), or for specific health-related events (49 ).","PVP is important because a low value means that noncases might beinvestigated, and outbreaks might be identified that are not true but are instead artifacts of the public health surveillance system (e.g., a ""pseudo-outbreak""). False-positive reports can lead to unnecessary interventions, and falsely detected outbreaks can lead to costly investigations and undue concern in the population under surveillance. A public health surveillance system with a high PVP will lead to fewer misdirected resources.

The PVP reflects the sensitivity and specificity of the case definition (i.e., the screening and diagnostic tests for the health-related event) and the prevalence of the health-related event in the population under surveillance. The PVP can improve with increasing specificity of the case definition. In addition, good communication between the persons who report cases and the receiving agency can lead to an improved PVP.",N/A,N/A,N/A,N/A,N/A,CDC 2001,"Representativeness is assessed by comparing the characteristics of reported events to all such actual events. Although the latter information is generally not known, some judgment of the representativeness of surveillance data is possible, based on knowledge of
* characteristics of the population, including, age, socioeconomic status, access to health care, and geographic location (60 );
* clinical course of the disease or other health-related event (e.g., latency period, mode of transmission, and outcome [e.g., death, hospitalization, or disability]);
* prevailing medical practices (e.g., sites performing diagnostic tests and physician-referral patterns) (33,61 ); and
* multiple sources of data (e.g., mortality rates for comparison with incidence data and laboratory reports for comparison with physician reports).

Representativeness can be examined through special studies that seek to identify a sample of all cases. For example, the representativeness of a regional injury surveillance system was examined using a systematic sample of injured persons (62 ). The study examined statistical measures of population variables (e.g., age, sex, residence, nature of injury, and hospital admission) and concluded that the differences in the distribution of injuries in the system's database and their distribution in the sampled data should not affect the ability of the surveillance system to achieve its objectives.

For many health-related events under surveillance, the proper analysis and interpretation of the data require the calculation of rates. The denominators for these rate calculations are often obtained from a completely separate data system maintained by another agency (e.g., the United States Bureau of the Census in collaboration with state governments [63 ]). The choice of an appropriate denominator for the rate calculation should be given careful consideration to ensure an accurate representation of the health-related event over time and by place and person. For example, numerators and denominators must be comparable across categories (e.g., race [64 ], age, residence, and/or time period), and the source for the denominator should be consistent over time when measuring trends in rates. In addition, consideration should be given to the selection of the standard population for the adjustment of rates (65 )","To generalize findings from surveillance data to the population at large, the data from a public health surveillance system should accurately reflect the characteristics of the health-related event under surveillance. These characteristics generally relate to time, place, and person. An important result of evaluating the representativeness of a surveillance system is the identification of population subgroups that might be systematically excluded from the reporting system through inadequate methods of monitoring them. This evaluation process enables appropriate modification of data collection procedures and more accurate projection of incidence of the health-related event in the target population (66 ).

For certain health-related events, the accurate description of the event over time involves targeting appropriate points in a broad spectrum of exposure and the resultant disease or condition. In the surveillance of cardiovascular diseases, for example, it might be useful to distinguish between preexposure conditions (e.g., tobacco use policies and social norms), the exposure (e.g., tobacco use, diet, exercise, stress, and genetics), a pre-symptomatic phase (e.g., cholesterol and homocysteine levels), early-staged disease (e.g., abnormal stress test), late-staged disease (e.g., angina and acute myocardial infarction), and death from the disease. The measurement of risk factor behaviors (e.g., tobacco use) might enable the monitoring of important aspects in the development of a disease or other health-related event.

Because surveillance data are used to identify groups at high risk and to target and evaluate interventions, being aware of the strengths and limitations of the system's data is important. Errors and bias can be introduced into the system at any stage (67 ). For example, case ascertainment (or selection) bias can result from changes in reporting practices over time or from differences in reporting practices by geographic location or by health-care providers. Differential reporting among population subgroups can result in misleading conclusions about the health-related event under surveillance.",N/A,N/A,N/A,N/A,N/A,CDC 2001,"The measurement of the sensitivity of a public health surveillance system is affected by the likelihood that
* certain diseases or other health-related events are occurring in the population under surveillance;
* cases of certain health-related events are under medical care, receive laboratory testing, or are otherwise coming to the attention of institutions subject to reporting requirements;
* the health-related events will be diagnosed/identified, reflecting the skill of health-care providers and the sensitivity of screening and diagnostic tests (i.e., the case definition); and
* the case will be reported to the system.
These situations can be extended by analogy to public health surveillance systems that do not fit the traditional disease care-provider model. For example, the sensitivity of a telephone-based surveillance system of morbidity or risk factors is affected by
* the number of persons who have telephones, who are at home when the call is placed, and who agree to participate;
* the ability of persons to understand the questions and correctly identify their status; and
* the willingness of respondents to report their status.
The extent to which these situations are explored depends on the system and on the resources available for assessing sensitivity. The primary emphasis in assessing sensitivity — assuming that most reported cases are correctly classified — is to estimate the proportion of the total number of cases in the population under surveillance being detected by the system, represented by A/(A+C) in this report (Table 3).

Approaches that have been recommended for improving sensitivity of reporting vaccine-preventable diseases might be applicable to other health-related events (44 ). For example, the sensitivity of a systemmight be improved by
* conducting active surveillance (i.e., contacting all providers and institutions responsible for reporting cases);
* using external standards (or other surveillance indicators) to monitor the quality of case reporting;
* identifying imported cases;
* tracking the number of cases of suspected disease that are reported, investigated, and ruled out as cases;
* monitoring the diagnostic effort (e.g., tracking submission of laboratory requests for diagnostic testing); and
* monitoring the circulation of the agent (e.g., virus or bacterium) that causes the disease.

The capacity for a public health surveillance system to detect outbreaks (or other changes in incidence and prevalence) might be enhanced substantially if detailed diagnostic tests are included in the system. For example, the use of molecular subtyping in the surveillance of Escherichia coli O157:H7 infections in Minnesota enabled the surveillance system to detect outbreaks that would otherwise have gone unrecognized (45 ).
The measurement of the sensitivity of the surveillance system (Table 3) requires a) collection of or access to data usually external to the system to determine the true frequency of the condition in the population under surveillance (46 ) and b) validation of the data collected by the system. Examples of data sources used to assess the sensitivity of health information or public health surveillance systems include medical records (47,48 ) and registries (49,50 ). In addition, sensitivity can be assessed through estimations of the total cases in the population under surveillance by using capture-recapture techniques (51,52 ).
To adequately assess the sensitivity of the public health surveillance system, calculating more than one measurement of the attribute might be necessary. For example, sensitivity could be determined for the system's data fields, for each data source or for combinations of data sources (48 ), for specific conditions under surveillance (53 ), or for each of several years (54 ). The use of a Venn diagram might help depict measurements of sensitivity for combinations of the system's data sources (55 ).","A literature review can be helpful in determining sensitivity measurements for a public health surveillance system (56 ). The assessment of the sensitivity of each data source, including combinations of data sources, can determine if the elimination of a current data source or if the addition of a new data source would affect the overall surveillance results (48 ).

A public health surveillance system that does not have high sensitivity can still be useful in monitoring trends as long as the sensitivity remains reasonably constant over time. Questions concerning sensitivity in surveillance systems most commonly arise when changes in the occurrence of a health-related event are noted. Changes in sensitivity can be precipitated by some circumstances (e.g., heightened awareness of a health-related event, introduction of new diagnostic tests, and changes in the method of conducting surveillance). A search for such ""artifacts"" is often an initial step in outbreak investigations.",N/A,CDC 2001,"A chart describing the flow of data and the lines of response in a surveillance system can help assess the simplicity or complexity of a surveillance system. A simplified flow chart for a generic surveillance system is included in this report (Figure 1).
The following measures (see Task B.2) might be considered in evaluating the simplicity of a system: amount and type of data necessary to establish that the health-related event has occurred (i.e., the case definition has been met)
* amount and type of other data on cases (e.g., demographic, behavioral, and exposure information for the health-related event);
* number of organizations involved in receiving case reports;
* level of integration with other systems;
* method of collecting the data, including number and types of reporting sources, and time spent on collecting data;
* amount of follow-up that is necessary to update data on the case;
* method of managing the data, including time spent on transferring, entering, editing, storing, and backing up data;
* methods for analyzing and disseminating the data, including time spent on preparing the data for dissemination;
* staff training requirements; and
* time spent on maintaining the system.","Thinking of the simplicity of a public health surveillance system from the design perspective might be useful. An example of a system that is simple in design is one with a case definition that is easy to apply (i.e., the case is easily ascertained) and in which the person identifying the case will also be the one analyzing and using the information. A more complex system might involve some of the following:
* special or follow-up laboratory tests to confirm the case;
* investigation of the case, including telephone contact or a home visit by public health personnel to collect detailed information;
* multiple levels of reporting (e.g., with the National Notifiable Diseases
Surveillance System, case reports might start with the health-care provider who makes the diagnosis and pass through county and state health departments before going to CDC [29 ]); and
* integration of related systems whereby special training is required to collect and/or interpret data.
Simplicity is closely related to acceptance and timeliness. Simplicity also affects the amount of resources required to operate the system",N/A,N/A,N/A,N/A,N/A,CDC 2001,"Measures of the system's stability can include
* the number of unscheduled outages and down times for the system's computer;
* the costs involved with any repair of the system's computer, including parts, service, and amount of time required for the repair;
* the percentage of time the system is operating fully;
* the desired and actual amount of time required for the system to collect or receive data;the desired and actual amount of time required for the system to manage the data, including transfer, entry, editing, storage, and back-up of data; and
* the desired and actual amount of time required for the system to release data.","A lack of dedicated resources might affect the stability of a public health surveillance system. For example, workforce shortages can threaten reliability and availability. Yet, regardless of the health-related event being monitored, a stable performance is crucial to the viability of the surveillance system. Unreliable and unavailable surveillance systems can delay or prevent necessary public health action.

A more formal assessment of the system's stability could be made through modeling procedures (73 ). However, a more useful approach might involve assessing stability based on the purpose and objectives of the system.",N/A,N/A,N/A,N/A,N/A,CDC 2001,"A simplified example of the steps in a public health surveillance system is included in this report (Figure 2). The time interval linking any two of these steps can be examined. The interval usually considered first is the amount of time between the onset of a health-related event and the reporting of that event to the public health agency responsible for instituting control and prevention measures. Factors affecting the time involved during this interval can include the patient's recognition of symptoms, the patient's acquisition of medical care, the attending physician's diagnosis orsubmission of a laboratory test, the laboratory reporting test results back to the physician and/or to a public health agency, and the physician reporting the event to a public health agency. Another aspect of timeliness is the time required for the identification of trends, outbreaks, or the effect of control and prevention measures. Factors that influence the identification process can include the severity and communicability of the health-related event, staffing of the responsible public health agency, and communication among involved health agencies and organizations. The most relevant time interval might vary with the type of health-related event under surveillance. With acute or infectious diseases, for example, the interval from the onset of symptoms or the date of exposure might be used. With chronic diseases, it might be more useful to look at elapsed time from diagnosis rather than from the date of symptom onset.","The timeliness of a public health surveillance system should be evaluated in terms of availability of information for control of a health-related event, including immediate control efforts, prevention of continued exposure, or program planning.
The need for rapidity of response in a surveillance system depends on the nature of the health-related event under surveillance and the objectives of that system. A study of a public health surveillance system for Shigella infections, for example, indicated that the typical case of shigellosis was brought to the attention of health officials 11 days after onset of symptoms — a period sufficient for the occurrence of secondary and tertiary transmission. This example indicates that the level of timeliness was not satisfactory for effective disease control (68 ). However, when a long period of latency occurs between exposure and appearance of disease, the rapid identification of cases of illness might not be as important as the rapid availability of exposure data to provide a basis for interrupting and preventing exposures that lead to disease. For example, children with elevated blood lead levels and no clinically apparent illness are at risk for adverse health-related events. CDC recommends that follow-up of asymptomatic children with elevated blood lead levels include educational activities regarding lead poisoning prevention and investigation and remediation of sources of lead exposure (69 ).
In addition, surveillance data are being used by public health agencies to track progress toward national and state health objectives (38,70 ).

The increasing use of electronic data collection from reporting sources (e.g., an electronic laboratory-based surveillance system) and via the Internet (a web-based system), as well as the increasing use of electronic data interchange by surveillance systems, might promote timeliness (6,29,71,72 ).",N/A,CDC 2001,"An assessment of the usefulness of a public health surveillance system should begin with a review of the objectives of the system and should consider the system's effect on policy decisions and disease-control programs. Depending on the objectives of a particular surveillance system, the system might be considered useful if it satisfactorily addresses at least one of the following questions. Does the system
* detect diseases, injuries, or adverse or protective exposures of public importance in a timely way to permit accurate diagnosis or identification, prevention or treatment, and handling of contacts when appropriate?
* provide estimates of the magnitude of morbidity and mortality related to the health-related event under surveillance, including the identification of factors associated with the event?
* detect trends that signal changes in the occurrence of disease, injury, or adverse or protective exposure, including detection of epidemics (or outbreaks)?
* permit assessment of the effect of prevention and control programs?
* lead to improved clinical, behavioral, social, policy, or environmental practices?
or
* stimulate research intended to lead to prevention or control?","Usefulness might be affected by all the attributes of a public health surveillance system (see Task D.2, Describe Each System Attribute). For example, increased sensitivity might afford a greater opportunity for identifying outbreaks and understanding the natural course of an adverse health-related event in the population under surveillance. Improved timeliness allows control and prevention activities to be initiated earlier. Increased predictive value positive enables public health officials to more accurately focus resources for control and prevention measures. A representative surveillance system will better characterize the epidemiologic characteristics of a health-related event in a defined population. Public health surveillance systems that are simple, flexible, acceptable, and stable will likely be more complete and useful for public health action",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,
arinikEvaluationFrameworkComparing2023,13550,Arinik 2023,An Evaluation Framework for Comparing Epidemic Intelligence Systems,An Evaluation Framework For Comparing Epidemic Intelligence Systems,2023,Nejat Arinik,nejat.arinik@inrae.fr,France,Evaluation framework designed to study and compare EBS systems and their output,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Extraction of Event Database,Goal is to identify common events between two event databases in an automatic manner,"Let E1 (resp. E2) be two event databases associated with IBS or EBS systems, containing NE1 and NE2 events, respectively. Also, we assume NE1 ≤ NE2 without loss of generality. Moreover, let S be the NE1 × NE2 similarity matrix of E1 and E2. The term S<sub>ij</sub>, with 1 ≤ i ≤ NE1 and 1 ≤ j ≤ NE2, represents the similarity score between events e<sub>i</sub> and e<sub>j</sub>, and it is calculated as described in Section I of the Appendix. Then, we look for a bijection: {1, 2, ..., NE1 } →{1, 2, ..., NE2 } such that the objective is to maximize the similarity between E1 and E2, as defined in Equation 1.
","The solution of the assignment problem, some events might be assigned to other events with negative or weak positive similarity scores. Therefore, we perform a post-processing by removing the assignment results, whose similarity scores are lower than some threshold value",N/A,Comparison Analysis,"The second step consists in performing a retrospective analysis of these events with four objectives: 1) spatial, 2) temporal, 3) thematic and 4) source dimensions","In the definition of the spatio-temporal representativeness, we say that an EBS system represents well a specific geographic zone for a given time interval, if it finds at least one event in ER. For this reason, its calculation requires fixing the spatial and temporal scales of the events in E (resp. ER) with lZ and lT , i.e. ElZlT (resp. ER lZlT ). Since there can be some reporting delay between the events of E and ER, we also consider in this calculation the previous (resp. next) time interval in order not to penalize an EBS system. For a given geographic zone, we perform this calculation for all the time intervals, and then we take their average to obtain a final score. This score is in the range [0, 1], where the score of 0 (resp. 1) indicates that ElZlT never (resp. always) finds an event in ERlZlT for a given geographic zone",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Event-Based Surveillance (EBS) systems have been proposed with the aim of promoting the early identification and characterization of potential epidemiological events from online sources of any nature, including online news outlets and social media, thanks to the recent developments in internet and digital technologies",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Spatial dimension,Spatial analysis: how the events are geographically distributed,Our evaluation strategy for the spatial dimension relies on the concept representativeness,Temporal dimension,Temporal analysis: how the events evolve over time and what temporal aspects characterize it,"For the temporal dimension, we include two evaluation assessments. The first one is a quantitative assessment based on the concept timeliness (Section III-D1). The second one is a qualitative assessment related to the consistent periodic behavior of the events (Section III-D2).",Thematic dimension,Thematic entity analysis: what thematic entities are extracted from the events and how they are related to spatiotemporal analysis,"Detailed information, as in a gold standard database ER. Note that this aspect is related to one of the relevant characteristics of an EBS system in the CDC's guideline, so-called completeness [14].",Source dimension,New outlet analysis: what news sources play key role in epidemiological information dissemination,"Our evaluation scheme consists of two different objectives.
Our first objective is that we want to identify important news outlets for information dissemination. In our second objective, we are interested in the ability of news reporting in timely manner.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The ability of describing accurately the distribution of events in terms of place, time and host",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The ability of identifying disease events in a timeframe enabling utilization of the information by decision makers to mitigate potentially dangerous situations as soon as possible.,N/A,"One specific criteria that one may want to optimize in event
detection is to minimize detection time (i.e. capturing an epidemiological event as soon as possible).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"In this article, we have presented a new evaluation framework to identify the strengths and drawbacks of EBS systems in terms of epidemic surveillance.",N/A,N/A,N/A,
auerCanadianAboriginalCommunities2001,2415,Auer 2001,Canadian Aboriginal communities: a framework for injury surveillance.,Canadian Aboriginal communities: a framework for injury surveillance,2001,Anna Marta Auer,aauer@sprint.ca,Canada,Conceptual design of an injury surveillance framework that would be culturally relevant within Aboriginal communities,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,Canada,l. No framework(s) or guidance document(s) were discussed,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Community-based focus group: team members from the first of four pilot communities,N/A,National focus group: representatives from the funding body supporting the study initiative as well as representatives from national Aboriginal organizations,The overall purpose of the national focus group was to establish consensus on the conceptual framework that would guide the further development of the injury surveillance system.,N/A,N/A,National focus group: Aboriginal community-based practitioners from across Canada,The overall purpose of the national focus group was to establish consensus on the conceptual framework that would guide the further development of the injury surveillance system.,N/A,N/A,"National focus group: ‚injury data experts.
These participants had international, national and community-based experience related to injury surveillance.",The overall purpose of the national focus group was to establish consensus on the conceptual framework that would guide the further development of the injury surveillance system.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Acceptability of the surveillance system by the focus group was linked to the system being available in both manual (paper) and electronic (computer) formats; the ability of the system to link data to action; and data being timely and placed in the hands of the community as soon as possible.,N/A,"Acceptability of the surveillance system by the focus group was linked to the system being available in both manual (paper) and electronic (computer) formats, the ability of the system to link data to action, and data being timely and placed in the hands of the community as soon as possible.

The dual platform was specifically identified in
order to address the requirements of smaller,
resource-limited, reserve-based communities. A
manual format was considered feasible for
communities working with a small population
(400-2000 residents) and without access to
computers",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Modifiable to local needs,N/A,"As previously noted, the medical management of injured patients from reserve-based communities varies based on factors such as geographic location, size and isolation, social and economic infrastructures, and health service providers internal and external to the community. As such, flexibility, as a design element, was considered primary to the viability of an injury surveillance system for reserve-based communities. Specifically, Aboriginal community-based practitioners identified the need for the system to allow for multi-site and multi-disciplinary data collection.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Works as a surveillance tool linked to action (i.e. describes, identifies, monitors, and provides community information for community action)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Collects information on cause, nature and circumstances of injury using qualitative and quantitative information

Works as a periodic monitoring tool (i.e. data helps community monitor and evaluate initiatives and programs)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Works as a surveillance tool linked to action (i.e. describes, identifies, monitors, and provides community information for community action)",N/A,N/A,N/A,"Simple to use (i.e. simple to collect data)

Data simple to pull out (i.e. easy and straightforward to analyse)

Common core variables

Data in the hands of the community as soon as possible",N/A,Simplicity was associated with the process of data collection as well as analyses and timely reporting,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Data in the hands of the community as soon as possible,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"A notable incongruency related to the issue of comparability. Although highly desirable and advocated by data experts in the group, the issue of comparability did not appear as high a priority for community-based practitioners. The primary concern of practitioners was that the system should have the capacity to collect meaningful data sufficient to describe the magnitude and nature of a community's injury problems, and to monitor community-based injury trends. Despite discussions outlining the benefits of comparability, community-based practitioners remained focused on‚ local needs and issues related to internal rather than external validity.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Potentially, personnel coming from various disciplines, diverse educational backgrounds, and varied levels of educational preparation can significantly influence data collection. Moreover, data management becomes the unique domain of the community.
As such, data management issues such as confidentiality, data storage and handling, and report generation become the jurisdiction of the community. Other limitations of the proposed system relate to the quality of data, the ability to compare data over time, and the ability to compare or interface with larger datasets at treaty, provincial/territorial or national levels.

The quality of data will be subject to such factors as skill levels, the availability of regular training, the ability to conduct data audits, and staff turnover at the community level.",N/A,N/A,"Declich, S. and Carter, A. O. (1994) Public health surveillance: historical origins, methods and evaluation. Bulletin of the World Health Organization, 72, 285-304.

Klauke, D. N. (1992) Evaluating public health surveillance systems. In Halperin, W. and Baker, E. L. (eds) Public Health Surveillance. Van Nostrand Reinhold, New York.

","Attributes of a culturally relevant system were defined as requiring data analyses and management being carried out within the community, and data col- lection being flexible, allowing for multi-site and multi-disciplinary data collection.

",
auerRelevanceWHOInjury2011,1594,Auer 2011,The relevance of WHO injury surveillance guidelines for evaluation: learning from the aboriginal community-centered injury surveillance system (ACCISS) and two institution-based systems.,The relevance of WHO injury surveillance guidelines for evaluation: learning from the Aboriginal Community-Centered Injury Surveillance System (ACCISS) and two institution-based systems,2011,Anna M Auer,aauer@shaw.ca,Sweden,Evaluation framework for injury surveillance systems at a community level,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,"Canada, China, and Scotland - reference provides a framework but also provides a comparative evaluation of three surveillance systems",k. Other,Injury Surveillance Guidelines (WHO 2001),Description of Injury Surveillance System Characteristics,"a. Focus (intentional - unintentional - all injuries - select injuries - population specific);  
b. Scope (local - regional - national); 
c. Level of Multiplicity (number & complexity of: sites - processes - policies - staff - stakeholders /end-users); 
d. General ISS Goals & Objectives; 
e. Age (period of operation) & Status of System (time limited project/pilot study - early implementation - ongoing established program); 
f. Locus of Operational Management (leadership - organizational structure & mandate)",N/A,N/A,N/A,Measurement of System Specific Metrics (operations and operational environment),"What are the key assumptions & rationale - relative to each key activity? 
What does each key activity entail?","Measurement of system attributes across all four key injury surveillance activities (collection, analysis, interpretation, and dissemination (active/passive)).",N/A,Acceptability is considered the evaluation focus.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Typically, injury data are being collected through a network of community-based services such as day care facilities, health centres, schools, Elders facilities, and home and community care programs. Community-centered networks are congruent and unique to the infrastructure of each community.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,"
Epidemiologic Dimensions",N/A,"Simplicity, flexibility, reliability, security and confidentiality, and acceptability",Public Health Dimensions,N/A,"Acceptability, utility, timeliness, and sustainability",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,People are willing to participate & are getting the results they need,"Process evaluation 
Identification of duplicate cases, wrongfully classified cases, missed cases & incorrect codes
Assessment of procedures -completion times, confidentiality

Method - review of data records & field observations of data collection processes

System environment evaluation 
Assessment of how well staff are able to operate the system relative to data collection, report generation & dissemination

Method - staff interviews, questionnaires processes (training, resources, confidentiality, reports generated, dissemination, data use)","Acceptability as an attribute considers the willingness of individuals to participate in the system as well as whether results are being achieved. From this viewpoint, the attribute of acceptability encompassed data collection as well as a range of additional factors when considered in relation to data analysis, interpretation, and dissemination. The relevance of acceptability in relation to the ACCISS was linked to numerous factors, each of which consistently interrelated to each respective attribute of a good surveillance system and surveillance activities. Some of these factors included: the affordability of the data management tools; positive hands-on learning experiences associated with seeing and working with injury data; the capacity to self-generate reports; the ability to produce data that was considered relevant in the day-to-day work of staff; and the capacity of each project community to independently respond to emerging injury issues.

Further, acceptability as described in the WHO guidelines does not explicitly address cultural relevance, yet several key aspects important to First Nations were found to be connected with acceptability. These aspects related to the: system working well within varied community populations and geographic environments; adaptability of the system in the face of varied skill sets; and data collection networks tailored to operate in relation to community-specific infrastructures. Another critical factor was the central importance and application of principles related to ownership, control, access, and possession, otherwise known as OCAP principles [27]. Acceptability was transparently linked to the cultural relevance of the ACCISS.


Level of need, capacity, readiness - to undertake key activities
Level of acceptability of the general goals & objectives of the ISS 
Level of acceptability - in relation to cultural factors 
Level of acceptability of the ISS relative to competing demands & available resources 
Level of acceptability regarding processes, policies, procedures & results - relative to each key activity 
Level of stakeholder involvement - relative to activity, frequency of involvement & level of input","Factors related to staff included: staffing levels and workload; staff support, motivation and perceptions; time limitations; and levels of training. 
Factors related to injury surveillance functions included: confidentiality; operating costs; levels of complexity and resources associated with each injury surveillance function; and the capacity to tailor and manage flexible processes [9-11]. 
Other key factors were related to: the ability to evaluate the reach and use of data collected by ISS; leadership support and continuity; involvement in decision-making processes; visible successes; measureable achievements; and the capacity to recognize, involve, and meet end-user needs [9-11].",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Easy to change as needed or desirable,Unclear,"Similarly, flexibility considered data collection tools and processes as well as the ability to tailor data analysis, interpretation, and dissemination functions to the needs and interests of each project community. 

Practical ability - to change or modify instrumentation & processes 
Capacity to respond - to staff, stakeholder, end-user needs 
Adaptable management of system",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"(Confidence in data)

Confidence in the reliability of the information
Sensitivity 
(injury & accuracy rates) 
PPV
Other measures",Unclear,"the efficacy of using sensitivity and PPV as metrics of reliability at the community level was determined to be very low by the ACCISS evaluation team.

Methods to assess data & key injury surveillance activities aligned with ISS 
Monitoring methods consistent & balanced across key activities",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Produces data in the most simple way,Unclear,"Simplicity from an end-user perspective considered whether activities related to analysis, interpretation, and dissemination were sufficiently straightforward to ensure that these activities could be undertaken by community-based staff.

Instrumentation - data variables, length of forms, clarity, ease of use 
Processes, procedures & policies - relative to staff, stakeholders, end-users",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Generates up to date information as needed,"System environment evaluation Assessment of how well staff are able to operate the system relative to data collection, report generation & dissemination

Method - staff interviews, questionnaires processes (training, resources, confidentiality, reports generated, dissemination, data use)","Lastly, utility, timeliness, and sustainability focus primarily on the practicality of procedures, budget, the ability to generate timely information, and system maintenance placing emphasis on staff and the supporting agencies actively involved in performing data related functions. Attention to data dissemination, the use of knowledge, and factors related to sustainability is notably limited in the WHO guidelines. Accordingly, these attributes shift the balance of attention towards data management and away from data dissemination and end-users needs.

Capacity to identify injury issues & risk factors 
Straightforward mechanisms to access injury data 
Timely injury surveillance activities - supporting timely use & action",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Security and Confidentiality: 
Records kept secure & individual case information kept confidential",Unclear,"Methods to assess security of data records 
Methods to protect & assess confidentiality",N/A,Utility: Practical Affordable,"System environment evaluation: Assessment of how well staff are able  to operate the system relative to data  collection, report generation &  dissemination; 
Method - staff interviews, questionnaires processes  (training, resources, confidentiality, reports generated,  dissemination, data use)","Lastly, utility, timeliness, and sustainability focus primarily on the practicality of procedures, budget, the ability to generate timely information, and system maintenance placing emphasis on staff and the supporting agencies actively involved in performing data related functions. Attention to data dissemination, the use of knowledge, and factors related to sustainability is notably limited in the WHO guidelines. Accordingly, these attributes shift the balance of attention towards data management and away from data dissemination and end-users needs.  Value relative to the degree of practicality, reasonableness & affordability - relative to each key  activity  Value of ISS - relative to diverse viewpoints within political, cultural, historical, economic value  systems e.g. data collector, public health practitioner, funder  Stakeholder / End User defined needs, challenges, benefits",N/A,Sustainability: Easy to maintain & update & continues to serve its purpose,"System environment evaluation: Assessment of how well staff are able  to operate the system relative to data  collection, report generation &  dissemination.  
Method - staff interviews, questionnaires processes  (training, resources, confidentiality, reports generated,  dissemination, data use)","Lastly, utility, timeliness, and sustainability focus primarily on the practicality of procedures, budget, the ability to generate timely information, and system maintenance placing emphasis on staff and the supporting agencies actively involved in performing data related functions. Attention to data dissemination, the use of knowledge, and factors related to sustainability is notably limited in the WHO guidelines. Accordingly, these attributes shift the balance of attention towards data management and away from data dissemination and end-users needs.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The WHO guidelines provide only a basic platform for evaluation. The guidelines over emphasize epidemiologic attributes and methods and under emphasize public health and injury prevention perspectives requiring adaptation for context-based relevance. Evaluation elements related to the dissemination and use of knowledge, acceptability, and the sustainability of ISS are notably inadequate. From a public health perspective, alternative reference points are required for re-conceptualizing evaluation paradigms. 

Findings suggest that attributes of a good surveillance system, when used as evaluation metrics, cannot be weighted equally across ISS. In addition, the attribute of acceptability likely holds more relevance than previously recognized and should be viewed as a critical underpinning attribute of ISS. Context-oriented evaluations sensitive to distinct operational environments are more likely to address knowledge gaps related to; understanding links between the production of injury data and its use, and the effectiveness, impact, and
sustainability of ISS. Current frameworks are predisposed to disassociating epidemiologic approaches from subjective factors and social processes.

The relevance of the guidelines required consideration in view of the age and stage of the ACCISS as a program within the project communities. The nature and level of attention to the epidemiologic dimensions of the attributes shifted during pre-implementation and implementation stages. More time and emphasis was placed on monitoring the epidemiologic dimensions of the attributes during the early stages of implementation and less time afterward as data collection activities became more established. As data collection activities stabilized and became more routine, attention increasingly shifted towards the public health dimensions of data analysis, interpretation, and dissemination to promote use of injury data by end-users.

Closely aligned with the four key functions of surveillance, reported results highlighted a significant and weighted emphasis on data collection with little to no emphasis directed towards data analysis, interpretation, and dissemination.

The relevance of the guidelines appeared contingent on the interpretation and use of the guidelines in relation to the age and status, locus of operational management, and design of the system.

The scope of issues identified relative to the evaluation of ISS is significant and the standard application of measures and methods of evaluation present challenges across different operational settings. Systematic attention to evaluation issues and methods, however, may support a starting place for re-conceptualizing evaluation frameworks.

The key finding identifies that the evaluation components of the WHO guidelines are disproportionately focused on data collection instruments and injury surveillance functions largely associated with data collection. Although this focus contributes to ensuring quality
data, at the same time it deflects attention from the dissemination and use of information by end-users central to a public health perspective.

In varying degrees, there appears to be a common presumption of understanding as to what each of these activities entails and consequently how these activities are carried out, when in reality these functions can vary significantly by the structure and operational environments in which ISS exist.

Moreover, the issue of data accessibility by end-users in relation to these functions is often poorly delineated or addressed.

Although the effective use of data, acceptability, and the sustainability of ISS represent primary concerns, clarity relative to how these aspects should be considered and evaluated remain relatively unfocused and unaddressed.",N/A,N/A,"Holder Y, Peden M, Krug E, Lund J, Gururaj G, Kobusingye O: Injury Surveillance Guidelines. World Health Organization; 2001.",N/A,
azofeifaEvaluatingBehavioralHealth2018,718,Azofeifa 2018,Evaluating Behavioral Health Surveillance Systems.,Evaluating Behavioral Health Surveillance Systems,2018,Donna F. Stroup,donnafstroup@dataforsolutions.com,N/A,Framework for evaluating behavioural health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,l. No framework(s) or guidance document(s) were discussed,N/A,Inputs,"* Staff 
* Data sources 
* Infrastructure 
* Equipment 
* Funding sources 
* Legislative support 
* Partner organization 
* Tools for data collection",N/A,N/A,Logic model for behavioural health surveillance.,Activities,"1. Develop surveillance
1a. Identify goals
1b. Select and develop case definitions and indicators
1c. Link existing data sources
1d. Select sites or population coverage
1e. Develop and implement a protocol with uniform guidelines
1f. Establish pilot for surveillance of behavioral health conditions
1g. Assess data quality and utility
1h. Develop and test methods for data analysis
1i. Analyze data and interpret findings
1j. Develop and write surveillance reports
1k. Disseminate surveillance results
1l. Develop strategies for sustaining surveillance
2. Engage partners
3. Evaluate and monitor",N/A,N/A,Logic model for behavioural health surveillance.,Outputs,"* Data for ongoing monitoring of trends in behavioral health indicators
* Surveillance activities
* Reports and recommendations
* Increases in evidence-based interventions, planning, and evaluation
* Identification of modifiable behavioral risk factors",N/A,N/A,Logic model for behavioural health surveillance.,Short-Term Outcomes,"* Enhanced knowledge of behiovral health patterns
* Uniform national or statewide implementation of surveillance programs
* Patients/clients receive counselling or treatment
* Increase in prevention/intervention programs for populations most in need",N/A,N/A,Logic model for behavioural health surveillance.,Midterm Outcomes,"* Identification of access barriers for counselling and treatment facilities
* Health care system treat, refer, and improve self-management of behavioral health conditions (e.g., substance abuse, mental health)
Improved community outreach programs
Increase in patient/client knowledge, attitudes, and beliefs",N/A,N/A,Logic model for behavioural health surveillance.,Long-Term Outcomes,"* Policy change
* Reduction in behavioral health conditions (e.g., substance misuse, mental health problems)
* Improved infrastructure for managing behavioral health conditions (e.g., substance misuse, mental health problems)
* Increase in patient/client knowledge, attitudes, and beliefs about behavioral health conditions
* Change in risk behaviors",N/A,N/A,Logic model for behavioural health surveillance.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Objectives of a behavioural health surveillance system could be inferred from the provided long-term outcomes from the logic model.,N/A,N/A,N/A,Public health scientists with experience in behavioral health surveillance and epidemiology.,"These experts came from the Substance Abuse and Mental Health Services Administration (SAMHSA), the Centers for Disease Control and Prevention (CDC), local and state health departments, and other partner organizations.",N/A,N/A,Federal and state surveillance epidemiologists with experience in behavioral health surveillance and epidemiology.,"These experts came from the Substance
Abuse and Mental Health Services Administration (SAMHSA), the Centers for Disease Control and Prevention (CDC), local and state health departments, and other partner organizations.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Acceptability is the willingness of individuals and groups (e.g., survey respondents, patients, health care providers, organizations) to participate in a public health surveillance system (9).","For behavioral surveillance, acceptability includes the willingness of people outside the sponsoring agency to report accurate, consistent, complete, and timely data. Factors influencing the acceptability of a particular system include: 
* Perceived public health importance of a health condition or behavior, risk factor, thought, or policy; 
* Nature of societal norms regarding the risk behavior or outcome (discrimination or stigma); 
* Collective perception of privacy protection and government trustworthiness; 
*Dissemination of public health data to reporting sources and interested parties; 
* Responsiveness of the sponsoring agency to recommendations or comments; 
* Costs to the person or agency reporting data, including simplicity, time required to enter data into the system, and whether the system is passive or active; 
* Federal and state statutes ensuring privacy and confidentiality of data reported; 
* Community participation in the system. When a new system imposes additional reporting requirements and increased burden on public health professionals, acceptability can be indicated by topic-specific or agency-specific participation rate, interview completion and question refusal rates, completeness of reporting, reporting rate, and reporting timeliness.","Assessment of acceptability includes considerations of other attributes, including simplicity and timeliness. Acceptability is directly related to the extent to which the surveillance system successfully addresses stigma associated with certain conditions, which is particularly important for behavioral surveillance, in terms of both the extent to which the questions included in the survey questionnaire are sensitive to the reluctance people may have to report various behavioral health problems and the nonjudgmental quality of questions.","* Perceived public health importance of a health condition or behavior, risk factor, thought, or policy
* Nature of societal norms regarding the risk behavior or outcome (discrimination or stigma)
* Collective perception of privacy protection and government trustworthiness
*Dissemination of public health data to reporting sources and interested parties
* Responsiveness of the sponsoring agency to recommendations or comments
* Costs to the person or agency reporting data, including simplicity, time required to enter data into the system, and whether the system is passive or active
* Federal and state statutes ensuring privacy and confidentiality of data reported
* Community participation in the system",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"System data quality is defined in terms of completeness and validity of data. Complete data have no missing values;
valid data have no error (bias) caused by invalid codes or systematic deviation.","For behavioral surveillance, measures of statistical stability (relative standard error) and precision (random variability and bias) are important. Completeness can be assessed at the item level (are values of a variable missing at random or clustering according to some characteristic?). Evaluation of completeness of the overall surveillance system can vary by data source. Completeness of a survey can be assessed by examining the sample frame (does it exclude groups of respondents?),
sampling methodology, survey mode, imputation, weighting, and ranking methods (18). For behavioral surveillance based on medical records, consideration should be given to the completeness of all fields, standardization across reporting units (eg, medical records systems), coding process, and specific nomenclature (eg, for drugs and treatment). For surveillance based on death certificates, variability in death scene investigation procedures, presence of a medical examiner versus a coroner, reporting standards across geographic boundaries, and the process of death certification will be relevant. 

Assessment of validity (ie, measurement of what is intended to be measured) also varies by data source. For use of data from a survey, consider cognitive testing of questions, focus groups, comparison with information from a health care provider, and identification of external factors that might influence reporting in a systematic way (19). An example of systematic influence is discrimination or prejudice in any form of arbitrary distinction, exclusion, or restriction affecting a person, usually (but not only) because of an inherent personal characteristic or perceived membership of a particular group (20).

Evaluation of statistical stability (precision) involves calculation of relative standard error of the primary estimate. Assessment of bias (systematic error) should address the following:
* Selection bias: systematic differences between sample and target populations
* Performance bias: systematic differences between groups in care provided or in exposure to factors other than the interventions of interest
* Detection bias: systematic differences in how the outcome is determined (eg, death scene investigation protocols)
* Attrition bias: systematic loss to follow up
* Reporting bias: systematic differences in how people report symptoms or ideation
* Other: biases related to a particular data source
","Many data-quality definitions depend on other system performance attributes (eg, timeliness, usefulness, acceptability) (21). Because of reliance on multiple data sources, data quality must be assessed in different ways. For surveillance relying on surveys, concepts of reliability, validity, and comparison with alternative data sources are important. For example, considerations of possible data-quality concerns arise with use of mortality data, particularly underreporting of suicide.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"A system is flexible if its design and operation can be adjusted easily in response to a demand for new information. For example, the Behavioral Risk Factor Surveillance System (BRFSS) (https://www.cdc.gov/brfss/) allows flexibility for states to add questions (optional modules), adapting to new demands or to local health-related events or concerns, but it retains a core set of questions that allows state-to-state comparisons. The optional modules can address important state and nationwide emergent and local health concerns. The addition of new survey modules also allows the programs to monitor new or changing behaviors in the states. Moreover, states can stratify their BRFSS samples to estimate prevalence data for regions or counties within their respective states.","Flexibility can be assessed retrospectively on the basis of historical evidence of response to change. A process map of steps needed to implement a change in the system as well as the following measures can address evaluation of flexibility:
* System technical design and change-process approval
* Time required to implement a change
Number of stakeholders or organizations involved in agreement to implement a change (decision-making authority and system ownership, both important factors)
* Resources needed for change, including funding, technical expertise, time, and infrastructure
* Need for legacy (ie, continuity or legislative mandates) versus flexibility
* Time and process for validating and testing questions (eg, population-based surveys)
* Ability to add questions for specific stakeholders (eg, states, partner organizations) versus comparability for national estimates
* Ability to access subtopics
* Methods of data collection (eg, move from landlines to cellular telephones)
*Ability to deal with emerging challenges (eg, new or evolving recreational drugs)","The Behavioral Health Surveillance Working Group recognizes different levels of flexibility. For example, BRFSS is flexible in terms of state-added questions, but adding a question to the core set is process-intensive. Flexibility should be assessed in the context of the data-collection purpose and the organization from which the data originate. For behavioral surveillance, flexibility to respond to changing norms and product availability is important.","* System technical design and change-process approval
* Time required to implement a change
Number of stakeholders or organizations involved in agreement to implement a change (decision-making authority and system ownership, both important factors)
* Resources needed for change, including funding, technical expertise, time, and infrastructure
* Need for legacy (ie, continuity or legislative mandates) versus flexibility
* Time and process for validating and testing questions (eg, population-based surveys)
* Ability to add questions for specific stakeholders (eg, states, partner organizations) versus comparability for national estimates
* Ability to access subtopics
* Methods of data collection (eg, move from landlines to cellular telephones)
*Ability to deal with emerging challenges (eg, new or evolving recreational drugs)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Predictive value positive (PVP) is the proportion of reported cases that actually have the health-related event, condition, behavior, thought, or policy under surveillance.","PVP's effect on the use of public health resources has 2 levels: outbreak identification and case detection.
First, PVP for outbreak detection is related to resources; if every reported case of suicide ideation is investigated and the community involved is given a thorough intervention, PVP can be high, but at a prohibitive expense. A surveillance system with low PVP (frequent false-positive case reports) might lead to misdirected resources. Thus, the proportion of epidemics identified by the surveillance system that are true epidemics can be used to assess PVP. Review of personnel activity reports, travel records, and telephone logbooks may be useful. Second, PVP might be calculated by analyzing the number of case investigations completed and the proportion of reported persons who actually had the behavioral health-related event. However, use of data external to the system (eg, medical records, registries, and death certificates) might be necessary for confirming cases as well as calculating more than one measurement of the attribute (eg, for the system's data fields, for each data source or combination of data sources, for specific health-related events).","Although the definition of PVP is the same as for infectious conditions, measuring PVP for behavioral health surveillance is hindered by a lack of easily measurable true positives as a result of stigma, communication, or cultural factors. Approaches cited previously for evaluating accuracy in absence of a gold standard can be helpful (12-16) in addition to the use of alternative data sources (eg, medical records, police reports, psychological autopsies), redundant questions within a survey (for survey-based surveillance), longitudinal studies, or follow-up studies.",N/A,N/A,N/A,N/A,N/A,A behavioral health surveillance system is representative if characteristics of the individuals (or people) assessed by the system as essentially the same as the characteristics of the population subject to surveillance.,"Assessment of representativeness requires definition of the target population and of the population at risk, which can differ. Examination of groups systematically excluded by the surveillance data source (eg, prisoners, homeless or institutionalized persons, freestanding emergency departments, people aged 65 in Veterans Affairs systems) can help to assess representativeness. An independent source of data regarding the outcome of interest is also helpful. Using behavioral health event data requires calculation of rates for a given year or for monitoring temporal trends. These will use denominator data from external data sources (eg, US Census Bureau ) that should be carefully ascertained for the targeted population. These considerations facilitate representation of health events in terms of time, place, and person.","Generalizing the findings of surveillance to the overall population should be possible with data captured from the surveillance system. Although sensitivity is the proportion of all health events of interest captured by the system, representativeness quantifies whether the data system accurately reflects the distribution of the condition or affected individuals in the general population (ie, whether systematic errors exist). For example, because many emergency departments and trauma centers that treat acute injuries test only a limited proportion of patients for alcohol, data regarding alcohol involvement in nonfatal injuries might not be representative of alcohol involvement in injuries overall. Generalization from these findings on alcohol involvement in nonfatal injuries to all persons who have experienced these outcomes is
problematic. Alternative survey methods are useful — respondent-driven sampling (22), network scale-up methods (16), and time/date/location sampling (23). Evaluation of representativeness can prompt modification of data-collection methods or redefining and accessing the target population to accurately represent the population of interest.
",N/A,N/A,N/A,N/A,N/A,"Sensitivity is the percentage of true behavioral health events, conditions, or behaviors occurring among the population detected by the surveillance system. A highly sensitive system might detect small changes in the number, incidence, or prevalence of events occurring in the population as well as historical trends in the occurrence of behavioral health events, conditions, or behaviors. Sensitivity may also refer to the ability to monitor changes in prevalence over time, including the ability to detect clusters in time, place, and segments of the population requiring investigation and intervention.","Measurement of the sensitivity of a public health surveillance system is affected by the likelihood that
* Health-related events, risk factors, or effects of public health policies are occurring in the population under surveillance
* Cases are coming to the attention of institutions (eg, health care, educational, community-based, harm-reduction, law enforcement, or survey-collection institutions) that report to a centralized system
* Cases will be identified, reflecting the abilities of health care providers; capacity of health care systems; type, quality, or availability of the screening tool; or survey implementation
* Events will be reported to the system. For example, in assessing sensitivity of a surveillance system based on a telephone-based survey, one can assess the 1) likelihood that people have telephones to take the call and agree to participate; 2) ability of respondents to understand the questions and correctly identify their status and risk factors, and 3) willingness of respondents to report their status

Because many important conditions for behavioral health surveillance are self-reported, validating or adjusting the self-report might be required using statistical methods (10), field-based studies (16), or methods in the absence of a gold standard (12-15).

Other factors related to behavioral health (eg, discrimination and variability in implementing parity in payment coverage between physical health and behavioral health care) can influence sensitivity, requiring alternative or parallel data sources. For example, when using surveys as a source for prevalence data, consider question redundancy or adding questions that might further identify people with a condition or leading indicator.

","An evaluation of the sensitivity of a behavioral health surveillance system should include a clear assessment of potential biases that range from case identification to case reporting. Case identification and case reporting will require workforce capacity, ability, and willingness to accurately and consistently identify and report plus an organized system for collecting, collating, and aggregating identified cases.",N/A,A public health surveillance system is simple in structure and function if it has a small number of components with operations that are easily understood and maintained.,"Simplicity is evaluated by considering the system's data-collection methods and the level to which it is integrated into other systems (9). For example, a surveillance system might rely on multiple information sources for case finding and data abstraction and for follow-up with confirmation by an independent data source or by an expert review panel. Evaluating simplicity would involve examining each data source individually and how the system works as a whole or how easily it integrates with other systems.

","As with infectious disease surveillance, behavioral health surveillance systems should be as simple as possible while still meeting the system's objective and purpose. Each behavioral health indicator or outcome should have a clear definition and be measurable in that surveillance system. Surveillance systems using population survey methods should have simple standard sampling methods (eg, paper-based, computer-based, or telephone-based), data processing (eg, data cleaning, screening, weighting, and editing or imputing), and data dissemination (eg, reports, internet pages). Analysis of trends in behavioral health data assumes no change in variable definition(s) over time and that data elements are consistently defined when the numerator and denominator are taken from different data sources. This can entail defining or stabilizing a standard behavioral health case definition (eg, binge drinking differences between men and women) or diagnostic coding methods (eg, International Statistical Classification of Diseases and Related Health Problems, 10th Revision [17]).
Simplicity is closely related to acceptance and timeliness (9) for detecting an event or outbreak.",N/A,N/A,N/A,N/A,N/A,"Stability of a public health surveillance system refers to a system's reliability (ability to collect, manage, and provide data dependably) and availability (ability to be operational when needed).","The system's stability might be assessed by protocols or model procedures based on the purpose and objectives of the surveillance system (9). Changes in diagnostic criteria or in the availability of services can affect stability. When relying on surveys, check the stability of questions and survey design. Assessing the system's workforce stability and continuity should include staff training, retention, and turnover. Existing measures for evaluating the stability of the surveillance system might be applicable for behavioral health surveillance systems (9).","The stability of a behavioral health surveillance system will depend on the operational legal or regulatory framework on which the surveillance system is based. For example, an established legal or regulatory framework ensures continuity in system funding and workforce capacity. Stability should be maintained while allowing flexibility to adapt to emerging trends. Assessing the stability of a surveillance system should be based on the purpose and objectives for which the system was designed.",N/A,N/A,N/A,N/A,N/A,Timeliness reflects the rate at which the data move from occurrence of the health event to public health action.,"Evaluating timeliness of behavioral health systems will depend on the measure used (eg, symptom, event, condition) and the system's purpose. Timeliness of a behavioral health surveillance system should be associated with timing of a consequent response for detecting a change in historical trends, outbreaks, or policy to control or prevent adverse health consequences. For example, quick identification and referral is needed for people experiencing a first episode of psychosis. However, for a community detecting an increase in binge-drinking rates, a longer period will be needed because the public health response requires a systemic engagement at the community level. Specific factors that can influence timeliness include
* Delays from symptom onset to diagnosis resulting from stigma (people might avoid diagnosis), lack of access to a facility or practitioner for diagnosis, policy (providers might be unable to bill for behavioral health diagnoses), credentials (relying on medical records or insurance claims misses people without insurance), or a failure to diagnose to avoid labeling
* Case definitions (eg, requiring symptoms be present for 6 months)
* A symptom that might be associated with multiple possible diagnoses, taking time to resolve
* Symptoms that appear intermittently
* Variance in detection methods
* Delays in recognizing a cluster or outbreak caused by lack of baseline data","For behavioral health conditions, long periods can occur between precedent symptoms, behavior, conditions, or exposure duration and the final appearance or diagnosis of a disease or condition. Unlike immediate identification and reporting needed for infectious diseases, some behavioral health conditions, similar to chronic conditions, might develop more slowly; for example, posttraumatic stress disorder (which often occurs in response to a particular traumatic event over time) versus an episodic depression (which may occur in response to an acute event). Nonetheless, baseline data are vital for determining the urgency of timely response to outbreaks or clusters of health problems related to behavioral health conditions. Ultimately, timeliness should be guided by the fact that behavioral health measures are not as discrete or easily measureable as most chronic or infectious disease  easures, and their etiology or disease progression is often not as linear.",N/A,"A public health surveillance system is useful if it contributes to preventing, treating, and controlling diseases, risk factors, and behaviors or if it contributes to implementation or evaluation of public health policies. Usefulness can include assessing the public health impact of a disease, risk, or behavior and assessing the status of effective prevention strategies and policies.","Depending on its objectives, the surveillance system can be considered useful if it satisfactorily addresses one or more of the following questions:
* Does the system detect behavioral health outcomes, risk factors, or policies of public health importance, and does it support prevention, treatment, and control of these conditions?
* Does the system provide estimates of the magnitude of morbidity and mortality of the behavioral health conditions under surveillance?
Does the system detect trends that signal changes in the occurrence of behavioral health conditions or clustering of cases in time or space?
* Does the system support evaluation of prevention, treatment, and control programs?
* Does the system ""lead to improved clinical, behavioral, social, policy, or environmental practices"" (9) for behavioral health problems?
* Does the system stimulate research to improve prevention, treatment, or control of behavioral health events under surveillance?

In addition to these attributes, a survey of people or stakeholders who use data from the system would be helpful in gathering evidence regarding the system's usefulness.","CSTE's set of behavioral health indicators draws on 8 data sources: mortality data (death certificates), hospital discharge and emergency department data, the Behavioral Risk Factor Surveillance System (https://www.cdc.gov/brfss/index.html), the Youth Risk Behavior Surveillance System (https://www.cdc.gov/healthyyouth/data/yrbs/index.htm), prescription drug sales (opioids), state excise taxes for alcohol, the Fatality Analysis Reporting System (https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars), and the National Survey on Drug Use and Health (https://www.samhsa.gov/data/population-data-nsduh).
These sources represent information regarding people, policies, and market data (eg, drug sales) and support different types of decisions for decision makers. Usefulness should be assessed in the context of the decision maker or interested stakeholders. In addition, surveillance data should provide clues to emerging problems and changing behaviors and products (eg, new drugs).","* Does the system detect behavioral health outcomes, risk factors, or policies of public health importance, and does it support prevention, treatment, and control of these conditions?
* Does the system provide estimates of the magnitude of morbidity and mortality of the behavioral health conditions under surveillance?
Does the system detect trends that signal changes in the occurrence of behavioral health conditions or clustering of cases in time or space?
* Does the system support evaluation of prevention, treatment, and control programs?
* Does the system ""lead to improved clinical, behavioral, social, policy, or environmental practices"" (9) for behavioral health problems?
* Does the system stimulate research to improve prevention, treatment, or control of behavioral health events under surveillance?",N/A,N/A,N/A,N/A,"Informatics capabilities: Public health informatics is the systematic application of information and computer science and technology to public health practice, research, and learning (24). Public health informatics has 3 dimensions of benefits to behavioral health surveillance: the study and description of complex systems (eg, models of behavioral health development and intervention), the identification of opportunities to improve efficiency and effectiveness of surveillance systems through innovative data collection or use of information, and the implementation and maintenance of surveillance processes and systems to achieve improvements (25).","When assessing informatics components of a surveillance system, the following aspects should be considered (25):
* Planning and system design: identifying information and sources that best address a surveillance goal; identifying who will access information, by what methods, and under what conditions; and improving interaction with other information systems
* Data collection: identifying potential bias associated with different collection methods (eg, telephone use or cultural attitudes toward technology); identifying appropriate use of structured data, vocabulary, and data standards; and recommending technologies to support data entry
* Data management and collation: identifying ways to share data across computing or technology platforms, linking new data with legacy systems, and identifying and remedying data-quality problems while ensuring privacy and security
* Analysis: identifying appropriate statistical and visualization applications, generating algorithms to detect aberrations in behavioral health events, and leveraging high-performance computational resources for large data sets or complex analyses
* Interpretation: determining usefulness of comparing information from a surveillance program with other data sets (related by time, place, person, or condition)
* Dissemination: recommending appropriate displays and best methods for reaching the intended audience, facilitating information finding, and identifying benefits for data providers
* Application to public health programs: assessing the utility of having surveillance data directly support behavioral health interventions","Initial guidelines for infectious disease surveillance (4) did not include assessment of informatics capability. Although this was included in a later publication (10), informatics was not portrayed as an attribute for evaluation. Because of the proliferation of electronic medical records and the standards for electronic reporting, assessment of informatics as an attribute will be crucial for behavioral health surveillance.",N/A,Population coverage: Population coverage refers to the extent that the observed population described by the data under surveillance describes the true population of interest.,"Population coverage can be assessed by the proportion of respondents (survey-based) or cases (hospital- or facility-based) included in the surveillance system. Two measurements resulting from population coverage assessment are 1) population undercoverage that results from the omission of respondents or cases belonging to the target population and 2) population overcoverage that occurs because of inclusion of elements that do not belong to the target population. In addition, a demographic analysis (26) can provide benchmarks for assessing completeness of coverage in the existing surveillance data and document changes in coverage from previous periods. Furthermore, independence and internal consistency of the demographic analysis allow using estimates to check survey-based coverage estimates.","Surveillance systems (ie, survey-based or hospital- or facility-based surveillance) can be defined by their geographic catchment area (ie, country, region, state, county, or city) or by the target population that the system is intended to capture. For example, the National Survey on Drug Use and Health's target population is the noninstitutionalized civilian population aged 12 years or older. Homeless people who do not use shelters, active duty military personnel, and residents of institutional group quarters (eg, correctional facilities, nursing homes, mental institutions, and long-term hospitals) are excluded. Such populations not covered by most surveillance systems can contribute to case counts in hospital- or facility-based systems (eg, drug poisoning, emergency department use for self-harm, prevalence of mental illness and substance abuse problems). Evaluation of population coverage typically requires an alternative data source. For example, the estimate from a national surveillance system can be compared with a special study or survey in the same geographic area targeting a specific population. Projections from previous estimates might aid in comparing existing surveillance data. Use of benchmark data sets might aid in estimating the undercoverage prevalence of behavioral health indicators: the US Department of Justice's Bureau of Justice Statistics data (https://www.bjs.gov/index.cfm?ty=dca) and the US Department of Housing of Urban Development's (http:// portal.hud.gov/hudportal/HUD) point-in-time estimates of homelessness. Finally, mortality data will contain all US residents' deaths occurring in a given year; however, residents who die abroad might not be included (resulting in undercoverage), and deaths of nonresidents might be included (resulting in overcoverage).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"4. Thacker SB, Stroup DF, Rothenberg RB, Brownson RC. Public health surveillance for chronic conditions: a scientific basis for decisions. Stat Med 1995;14(5-7):629-41. 
5. Thacker SB, Qualters JR, Lee LM; Centers for Disease Control and Prevention. Public health surveillance in the United States: evolution and challenges. MMWR Suppl 2012;61(3):3-9. 
6. Nsubuga P, White ME, Thacker SB, Anderson MA, Blount SB, Broome CV, et al.Public health surveillance: a tool for targeting and monitoring interventions [Chapter 53]. In: Jamison DT, Breman JG, Measham AR, Alleyne G, Claeson M, Evans DB, et al, editors. Disease control priorities for developing countries. 2nd edition. Washington (DC): World Bank Publishers; 2006. p. 997-1015.

10. Groseclose SL, German RB, Nsbuga P. Evaluating public health surveillance [Chapter 8]. In: Lee LM, Teutsch SM, Thacker SB, St. Louis ME, editors. Principles and practice of public health surveillance. 3rd edition. New York, (NY): Oxford University Press; 2010:166-97.",N/A,
babaiePerformanceAssessmentCommunicable2015,1444,Babaie 2015,Performance assessment of communicable disease surveillance in disasters: a systematic review.,Performance Assessment of Communicable Disease Surveillance in Disasters: A Systematic Review,2015,Ali Ardalan,aardalan@tums.ac.ir,Iran,Systematic review of performance assessments for communicable disease surveillance systems in disasters,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),"The included articles used a variety of methods, primarily the CDC updated framework and/or comparative evaluation methods.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No definition provided in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No definition provided in review,N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,"Identified in review (""CDC's updated guidelines for surveillance system evaluation"")",N/A,N/A,N/A,Cost minimization,N/A,N/A,N/A,Cost-effectiveness analysis,N/A,N/A,N/A,Cost utility,N/A,N/A,N/A,Cost benefit,N/A,N/A,N/A,Percentage of visits by established SS and national surveillance,N/A,N/A,N/A,Percentage of samples with positive results,N/A,N/A,N/A,Agreement between discharge diagnoses and developed form,N/A,N/A,N/A,"Structure (legal framework and financial, human and physical resource)",N/A,N/A,N/A,"Surveillance procedure (capacity to detect, assess, notify)",N/A,N/A,N/A,"Response (investigate, intervene, and communicate)",N/A,N/A,N/A,Appropriateness,N/A,N/A,N/A,Dissemination of data,N/A,N/A,N/A,"Process (first clinical observation , accurate diagnosis, laboratory confirmation, identification of exposure source, report to public health authority, report to law enforcement authority, initiation of emergency operation plan , initation of risk- mitigation activities, initiation of past exposure prophylaxis, initiation of public health education activities, initiation of risk advice to health care workers, last reported new case)",N/A,N/A,N/A,"Outcome indicators (primary cases, total cases, secondary cases, HCW[1]s infected)",N/A,N/A,N/A,"Percentage of emergency department visits, percentage of hospitalization",N/A,N/A,N/A,Incidence of heat related diseases,N/A,N/A,N/A,Utility,N/A,N/A,N/A,Water sanitation,N/A,N/A,N/A,Immunization,N/A,N/A,N/A,Organization of health services,N/A,N/A,N/A,Public education,N/A,N/A,N/A,Zero reporting,N/A,N/A,N/A,"The number of cholera cases for which samples were confirmed by the laboratory,",N/A,N/A,N/A,The number of malaria cases confirmed by blood smear date of onset of the first case,N/A,N/A,N/A,Date of reporting using outbreak alert form,N/A,N/A,N/A,Date of investigation,N/A,N/A,N/A,Date of response,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,To review identified articles from review to determine if they provide operationalized definitions and evaluation methods for the listed attributes.,"The CDC updated guidelines for public health surveillance system evaluation was used exclusively in 3 studies. In the performance assessment of mortality, morbidity, and CDS systems, the CDC guidelines were also used as part of the assessment. 

Of the CDC public health surveillance evaluation attributes, the most widely applied was timeliness, which was used in 7 studies. Flexibility was used in 5 studies, data quality in 4, simplicity in 3, stability in 3, and usefulness and representativeness in 2 studies. In all cases, timeliness, data quality, sensitivity, specificity, PPV, cost, and representativeness were calculated quantitatively. Flexibility, usefulness, simplicity, and acceptability were calculated in a qualitative manner. Stability was calculated both quantitatively and qualitatively.

Some economic assessment criteria have been suggested for use in the performance assessment of SS in disasters, but these criteria have not been used in practice.

Despite the reasonably wide spread use of the CDC guidelines for systems performance assessment in response to disasters and emergencies, experts have emphasized that there are no generally accepted metrics. Many scientists, universities, and research centers have identified this deficiency, and it has been a research priority for many years. However, there is still an urgent need for the development of universal frameworks, methodologies, metrics, and criteria for the performance assessment of CDS systems in response to disasters and emergencies.",
babomartinsEconomicsZoonosesSurveillance2017,879,BaboMartins 2017,Economics of zoonoses surveillance in a 'One Health' context: an assessment of Campylobacter surveillance in Switzerland.,Economics of zoonoses surveillance in a One Health context: an assessment of Campylobacter surveillance in Switzerland,2017,S. Babo Martins,smartins@rvc.ac.uk,United Kingdom,To explore the economics of the cross-sectorial One Health approach,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",d. One Health,Switzerland,k. Other,Economic assessment of zoonoses surveillance in a One Health context: a conceptual framework (Babo Martins 2015),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Assessed,"Measured in relation to disability-adjusted life years (DALYs)

Total years of life lost to disability (YLD), to mortality (YLL), and overall DALYs for the years under analysis were calculated by applying a stochastic model using the DALY Calculator interface developed in R

See original framework for more information (reference 18) and comments in Q23",See original framework for more information (reference 18) and comments in Q23,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Some limitations to our estimates should be considered. The cost analysis and results for marginal cost increase associated with the cross-sectorial mitigation efforts for Campylobacter in this study focused on official surveillance programmes and interventions reliant on public spending. Yet, in addition to the official surveillance and control activities, the poultry industry has also been carrying out mitigation activities to tackle Campylobacter at pre-harvest and post-harvest levels. Since our estimates do not account for the costs of such activities, our results are likely an underestimation of the societal efforts in terms of expenditure in Campylobacter surveillance and mitigation. In the same way, we did not exhaustively assess all benefit streams potentially linked to surveillance integration.",N/A,N/A,"18. Babo Martins S, Rushton J, Stark KDC. Economic assessment of zoonoses surveillance in a One Health context: a conceptual framework. Zoonoses and Public Health 2015; 63: 386-395.","See Fig 2 and Table 1 for the conceptual representation of assessed costs and benefits.

The break-even point for the system, i.e. the point at which cost or expenses and benefits are equal and the system would recover its costs, was calculated in terms of the number of disability-adjusted life years (DALYs) - the metric used to assess marginal benefits of the system - that would have to be averted.

Burden of disease was calculated using DALYs, applying the methodology developed by Murray & Lopez [27] and building upon the model recently used in Denmark for the estimation of the burden of foodborne disease [28].

Total years of life lost to disability (YLD), to mortality (YLL), and overall DALYs for the years under analysis were calculated by applying a stochastic model using the DALY Calculator interface developed in R [38].

Our results suggest that, in the first 5 years of the system, the level of the expenditure increased with a cross-sectorial approach to surveillance and intervention for Campylobacter in the country, particularly in research funding and surveillance activities in poultry. In the period of this work, integrated surveillance information contributed mainly to the assessment of trends, to perform risk assessments and to inform discussion on gaps and information needs regarding Campylobacter in the country, thus contributing to the shaping of research efforts and strengthening of the knowledge base regarding the disease. Consequently, in these initial 5 years, the nature of benefits was intangible, including the generation of intellectual capital. The latter relates to the intangible value (information, intellectual property, experience) in the knowledge and relationships of employees, management staff, and other stakeholders of a company or institution, that can be used, in the future, to generate wealth. In the public sector context, measurement of intellectual capital and knowledge assets has been carried out by universities and research funding institutions [39].

Such intellectual capital created by surveillance can later generate measurable value when it is translated into control measures that mitigate the impact of the disease.

The timing of our analysis is therefore particularly relevant for the benefits assessment. A time delay between initiating research and implementing interventions with possible health effects can be expected. Furthermore, it can be expected that the power of an integrated surveillance system increases with time as information is gathered and trends and sources are more accurately identified. 

Future burden of disease or cost-of-illness estimations would greatly benefit from information on the parameters that seem impact the model results most, notably human incidence and prevalence data.

Gains in information and knowledge have been recognized as benefits from One Health approaches. However, the lack of ability to measure the final outputs in tangible indicators means that it is infrequent to have such benefits incorporated into economic assessments. The same situation is observable in overall economic assessment of disease control. We believe that to accurately understand the added value of One Health and surveillance integration for decision making, the assessment of these assets needs to be an integral part of the analysis. This is particularly relevant for the surveillance systems that are at a similar maturity stage, i.e. mainly informing assessment and producing knowledge, as the Campylobacter mitigation system in Switzerland in the period 2009-2013. Further work on the importance of these intangible assets generated by surveillance integration would enrichen our understanding of the economic aspects of zoonoses surveillance and policy making.

Overall, the framework used as the basis for economic assessment allowed the identification of cross-sectorial cost items and benefits streams, associated with Campylobacter in Switzerland in the period in analysis, through the conceptualization of its links to intervention. By providing information on the economics of cross-sectorial surveillance of Campylobacter as well as the tools for this assessment, the results of this work can be directly applicable and can inform planning of effective and efficient future surveillance programmes for zoonoses. Such assessments require an understanding of how information generated by surveillance is part of the zoonoses mitigation process, and availability of data on costs of activities conducted and on the impacts of such activities in terms of intangible and tangible benefits. The latter set of benefits can only be accurately assessed if adequate surveillance information allows capturing changes in disease dynamics in the populations.

",
bakerGlobalPublicHealth2006,2090,Baker 2006,Global public health surveillance under new international health regulations.,Global Public Health Surveillance under New International Health Regulations,2006,Michael G. Baker,michael.baker@otago.ac.nz,New Zealand,Formal evaluation of the IHR 2005 surveillance system,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",a. Public Health,International,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Willingness of persons and organizations to participate,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Completeness and validity of recorded data,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Ability to adapt to changing information needs and operating conditions,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Ability to describe events over time and their distribution by place and person,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Proportion of true events detected by system and ability to detect outbreaks,N/A,"The sensitivity of the IHR 2005 surveillance system will probably be affected by 2 factors. First, in all likelihood, inadequate capacities at the local and intermediate levels within state parties will limit the system's sensitivity more than capacities at the national level. Second, state
parties may not always be willing to comply with their reporting obligations in the face of possible adverse political and economic consequences that may result from alerting the world to a disease event in their territories.",N/A,Simplicity of structure and ease of operation,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Reliability and availability of surveillance system,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Speed between steps particularly from event onset to response,N/A,"Timely surveillance is also stressed in connection with strategies to deal with pandemic influenza. Timeliness may be the most important attribute that IHR 2005 will have to demonstrate to be effective.

WHO's ability to draw on a wide array of sources of information, including the Internet and nongovernmental
organizations and actors, may enhance the timeliness of the IHR 2005 surveillance system.

",N/A,Contribution to prevention and control of adverse health-related events,N/A,"The usefulness of surveillance under IHR 2005 represents the sum of all the critical system attributes and can only be assessed after the system is in operation, so this attribute is not discussed here.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Emphasis on timeliness,"12. Jajosky RA, Groseclose SL. Evaluation of reporting timeliness of public health surveillance systems for infectious diseases. BMC Public Health. 2004;4:29

27. Bravata DM, McDonald KM, Smith WM, Rydzak C, Szeto H, Buckeridge DL, et al. Systematic review: surveillance systems for early detection of bioterrorism-related diseases. Ann Intern Med. 2004;140:910-22.","Public health surveillance has been defined as ""the ongoing systematic collection, analysis, and interpretation of outcome-specific data for use in the planning, implementation, and evaluation of public health practice"".

The regulations define surveillance as ""the systematic ongoing collection, collation and analysis of data for public health purposes and the timely dissemination of public health information for assessment and public health response as necessary"".

Of these attributes, usefulness, sensitivity, timeliness, and stability will be most critical to the success of the IHR 2005 surveillance system. Simplicity, acceptability, and flexibility will affect the establishment and sustainability of the surveillance system. Data quality, positive predictive value, and representativeness are central to accurately characterizing health-related events under surveillance.

See Table 2 for a description of potential barriers.",
bennaniEvaluatingIntegratedSurveillance2021,114,Bennani 2021,Evaluating Integrated Surveillance for Antimicrobial Use and Resistance in England: A Qualitative Study.,Evaluating Integrated Surveillance for Antimicrobial Use and Resistance in England: A Qualitative Study,2021,Houda Bennani,hbennani@rvc.ac.uk,United Kingdom,Aimed to evaluate the performance and value of integrated surveillance system for AMU/AMR in England by applying the ISSE framework,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",d. One Health,England,k. Other,Integrated Surveillance System Evaluation (ISSE) framework (Aenishaenslin 2021),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Policy and regulatory bodies (humans, animals, food, and environment)",N/A,N/A,"In a previous study to characterise and map the surveillance system for AMU/AMR in the UK, a list of key organisations involved in the national surveillance system for AMU/AMR was developed (10). Interviewees were purposefully selected from this list and also using snowball sampling (i.e., participant referrals of other participants). The key informants were selected because they had knowledge and expertise on AMU/AMR surveillance in England and were directly involved in the surveillance system.",Implementing bodies (animals),N/A,N/A,"In a previous study to characterise and map the surveillance system for AMU/AMR in the UK, a list of key organisations involved in the national surveillance system for AMU/AMR was developed (10). Interviewees were purposefully selected from this list and also using snowball sampling (i.e., participant referrals of other participants). The key informants were selected because they had knowledge and expertise on AMU/AMR surveillance in England and were directly involved in the surveillance system.","Other sectors/stakeholder (animal industry, small animal sub-sector, academia/research, veterinary body, One Health AMR group)",N/A,N/A,"In a previous study to characterise and map the surveillance system for AMU/AMR in the UK, a list of key organisations involved in the national surveillance system for AMU/AMR was developed (10). Interviewees were purposefully selected from this list and also using snowball sampling (i.e., participant referrals of other participants). The key informants were selected because they had knowledge and expertise on AMU/AMR surveillance in England and were directly involved in the surveillance system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Survey question: 
* How does this cross-sectoral collaboration impacts on decision making? 
Can you give examples from your experience? (how information produced by integrated surveillance activities has been used by you or other stakeholders you work with?). 
Prompts: 
o Policy change regarding AMU/AMR: legislation on AMU in agriculture and humans, enhanced surveillance, awareness programs, etc..) 
o Behaviour change in veterinarians, producers, distributors, consumers and the general public (AMU, consumption of animal products, societal values, etc..) 
o Interventions",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Four main themes emerged from the analysis: (1) Cross-sectoral integration in the surveillance system for AMU/AMR; (2) Production of OH outputs and outcomes; (3) Drivers and barriers to cross-sectoral collaboration; and 4) Need for more cross-sectoral collaboration.

PMP-AMR, ATLASS, ECoSur and NEOH are evaluation tools that provide a scoring system to obtain semi-quantitative results, whereas ISSE and SurvTools would result in a plan for how to conduct evaluation(s). The NEOH and ISSE were perceived as the best tools for evaluation of OH aspects, and ECoSur as best for evaluation of the quality of collaboration (7).

Depending on the evaluation questions, assessors will need to select a tool that suits their needs (7). To guide users in choosing a suitable evaluation tool, an international network of scientists developed guidance for choosing an assessment approach from an inventory of tools suitable for evaluating integrated AMU and AMR surveillance systems in the project ""Co-Eval-AMR-Convergence in evaluation frameworks for integrated surveillance of AMU and AMR.""

The logic model (Figure 1) illustrates the relationships between the different integrated surveillance activities, outputs and the expected outcomes and impact. A modification was made to the logic model by adding a planning step to the surveillance activities.The different levels of the evaluation target different aspects in the system that include: (1) OH integration across the different components of the surveillance system including data collection, analysis and interpretation, and information dissemination; (2) Production of OH information and expertise; (3) Generation of actionable knowledge; (4) Influence on decision making; and (5) Contribution to desirable outcomes.

See Figure 1 for an overview of the adapted ISSE logic model for the evaluation.

The guide was developed to capture data on (i) integrated surveillance activities for AMU/AMR in England (the activity was considered integrated if there was collaboration between at least two of the following sectors: animal, human, food and the environment), (ii) links between surveillance activities and outputs, (iii) links between outputs and outcomes, (iv) the impact of surveillance information on decision making, (v) the impacts of the decisions attributable to integrated activities, (vi) data and information sharing, (vii) need for improvement. Questions (i) to (v) were developed by the authors following the logic of the ISSE framework to explore the links between the integrated surveillance activities and the outputs and outcomes. To account for data on OH sharing [questions (vi)], questions related to the evaluation of data and information sharing were included based on protocols from the NEOH framework (11). Because effective coordination underpins all surveillance activities, questions related to the steering and coordination of integrated surveillance activities were added to questions (i) based on the
ECoSur tool (12).

Key themes identified from interviews are presented (an overview of the themes and subthemes is presented in Figure 2):
(1) cross-sectoral integration in the surveillance system for AMU/AMR
- Integrated Activities
- Data and Information Sharing
- Coordination of Cross-Sectoral Activities for AMU/AMR Surveillance
- Resources for Cross-Sectoral Collaboration
- Global Collaboration and the Value of Collective Data
- Regional Collaboration
- Surveillance and Research

(2) production of OH outputs and outcomes
- Detection of Emerging Resistance
- Provision of Enhanced Information for Risk Assessment Leading to Better Risk Management and Decision Making
- Better Harmonisation Between Sectors 
- Exchange of Information and Expertise
- Increase in Awareness and Understanding
- Building Good Working Relationship
- Provision of Stronger Message and Evidence to Inform Interventions
- Impact on Decision-Making
- Cross-Sectoral Learning

(3) drivers and barriers to cross-sectoral collaboration
- Methods
- Resources and Capacity
- National Action Plan
- Cross-secotoral Issue

(4) the need for more cross-sectoral collaboration
- Methods
- Resources and Capacity
- Improved Coordination of Integrated Surveillance Activities
- Surveillance Data From the Environment
- Surveillance Data From Companion Animals
- Communication and Sharing of Information

The results showed that there are links between integrated surveillance information, decision making and intervention; especially in the case of the Res-Alert programme. However, there were only few OH examples where the potential of collaboration was fully exploited. Many benefits described were related to the generation of information and increase in knowledge and understanding without explicit use of the information for policy or intervention development. These intangible benefits have a value but being able to link surveillance information and mitigation measures is very important as it would help to enhance the value of integrated surveillance efforts. This is particularly relevant considering budget constraints and the need to justify resource allocation to activities. Integration and collaboration are resource consuming and full integration in a system might not be necessary to achieve the wanted outputs. Therefore, it is important to identify the level of collaboration that will achieve the optimal performance and cost-effectiveness.

This study allowed an understanding of the capacity of the system to produce OH surveillance information and the links between this OH information produced and the various outputs and outcomes. Based on this evaluation, we propose the following indicators that can be used for the assessment of the performance of integrated surveillance system for AMU/AMR. These are: (i) the capacity of the system to produce OH information; (ii) the capacity of the system to use the OH information generated to enhance the knowledge and inform the implementation of interventions; and (iii) the capacity of the system to provide a OH response in the case of identification of resistance bacteria or genes posing a high risk to human or animal health. Future work on surveillance evaluation should consider ways of measuring these three indicators. 

See supplemental file for criteria posed in survey - it is unclear what questions lead to which attributes from the ISSE framework.",
bingleEvaluationOntarioRapid2005,2188,Bingle 2005,An evaluation of the Ontario Rapid Risk Factor Surveillance System.,An Evaluation of the Ontario Rapid Risk Factor Surveillance System,2005,Catherine L. Bingl,cbingle@simcoehealth.org,Canada,"Evaluation framework for young public health surveillance systems, and formal evaluation of the Rapid Risk Factor Surveillance System (RRFSS) in Canada","a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,Canada,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001),Protocol for the Evaluation of Epidemiological Surveillance Systems (WHO 1997),Performance Areas,Determine performance areas,N/A,N/A,Process effectiveness; collaboration effectiveness; usefulness; cost effectiveness,Evaluation Questions,Create/determine evaluation questions for all themes,N/A,N/A,See domains section,Data Collection Strategies,Collect data based on evaluation questions,See themes section,N/A,See themes section,Intermediate Outcomes,Determine intermediate outcomes based evaluation themes,N/A,N/A,"Increased local awareness of surveillance information; involvement in generating appropriate, accurate information; and practice of evidence-based program planning (use of this information);
Demonstrated or potential cost effectiveness for public health agencies in implementation of RRFSS",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Health unit staff,N/A,Health unit staff,"Questions were developed with the help of the Institute for Social Research (ISR) at York University, health unit staff, MOHLTC consultants and experts in the field.

Different survey tools were developed for different stakeholder groups, including interview questions for a representative of ISR, and a survey for the Public Health Branch of the MOHLTC. Within health units participating in RRFSS, separate surveys were developed for the RRFSS representatives (usually a health unit epidemiologist), program staff, and the Medical Officer of Health (MOH). Epidemiologists in non-participating health units also had a separate survey. All surveys were self-administered and contained both open and closed questions.",Representatives from the Ontario Ministry of Health and Long-Term care (MOHLTC),N/A,Representatives from the Ontario Ministry of Health and Long-Term care (MOHLTC),"Questions were developed with the help of the Institute for Social Research (ISR) at York University, health unit staff, MOHLTC consultants and experts in the field.

Different survey tools were developed for different stakeholder groups, including interview questions for a representative of ISR, and a survey for the Public Health Branch of the MOHLTC. Within health units participating in RRFSS, separate surveys were developed for the RRFSS representatives (usually a health unit epidemiologist), program staff, and the Medical Officer of Health (MOH). Epidemiologists in non-participating health units also had a separate survey. All surveys were self-administered and contained both open and closed questions.",Representatives from local health and social services agencies,N/A,Representatives from local health and social services agencies,"Questions were developed with the help of the Institute for Social Research (ISR) at York University, health unit staff, MOHLTC consultants and experts in the field.

Different survey tools were developed for different stakeholder groups, including interview questions for a representative of ISR, and a survey for the Public Health
Branch of the MOHLTC. Within health units participating in RRFSS, separate surveys were developed for the RRFSS representatives (usually a health unit epidemiologist), program staff, and the Medical Officer of Health (MOH). Epidemiologists in non-participating health units also had a separate survey. All surveys were self-administered and contained both open and closed questions.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Survey results reported the use of RRFSS results reported by program staff after nearly a year of data collection. The following uses were provided in Figure 2: program planning, program evaluation, media campaign, communication product, education initiative, proposal for funding, reporting, policy development, advocacy work, presentation, informing a decision, other. 

Questions used to determine this are listed under Additional Theme 11: Use.

After almost a year of data collection, nearly all health units reported using RRFSS results. A third of program staff had not yet received results and most had not yet used them. Most uses were in planning, evaluation, and communications (Fig. 2). Chronic and communicable disease prevention and environmental health programs were the most frequent users.

Key barriers to use of RRFSS results were weak awareness among staff and the time needed to analyze and present data. Central coordination, common analytical tools, and stronger analysis and dissemination programs in health units were identified needs to better promote use.",Process Effectiveness,Awareness; Data Analysis; Dissemination; Questionnaire Development; Data Quality; Overall Implementation in Health Unit,N/A,Collaboration Effectiveness,Partnership in General; Work Groups; Decision-making,N/A,Usefulness,Relevance; Use; Impact,N/A,Cost Effectiveness,"Current Costs and Return on Investment; Future Costs and 
Sustainability",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Awareness:,1. RRFSS Rep questionnaire 2. MOH questionnaire 4. Non participating HU questionnaire 5. ISR interview 6. MOHLTC questionnaire,N/A,What is the level of awareness about RRFSS in health units (HUs)?,Data Analysis,1. RRFSS Rep questionnaire 2. MOH questionnaire 4. Non participating HU questionnaire 5. ISR interview 6. MOHLTC questionnaire,N/A,"* Are HUs analyzing data? ; 
* Do HUs have adequate resources to analyze RRFSS data?",Dissemination,"1. RRFSS Rep questionnaire
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,* How is RRFSS information disseminated? Is it rapid and timely?,Questionnaire Development,1. RRFSS Rep questionnaire 2. MOH questionnaire 4. Non participating HU questionnaire 5. ISR interview 6. MOHLTC questionnaire,N/A,"* Are processes for selecting modules, adding questions, and making revisions, satisfactory?; 
* Is RRFSS flexible and responsive to HU planning needs?; 
* Does questionnaire content meet HU needs?",Data Quality,"1. RRFSS Rep questionnaire 
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,"* Is the quality of data, questions, and methods acceptable?; 
* Are response rates acceptable?",Overall Implementation in Health Unit,"1. RRFSS Rep questionnaire 
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,"Overall Satisfaction: 
* Is RRFSS implemented well in HUs?; 
* What are some of the limitations of RRFSS? Are these time-limited/developmental?",Partnership in General,"1. RRFSS Rep questionnaire 
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,"* What partnerships were developed for implementation of RRFSS?; 
* How satisfied are RRFSS HUs with the way the partnership works?",Work Groups,"1. RRFSS Rep questionnaire 
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,"* Is the RRFSS provincial support network structure and process effective? (mainworking group, advisory group, evaluation group, analysis group, ISR, ad hocgroups)
* What is the character of theworking relationship among partners and work groups?",Decision-making,"1. RRFSS Rep questionnaire 
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,"* What level of involvement is there in partnerships?; 
* Do HUs have an equal voice in decisions?; 
* Is there an equal partnership among RRFSS HUs?",Relevance,"1. RRFSS Rep questionnaire 
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,"* Is RRFSS a satisfactory surveillance method? 
* Does RRFSS meet HUs' needs? 
* Does RRFSS fill any data gaps? 
* What would increase RRFSS usefulness for HUs?",Use,"1. RRFSS Rep questionnaire 
2. MOH questionnaire 
4. Non participating HU questionnaire 
5. ISR interview 
6. MOHLTC questionnaire",N/A,"* Have HUs used RRFSS data?; 
* Who is using RRFSS data? ; 
* For what uses?; 
* What are the barriers to; using RRFSS?; 
* How can data use be; improved?",Impact,1. RRFSS Rep questionnaire 2. MOH questionnaire 4. Non participating HU questionnaire 5. ISR interview 6. MOHLTC questionnaire,N/A,"* What are the perceived benefits and impacts of RRFSS?  
* Has there been an increase in data use for decisions, planning, evaluation, other  applications? 
* Did use of RRFSS affect HUs' capacity for program planning, evaluation and ability to meet compliance indicators? 
* What implications would  there be for HUs were RRFSS data not available?",Current Costs and Return on Investment,1. RRFSS Rep questionnaire 2. MOH questionnaire 4. Non participating HU questionnaire 5. ISR interview 6. MOHLTC questionnaire,N/A,"* What is the cost per HU  including fees, staffing, operations, or other costs? 
* What were staffing requirements to participate in and  implement RRFSS within HUs? Return on Investment 
* What are HU perceptions of return on investment in RRFSS? 
* Were savings incurred  through collaboration among HUs? 
* Were any decisions that  saved money informed by RRFSS? 
* What are the challenges with  respect to costs for RRFSS?  
* What would be a realistic price?",Future Costs and Sustainability,1. RRFSS Rep questionnaire; 2. MOH questionnaire; 4. Non participating HU questionnaire; 5. ISR interview; 6. MOHLTC questionnaire.,N/A,"* Are savings or revenue generation opportunities anticipated due to RRFSS? 
* What are the barriers to broader participation in RRFSS? 
* What participation should  there be in RRFSS by public  health jurisdictions in Ontario? 
* Are there sustainability  issues? What are they? 
* Are there ways to increase  efficiency and decrease cost?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Several suggestions for improving RRFSS were proposed. Key areas for improvement were:
* Ways to improve implementation and supports: resourcing of a central coordinating group, improvement of questionnaire development procedures, better developed data analysis systems, and improved function of work groups.
* Strategies to increase data use: central coordination of certain tasks to reduce duplication, coordination of data analysis and dissemination strategies, and more dissemination and awareness-building activities within health units.
* Cost reduction prospects: central coordination, expanded partnerships, and efficiencies obtained through system maturation.
* Paths to greater participation: provincial cost sharing, core questionnaire funding, increased marketing, and more activities promoting use of RRFSS data.

Not all potential stakeholders were included. Inquiries to potential partner organizations indicated that RRFSS awareness among entities other than the MOHLTC was not sufficient at the time to warrant including them given the types of information to be collected. Local partners and audiences were also recognized stakeholders and informants on RRFSS use and impact in communities. However, at the time of evaluation, most participating health units were planning their first major release of RRFSS results in 2002, so studying community impact was premature.",N/A,N/A,N/A,Says that the evaluation framework was developed from CDC and WHO guidelines but does not provide their own definitions for comparison against previous guidelines.,
bordierOneHealthSurveillance2019,914,Bordier 2019,One Health Surveillance: A Matrix to Evaluate Multisectoral Collaboration.,One Health Surveillance: A Matrix to Evaluate Multisectoral Collaboration,2019,Marion Bordier,Marion.bordier@cirad.fr,Vietnam,Matrix to evaluate collaboration in a multisectorial surveillance system,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Epidemiologists,"Identified as authors of articles related to OH surveillance or who had been involved in research consortiums working either on integrated surveillance evaluation (Risksur project) or on OH evaluation (NEOH).

Most of them were epidemiologists (74%) and/or veterinarians (72%), working mainly in research institutes, universities, or expertise agencies (54%), intergovernmental agencies (21%), or national authorities (18%). Remaining respondents worked in the private sector (13%) or in non-governmental organizations (1%). Respondents' main fields of expertise included epidemiology (95%), veterinary public health (77%), public health (67%), and food safety (61%). Most participants had substantial experience in health surveillance (56%) and in the OH concept (66%). Most of them (85%) demonstrated at least 1 year of experience in OH surveillance.",N/A,N/A,Veterinarians,"Identified as authors of articles related to OH surveillance or who had been involved in research consortiums working either on integrated surveillance evaluation (Risksur project) or on OH evaluation (NEOH).

Most of them were epidemiologists (74%) and/or veterinarians (72%), working mainly in research institutes, universities, or expertise agencies (54%), intergovernmental agencies (21%), or national authorities (18%). Remaining respondents worked in the private sector (13%) or in non-governmental organizations (1%). Respondents' main fields of expertise included epidemiology (95%), veterinary public health (77%), public health (67%), and food safety (61%). Most participants had substantial experience in health surveillance (56%) and in the OH concept (66%). Most of them (85%) demonstrated at least 1 year of experience in OH surveillance.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Organizational Attributes - Governance Level,"Governance and operation attributes on the organization of multisectorial collaboration.

G.1 Formalization and endorsement of the collaborative surveillance strategy
G.2 Relevance of collaborative objective(s) and purpose
G.3 Formalization of collaborative modalities
G.4 Relevance of collaborative modalities
G.5 Coverage
G.6 Governance of resources for collaboration
G.7 Mechanism(s) for steering collaboration
G.8 Mechanism(s) for coordinating collaboration
G.9 Mechanism(s) for technically and scientifically supporting collaboration
G.10 Training
G.11 Information and communication
G.12 Performance and evaluation
G.13 Engagement",N/A,Organizational Attributes - Operational Level,"Governance and operation attributes on the organization of multisectorial collaboration.

O.1 Collaboration for surveillance design
O.2 Collaboration for sampling
O.3 Collaboration for laboratory testing
O.4 Collaboration for data sharing
O.5 Collaboration for sharing surveillance results
O.6 Collaboration for data management and storage
O.7 Collaboration for data analysis and interpretation
O.8 Collaboration for communication to surveillance actors
O.9 Collaboration for external communication
O.10 Collaboration for dissemination to beneficiaries

",N/A,Functional Attributes,"Functional attributes on the qualities of core collaboration functions required for an effective multisectoral surveillance system.

Stability
Relevance
Operationality
Acceptability
Resources
Adaptability
Inclusiveness
Shared leadership
System knowledge",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Surveillance actors demonstrate trust into the system, mutual understanding and willingness to collaborate. The objective(s) of collaboration and outputs of the multi-sectoral surveillance system meet stakeholders (surveillance actors and end-users) expectations.",N/A,N/A,"4. Endorsement of the documents where the rationale, the objective(s) and purpose of collaboration, and the areas of actions by relevant stakeholders from different sectors, disciplines and decision scales involved.
5. Relevance of the collaborative objective(s) and purpose regarding actors and end-users' expectations (including meeting the sectoral objectives).
10. Endorsement of the documents -formalising collaborative modalities, and role and responsibilities of surveillance actors involved- by all stakeholders from different sectors, disciplines and decision scales involved OR consistency of documents' contents across the institutions.
16. Adequation between areas of action, and roles and responsibilities assigned in the multi-sectoral surveillance system (collaborative and sectoral activities) regarding professional competencies.
32. Accessibility of initial training in relevant timeframe for operating actors involved in collaborative activities.
33. Relevance of initial training for operating actors involved in collaborative activities with the collaborative modalities and context.
35. Accessibility of ongoing training in relevant timeframe for operating actors involved in collaborative activities.
36. Relevance of ongoing training for operating actors involved in collaborative activities with the collaborative modalities and context.
38. Accessibility of the institutional memory to surveillance actors and end-users.
40. Appropriateness of the communication (both in terms of content and means) of the information produced by the multi-sectoral surveillance system to surveillance actors and end users.
45. Engagement of actors in their assigned areas of action, role and responsibilities in the multi-sectoral surveillance system",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Formalisation and endorsement of the collaborative surveillance strategy: Formalisation of the rationale, objective(s) and purpose of collaboration for the multi-sectoral surveillance system as well as the surveillance actors' area of actions and endorsement by relevant stakeholders involved from all sectors, disciplines and decision-making scales.",N/A,N/A,"1. Formalisation of rationale behind the willingness to collaborate for surveillance.
2. Formalisation of the objective(s) and purpose of collaboration for surveillance.
3. Formalisation of the surveillance actor's areas of action in the multi-sectoral surveillance system, i.e. the tasks they are assigned regarding collaboration and coordination of sectoral surveillance.
4. Endorsement of the documents where the rationale, the objective(s) and purpose of collaboration, and the areas of actions by relevant stakeholders from different sectors, disciplines and decision scales involved.","Relevance of collaborative objective(s) and purpose: Relevance of the collaborative objective(s) and purpose regarding stakeholders' expectations, the epidemiological and socio-economic context, the international/regional guidance (regulations, recommendations, standards).",N/A,N/A,"5. Relevance of the collaborative objective(s) and purpose regarding actors and end-users' expectations (including meeting the sectoral objectives).; 
6. Relevance of the collaborative objective(s) and purpose regarding the epidemiological, socio-political and economic context.; 
7. Relevance of the collaborative objective(s) and purpose regarding the international/regional guidance (regulations, recommendations, standards).","Formalisation of collaborative modalities: Description of collaboration in terms of modalities (area and degree of collaboration), and role and responsibilities of surveillance actors.",N/A,N/A,"8. Formalisation of the collaborative modalities, i.e. the area of collaboration (steps of the surveillance process) and the degree of collaboration; 
9. Formalisation of roles and responsibilities of actors involved in collaborative modalities; 
10. Endorsement of the documents -formalising collaborative modalities, and role and responsibilities of surveillance actors involved- by all stakeholders from different sectors, disciplines and decision scales involved OR consistency of documents' contents across the institutions.
",Relevance of collaborative modalities:Relevance of the collaborative modalities (area and degree of collaboration) across the different dimensions regarding collaborative objective(s) and context (including sectoral surveillance capacities),N/A,N/A,11. Relevance of the collaborative modalities regarding the collaborative objective(s) and context (including sectoral surveillance capacities),Coverage:Relevance of the dimensions and data sources covered by the multi-sectoral surveillance system regarding the collaborative objective(s) and context.,N/A,N/A,"12. Relevance of the collaborative dimensions (sectors, disciplines, decision making scales, professions) considered in the multi-sectoral surveillance system regarding the collaborative objective(s) and context.; 
13. Relevance of the data sources included in the multi-sectoral surveillance system regarding the collaborative objective(s) and context.",Governance of resources for collaboration: Definition of resource allocation mechanisms in the collaborative strategy and allocation of relevant resources for the implementation of collaborative modalities.,N/A,N/A,"14. Definition of specific mechanisms for financial, material and human resources allocation in the collaborative strategy.; 
15. Allocation of relevant financial, material and human resources for the implementation of collaborative modalities.; 
16. Adequation between areas of action, and roles and responsibilities assigned in the multi-sectoral surveillance system (collaborative and sectoral activities) regarding professional competencies.","Mechanism(s) for steering collaboration: Existence of appropriate and functional mechanism(s), including feed-back loop, for steering collaboration in the multi-sectoral surveillance system.",N/A,N/A,"17. Existence and formalisation of mechanism(s) for steering collaboration in the multi-sectoral surveillance system.; 
18. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the steering mechanism(s) for collaboration (inclusion, participation and appropriate voice).; 
19. Operationality of mechanism(s) for steering collaboration including the capacity to advocate for change.; 
20. Existence of appropriate feed-back loop in mechanism(s) for steering collaboration.; 
21. Availability of all appropriate resources to support mechanism(s) for steering collaboration.","Mechanism(s) for coordinating collaboration: Existence of appropriate and functional mechanism(s), including feed-back loop, for coordinating collaboration in the multi-sectoral surveillance system.",N/A,N/A,"22. Existence and formalisation of mechanism(s) for coordinating collaboration in the multi-sectoral surveillance system; 
23. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the coordinating mechanism(s) for collaboration (inclusion, participation and appropriate voice); 
24. Operationality of mechanism(s) for coordinating collaboration including the capacity to advocate change; 
25. Existence of appropriate feed-back loop in mechanism(s) for coordinating collaboration; 
26. Availability of all appropriate resources to support mechanism(s) for coordinating collaboration.","Mechanism(s) for technically and scientifically supporting collaboration: Existence of appropriate and functional mechanism(s), including feed-back loop, to technically and scientifically support collaboration in the multi-sectoral surveillance system.",N/A,N/A,"27. Existence and formalisation of mechanism(s) for supporting scientifically and technically collaboration in the multi-sectoral surveillance system.; 
28. Representativeness of all appropriate actors from relevant sectors, decisions scales and disciplines for supporting scientifically and technically collaboration (inclusion, participation and appropriate voice).; 
29. Operationality of mechanism(s) for supporting scientifically and technically collaboration including the capacity to advocate for change.; 
30. Existence of appropriate feedback loop for supporting scientifically and technically collaboration.",Training: Provision of relevant initial and ongoing training for operating actors involved in collaborative activities.,N/A,N/A,"31. Existence of designed and planned initial training for operating actors involved in collaborative activities.; 
32. Accessibility of initial training in relevant timeframe for operating actors involved in collaborative activities.; 
33. Relevance of initial training for operating actors involved in collaborative activities with the collaborative modalities and collaborative context.; 
34. Existence of designed and planned ongoing training for operating actors involved in collaborative activities.; 
35. Accessibility of ongoing training in relevant timeframe for operating actors involved in collaborative activities.; 
36. Relevance of ongoing training for operating actors involved in collaborative activities with the collaborative modalities and collaborative context.","Information and communication: Appropriate information production, management and communication.",N/A,N/A,"37. Existence of an institutional memory including all information related to the rationale of collaboration, to the organisation and functioning of the multi-sectoral surveillance system and to the outputs of the multi-sectoral surveillance system; 
38. Accessibility of the institutional memory to surveillance actors and end-users; 
39. Relevance of the information produced by multi-sectoral surveillance system regarding the collaborative objective(s); 
40. Appropriateness of the communication (both in terms of content and means) of the information produced by the multi-sectoral surveillance system to surveillance actors and end users.",Performance and evaluation:Existence of specific performance indicators of collaboration routinely used and of periodic external evaluations of collaboration.,N/A,N/A,"41. Existence and relevance of specific performance indicators of collaboration routinely used.; 
42. Existence of periodic external evaluation of collaboration or of the multi-sectoral surveillance system (including evaluation of collaboration).; 
43. Existence of periodic internal evaluation of collaboration or of the multi-sectoral surveillance system (including evaluation of collaboration).; 
44. Implementation of corrective measures, if deemed necessary following performance monitoring and evaluation results.","Engagement: Engagement of actors in their assigned areas of action, role and responsibilities in the multi-sectoral surveillance system",N/A,N/A,"45. Engagement of actors in their assigned areas of action, role and responsibilities in the multi-sectoral surveillance system","Collaboration for surveillance design: Implementation of appropriate and functional collaborative activities for the design of the surveillance programme (ex: selection of hazards and population under surveillance, data format, etc.).",N/A,N/A,"46. Relevance of the collaborative activities for surveillance design regarding the collaborative modalities and context; 
47. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for surveillance design to meet the collaborative objective(s);
48. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for surveillance design.","Collaboration for sampling: Implementation of appropriate and functional collaborative activities for sampling (ex: joint sample collection campaign, harmonised sample forms).",N/A,N/A,"49. Relevance of the collaborative activities for sampling regarding the collaborative modalities and context; 
50. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for sampling to meet the collaborative objective(s); 
51. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for sampling.","Collaboration for laboratory testing: Implementation of appropriate and functional collaborative activities for laboratory testing (ex: harmonization of testing methods, interpretation rules, data reporting, etc.).",N/A,N/A,"52. Relevance of the collaborative activities for laboratory testing regarding the collaborative modalities and context; 
53. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for laboratory testing to meet the collaborative objective(s); 
54. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for laboratory testing.",Collaboration for data sharing: Implementation of appropriate and functional collaborative activities for data sharing (ex: compatibility of information systems across sectors).,N/A,N/A,"55. Relevance of the collaborative activities for data sharing regarding the collaborative modalities and context;
56. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data sharing to meet the collaborative objective(s); 
57. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data sharing.",Collaboration for sharing surveillance results: Implementation of appropriate collaborative activities for sharing surveillance results (ex: joint inter-sectoral meeting).,N/A,N/A,"58. Relevance of the collaborative activities for results sharing regarding the collaborative modalities and context; 
59. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for results sharing to meet the collaborative objective(s); 
60. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for results sharing.","Collaboration for data management and storage: Implementation of appropriate and functional collaborative activities for data management/storage (ex: rules for data accessibility, usage and ownership, etc.).",N/A,N/A,"61. Relevance of the collaborative activities for data management/storage regarding the collaborative modalities and context; 
62. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data management/storage to meet the collaborative objective(s); 
63. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data management/storage.","Collaboration for data analysis and interpretation:I mplementation of appropriate and functional collaborative activities for data analysis and interpretation (ex: establishment of an inter-sectoral technical working group, etc.).",N/A,N/A,"64. Relevance of the collaborative activities for data analysis and interpretation regarding the collaborative modalities and context; 
65. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data analysis and interpretation to meet the collaborative objective(s); 
66. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data analysis and interpretation.","Collaboration for communication to surveillance actors: Implementation of appropriate collaborative activities for communication of surveillance results to surveillance actors (ex: joint inter-sectoral website, joint inter-sectoral meetings, etc).",N/A,N/A,"67. Relevance of the collaborative activities for communication of surveillance results to surveillance actors, regarding the collaborative modalities and context; 
68. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for communication of surveillance results to surveillance actors, to meet the collaborative objective(s); 
69. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for communication of surveillance results to surveillance actors.","Collaboration for external communication:Implementation of appropriate collaborative activities for external communication of surveillance results (ex: joint inter-sectoral website, joint reports, etc).",N/A,N/A,"70. Relevance of the collaborative activities for external communication of surveillance results regarding the collaborative modalities and context; 
71. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for external communication of surveillance results to meet the collaborative objective(s); 
72. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for external communication of surveillance results.","Collaboration for dissemination to beneficiaries: Implementation of appropriate collaborative activities for dissemination of surveillance results to beneficiaries (ex: joint inter-sectoral reporting to decision-makers, inter-sectoral platform for knowledge transfer, etc.).",N/A,N/A,"73. Relevance of the collaborative activities for dissemination of surveillance results regarding the collaborative modalities and context; 
74. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for dissemination of surveillance results to meet the collaborative objective(s); 
75. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for dissemination of surveillance results","Stability: Collaboration is stable in time, it is formalised and endorsed by all relevant stakeholders (surveillance actors and end-users).",N/A,N/A,"1. Formalisation of rationale behind the willingness to collaborate for surveillance;
2. Formalisation of the objective(s) and purpose of collaboration for surveillance;
3. Formalisation of the surveillance actor's areas of action in the multi-sectoral surveillance system, i.e. the tasks they are assigned regarding collaboration and coordination of sectoral surveillance;
4. Endorsement of the documents where the rationale, the objective(s) and purpose of collaboration, and the areas of actions by relevant stakeholders from different sectors, disciplines and decision scales involved;
8. Formalisation of the collaborative modalities, i.e. the area of collaboration (steps of the surveillance process) and the degree of collaboration;
9. Formalisation of roles and responsibilities of actors involved in collaborative modalities;
10. Endorsement of the documents -formalising collaborative modalities, and role and responsibilities of surveillance actors involved- by all stakeholders from different sectors, disciplines and decision scales involved OR consistency of documents' contents across the institutions;
14. Definition of specific mechanisms for financial, material and human resources allocation in the collaborative strategy;
17. Existence and formalisation of mechanism(s) for steering collaboration in the multi-sectoral surveillance system;
22. Existence and formalisation of mechanism(s) for coordinating collaboration in the multi-sectoral surveillance system;
27. Existence and formalisation of mechanism(s) for supporting scientifically and technically collaboration in the multi-sectoral surveillance system;
31. Existence of designed and planned initial training for operating actors involved in collaborative activities;
34. Existence of designed and planned ongoing training for operating actors involved in collaborative activities.","Relevance: Collaborative strategy, modalities and activities are relevant regarding the collaborative objective and context.",N/A,N/A,"5. Relevance of the collaborative objective(s) and purpose regarding actors and end-users' expectations (including meeting the sectoral objectives).; 
6. Relevance of the collaborative objective(s) and purpose regarding the epidemiological, socio-political and economic context.; 
7. Relevance of the collaborative objective(s) and purpose regarding the international/regional guidance (regulations, recommendations, standards).; 
11. Relevance of the collaborative modalities regarding the collaborative objective(s) and context (including sectoral surveillance capacities); 
12. Relevance of the dimensions (sectors, disciplines, decision making scales, professions) regarding the collaborative objective(s) and context; 
13. Relevance of the data sources regarding the collaborative objective(s) and context.; 
46. Relevance of the collaborative activities for surveillance design regarding the collaborative modalities and context; 
49. Relevance of the collaborative activities for sampling regarding the collaborative modalities and context; 
52. Relevance of the collaborative activities for laboratory testing regarding the collaborative modalities and context; 
55. Relevance of the collaborative activities for data sharing regarding the collaborative modalities and context; 
58. Relevance of the collaborative activities for results sharing regarding the collaborative modalities and context; 
61. Relevance of the collaborative activities for data management/storage regarding the collaborative modalities and context; 
64. Relevance of the collaborative activities for data analysis and interpretation regarding the collaborative modalities and context; 
67. Relevance of the collaborative activities for communication of surveillance results to surveillance actors, regarding the collaborative modalities and context; 
70. Relevance of the collaborative activities for external communication of surveillance results regarding the collaborative modalities and context; 
73. Relevance of the collaborative activities for dissemination of surveillance results regarding the collaborative modalities and context.","Operationality: The governance of collaboration is operational, and collaboration is effectively implemented to meet the surveillance objective.",N/A,N/A,"19. Operationality of mechanism(s) for steering collaboration including the capacity to advocate for change; 
20. Existence of appropriate feed-back loop in mechanism(s) for steering collaboration; 
24. Operationality of mechanism(s) for coordinating collaboration including the capacity to advocate change; 
25. Existence of appropriate feed-back loop in mechanism(s) for steering collaboration; 
29. Operationality of mechanism(s) for supporting scientifically and technically collaboration including the capacity to advocate for change; 
30. Existence of appropriate feedback loop for supporting scientifically and technically collaboration; 
39. Relevance of the information produced by multi-sectoral surveillance system regarding the collaborative objective(s); 
47. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for surveillance design to meet the collaborative objective(s); 
50. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for sampling to meet the collaborative objective(s); 
53. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for laboratory testing to meet the collaborative objective(s); 
56. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data sharing to meet the collaborative objective(s); 
59. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for results sharing to meet the collaborative objective(s); 
62. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data management/storage to meet the collaborative objective(s); 
65. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data analysis and interpretation to meet the collaborative objective(s); 
68. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for communication of surveillance results to surveillance actors, to meet the collaborative objective(s); 
71. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for external communication of surveillance results to meet the collaborative objective(s); 
74. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for dissemination of surveillance results to meet the collaborative objective(s).",Resources: The mechanisms for resources allocation are defined. The resources are appropriate and available for the effective implementation of activities of collaboration.,N/A,N/A,"14. Definition of specific mechanisms for financial, material and human resources allocation in the collaborative strategy; 
15. Allocation of relevant financial, material and human resources for the implementation of collaborative modalities; 
21. Availability of all appropriate resources to support mechanism(s) for steering collaboration; 
26. Availability of all appropriate resources to support mechanism(s) for coordinating collaboration; 
32. Accessibility of initial training in relevant timeframe for operating actors involved in collaborative activities; 
35. Accessibility of ongoing training in relevant timeframe for operating actors involved in collaborative activities; 
48. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for surveillance design; 
51. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for sampling; 
54. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for laboratory testing; 
57. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data sharing; 
60. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for results sharing; 
63. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data management/storage; 
66. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data analysis and interpretation; 
69. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for communication of surveillance results to surveillance actors,; 
72. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for external communication of surveillance results; 
75. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for dissemination of surveillance results.","Adaptability: Collaboration can adapt and evolve upon changes in governance modalities, knowledge and context.",N/A,N/A,"19. Operationality of mechanism(s) for steering collaboration including the capacity to advocate for change; 
20. Existence of appropriate feed-back loop in mechanism(s) for steering collaboration; 
24. Operationality of mechanism(s) for coordinating collaboration including the capacity to advocate change; 
25. Existence of appropriate feed-back loop in mechanism(s) for coordinating collaboration; 
29. Operationality of mechanism(s) for supporting scientifically and technically collaboration including the capacity to advocate for change; 
30. Existence of appropriate feedback loop for supporting scientifically and technically collaboration; 
41. Existence and relevance of specific performance indicators of collaboration routinely used; 
42. Existence of periodic external evaluation of collaboration or of the multi-sectoral surveillance system (including evaluation of collaboration); 
43. Existence of periodic internal evaluation of collaboration or of the multi-sectoral surveillance system (including evaluation of collaboration); 
44. Implementation of corrective measures, if deemed necessary following performance monitoring and evaluation results","Inclusiveness: Relevant surveillance actors and end-users participate in governance mechanisms. Roles in collaboration are adequately allocated to actors with regard their mandates and competencies. At the relevant dimensions, corresponding actors and data sources are considered to meet the collaborative objective(s).",N/A,N/A,"12. Relevance of the collaborative dimensions (sectors, disciplines, decision making scales, professions) considered in the multi-sectoral surveillance system regarding the collaborative objective(s) and context; 
13. Relevance of the data sources included in the multi-sectoral surveillance system regarding the collaborative objective(s) and context; 
16. Adequation between areas of action, and roles and responsibilities assigned in the multi-sectoral surveillance system (collaborative and sectoral activities) regarding professional competencies; 
18. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the steering mechanism(s) for collaboration (inclusion, participation and appropriate voice); 
23. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the coordinating mechanism(s) for collaboration (inclusion, participation and appropriate voice); 
28. Representativeness of all appropriate actors from relevant sectors, decisions scales and disciplines for supporting scientifically and technically collaboration (inclusion, participation and appropriate voice).","Shared leadership: Governance mechanisms are appropriate to guide the operation of collaboration in the multi-sectoral surveillance system. They provide a trustworthy environment where stakeholders can freely express their views and be heard, creating mutual understanding.",N/A,N/A,"4. Endorsement of the documents where the rationale, the objective(s) and purpose of collaboration, and the areas of actions by all stakeholders from different sectors, disciplines and decision scales involved;  
5. Relevance of the collaborative objective(s) and purpose regarding actors and end-users' expectations (including meeting the sectoral objectives);  
18. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the steering mechanism(s) for collaboration (inclusion, participation and appropriate voice);  
19. Operationality of mechanism(s) for steering collaboration including the capacity to advocate for change;  
23. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the coordinating mechanism(s) for collaboration (inclusion, participation and appropriate voice);  
24. Operationality of mechanism(s) for coordinating collaboration including the capacity to advocate change;  
28. Representativeness of all appropriate actors from relevant sectors, decisions scales and disciplines for supporting scientifically and technically collaboration (inclusion, participation and appropriate voice);  
29. Operationality of mechanism(s) for supporting scientifically and technically collaboration including the capacity to advocate for change.","System knowledge:The multi-sectoral surveillance system has a comprehensive and accessible institutional memory and demonstrates an effective communication system. Stakeholders (surveillance actors and end-users) have access to relevant information about the collaborative surveillance organisation and outputs. Surveillance data and results are shared at a relevant level, with regard to collaborative objective and context.",N/A,N/A,"12. Relevance of the collaborative dimensions (sectors, disciplines, decision making scales, professions) considered in the multi-sectoral surveillance system regarding the collaborative objective(s) and context;  
13. Relevance of the data sources included in the multi-sectoral surveillance system regarding the collaborative objective(s) and context;  
29. Operationality of mechanism(s) for supporting scientifically and technically collaboration including the capacity to advocate for change;  
33. Relevance of initial training for operating actors involved in collaborative activities with the collaborative modalities and collaborative context;  
36. Relevance of ongoing training for operating actors involved in collaborative activities with the collaborative modalities and collaborative context;  
37. Existence of an institutional memory including all information related to the rationale of collaboration, to the organisation and functioning of the multi-sectoral surveillance system and to the outputs of the multi-sectoral surveillance system;  
38. Accessibility of the institutional memory to surveillance actors and end-users;  
39. Relevance of the information produced by multi-sectoral surveillance system regarding the collaborative objective(s);  
40. Appropriateness of the communication (both in terms of content and means) of the information produced by the multi-sectoral surveillance system to surveillance actors and end users;  
56. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data sharing to meet the collaborative objective(s);  
59. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for results sharing to meet the collaborative objective(s);  
65. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data analysis and interpretation to meet the collaborative objective(s)","Management index: All elements contributing to the management of collaboration: existence and formalisation of a collaborative strategy, governance mechanisms for steering and coordination, performance monitoring and evaluation.",N/A,"In contrast to attributes, which relate to a specific organizational characteristic of collaboration, indexes aim at reflecting the collaboration's organization at a macro level.","01. Formalisation of rationale behind the willingness to collaborate for surveillance.; 
02. Formalisation of the objective(s) and purpose of collaboration for surveillance.; 
03. Formalisation of the surveillance actor's areas of action in the multi-sectoral surveillance system, i.e. the tasks they are assigned regarding collaboration and coordination of sectoral surveillance.; 
04. Endorsement of the documents where the rationale, the objective(s) and purpose of collaboration, and the areas of actions by relevant stakeholders from different sectors, disciplines and decision scales involved.; 
05. Relevance of the collaborative objective(s) and purpose regarding actors and end-users' expectations (including meeting the sectoral objectives).; 
06. Relevance of the collaborative objective(s) and purpose regarding the epidemiological, socio-political and economic context.; 
07. Relevance of the collaborative objective(s) and purpose regarding the international/regional guidance (regulations, recommendations, standards).; 
08. Formalisation of the collaborative modalities, i.e. the area of collaboration (steps of the surveillance process) and the degree of collaboration; 
09. Formalisation of roles and responsibilities of actors involved in collaborative modalities.; 
10. Endorsement of the documents -formalising collaborative modalities, and role and responsibilities of surveillance actors involved- by all stakeholders from different sectors, disciplines and decision scales involved OR consistency of documents' contents across the institutions.; 
11. Relevance of the collaborative modalities regarding the collaborative objective(s) and context (including sectoral surveillance capacities); 
12. Relevance of the collaborative dimensions (sectors, disciplines, decision making scales, professions) considered in the multi-sectoral surveillance system regarding the collaborative objective(s) and context.; 
13. Relevance of the data sources included in the multi-sectoral surveillance system regarding the collaborative objective(s) and context.; 
14. Definition of specific mechanisms for financial, material and human resources allocation in the collaborative strategy.; 
17. Existence and formalisation of mechanism(s) for steering collaboration in the multi-sectoral surveillance system.; 
18. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the steering mechanism(s) for collaboration (inclusion, participation and appropriate voice).; 
19. Operationality of mechanism(s) for steering collaboration including the capacity to advocate for change.; 
20. Existence of appropriate feed-back loop in mechanism(s) for steering collaboration.; 
21. Availability of all appropriate resources to support mechanism(s) for steering collaboration.; 
22. Existence and formalisation of mechanism(s) for coordinating collaboration in the multi-sectoral surveillance system.; 
23. Representativeness of all appropriate actors and end-users from relevant sectors, decisions scales and disciplines in the coordinating mechanism(s) for collaboration (inclusion, participation and appropriate voice).; 
24. Operationality of mechanism(s) for coordinating collaboration including the capacity to advocate change.
25. Existence of appropriate feed-back loop in mechanism(s) for coordinating collaboration.
26. Availability of all appropriate resources to support mechanism(s) for coordinating collaboration.
41. Existence and relevance of specific performance indicators of collaboration routinely used.
42. Existence of periodic external evaluation of collaboration or of the multi-sectoral surveillance system (including evaluation of collaboration).
43. Existence of periodic internal evaluation of collaboration or of the multi-sectoral surveillance system (including evaluation of collaboration).
44. Implementation of corrective measures, if deemed necessary following performance monitoring and evaluation results
45. Engagement of actors in their assigned areas of action, role and responsibilities in the multi-sectoral surveillance system
","Support index: All elements in place that ensure the smooth operation of collaboration: resources allocation, training, information and communication, technical and scientific support",N/A,"In contrast to attributes, which relate to a specific organizational characteristic of collaboration, indexes aim at reflecting the collaboration's organization at a macro level.","15. Allocation of relevant financial, material and human resources for the implementation of collaborative modalities; 
16. Adequation between areas of action, and roles and responsibilities assigned in the multi-sectoral surveillance system (collaborative and sectoral activities) regarding professional competencies; 
27. Existence and formalisation of mechanism(s) for supporting scientifically and technically collaboration in the multi-sectoral surveillance system; 
28. Representativeness of all appropriate actors from relevant sectors, decisions scales and disciplines for supporting scientifically and technically collaboration (inclusion, participation and appropriate voice); 
29. Operationality of mechanism(s) for supporting scientifically and technically collaboration including the capacity to advocate for change; 
30. Existence of appropriate feedback loop for supporting scientifically and technically collaboration; 
31. Existence of designed and planned initial training for operating actors involved in collaborative activities; 
32. Accessibility of initial training in relevant timeframe for operating actors involved in collaborative activities; 
33. Relevance of initial training for operating actors involved in collaborative activities with the collaborative modalities and collaborative context; 
34. Existence of designed and planned ongoing training for operating actors involved in collaborative activities; 
35. Accessibility of ongoing training in relevant timeframe for operating actors involved in collaborative activities; 
36. Relevance of ongoing training for operating actors involved in collaborative activities with the collaborative modalities and collaborative context; 
37. Existence of an institutional memory including all information related to the rationale of collaboration, to the organisation and functioning of the multi-sectoral surveillance system and to the outputs of the multi-sectoral surveillance system.
38. Accessibility of the institutional memory to surveillance actors and end-users.
40. Appropriateness of the communication (both in terms of content and means) of the information produced by the multi-sectoral surveillance system to surveillance actors and end users.
48. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for surveillance design.
51. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for sampling.
54. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for laboratory testing.
57. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data sharing.
60. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for results sharing.
63. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data management/storage.
66. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for data analysis and interpretation.
69. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for communication of surveillance results to surveillance actors.
72. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for external communication of surveillance results.
75. Availability of appropriate resources (financial, technical, material and human) to implement the collaborative activities for dissemination of surveillance results.",Operation index: All collaborative activities for surveillance (from surveillance design to results dissemination) that generate the relevant collaborative surveillance outputs to meet the collaborative objective(s) and purpose(s),N/A,"In contrast to attributes, which relate to a specific organizational characteristic of collaboration, indexes aim at reflecting the collaboration's organization at a macro level.","39. Relevance of the information produced by multi-sectoral surveillance system regarding the collaborative objective(s); 
46. Relevance of the collaborative activities for surveillance design regarding the collaborative modalities and context; 
47. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for surveillance design to meet the collaborative objective(s); 
49. Relevance of the collaborative activities for sampling regarding the collaborative modalities and context; 
50. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for sampling to meet the collaborative objective(s); 
52. Relevance of the collaborative activities for laboratory testing regarding the collaborative modalities and context; 
53. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for laboratory testing to meet the collaborative objective(s); 
55. Relevance of the collaborative activities for data sharing regarding the collaborative modalities and context; 
56. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data sharing to meet the collaborative objective(s); 
58. Relevance of the collaborative activities for results sharing regarding the collaborative modalities and context; 
59. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for results sharing to meet the collaborative objective(s); 
61. Relevance of the collaborative activities for data management/storage regarding the collaborative modalities and context; 
62. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data management/storage to meet the collaborative objective(s); 
64. Relevance of the collaborative activities for data analysis and interpretation regarding the collaborative modalities and context; 
65. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for data analysis and interpretation to meet the collaborative objective(s); 
67. Relevance of the collaborative activities for communication of surveillance results to surveillance actors, regarding the collaborative modalities and context; 
68. Appropriateness of the outputs of collaborative activities (including sectoral surveillance capacities) for communication of surveillance results to surveillance actors, to meet the collaborative objective(s).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"In its current form, the matrix has three main limitations.
First, the evaluation is based on a semiquantitative method to score criteria; this is undoubtedly marked by subjectivity despite the development of the scoring guide. Second, the current matrix does not evaluate the effectiveness of collaboration, nor its impacts and cost, which are crucial parameters for decision-makers (2, 17, 18). Third, the selection of the criteria to support the evaluation of attributes or indexes has not been validated by experts. Furthermore, the scoring method leading to evaluation results of attributes and indexes is assuming that all criteria are of equal importance and may be questioned.

The tool still needs to be finalized through field-testing and the development of a detailed framework to standardize its application. Once these steps are completed, the tool will enable the evaluation of a collaboration's capacity to achieve its goal in a multisectoral setting, as well as its strengths and weaknesses in terms of organization, implementation, and functionality.
 Evaluation results could then be used to support the development of recommendations to improve the quality and appropriateness of collaboration.",N/A,N/A,"8. Hattendorf J, Bardosh KL, Zinsstag J. One Health and its practical implications for surveillance of endemic zoonotic diseases in resource limited settings. Acta Trop. (2017) 165:268-73. doi: 10.1016/j.actatropica.2016.10.009 
11. Ruegg SR, Nielsen LR, Buttigieg SC, Santa M, Aragrande M, Canali M, et al. A systems approach to evaluate One Health initiatives. Front Vet Sci. (2018) 5:23. doi: 10.3389/fvets.2018.00023 
13. Bordier M, Binot A, Pauchard Q, Nguyen DT, Trung TN, Fortané N. Antibiotic resistance in Vietnam: moving towards a One Health surveillance system. BMC Public Health. (2018) 18:1136. doi: 10.1186/s12889-018-6022-4 
14. RISKSUR. Best Practices for Risk-Based and Cost Effective Animal Health Surveillance. (2015). Available online at: https://www.fp7-risksur.eu/sites/default/files/documents/publications/riskbasedsurv_BPdoc_FINAL_formatted_03.pdf (Accessed June 12, 2018). 
15. D'Amour D, Ferrada-Videla M, San Martin Rodriguez L, Beaulieu MD. The conceptual basis for interprofessional collaboration: core concepts and theoretical frameworks. J Interprof Care. (2005) 19(Suppl 1):116-31. doi: 10.1080/13561820500082529 
17. Baum SE, Machalaba C, Daszak P, Salerno RH, Karesh WB. Evaluating one health: are we demonstrating effectiveness? One Health. (2017) 3:5-10. doi: 10.1016/j.onehlt.2016.10.004 
18. Lee K, Brumme ZL. Operationalizing the One Health approach: the global governance challenges. Health Policy Plan. (2013) 28:778-85. doi: 10.1093/heapol/czs127 
19. Edelstein M, Lee LM, Herten-Crabb A, Heymann DL, Harper DR. Strengthening global public health surveillance through data and benefit sharing. Emerg Infect Dis. (2018) 24:1324-30. doi: 10.3201/eid2407.151830","To review supplemental file 4 when drafting evaluation framework.

Although the matrix can be used independently if there is a need to focus on collaboration only, it can be combined with surveillance attributes within existing evaluation tools for an overall assessment of the multisectoral surveillance system.

The matrix enables the evaluation of collaboration by assessing satisfaction from different angles, namely: (i) the collaboration's organization at a microlevel with regards to attributes relating to specific collaborative characteristics; (ii) the collaboration's organization at a macrolevel with regards to indexes encompassing a wide range of elements contributing to the same process; and (iii) the collaboration's functions with regards to attributes reflecting core collaborative functionalities. The evaluation attributes have been validated by a group of experts in the field of OH surveillance, and converge with those defined as characterizing collaboration in other activity fields, such as inter-professional collaboration in health care facilities. Indeed, collaboration is not specific to multisectoral surveillance systems, and the attributes developed for the purpose of this matrix could be efficiently used to assess collaboration in other surveillance settings and, after adaptation, even in other multistakeholder systems.",
bordierCharacteristicsOneHealth2020,465,Bordier 2020,Characteristics of One Health surveillance systems: A systematic literature review.,Characteristics of One Health surveillance systems: A systematic literature review,2020,Marion Bordier,marion.bordier@cirad.fr,Vietnam,Systematic review of characteristics of One Health surveillance systems with conceptual framework for One health surveillance system collaboration,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Coordination of the surveillance system,N/A,N/A,"Mono or multi-institutional coordination

 Number of institutions in charge of the coordination

 Type of institutions involved in the coordination (government, academia, independent agency, etc.)

 Administrative-level in charge of the coordination

 Number of sectors involved in the coordination

 Type of sectors in charge of the coordination",Geographical area,N/A,N/A,"Level of coverage of the surveillance (supra-national, national, subnational); Territory under surveillance",Date,N/A,N/A,Year of establishment of first collaborative efforts,General organisation,N/A,N/A,"Status of the surveillance system (stand-alone or part of a programme); 
Origin of funds (state, private, external, etc.); 
Sustainability of funding; 
A priori or a posteriori integration of sectoral surveillance components.",Objectives and purposes,N/A,The ability of the system to meet the objectives of the different stakeholders was specifically identified to be the key to success and sustainability of the surveillance system.,Objectives of the surveillance system; Purposes of the surveillance systems,Hazards under surveillance,N/A,N/A,Number of hazards (mono or multi-hazards); Type of hazards; Communicability of hazards under surveillance,Domains under surveillance,N/A,Availability of a joint database or the ease of data exchange favours collaboration.,"Type of domains under surveillance (domestic animal, human, food, wildlife, etc.); 
Number of domains under surveillance; 
Data sources in each domain; 
Type of data in each domain; 
Epidemiological status in each domain",Terminology,N/A,N/A,Terms which are used to describe inter-sectoral and inter-disciplinary collaboration,Type of collaboration,N/A,"The analysis of the existing systems led to the identification of four main dimensions where collaboration across sectors and disciplines may occur (variables 25-33 in Table 2): 
(i) institutional collaboration across sectors for the governance and operation of the surveillance system; 
(ii) collaboration at the different scales of the decision-making process; 
(iii) collaboration across disciplines; 
(iv) collaboration through public-private partnerships.  The first dimension refers to collaboration between sectoral institutions with different jurisdictions and mandates, mainly public health, animal health, plant health, environmental health and food safety.  
The second collaborative dimension concerns the engagement of different disciplines, among biosciences, social sciences and engineering.  A third collaborative dimension can be described regarding collaboration between different decision-making scales. These scales include the different administrative jurisdictional scales within a same country (central, provincial and local authorities) but also the supra-national scales such as the international-scale (e.g. international organisations) or the regional-scale (e.g. regional economic communities). Within this dimension, the engagement of civil society must also be considered and is, for instance, clearly emphasised for two surveillance systems targeting rabies.  Finally, a last collaborative dimension can be defined through the development of public-private partnerships within, but also across, sectors. For instance, in Canada, veterinary pharmaceutical companies as well as private veterinarians collaborate within the surveillance system for antimicrobial resistance, which is coordinated by the Ministry of Health.","Type of sectors collaborating within the surveillance process;  
Mechanisms in place to support institutional collaboration;  
Decision-making scales involved in surveillance activities (supra-national authorities/organisations, national authorities, subnational authorities, etc.);  
Private actors involved in surveillance activities (veterinarians, food/feed operators, pharmaceutical companies, etc.);  
Type of collaborative efforts for surveillance activities (conception of the surveillance protocol, joint sampling campaigns laboratory facilities sharing, data exchange, inter-sectoral data analysis and interpretation, etc.);  
Mechanisms in place to support collaboration for surveillance activities;  
Type of collaborative efforts for dissemination of surveillance results;  
Mechanisms in place to support collaboration for dissemination of surveillance results;  
Type of disciplines involved in the surveillance process.",Factors influencing collaboration,N/A,"Factors that have positively influenced the implementation and the functioning of a collaborative surveillance system are: 
- Existence of an appropriate framework to ease collaboration across sectors; 
- Surveillance systems are embedded in an overarching OH programme and benefit from the existing inter-sectoral framework to develop collaborative surveillance activities; 
- Existence of an appropriate legal or institutional framework as a lever for collaboration; 
- Preferential relationships existing between individuals working in different sectors and disciplines; 
- Clear definition of roles and duties of the different agencies involved is considered to have strongly supported the operationalisation of collaboration; 
- Existence of inter-sectoral collaboration mechanisms already established at a supra-level will also usually provide a framework for infra-level collaboration; 
- Supervision, by the same authority, of sectors in charge of surveillance components.
Other favouring factors are related to mechanisms ensuring the commitment of stakeholders, at the political and operational-levels.",Favouring factors for collaboration,Performance of the surveillance system,N/A,N/A,"Elements supporting evidence of a good performance of the system; 
Elements supporting evidence of a bad performance of the system",Benefits,N/A,N/A,Elements supporting evidence of benefits of collaboration,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Our findings reinforce the hypothesis that the lack of a conceptual framework to accurately define the notion of OH surveillance is undermining the operationalisation of collaborative efforts for efficient and sustainable surveillance systems.,N/A,N/A,"Baum, S.E., Machalaba, C., Daszak, P., Salerno, R.H., Karesh, W.B., 2017. Evaluating one health: are we demonstrating effectiveness? One Health 3, 5-10.

Uchtmann, N., Herrmann, J.A., Hahn, E.C., Beasley, V.R., 2015. Barriers to, efforts in, and optimization of integrated one health surveillance: a review and synthesis. EcoHealth 12 (2), 368-384.","A OH surveillance system is a system in which collaborative efforts exist between at least two sectors (among human health, animal health, plant health, food safety, wildlife and environmental health) at any stage of the surveillance process, to produce and disseminate information with the purpose of improving an aspect of human, animal or environmental health.

Operational collaboration can occur at any/all steps of the surveillance process: planning, data collection, data sharing, data analysis/interpretation, results dissemination.

Barriers that hamper the operation of collaborative surveillance systems have been specified for 20 systems (48.8%). These are mostly technical barriers (78.6%): a lack of standardisation and harmonisation for data collection, incomplete data, insufficient data-sharing across sectors including unreliable cross-sectoral alert systems, incomplete multi-domain data analysis and interpretation. In four cases, the collaboration might not have reached a sufficient level because of the absence of engagement among the private sector (Sorensen et al., 2014) or an insufficient integration with certain sectoral components still conducted separately.

 In addition, legal constraints are also mentioned for 42.9% of systems: the property and confidentiality of data, ethical issues, and an inadequate legal and operational framework to precisely define the roles and mandates of the different actors involved and to support collaboration at ground-level. Inappropriate amounts and allocation of resources are also impediments to collaborative approaches. On the one hand, budgets are vertically allocated and there are no resources available for cross-sectoral actions. On the other hand, resources are scarce, especially for surveillance activities, and stakeholders may have to compete for them, reinforcing the lack of collaboration. 

Finally, competing priorities among actors may also obstruct the involvement of the different parties in a OH surveillance system.

The same observation can be made regarding the terms ""multi-disciplinary"" and ""multi-sectoral"" which are regularly used, one for the other, to describe ongoing collaboration happening within surveillance systems. Discipline refers to a branch of knowledge (medicine, epidemiology, economics, sociology, etc.) while sector refers to a branch of activities (animal health, public health, food and water safety, environmental health, etc.). In our view, a surveillance system showing a multi-disciplinary approach without cross-sectoral collaboration should not be qualified as OH. 

Transdisciplinarity is, however, the quintessence of a OH initiative and refers to the integration across both sectors and disciplines.

See Figure 3 for the organisation of collaboration in a One Health surveillance system: a conceptual framework.",
bordierEvaluationCollaborationMultisectoral2022,13692,Bordier 2022,Evaluation of collaboration in a multisectoral surveillance system: The ECoSur tool,Evaluation of Collaboration in a Multisectoral Surveillance System: The ECoSur Tool,2022,Marion Bordier,Marion.bordier@cirad.fr,Vietnam,Tool for the evaluation of collaboration for surveillance taking place in multisectorial surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,First Step: Defining the Evaluation Question and the Evaluation Boundaries,"The aim of ECoSur is to answer the overall question: Is collaboration appropriate to produce the expected results in the given context?

However, the rationale and objective for conducting the evaluation might differ from a situation to another and should be clearly defined with stakeholders requiring  the evaluation to adjust the evaluation process as well as the report's format and contents.",Use of data collection file,N/A,"It is highly important that the evaluation team defines the boundaries of the system under evaluation and the type of collection programs that will be included, and then adheres to this definition throughout the evaluation process. Finally, in very complex systems with more than 20 components, some components may be more connected than others, creating subsystems within the whole system. For certain attributes, it may be necessary to evaluate the entire system and then each subsystem independently. If this methodological approach is adopted, the evaluation team will have to set a clear scoring protocol to ensure consistency.

Before launching the evaluation process, it is recommended to organize a meeting with the evaluation team and selected stakeholders to present the evaluation exercise and to agree on the evaluation objective and expected outputs. Stakeholders here consist of people initiating the evaluation and people involved in the sectoral and multisectoral governance mechanisms.",Second Step: Collecting Data,N/A,"Use of data collection file and data collection form

A preliminary desktop study should be done to collect all necessary data to complete the data collection file as much as possible, both the actors and components sheets, and the data collection form. This study can be completed with interviews of informants identified as having an extensive knowledge about the surveillance system.","It is recommended to start filling out the data collection file before the data collection form. However, the data collection step is not linear and a back-and-forth process between the tables and the form will most realistically occur. Once all the information available is captured in both the form and the file, a list of missing or unreliable information should be drawn up. Interviews with informants must be conducted to clarify and collect additional information. All the surveillance component coordinators should be interviewed. Additional informants to be interviewed depend on the multisectoral surveillance system under evaluation (including the rationale behind its establishment), the evaluation context (time and resources allocated, evaluation objective), and the sought information.","The time required to complete this step is dependent on the evaluation team's knowledge about the system, the availability and reliability of data in the literature, the number of surveillance components comprising the system, and the number of required interviews. It may take one or two weeks (full time) on average.

- It is highly recommended to harmonize information captured in the different columns of the data collection file, so filters can be applied and information easily extracted for filling the data collection form.
- It can be useful to map the system simultaneously as the information is retrieved to get a graphical representation of the interactions among actors and collaboration across components.
",Third Step: Scoring the Criteria of the Organizational and Function Attributes,N/A,"Use of evaluation matrix For each criterion, evaluators analyze the information available in the data collection file and form and choose the most appropriate grade. There are four grades ranging from Grade 0 to Grade 3 (best score).",N/A,"If the data collection form and file have been appropriately filled, the scoring process can be completed within the relatively short time of 2 days. However, if the surveillance is complex with many components involved, it can take more time as evaluation might be conducted both at the system and at the subsystems levels.
- It is advised that, where not all required elements for a grade are met, the grade below should be given in order that improvements be clearly noticeable in the future.
- There are 74 criteria to be scored in total. Each criterion is very specific in addressing a characteristic of collaboration at one of the different collaborative levels, namely collaborative strategy, modalities, and activities. Evaluators should go through all the criteria once before starting the scoring to get an overview of the full process. This may help prevent them from evaluating at the wrong stage a characteristic that is addressed in a later criterion.
- Some criteria address the collaboration only while others evaluate the multisectoral surveillance system as a whole (sectoral surveillance and collaborative efforts). Evaluators should clearly identify the evaluation level each criterion is considering when scoring.",Fourth Step: Interpreting Evaluation Results,"Once the scoring is done, the spreadsheet will automatically produce three graphical outputs on the third sheet, which correspond to the evaluation results of the organizational attributes and indexes, and functional attributes
- Output 1 provides the individual results of the 12 organizational attributes in independent pie charts. It allows the easy identification of the weak parts of the collaborative organization. Evaluators can refer to the second sheet of the matrix to track back the criteria that contribute to the scoring of each attribute. It helps to better understand the reasoning behind the scoring and to determine how the different criteria impact the attribute's grade.
- Output 2 displays the results of the organizational indexes in a single histogram. This graphical representation illustrates the level of satisfaction regarding the collaborative effort's organization at a macro level, from the management, support, and operational points of view. The use of the histogram allows for the visualization of these three highly aggregated evaluation results at a glance and enables an easy comparison.
- Output 3 shows the efficacy of the collaborative effort within the multisectoral surveillance system. It facilitates the analysis of the balance between the different collaborative functions. It can help to identify the specific collaborative functions that need to be strengthened to make the system more effective.",Automatically calculated in spreadsheet,N/A,"These outputs need to be analyzed and interpreted according to the justification of the scoring. They should support the identification of the strengths and weaknesses of collaboration and provide the foundation for drafting of recommendations for its improvement, if deemed necessary.",Fifth Step: Organizing a Workshop to Validate the Evaluation Results,"Once the scoring has been completed and evaluation results interpreted by the evaluation team, a workshop must be organized with key actors of the multisectoral surveillance system under evaluation.",N/A,N/A,"Key actors might be coordinators of the surveillance components or informants who were interviewed during the data collection step. The number of participants should not exceed 10 people to ease facilitation of discussion. The aim of this workshop is to discuss, revise if necessary, and validate the scores, as well as the justification provided. On this basis, recommendations can be refined. To review all the criteria, the workshop will need to take one day, or one-and-a-half days if the system is large.",Sixth Step: Drafting the Report,All evaluation results and recommendations should be released in a report drafted by the evaluation team. Evaluation results should always be communicated with relevant explanation and contextualization.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Epidemiologists with at least one experimented in surveillance,N/A,"ECoSur is meant to be applied by an evaluation team. It is recommended that the team members are not involved in the governance of the multisectoral surveillance system, meaning that they are not in charge of steering or coordinating sectoral or collaborative surveillance activities. At least one team member should be familiar with ECoSur while all others should follow a quick training prior the evaluation exercise.",N/A,Not specified,N/A,"Along with the evaluation team, one or two stakeholders of the multisectoral surveillance system should be identified and involved in the whole evaluation process. This will favor the acceptability of the evaluation process.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,Evaluation matrix appears to be the same as that provided in Bordier 2019 (One Health Surveillance: A Matrix to Evaluate Multisectoral Collaboration). See supplemental files and extracted information for the 2019 article.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"What ECoSur is not doing:
* This tool does not consider collaboration between actors operating in the same surveillance component.
* This tool does not evaluate the overall performance of the multisectoral surveillance system itself; however, the evaluation of certain collaborative attributes uses data on sectoral surveillance components.
* At this stage of development, this tool does not evaluate the impacts and cost of collaboration and so it does not intend to measure the relation between the quality of collaboration and the effectiveness of the multisectoral surveillance system.
* The tool is not intended to measure the extent of integration achieved in the multisectoral surveillance system. The aim is to characterize the integration that the multisectoral surveillance system seeks to achieve, to assess if this integration level is coherent with the collaborative context and objective(s), and whether the collaborative activities implemented to achieve the intended integration generate the expected outputs.",N/A,N/A,Related resources at: https://survtools.org/wiki/surveillance-evaluation/doku.php?id=quality_of_the_collaboration,"IMPORTANT: Evaluation matrix appears to be the same as that provided in Bordier 2019 (One Health Surveillance: A Matrix to Evaluate Multisectoral Collaboration). See supplemental files and extracted information for the 2019 article. ECoSur can be used independently if there is a need to focus on collaboration only or combined with existing evaluation tools for an overall assessment of the multisectoral surveillance system. In this context, the ECoSur tool (Evaluation of Collaboration for Surveillance) allows for the evaluation of the quality and appropriateness of multisectoral collaboration through an in-depth analysis of its organization and functions. The final purpose is to assess if collaboration as planned and implemented is relevant and functional to produce the expected collaborative outputs and to identify its strengths and weaknesses to formulate recommendations for its improvement. By collaboration we mean interactions between actors operating in different surveillance components and that have been established to improve the surveillance value, mainly in terms of performance and cost-effectiveness, in such a way that the outputs of the surveillance would not be possible without collaboration.

The basic principle behind the development of this tool is that, for multisectoral surveillance systems to be functional and sustainable, collaboration must be planned and organized at three levels:
* The policy level, where the collaborative strategy is stated.
* The strategy describes the desired goals of developing collaboration for surveillance and the course of actions to achieve those goals. It also covers the desired multisectoral organizational model and the areas of action of the main stakeholders within this organization. The strategy may be described in various documents depending on the legal tradition of the country, and on who developed it (government, academia, professional organizations, etc.). These can be policies, strategies, memorandums, laws, etc. Such documents are developed at a high political level when it comes to official surveillance. The collaborative strategy for surveillance can be described in a stand-alone document or in an overarching document (control program for a specific health issue, national One Health strategy, etc.).
* The institutional level, where relevant collaborative modalities for the governance and implementation of surveillance activities are defined to achieve the desired goal of the strategy.
* The collaborative modalities for the governance are described in terms of steering and coordinating mechanisms as well as of scientific and technical support. The collaborative modalities for the operation are usually expressed in terms of area of collaboration (i.e., the steps of the surveillance process where collaboration is implemented) and degree of integration (i.e., the strength of collaboration for each area of collaboration). (See Table 9.1 for the possible collaborative modalities in a multisectoral surveillance system.) The modalities are usually described in implementing texts, such as regulations, agreements, or charters.
* The operational level where surveillance activities are implemented to ensure the routine operation of the collaborative modalities.
* These activities are conducted at the ground level by surveillance actors to make the collaboration happen. They are usually supported by operational procedures.

See Table 9.1 for the possible collaborative modalities for the implementation of surveillance activities. Area of collaboration during the surveillance process include: surveillance protocol design; data collection (sampling, laboratory testing); data storage and management; data sharing; data analysis and interpretation; results sharing; dissemination to decision-makers; communication to surveillance actors and end-users.

See Figure 9.1 for a description of the three levels of collaboration. The three levels of collaboration must be clearly formalized and endorsed by stakeholders and be relevant to each other. Collaboration for surveillance is generated by stakeholders' expectations regarding the multisectoral surveillance system and is under the influence of a broad range of contextual elements, such as socioeconomic and epidemiological factors, international guidance, and sectoral surveillance capacities.

To evaluate collaboration in a multisectoral surveillance system, attributes and indexes were defined as below:
- A list of 22 organizational attributes that aims at evaluating core characteristics for the organization of collaboration for the governance and implementation of surveillance activities.
- A list of nine functional attributes that aims at evaluating core functions of collaboration for an effective and sustainable multisectoral surveillance system.
- A list of three organizational indexes that aims at evaluating organization of collaboration at a macro level.

The level of satisfaction of these attributes and indexes is then measured using 74 evaluation criteria, which are scored following a four-tiered scoring grid. The same criterion can be used to evaluate several functional attributes. On the contrary, each organizational attribute and index is evaluated with a set of specific criteria without any overlap.

ECoSur is composed of four elements.
* A spreadsheet file, referred to as ""Data collection file,"" allows for the collection of preliminary information on all the different surveillance actors and components of the multisectoral surveillance system being evaluated. It includes two sheets, one specific to the surveillance components and one to actors.
* A text file, referred to as ""Data collection form,"" allows a synthesis of all data describing precisely the governance and operation of collaboration in the multisectoral surveillance system that will be used to score the evaluation attributes. This form is divided into three sections: contextualization, governance, and operation of collaboration.
* A spreadsheet, referred to as ""Evaluation matrix,"" consisting of four distinct sheets:
- The first sheet (""Criteria Scoring"") contains the scoring grid for the 74 evaluation criteria. Four grades are defined: Grade 3 indicates that the situation complies fully with the criterion while Grade 0 indicates a total absence of compliance. Grades 2 and 1 are intermediate grades depending on the level of compliance. In some cases, the value ""Non-relevant"" can be used if the criterion is not relevant to the multisectoral surveillance system under evaluation. A scoring guide was developed to describe the situation in which grades should be awarded.
- The second sheet (""Attributes Indexes"") displays the list of attributes and indexes as well as the criteria contributing to their evaluation.
- Once the scoring is completed in the first sheet, the third sheet (""Evaluation Results"") automatically produces three graphical representations of the evaluation results. Different chart types help to differentiate easily the three levels of evaluation obtained: organization at a micro level, organization at a macro level, and functions.

The first display represents the evaluation results for the 22 organizational attributes (12 governance and 10 operational attributes). The result for each attribute can be visualized in a pie chart. Each colored area within a pie chart represents the attribute's level of compliance regarding a nominal situation where all evaluation criteria score 3.

The second display represents the evaluation results of the indexes. Results of the three indexes are expressed as percentages of compliance of the situation as compared to a nominal situation where all criteria score 3.The last display represents the evaluation results of the nine functional attributes on a spider chart. Results are expressed on a five-tiered scale, from A to E corresponding to the level of satisfaction for each core collaborative function. Grade A corresponds to a level ranging from 76 to 100%, meaning that almost all criteria supporting the evaluation of the attribute scored 3, while grade E corresponds to 0%, meaning that they all scored 0. Grades B, C, and D are intermediate levels of satisfaction, representing ranges of 51-75, 26-50, and 1-25%, respectively.
- The fourth sheet (""Calculation"") contains all the formula to obtain the scoring of attributes and indexes and displays the numerical results of evaluation for each of them. The same formula is used for all calculation: the sum of the grade awarded to the criteria contributing to their definition, divided by the sum of the highest score obtained by these criteria when the ideal situation is met (i.e., all criteria scored 3).
",
bravataEvaluatingDetectionDiagnostic2004,10990,Bravata 2004,Evaluating detection and diagnostic decision support systems for bioterrorism response.,Evaluating Detection and Diagnostic Decision Support Systems for Bioterrorism Response,2004,Dena M. Bravata,bavata@healthpolicy.stanford.edu,United States of America,Framework for the design of future evaluations of detection and diagnostic decisions support system for bioterrorism repsonse,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Is the portability of the system described?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Are diagnostic sensitivity and specificity described?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Are diagnostic sensitivity and specificity described?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Is the timeliness of diagnostic information described?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,See section 23 for related answer.,N/A,N/A,"Bravata DM, McDonald K, Owens DK, Smith W, Rydzak C, Szeto H, et al. Bioterrorism preparedness and response: use of information technologies and decision support systems (Evidence Report/Technology Assessment No. 59). Rockville (MD): prepared by the UCSF-Stanford Evidence-based Practice Center under Contract No. 290-97-0013 for the Agency for Healthcare Research and Quality; 2002.","Evaluation criteria

Is the timeliness of diagnostic information described? 
Are diagnostic sensitivity and specificity described? 
Is the reference standard against which the system was compared described? 
Are the system's security measures described? 
Is the evaluation of the system over a range of clinical situations or patient populations described? 
Is the portability of the system described? 
Is the system's ability to run more than one sample at a time described? 
Is the system's ability to detect more than one bioterrorism agent described? 
Is the system's ability to detect either/both toxins and organisms described? 
Is the inclusion of all bioterrorism agents and associated illnesses in the system's knowledge base described? 
Is the flexibility to update the probability of bioterrorism-related illness as the epidemic progresses described? 
Is the method of reasoning used by inference engine described? 
Is the use of standard vocabulary described? 

The first important design consideration is that both sensitivity and specificity (or likelihood ratios) must be measured relative to an appropriate reference standard.
Because sensitivity and specificity are jointly determined by the choice of threshold for a positive (or abnormal) test, either sensitivity or specificity can be made arbitrarily high at the expense of the other. Thus, reporting one without the other is not informative. Reporting both sensitivity and specificity for a variety of thresholds for abnormal tests as a receiver operating characteristic (ROC) curve (Figure 2) is preferable.

To develop unbiased estimates of sensitivity and specificity, studies of detection systems should use an appropriate reference standard test, the reference standard should be applied to all samples, the tests should be interpreted while blinded to results of the reference standard, and the samples or patient population should resemble as closely as possible the populations in which the system will be used (40). The reference standard should be used for all positive and negative samples. Selective use of the reference standard, for example, using the reference standard only on samples that are positive on the test under consideration, creates so-called test referral bias which can produce overestimates of sensitivity and underestimates of specificity (40). 

Finally, the detection system should be evaluated under the most realistic conditions possible, which may be difficult to implement for bioterrorism agents given the range of conditions from hoaxes with no cases to real situations with a number of cases.",
bravataEvaluatingDetectionDiagnostic2004,2254,Buehler 2004,Framework for evaluating public health surveillance systems for early detection of outbreaks: recommendations from the CDC Working Group.,Framework for Evaluating Public Health Surveillance Systems for Early Detection of Outbreaks: Recommendations from the CDC Working Group,2004,James W. Buehler,unknown,United States of America,Framework for evaluating public health surveillance system for early outbreak detection (supplement to previous CDC guidelines),"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,A. System Description,"1. Purpose. The purpose(s) of the system should be explicitly and clearly described and should include the intended uses of the system; 
2. Stakeholders. The stakeholders of the system should be listed. Stakeholders include those who provide data for the system and those who use the information generated by the system (e.g., public health practitioners; health-care providers; other health-related data providers; public safety officials; government officials at local, state, and federal levels; community residents; nongovernmental organizations; and commercial systems developers). The stakeholders might vary among different systems and might change as conditions change. Listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results; 
3. Operation. All aspects of the operation of the syndromic surveillance system should be described in detail to allow stakeholders to validate the description of the system and for other interested parties to understand the complexity and resources needed to operate such a system","Detailed system description also will facilitate evaluation by highlighting variations in system operation that are relevant to variations in system performance (Figure 1). Such a conceptual model can facilitate the description of the system. The description of the surveillance
process should address 1) systemwide characteristics (data flow [Figure 2]), including data and transmission standards to facilitate interoperability and data sharing between information systems, security, privacy, and confidentiality; 2) data sources (used broadly in this framework to include the data-producing facility [i.e., the entity sharing data with the public health surveillance system], the data type [e.g., chief complaint, discharge diagnosis, laboratory test order], and the data format [e.g., electronic or paper, text descriptions of events or illnesses, or structured data reworded or stored in standardized format]); 3) data processing before analysis (the data collation, filtering, transformation, and routing functions required for public health to use the data, including the classification and assigning of syndromes); 4) statistical analysis (tools for automated screening of data for potential outbreaks); and 5) epidemiologic analysis, interpretation, and investigation (the rules, procedures, and tools that support decision-making in response to a system signal, including adequate staffing with trained epidemiologists who can review, explore, and interpret the data in a timely manner).",N/A,"The description of purpose should include the indications for implementing the system; whether the system is designed for short-term, high-risk situations or long-term, continuous use; the context in which the system operates (whether it stands alone or augments data from other surveillance systems); what type of outbreaks the system is intended to detect; and what secondary functional value is desired. Designers of the system should specify the desired sensitivity and specificity of the system and whether it is intended to capture small or large events.",B. Outbreak Detection,"The ability of a system to reliably detect an outbreak at the earliest possible stage depends on the timely capture and processing of the data produced by transactions of health behaviors (e.g., over-the-counter pharmaceutical sales, emergency department visits, and nurse call-line volume) or health-care activities (e.g., laboratory test volume and triage categorization of chief complaint) that might indicate an outbreak; the validity of the data for measuring the conditions of interest at the earliest stage of illness and the quality of those data; and the detection methods applied to these processed surveillance data to distinguish expected events from those indicative of an outbreak.",Timeliness; validity; sensitivity; PVP; PVN; Data Quality (Representativeness; completeness of data),N/A,N/A,C. System Experience,The performance attributes described in this section convey the experience that has accrued in using the system.,System usefulness; flexibility; system acceptability; portability; system stability; system costs,N/A,N/A,D. Conclusions and Recommendations for Use and Improvement of Systems for Early Outbreak Detection,"The evaluation should be summarized to convey thestrengths and weaknesses of the system under scrutiny. Summarizing and reporting evaluation findings should facilitate the comparison of systems for those making decisions about new or existing surveillance methods. These conclusions should be validated among stakeholders of the system and modified accordingly. Recommendations should address adoption, continuation, or modification of the surveillance system so that it can better achieve its intended purposes. Recommendations should be disseminated widely and actively interpreted for all",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Supporting case detection and public health interventions,Estimating the impact of a disease or injury,Portraying the natural history of a health condition,Determining the distribution and spread of illness,Generating hypotheses and stimulating research,Evaluating prevention and control measures,Facilitating planning,"Outbreak detection (i.e., identifying an increase in frequency of disease above the background occurrence of the disease)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Objectives listed are the provided objectives for public health surveillance in general.,N/A,N/A,Public health practitioners,N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,Health-care providers,N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,Other health-related data providers,N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,Public safety officials,N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,"Government officials at local, state, and federal levels",N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,Community residents,N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,Nongovernmental organizations,N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,Commercial systems developer,N/A,"Framework states that listing stakeholders helps define who the system is intended to serve and provides context for the evaluation results. Does not provide a list of those recommended to be involved in the evaluation, however is somewhat implied.",N/A,N/A,N/A,N/A,none provided,Outbreak Detection,Timeliness; validity; sensitivity; PVP; PVN; Data Quality (Representativeness; completeness of data),"It is unclear how sensitivity, PVP, and PVN are grouped and their relation to validity.",System Experience (Performance Attributes),"The performance attributes described in this section convey the experience that has accrued in using the system.

System usefulness; flexibility; system acceptability; portability; system stability; system costs",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"As with the routine evaluation of public health surveillance systems (1), the acceptability of a surveillance system for early outbreak detection is reflected by the willingness of participants and stakeholders to contribute to the data collection and analysis.","Acceptability of a system can be inferred from the extent of its adoption. Acceptability is reflected by the participation rate of potential reporting sources, by the completeness of data reporting, and by the timeliness of person-dependent steps in the system (e.g., manual data entry from emergency department logs as distinguished from electronic data from the normal clinical workflow).","This concept includes the authority and willingness to share electronic health data and should include an assessment of the legal basis for the collection of prediagnosis data and the implications of privacy laws (e.g., Health Insurance Portability and Accountability Act Privacy Rule) (15). 

Acceptability can vary over time as the threat level, perceived
value of early detection, support for the methods of surveillance, and resources fluctuate.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Completeness of data: The frequency of unknown or blank responses to data items in the system can be used to measure the level of completeness.,"Evaluation of completeness should include a description of the problems experienced with manual data management (e.g., coding errors or loss of data) and the problems with automated data management (e.g., programming errors or inappropriate filtering of data).","For systems that update data from previous transmissions, time should be factored into measurement by indicating the percentage of records that are complete (i.e., all variables are captured for a record) on initial report and within an appropriate interval (e.g., 48 hours) of ubmission. Sites with substantial reporting delays can be flagged for reliability concerns and targeted for improvement. Incomplete data can require follow-up before analysis, with associated decreases in timeliness and increase in cost. When multiple data providers contribute to a common data store for statistical analysis, the percentage of reporting sources that submit their data on a routine interval (e.g., every 24 hours) conveys the completeness of the aggregate data-base for routine analysis.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Direct costs include the fees paid for software and data, the personnel salary and support expenses (e.g., training, equipment support, and travel), and other resources needed to operate the system and produce information for public health decisions (e.g. office supplies, Internet and telephone lines, and other communication equipment). Fixed costs for running the system should be differentiated from the variable costs of responding to system alarms. Variable costs include the cost of follow-up activities (e.g., for diagnosis, case-management, or community interventions).","Cost savings should be estimated by assessing the impact of prevention and control efforts (e.g., health-care costs and productivity losses averted)

Questions to answer include the following:
* How many investigations were initiated as a result of these data?
* What response was made and what cost was incurred through follow-up of flagged events?
* What were the indications for responding?
* How much staff time was required for follow-up?
* Was anxiety raised unnecessarily by false alarms?
* Was benefit obtained (e.g., through improved communication and confidence in the responsibility and performance of public health) when false alarms were investigated?
* Who was affected?
* What costs did partners incur in follow-up of signals (e.g., medical record staff work and clinical staff efforts)?
Follow-up costs for false alarms should be distinguished
from costs related to investigations that uncover real outbreaks that warrant a public health response.
* Did the health department fail to respond to a true event because of complacency or the response burden resulting from false alarms?
* Did late recognition of an outbreak result in unnecessary morbidity?
* Have lessons learned from earlier events reduced costs as the system has continued to operate?","Cost is a vital factor in assessing the relative value of surveillance for terrorism preparedness. Cost-effectiveness analyses and data modeling are needed under a range of scenarios to estimate the value of innovations in surveillance for outbreak detection and terrorism preparedness
(17). Improved methods of measuring cost and impact are needed. Costs borne by data providers should be noted; however, the cost perspective should be that of the community (societal perspective) to account for costs of prevention and treatment born by the community.

The cost of responding to false alarms represents a variable but inherent inefficiency of an early detection system that should be accounted for in the evaluation. Similarly, variable costs include the financial and public health costs of missing outbreaks entirely or recognizing them late. Costs vary because the sensitivity and timeliness of the detection methods can be modified according to changes in tolerance for missing outbreaks and for responding to false alarms. Similarly, the threshold and methods for investigating system alarms can vary with the perceived risk and need to respond. Costs from public health response to false alarms with traditional surveillance systems need to be measured in a comparable way when assessing the relative value of new surveillance methods.","* How many investigations were initiated as a result of these data?
* What response was made and what cost was incurred through follow-up of flagged events?
* What were the indications for responding?
* How much staff time was required for follow-up?
* Was anxiety raised unnecessarily by false alarms?
* Was benefit obtained (e.g., through improved communication and confidence in the responsibility and performance of public health) when false alarms were investigated?
* Who was affected?
* What costs did partners incur in follow-up of signals (e.g., medical record staff work and clinical staff efforts)?
Follow-up costs for false alarms should be distinguished from costs related to investigations that uncover real outbreaks that warrant a public health response.
* Did the health department fail to respond to a true event because of complacency or the response burden resulting from false alarms?
* Did late recognition of an outbreak result in unnecessary morbidity?
* Have lessons learned from earlier events reduced costs as the system has continued to operate?",CDC 2001,N/A,"The validity of syndromic surveillance system data is dependent on data quality. Error-prone systems and data prone to inaccurate measurement can negatively affect detection of unusual trends. Although data quality might be a less critical problem for screening common, nonspecific indicators for statistical aberrations, quality should be evaluated and improved to the extent possible. Measuring data quality is dependent on a standard (e.g., medical record review or fabricated test data with values known to the evaluator).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The flexibility of a surveillance system refersm to the system's ability to change as needs change. The adaptation to changing detection needs or operating conditions should occur with minimal additional time, personnel, or other resources.",N/A,"Flexibility generally improves the more data processing is handled centrally rather than distributed to individual data-providing facilities because fewer system and operator behavior changes are needed. Flexibility should address the ability of the system to apply evolving data standards and code sets as reflected in Public Health Information Network (PHIN) standards (http://www.cdc.gov/phin). Flexibility includes the adaptability of the system to shift from outbreak detection to outbreak management. The flexibility of the system to meet changing detection needs can include the ability to add unique data to refine signal detection, to capture exposure and other data relevant to managing an outbreak, to add data providers to increase population coverage and detect or track low frequency events, to modify case definitions (the aggregation of codes into syndrome groupings), to improve the detection algorithm to filter random variations in trends more efficiently, and to adjust the detection threshold. Flexibility also can be reflected by the ability of the system to detect and monitor naturally occurring outbreaks in the absence of terrorism. System flexibility is needed to balance the risk for an outbreak, the value of early intervention, and the resources for investigation as understanding of these factors changes.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,PVN reflects the probability that no outbreak is occurring when the system does not yield a signal.,N/A,N/A,N/A,The portability of a surveillance system addresses how well the system could be duplicated in another setting.,"Examples should be provided of the deployment of similar systems in other settings, and the experience of those efforts should be described. In the absence of examples, features of the system that might support or detract from portability should be described.","Adherence to the PHIN standards can enhance portability by reducing variability in the application of information technology between sites. 

Reliance on person-dependent steps, including judgment and action criteria (e.g., for analysis and interpretation) should be fully documented to improve system portability. 

Portability also is influenced by the simplicity of the system.",N/A,PVP reflects the probability of a system signal being an outbreak.,Methods described in CDC 2001,"The high costs associated with responding to false alarms and with delayed response to outbreaks demand efforts to quantify and limit the impact of both.

Better performance can be achieved in one attribute (e.g., sensitivity) without a performance decrement in another (e.g., PVP) by changing the system (e.g., adding a data type or applying a better detection algorithm).
Improving sensitivity by lowering the cut-off for signaling an outbreak will reduce PVP. Sensitivity and PVP for these surveillance systems will ultimately be calibrated in each system to balance the secondary benefits (e.g., detection of naturally occurring outbreaks, disease case finding and management, reassurance of no outbreak during periods of heightened risk, and a stronger reporting and consultation relation between public health and clinical medicine) with the locally acceptable level of false alarms.",N/A,N/A,N/A,N/A,N/A,"When case ascertainment within a population is incomplete (e.g., in a sentinel system or a statistically based sample), representativeness reflects whether a system accurately describes the distribution of cases by time, place, and person",N/A,Geographic representativeness is particularly important for detecting outbreaks of infectious diseases.,N/A,N/A,N/A,N/A,N/A,Sensitivity is the percentage of outbreaks occurring in the jurisdiction detected by the system.,"Methods described in CDC 2001

 Sensitivity for outbreak detection could be assessed through capture-recapture techniques with two independent data sources.","Measurement of sensitivity requires an alternative data source of high quality (e.g., ""gold"" standard) to confirm outbreaks in the population that were missed by the surveillance system.

Better performance can be achieved in one attribute (e.g., sensitivity) without a performance decrement in another (e.g., PVP) by changing the system (e.g., adding a data type or applying a better detection algorithm).
Improving sensitivity by lowering the cut-off for signaling an outbreak will reduce PVP. Sensitivity and PVP for these surveillance systems will ultimately be calibrated in each system to balance the secondary benefits (e.g., detection of naturally occurring outbreaks, disease case finding and management, reassurance of no outbreak during periods of heightened risk, and a stronger reporting and consultation relation between public health and clinical medicine) with the locally acceptable level of false alarms.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The stability of a surveillance system refers to its resilience to system changes (e.g., change in coding from International Classifications of Disease, Ninth Revision [ICD-9] to ICD-10).","Stability can be measured by the frequency of system outages or downtime for servicing during periods of need, including downtime of data providers, the frequency of personnel deficiencies from staff turnover, and budget constraints. Ongoing support by system designers and evolving software updates might improve system stability. Stability also can be reflected in the extent of control over costs and system changes that the sponsoring agency maintains.",Stability can be demonstrated by the duration and consistent operation of the system. System stability is distinguished from the reliability of data elements within the system. The consistent representation of the condition under surveillance (reliability) is an aspect of data quality.,N/A,N/A,N/A,N/A,N/A,The timeliness of surveillance approaches for outbreak detection is measured by the lapse of time from exposure to the disease agent to the initiation of a public health intervention.,"A timeline with interim milestones is proposed to improve the specificity of timeliness measures (Figure 3).
Although measuring all of the time points that define the intervals might be impractical or inexact in an applied outbreak setting, measuring intervals in a consistent way can be used to compare alternative outbreak-detection approaches and specific surveillance systems.","* Onset of exposure: By anchoring the timeline on exposure, the timeliness advantage of different data sources can be assessed and compared. Exposure can most easily be estimated in a point-source outbreak. Time of exposure is often inferred from knowledge of the agent (e.g., incubation period) and the epidemiology of the outbreak.

* Onset of symptoms: The interval to symptom onset in each case is defined by the incubation period for the agent. Time of symptom onset might be estimated using case interviews or existing knowledge of the agent and the time of exposure. The incubation period might vary according to host factors and the route and dose of the exposure.

* Onset of behavior: Following symptom onset, several health behaviors can occur (e.g., purchasing over-the-counter medication from a store, calling in sick to work, or visiting an urgent-care center). When an affected person interacts with the health-care system, a variety of health-care provider behaviors might be performed (e.g., order of a laboratory test and admission to a hospital). The selection of data sources for a system has a strong influence on timeliness. Some of those experiencing symptoms will initiate a health behavior or stimulate a healthcare provider behavior that is a necessary step to being captured in the surveillance system.

* Capture of data: The timing of the capture of a behavior by the data-providing facility varies by data type and can be influenced by system design. A retail purchase might be entered in an electronic database at the moment the transaction is completed, or a record might not be generated in a clinical setting until hours after health care was sought.

* Completion of data processing: Time is required for the facility providing the data to process the data and produce the files needed for public health. Records might be transmitted to a central repository only periodically (e.g., weekly). Data form can influence processing time (e.g., transcription from paper to electronic form and coding text-based data), and data manipulations needed to de-identify data and prepare necessary files can affect processing time.

* Capture of data in public health surveillance system:
The time required to transfer data from the data providing facility to the public health entity varies according to the frequency established for routine data transmission and by the data transmission method (e.g., Internet, mail, or courier).

* Application of pattern recognition tools/algorithms:
Before analytic tools can be applied to the data in the surveillance system, certain processing steps are necessary (e.g., categorization into syndrome categories, application of case definition, and data transformations).

* Generation of automated alert: The detection algorithm's alerting interval is a product of how often the algorithm is run and a report generated and the capacity of the algorithm to filter noise and detect an aberration as early as possible in the course of the outbreak.

* Initiation of public health investigation: The initiation of a public health investigation occurs when a decision is made to acquire additional data. Analysis and judgment are applied by public health-care providers to the processed surveillance data and other available information to decide whether new data collection is warranted to confirm the existence of an outbreak. The challenge of interpreting data from multiple surveillance systems could diminish potential advantages in timeliness. The focus on outbreak detection allows for investigations of potential outbreaks to proceed before a specific clinical diagnosis is obtained.

* Initiation of public health intervention: When an outbreak of public health significance is confirmed, interventions can be implemented to control the severity of disease and prevent further spread. Interventions might be of a general nature directed to the recognition of an outbreak (e.g., apply respiratory infection precautions and obtain clinical specimens for diagnosis) or can be specific to the diagnosis (e.g., antibiotic prophylaxis or vaccination).

Electronic laboratory reporting (i.e., the automated transfer of designated data from a laboratory database to a public health data repository using a defined message structure) also will improve the timeliness and completeness of reporting notifiable conditions (6-8) and can serve as a model for electronic reporting of a wider range of clinical information.",N/A,A surveillance system is useful for outbreak detection depending on its contribution to the early detection of outbreaks of public health significance that leads to an effective intervention.,"An assessment of usefulness goes beyond detection to address the impact or value added by its application. Measurement of usefulness is inexact. As with validity, measurement will benefit from common terminology and standard data elements. In the interim, detailed efforts to describe and illustrate the consequences of early detection efforts will improve understanding of their usefulness.

Evaluation should begin with a review of the objectives of the system and should consider the priorities. To the extent possible, usefulness should be described by the disease prevention and control actions taken as a result of the analysis and interpretation of the data from the system.

The impact of the surveillance system should be contrasted with other mechanisms available for outbreak detection. An assessment of usefulness should list the outbreaks detected and the role that different methods played in the identification of each one. Examples of how the system has been used to detect or track health problems other than outbreaks in the community should be included. The public health response to the outbreaks and health problems detected should be described as well as how data from new or modified surveillance systems support inferences about disease patterns that would not be possible without them.","Surveillance systems for early outbreak detection are sometimes justified for the reassurance they provide when aberrant patterns are not apparent during a heightened risk period or when the incidence of cases declines during an outbreak. When community reassurance is claimed as a benefit of the surveillance system, reassurance should be defined and the measurement quantified (e.g., number of phone calls from the public on a health department hotline, successful press conferences, satisfaction of public health decision-makers, or resources to institutionalize the new surveillance system). A description should include who is reassured and of what they are reassured, and reassurance should be evaluated for validity by estimating the PVN.",N/A,Validity of a system for outbreak detection,Use of historical data or simulations,"Measuring the validity of a system for outbreak detection requires an operational definition of an outbreak.
Although a statistical deviation from a baseline rate can be useful for triggering further investigation, it is not sufficient for defining an outbreak. In practice, the confirmation of an outbreak is a judgment that depends on past experience with the condition, the severity of the condition, the communicability of the condition, confidence in the diagnosis of the condition, public health concern about outbreaks at the time, having options for effective prevention or control, and the resources required and available to respond. Operationally, an outbreak is defined by the affected public health jurisdiction when the occurrence of a condition has changed sufficiently to warrant public health attention.

Measuring the validity of a system for outbreak detection requires an operational definition of an outbreak.
Although a statistical deviation from a baseline rate can be useful for triggering further investigation, it is not sufficient for defining an outbreak. In practice, the confirmation of an outbreak is a judgment that depends on past experience with the condition, the severity of the condition, the communicability of the condition, confidence in the diagnosis of the condition, public health concern about outbreaks at the time, having options for effective prevention or control, and the resources required and available to respond. Operationally, an outbreak is defined by the affected public health jurisdiction when the occurrence of a condition has changed sufficiently to warrant public health attention.

* Case definitions: Establish the specificity and sensitivity for the condition of interest on the basis of the data source, data type, and response criteria.

* Baseline estimation: Determine the stability of the background occurrence of cases. Estimations are affected by factors such as population size and geographic distribution. The performance of detection algorithms will vary by the quality and duration and inherent variability of baseline data.

* Reporting delays: Result in incomplete data, introducing bias that will diminish the performance of detection algorithms.

* Data characteristics: Includes underlying patterns in the data (e.g., seasonal variation) and systematic errors inherent in the data (e.g., product sales that influence purchasing behaviors unrelated to illness).

* Outbreak characteristics: Results from agent, host, and environmental factors that affect the epidemiology of the outbreak. For example, a large aerosol exposure with an agent causing serious disease in a highly susceptible population will have different detection potential than an outbreak of similar size spread person-to-person over a longer time and dispersed distribution.

* Statistical analysis: Defines how data are screened for outbreak detection. Detection algorithms have different performance characteristics under different outbreak onditions.

* Epidemiologic analysis, interpretation, and investigation: The procedures, resources, and tools for analysis, interpretation, and response that can substantially affect the ability to detect and respond to outbreaks.

Standardized classification of system and outbreak factors will enable comparison of experiences across systems. Pending the development of classification standards, descriptive evaluation should include as much detail as possible. 

Different approaches to outbreak detection need to be evaluated under the same conditions to isolate the unique features of the system (e.g., data type) from the outbreak characteristics and the health department capacity. The data needed to evaluate and compare the performance of surveillance systems for early outbreak detection can be obtained from naturally occurring outbreaks or through simulation.

The measurement of outbreaks detected, false alarms, and outbreaks missed or detected late should be designed as a routine part any system workflow and conducted with minimal effort or complexity. Routine reporting should be automated where possible. Relevant information needs include: the number of statistical aberrations detected at a set threshold in a defined period of time (e.g., frequency per month at a given p-value); the action taken as a result of the signals (e.g., review for data errors, in-depth follow-up analysis of the specific conditions within the syndrome category, manual epidemiologic analysis to characterize a signal, examining data from other systems, and increasing the frequency of reporting from affected sites); resources directed to the follow-up of the alert; public health response that resulted (e.g., an alert to clinicians, timely dissemination of information to other health entities, a vaccination campaign, or no further response); documentation of how every recognized outbreak in the jurisdiction was detected; an assessment of the value of the follow-up effort (e.g., the effort was an appropriate application of public health resources); a detailed description of the agent, host, and environmental conditions of the outbreak; and the number of outbreaks detected only late in their course or in retrospect.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Public health surveillance is the ongoing, systematic collection, analysis, interpretation, and dissemination of data about a health-related event for use in public health action to reduce morbidity and mortality and to improve health (1). 

The report provides a framework to evaluate timeliness for outbreak detection and the balance among sensitivity, predictive value positive (PVP), and predictive value negative (PVN) for detecting outbreaks. This framework also encourages detailed description of system design and operations and of their experience with outbreak detection.

The framework is best applied to systems that have data to demonstrate the attributes of the system under consideration. Nonetheless, this framework also can be applied to systems that are in early stages of development or in the planning phase by using citations from the published literature to support conclusions. Ideally, the evaluation should compare the performance of the surveillance system under scrutiny to alternative surveillance systems and produce an assessment of the relative usefulness for early detection of outbreaks.

Early detection of outbreaks can be achieved in three ways: 1) by timely and complete receipt, review, and investigation of disease case reports, including the prompt recognition and reporting to or consultation with health departments by physicians, health-care facilities, and laboratories consistent with disease reporting laws or regulations; 2) by improving the ability to recognize patterns indicative of a possible outbreak early in its course, such as through analytic tools that improve the predictive value of data at an early stage of an outbreak or by lowering the threshold for investigating possible outbreaks; and 3) through receipt of new types of data that can signify an outbreak earlier in its course.

Syndromic surveillance for early outbreak detection is an investigational approach where health department staff, assisted by automated data acquisition and generation of statistical signals, monitor disease indicators continually (real-time) or at least daily (near real-time) to detect outbreaks of diseases earlier and more completely than might otherwise be possible with traditional public health methods (e.g., by reportable disease surveillance and telephone consultation).

It is unclear how sensitivity, PVP, and PVN are grouped and their relation to validity.",
buehlerEvaluationSurveillanceSystems2008,12641,Buehler 2008,Evaluation of Surveillance Systems for Early Epidemic Detection,Evaluation of surveillance systems for early epidemic detection,2008,James W. Buehler,unknown,unknown,Framework for evaluating the utility of syndromic surveillance systems for early pandemic detection,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Evaluation Step A: describing the existing or proposed system,"Responsibility for managing the system

Data source

Legal authorities, confidentiality policies, and terms of collaboration

Data transmission, storage, and security

Syndrome definitions

Statistical methods for aberration detection

Display methods

Response to alerts

","Who are the parties involved in managing the system?

What are the data sources and data elements collected? Also, how might various stages of epidemic illness result in perturbations of the source data?

Under what legal authority are data collected, stored, and used? What policies are in place to protect against inappropriate or unauthorized release? Are data collection and management procedures compliant with applicable privacy or confidentiality laws? To what extent are data de-identified? Have agreements been established regarding access to additional information, including possible follow-back to patients, when investigations are warranted? When systems involve collaborations between health departments and university-based or commercial partners, how are data-sharing arrangements defined so that health departments can execute their legal mandate to investigate suspect epidemics?

How are data transmitted, including the frequency and timing of data transmission? What procedures are used to encrypt or otherwise protect data security during transmission? How are computer systems secured to protect against unauthorized access? Are system users with different roles (e.g., staff at facilities that provide data, public health officials in local or state governments) granted different degrees of access to detailed information? How is system access governed?

How are indicators aggregated into syndrome categories? To what extent have syndrome classification criteria been validated?

What statistical tests are employed? Do these methods test for temporal abnormalities alone or for temporal and geospatial clustering? How are thresholds set for triggering alerts?

How are trend results, geographic patterns, and statistical alerts displayed on Internet sites? How frequently are reports updated? To what extent does the system-Internet interface allow users to probe reported data in follow-up to an alert?

What procedures or policies have been established to determine whether, when, or to what extent follow-up investigations are conducted? Are findings from one data source interpreted in concert with findings from others? How is responsibility for human oversight assigned? Who is responsible for follow-up investigations? What has been the experience with investigations triggered by alerts? To what extent have epidemics detected by other means also been recognized by the system?","Syndromic surveillance systems are typically managed by public health agencies. Because the development of syndromic surveillance has required the application of advanced epidemiologic, statistical, and informatics methods, university-based investigators are often involved [4]. Commercial vendors may provide software or manage systems that tap specific information sources, such as hospital or ambulance dispatch records. In the US, the military has also been substantially engaged in surveillance, reflecting its role as a major healthcare provider and insurer [11].",N/A,Evaluation Step B: assessing the attributes and performance of the system,Evaluation of CDC 2001 attributes for evaluating a public health surveillance system,See attributes listed in Q18,"It is impossible for any system to fully achieve all of these attributes, since some are mutually antagonistic. For example, efforts to enhance timeliness and sensitivity of outbreak detection are likely to result in a lower predictive value of alerts. However, a balance must be obtained to maximize the effectiveness of a surveillance system.

The cost of conducting syndromic surveillance will be shaped by how these attributes are valued, and costs of systems may vary widely depending on the scope of data collection.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"CDC 2001 [i.e., ""Acceptability reflects the willingness of persons and organizations to participate in the surveillance system""]",N/A,N/A,"From the perspective of data providers, are procedures for obtaining data nonintrusive and are the data useful for institution-specific purposes? For the public and policymakers, is syndromic surveillance perceived as a wise investment of public resources and a warranted exercise of governments' authority to tap health records?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001,N/A,N/A,"Is the source data of sufficient quality and consistency to assure reliable use for the intended purpose?
Are variations in data quality apt to increase the likelihood of alerts that do not represent actual disease trends or decrease the likelihood of alerts when meaningful changes in actual trends occur?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001,N/A,N/A,"How readily can the system be adapted to meet changing information needs or priorities?
To what extent can users customize system utilities to suit local information needs or display preferences?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001,N/A,Efforts to enhance timeliness and sensitivity of outbreak detection are likely to result in a lower predictive value of alerts,"When systems send statistical alerts, what is the likelihood that alerts represent events that public health agencies are seeking to detect?",N/A,N/A,N/A,N/A,CDC 2001,N/A,N/A,To what extent is the pattern of disease detected by syndromic surveillance representative of the health of the population within a public health jurisdiction?,N/A,N/A,N/A,N/A,CDC 2001,N/A,Efforts to enhance timeliness and sensitivity of outbreak detection are likely to result in a lower predictive value of alerts,"What percentage of epidemics or outbreaks targeted for detection are detected by the system?
Is the cost of syndromic justified by greater sensitivity (or timeliness or predictive value) when compared to other epidemic detection methods?",CDC 2001,N/A,N/A,"To what extent is the system easy to access and use, from the perspectives of various users?",N/A,N/A,N/A,N/A,CDC 2001,N/A,N/A,Does the surveillance operation assure that observed trends reflect community health and not variations in how data are collected or managed?,N/A,N/A,N/A,N/A,CDC 2001,N/A,Efforts to enhance timeliness and sensitivity of outbreak detection are likely to result in a lower predictive value of alerts,Does the syndromic surveillance system provide alerts early enough to allow timely investigations and effective public health interventions?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Lessons learned from a comprehensive evaluation project:
- Need for standardization
- Choosing syndrome definitions
- Determining alert notifications useful to health departments
- Choosing an alert detection algorithm
- Accounting for variation in clinicians' coding practices
- Using recent history to predict illness levels
- Identifying and accounting for changes in electronic medical records
- Accommodating delayed information from clinicians
- Accommodating real or apparent changes in the population under observation
- Determining the size of the area in which clusters should be sought",N/A,N/A,"4 Bravata DM, McDonald KM, Smith WM, et al. Systematic review: surveillance systems for early detection of bioterrorism-related diseases. Ann Intern Med2004;140:910-22. Available from: http://www.annals.org/cgi/reprint/140/11/910.pdf. Accessed May 30, 2006.

10 Centers for Disease Control and Prevention. Framework for program evaluation in public health. MMWR Morb Mortal Wkly Rep 1999;48(RR11):1-40. Available from: http://www.cdc.gov/mmwr/preview/mmwrhtml/rr4811a1.htm. Accessed May 30, 2006.

13 Drummond MF, Sculpher MJ, Torrance GW, O'Brien BJ, Stoddart GL. Methods for the Economic Evaluation of Health Care Programmes. 2nd edn. Oxford: Oxford University Press; 2005.","Syndromic surveillance represents an effort to automate and hasten the process of epidemic recognition described in this scenario, raising the following questions:
- At what stage should syndromic surveillance provide an alert—when most patients have nonspecific prodromal illness or when more have developed severe disease?
- Which data source(s), syndrome definitions, and statistical alert criteria are most likely to assure the earliest possible event detection?
- What frequency of false alarms is acceptable to assure that the event is not missed before it would otherwise be recognized?
Together, these questions establish a fundamental dynamic in the evaluation of syndromic surveillance. Last, how should the information gathered through syndromic surveillance be used? Should epidemiologists respond to alerts in ways that maximize opportunities for early epidemic detection and make effective use of health department and partners (i.e., healthcare workers and laboratorians)?

Adapting standard public health program evaluation questions [10] to syndromic surveillance, three questions must be answered: (1) what types of epidemics should be detected, (2) does the system detect such epidemics quickly, and (3) do actions triggered by system alerts represent an effective use of public health resources?

Direct costs include the salary of personnel who operate the system and expenses associated with computing resources, establishing connections to data sources, and other operational expenses. Information on direct costs may be available from budgets submitted to funding agencies.
There may be costs borne voluntarily by collaborating organizations, such as hospitals or others who provide data for syndromic surveillance, or these entities may require at least partial reimbursement for their efforts in establishing links with public health agencies. When syndromic surveillance systems produce alerts, there are costs associated with follow-up efforts, both for public health agency staff and for staff at collaborating healthcare institutions, and these costs will be heightened by frequent false alarms. Some costs are more intangible, such as potential loss of credibility for public health agencies if false alarms are excessive or if the promise of syndromic surveillance is unfulfilled.
Benefits of syndromic surveillance may include the following: early indication of situations that herald epidemics, assurance that outbreaks are not occurring if rumors arise or if environmental sampling detects the presence of a suspect agent in air samples, and flexibility to monitor a spectrum of health threats beyond infectious diseases. In some situations it may be possible to estimate the savings associated with reductions in morbidity and mortality when syndromic surveillance provides an early warning.

There is general concurrence that existing evaluations of syndromic surveillance are insufficient to guide decisions about its use and development [3,4,14]. Approaches are needed to delineate the sensitivity and predictive value of different outbreak detection methods, the lead time gained or lost (timeliness), and the impact on morbidity and mortality resulting from syndromic surveillance [8].",
calbaSurveillanceSystemsEvaluation2015,1113,Calba 2015,Surveillance systems evaluation: a systematic review of the existing approaches.,Surveillance systems evaluation: a systematic review of the existing approaches,2015,Clémentine Calba,clementine.calba@cirad.fr,France,Systematic review of existing health surveillance system evaluation approaches to inform the development of an evaluation framework within the RISKUR project,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Effectiveness attributes,"Timeliness, sensitivity, representativeness, specificity, predictive value positive, completeness, reliability",N/A,Functional attributes,"Acceptability/participation, flexibility, data quality, stability, simplicity, portability",N/A,Value attributes,"Usefulness, cost, effectiveness/efficacy, efficiency, impact",N/A,Organizational attributes,"Communication, data management, laboratory management",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Acceptability/participation: Identified in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Completeness of surveillance data is relatively simple to measure and should be considered at two levels: fields and records. Most commonly Data completeness is measured as the proportion of records with missing or invalid data in the data fields – where data fields are variables containing demographic, clinical, pathologic or epidemiological information recorded for each sample. Key data fields (eg animal id, holding of origin, diagnostic result etc) should be identified and the proportion of completeness measured. Measurement of the proportion of records or observations that have been collated in the data system may also be considered. This will require comparison with an alternative source of data (eg the sample frame or paper records of sampling and laboratory test results). Poor data completeness may indicate problems in the Data collection, Data Management or Communication and engagement attributes.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No definition provided in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Effectiveness / efficacy: Identified in review,N/A,N/A,N/A,Effectiveness / efficacy: Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,Identified in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Impact: Identified in review,N/A,N/A,N/A,Communication: Identified in review,N/A,N/A,N/A,Data management: Identified in review,N/A,N/A,N/A,Laboratory management: Identified in review,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Practical aspects identified in a review of evaluation approaches for health surveillance systems, and their role in the evaluation process:
- List of evaluation attributes to be assessed (Usefulness: Design the evaluation)
- Definitions of the evaluation attributes to be assessed (Usefulness: Design the evaluation)
- Case study presentation (Usefulness: Ease of applicability)
- Visual representation of the results (Usefulness:Ease of communication)
- Information about evaluator(s) (e.g. required expertise level) (Usefulness: Design the evaluation)
- List of methods and tools to assess the evaluation attributes targeted (Usefulness: Design the evaluation; Ease of applicability)
- Guide for the selection of relevant evaluation attributes (Usefulness: Design the evaluation; Ease of applicability)

One of the main limitations of the existing approaches was the level of detail provided to the evaluators in order to practically implement the evaluation. Most of the identified approaches provided generic recommendations for evaluations (i.e. framework and guidelines) with more or less level of detail on the different steps to implement. Only three included methods and tools for the implementation of the evaluation (i.e. ready-to-use questionnaires and/or scoring guides) [18,19,27], of which only one related to AH [27]. This highlights the need for practical tool development in this field. The requirement for flexibility to account for variations in the surveillance system and available resources has been emphasised [6].
Indeed the methods and tools presented did not allow the evaluator to design his/her own evaluation process according to the surveillance context or to socio-economic constraints.

A further limitation of the existing approaches is the absence of a comprehensive list of attributes to be assessed, flexibility in the choice of attributes and guidance on how these should be selected.

There was limited guidance provided about the methods for assessment of attributes. Only one approach (clearly labelled as a tool) provided detailed methods for the assessment of attributes [27] but this allowed no flexibility in the selection of methods for the assessment of attributes. The selection of an appropriate assessment method could be complex and an evaluation approach should provide sufficient elements to help the evaluators' choices.

None of the approaches provided gold standards which could guide the interpretation of the assessment results and target the corrective actions to be implemented. How to set the economic target would also need to be considered in the evaluation approaches in order to provide recommendations on how to balance performances versus costs, especially in situation where resources are scarce.
Other limitation of the existing approaches included the absence of recommendations about who should carry out the evaluation, which would help in setting up the evaluation, and of graphical representation of the outputs to assist with dissemination of the results. In addition a description of case study applications could assist end users in understanding how to implement the evaluation. Also, some transparency in the development process of the approaches would add to their usability by providing possibilities to see and evaluate possible conflicts of interest.

This review highlighted the needs to develop a comprehensive approach for the evaluation of surveillance systems, based on the existing ones, and including guidance on the assessment of individual attributes. This approach would need to be (i) complete, i.e. to provide a
full list of attributes not only covering the epidemiological aspects for the evaluation, but also the social and economic aspects; (ii) flexible and adaptable to the context (surveillance purpose and objective of the evaluation) and evaluations constraints (time, resources,
available data, etc.); and (iii) operational, i.e. to provide a structured process for carrying out the evaluation which includes guidance on how to select appropriate attributes and the selection of practical methods and tools for their assessment.",N/A,N/A,"4. Shahab S. Finding value in the evaluation of public health syndromic surveil lance systems from a policy perspective. In: Finding value in the evaluation of public health syndromic surveil lance systems from a policy perspective. Alberta, Canada: Alberta Health Services; 2009. p. 1-24.

18. World Health Organization. Core components for infection prevention and control programmes: assessment tools for IPC programs. In: Core components for infection prevention and control programmes: assessment tools for IPC programs. World Health Organization (WHO); 2011. http://www.wpro.who.int/hrh/about/nursing_midwifery/ core_components_for_ipc.pdf.

23. European Centre for Disease Prevention and Control. Framework for the evaluation and assessment of EU-wide surveil lance networks in 2006-2008. In: Framework for the evaluation and assessment of EU-wide surveil lance networks in 2006-2008. City: European Center for Disease Prevention and Control (ECDC); 2006. p. 13.

25. Kansanterveyslaitos Folkhlsoinstitutet. Protocol for the evaluation of EU- wide surveil lance networks on communicable diseases. In: Protocol for the evaluation of EU-wide surveil lance networks on communicable diseases. City: National Public Health Institute (KTL); 2004. p. 59.

30. Malecki KC, Resnick B, Burke TA. Effective environmental public health surveil lance programs: a framework for identifying and evaluating data resources and indicators. J Public Health Manag Pract. 2008;14:543-51.

33. Peyre M, Hoinvil le L, Hasler B, Lindberg A, Bisdorff B, Dorea F, et al. Network analysis of surveil lance system evaluation attributes: a way towards improvement of the evaluation process. Havana, Cuba: Presented at the International Conference for Animal Health Surveil lance (ICAHS2); 2014.","- A framework is considered to be skeletal support used as the basis for something being constructed; it is an organization of concepts that provides a focus for inquiry [8,9].
- A guideline can be defined as a document to be followed in the performance of certain tasks; this provides recommendations (a set of standards or criteria) for the steps that should be used to achieve a desired goal [10,11].
- A method provides information about how to accomplish an end; it is a regular and systematic way of accomplishing something [12].
- A tool can be defined as a process with a specific purpose; it is used as a mean of performing an operation or achieving an end [13,14].

In other words, frameworks would help users to define what to take into consideration in the evaluation process; guidelines would inform the different steps needed to conduct the evaluation; methods would detail how to implement the evaluation (what to assess and how); and tools would not only provide a methodology but also include practical elements to be used to conduct the evaluation (e.g. spreadsheets, questionnaires).

Three main objectives were identified (Table 1): evaluate surveillance systems performance and effectiveness, design efficient surveillance systems, and evaluate the completeness of the surveillance systems in terms of core components.

Although the evaluation objectives of the various approaches varied according to the field of application and to the type of approach, four common steps in the evaluation process were identified: (i) description of the context, (ii) description of the evaluation process, (iii) implementation, and (iv) recommendations. Three evaluation approaches focused on the evaluation of the structure of the system [18,19,31] but the majority also included an evaluation of the quality of the data generated and the system's performance. Those approaches also considered implicitly the structure of the system which has to be described in order to understand the surveillance process, to select relevant attributes to be assessed and to provide relevant recommendations.

The evaluation approaches most frequently focused on attributes related to the effectiveness of the system (Figure 2), especially timeliness which was included in all the identified approaches [5,20-28], and sensitivity in 9/10 [5,20-22,24-28]. Regarding the functional attributes, the evaluation approaches mainly recommended the assessment of acceptability (8/10) [5,20-22,24,26-28], flexibility (7/10) [5,20,21,24,26-28], stability (6/10) [5,22,24,26-28] and simplicity (5/10) [5,20,21,26,27].
Other attributes such as usefulness (9/10) [5,20-27],representativeness (8/10) [5,20,21,24-28] and data quality (7/10) [5,22-27] were also included in more than half of the approaches. Attributes aimed at assessing the value of surveillance system were not often considered, especially economic attributes: assessment of the cost was recommended in only 3/10 approaches [22,24,28]; impact, effectiveness/efficacy and efficiency in only 2/10 [5,22,28].

This review confirmed previous publication highlighting the need to consider economic attributes in the evaluation approaches (e.g. cost-effectiveness, cost-benefits). There are needs regarding sociological attributes as well (e.g. acceptability, communication, non-monetary benefits), due to the fact that none of the evaluation approaches provided information on how to take into consideration stakeholders' perceptions, needs and expectations. These aspects are essential to ensure the surveillance systems acceptability, sustainability and impact. It is important to understand stakeholders' perceptions and expectations in order to ensure that the system is working properly and provides relevant information. As described in the paper by Auer and co-workers [34], acceptability can be considered as an underpinning attribute.

",
calbaApplyingParticipatoryApproaches2015,1062,Calba 2015,Applying participatory approaches in the evaluation of surveillance systems: A pilot study on African swine fever surveillance in Corsica.,Applying participatory approaches in the evaluation of surveillance systems: A pilot study on African swine fever surveillance in Corsica,2015,Clémentine Calba,clementine.calba@cirad.fr,Belgium,Applying participatory approaches in the evaluation of animal health surveillance systems,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",e. Other,France,j. OASIS: An assessment tool of epidemiological surveillance systems in animal health and food safety (Hendrikx 2011); k. Other,"Note: an ""OASIS flash"" evaluation was conducted.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Farmers and hunters,N/A,N/A,"Participants were interviewed using focus groups or individual semi-structured interviews. Focus groups are designed to expose a group of people to common stimuli (Pahl-Wostl, 2002). They are particularly important in assessing complex issues through the analysis of social processes and discussions (Pahl-Wostl, 2002). The data collection process relied on interviewing representatives at every level of the surveillance system.

 Another objective was to reach theoretical saturation which has become the gold standard for health science research (Guest et al., 2006) and which refers to the point at which no new information is observed in the data (Guest et al., 2006).","Private veterinarians, of ""Groupements de Défense Sanitaire"" animal health groups (GDS, association of farmers addressing health issues, officially recognized by French law (Bronner et al., 2014)), local laboratories, or of wildlife organizations (hunters' federations, for example)",N/A,N/A,"Participants were interviewed using focus groups or individual semi-structured interviews. Focus groups are designed to expose a group of people to common stimuli (Pahl-Wostl, 2002). They are particularly important in assessing complex issues through the analysis of social processes and discussions (Pahl-Wostl, 2002). The data collection process relied on interviewing representatives at every level of the surveillance system.

 Another objective was to reach theoretical saturation which has become the gold standard for health science research (Guest et al., 2006) and which refers to the point at which no new information is observed in the data (Guest et al., 2006).","Veterinary Services, at local, regional, and national levels",N/A,N/A,"Participants were interviewed using focus groups or individual semi-structured interviews. Focus groups are designed to expose a group of people to common stimuli (Pahl-Wostl, 2002). They are particularly important in assessing complex issues through the analysis of social processes and discussions (Pahl-Wostl, 2002). The data collection process relied on interviewing representatives at every level of the surveillance system.

 Another objective was to reach theoretical saturation which has become the gold standard for health science research (Guest et al., 2006) and which refers to the point at which no new information is observed in the data (Guest et al., 2006).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Acceptability refers to the willingness of persons and organizations to participate in the surveillance system, and to the degree to which each of these users is involved in the surveillance.

Acceptability elements:
1. Objective
2. Operation
2a. Role of each actor and representation of its own utility
2b. Consequences of information flow
2c. Perception by each actor of its own role relative to other actors'
2d. Relations between stakeholder
3.Trust
3a. In the system
3b. In other stakeholders involved in the system.
","Participatory methods used to assess acceptability

1. Objective: Impact diagram
2. Operation
2a. Role of each actor and representation of its own utility: Flow diagram
2b. Consequences of information flow: 
Impact diagram associated with proportional piling
2c. Perception by each actor of its own role relative to other actors': Flow diagram
2d. Relations between stakeholder: Relational diagram
3.Trust
3a. In the system: 
Flow diagram associated with proportional piling
3b. In other stakeholders involved in the system: 
Flow diagram associated with proportional piling

These elements were assessed using a combination of participatory diagraming and scoring tools, both of which were developed for, and adapted to, this specific context. Three main tools were implemented: (i) relational diagrams, (ii) flow diagrams (associated with proportional piling), and (iii)impact diagrams (associated with proportional piling). These tools were implemented with all participants, either through focus groups or through individual semi-structured interviews.

OASIS flash evaluation of acceptability:
The assessment of acceptability was based on 20 criteria according to the OASIS flash method, which can be grouped into 8 main categories: the organization of the surveillance system (e.g., existence of a charter), its animation (e.g., meetings frequencies), and
organization (e.g., integration of laboratories in the system), the human and material resources, feedback to stakeholders, consequences of a suspicion, training provided, partnerships and stakeholder sensitization.","Acceptability is relevant to different aspects of the surveillance system. It first refers to the actors' acceptance of the system's objectives and of the way it is operates. The acceptance of the way the system operates refers to (i) the role of each actor and the representation of their own utility, (ii) the consequences of the flow of information for each actor (i.e., changes in their activity and in their relations following a suspicion), (iii) the perception by each actor of the importance and recognition of their own role relative to that of other actors, and (iv) the relations between stakeholders. Trust is another essential element of acceptability; trust in the system and also trust in other stakeholders involved in the system.","Objective: 
Is the objective(s) of the surveillance system in the line with the stakeholders' expected objective(s)?

Operation: 
Are stakeholders satisfied with their duty?
Are stakeholders satisfied with the consequences of information flow? 
What is the perception of each actor of its own role relative to other actors'?
Are stakeholders satisfied with the relations they have with other stakeholders?

Trust: 
Do stakeholders trust the system to fulfil its surveillance objective(s)?
Do stakeholders trust the other stakeholders to fulfil their role in the system?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Non-monetary benefits: Non-monetary benefits refer to the positive direct and indirect consequences produced by the surveillance system and help to assess whether users are satisfied that their requirements have been met (definition developed by the RISKSUR1 Consortium.,"The economic value of sanitary information was assessed through a contingent valuation method (CVM) using proportional piling and was implemented through individual semi-structured interviews with farmers. This method has been used by economists to value changes in natural resources and environments, and it is somewhat similar to methods used in marketing to evaluate new concepts for goods and products (Louviere et al., 2003).

This method consists of direct interviews during which facilitators ask individuals what they would be willing to pay for a change (Louviere et al., 2003); in the present study, they were asked what they would be willing to pay for sanitary information related to ASF.

",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Impact diagrams were problematic, and not easily understood by participants. They had trouble identifying positive impacts following a suspicion, mostly due to the fact that they were focusing more on outbreaks rather than on suspected cases. 

Nonetheless, the implementation of participatory approaches appeared to be time consuming.
Time was required to make individual contact with stakeholders, to present the project to them and to define their willingness to participate in the study. It also took time to define a date and to find a place for the interview. Another constraint was related to the playful aspects of these approaches, which might have appeared to some stakeholders to be lacking in earnestness (mainly in focus groups). However, participants generally welcomed the evaluation process and the use of visual representation tools which allowed them to clearly represent their perception of the system.",N/A,N/A,"Hendrickx, S., El Masry, I., Atef, M., Aref, N., El Zahraa Kotb, F., El Shabacy, R., Jobre, Y., 2011. A Manual for Practitioners in Community-based Animal Health Outreach (caho) for Highly Pathogenic Avian Influenza. The International Livestock Research Institute and the Food and Agriculture Organization of the United Nations, pp. 77.

Mariner, J., Hendrickx, S., Pfeiffer, D., Costard, S., Knopf, L., Okuthe, S., Chibeu, D., Parmley, J., Musenero, M., Pisang, C., 2011. Integration of participatory approaches into surveillance systems. Rev. Sci. Technol. 30, 653-659.

Peyre, M., Hoinville, L., Haesler, B., Lindberg, A., Bisdorff, B., Dorea, F., Wahlstrom, H., Frossling, J., Calba, C., Grosbois, V., Goutard, F., 2014. Network analysis of surveillance system evaluation attributes: a way towards improvement of the evaluation process. In: International Conference on Animal Health Surveillance (ICAHS), La Havane, Cuba.","According to the Health Systems Strengthening Glossary developed by the World Health Organisation (WHO), evaluation refers to the systematic and objective assessment of the relevance, adequacy, progress, efficiency, effectiveness and impact of a course of actions, in relation to objectives and taking into account the resources and facilities that have been deployed' (WHO, undated)

Participatory approaches refer to a range of methods and tools that enable stakeholders, to a variable extent, to play an active role in the definition and in the analysis of the problems they may encounter, and in their solution (Pretty, 1995; Pretty et al., 1995; Johnson et al., 2004; Mariner et al., 2011; Peyre et al., 2014). 

These methods make it possible to capture locking points in the system, such as communication and coordination between stakeholders, which can go unnoticed when using classical evaluation tools. The use of these tools should give rise to realistic and context-adapted recommendations. More importantly, these tools lead to enhanced acceptability of the evaluation, to an improved feeling of belonging to the system, and to even ownership of the evaluation outputs (Pahl-Wostl, 2002).

The decision to report a suspected event is a critical function of an emerging infectious disease surveillance system (Tsai et al., 2009).
In order to limit the under-reporting of suspected cases and to identify the best ways to improve the current surveillance system, it is crucial to assess the stakeholders' willingness to participate in this system (Bronner et al., 2014).

The use of participatory methods and tools in the evaluation process led to the empowerment of stakeholders, thus improving both their acceptance of the evaluation and their feeling of ownership. This could improve the sustainability of health interventions (Calba et al., 2014). Several authors highlight that, besides its challenges, participatory evaluation can be seen as a very useful approach to the evaluation of health prevention programs as it strengthens capacities and alliances among participants, fosters commitment to health program principles and has also proved to be a useful decision making tool (Rice and Franceschini, 2009; Nitsch et al., 2013)",
calbaAddedValueUsingParticipatory2016,962,Calba 2016,The Added-Value of Using Participatory Approaches to Assess the Acceptability of Surveillance Systems: The Case of Bovine Tuberculosis in Belgium.,The Added-Value of Using Participatory Approaches to Assess the Acceptability of Surveillance Systems: The Case of Bovine Tuberculosis in Belgium,2016,Clémentine Calba,clementine.calba@cirad.fr,France,To compare the measure of acceptability of an animal health surveillance system using the OASIS flash tool and participatory methods,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",e. Other,Belgium,j. OASIS: An assessment tool of epidemiological surveillance systems in animal health and food safety (Hendrikx 2011); k. Other,"Note: an ""OASIS flash"" evaluation was conducted. In addition, a variety of participatory methods (methods later formalized in the RISKUR framework), was used to evaluate the system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Different stakeholders were involved for each evaluation method and/or component.,N/A,N/A,"For the cattle surveillance system, 22 stakeholders were interviewed using 4 focus group discussions and 4 individual interviews. Among these stakeholders, 8 were farmers, 7 were private veterinarians, 2 were representatives from the national reference laboratory, one was a representative from the PCU, 2 were representatives from the FASFC and 2 from the FPS.

For the wildlife surveillance, 12 stakeholders were interviewed using one focus group discussions and 9 individual interviews: 7 hunters were involved, 4 forest rangers and the system coordinator.

A total of 15 stakeholders joined the OASIS flash scoring process:
3 members of the evaluation team and 12 members of the scoring team (Table 4). This full day meeting joined representatives of (i) the federal competent authorities (i.e. FASFC, FPS), (ii) the national reference laboratory, (iii) the veterinary officers at slaughterhouses, (iv) the wildlife surveillance coordinator, (v) the farmers (president of the European federation of animal health and sanitary safety (FESASS)) and (vi) the Scientific Institute of Public Health (WIV-ISP).


",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Participatory approaches: 
RISKUR participatory method for acceptability (later finalized in the framework)

(i) Identification of the stakeholders' professional network and assessment of the satisfaction of the relations among them, through the elaboration of relational diagrams and the use of smileys
(ii)Representation of the information flow within the system and assessing the trust devoted to the system to fulfil its objectives, with the use of flow diagrams associated with proportional piling.
(iii) Assessment of the satisfaction of the information flow (i.e. positive and negative impacts following a suspicion) with the use of impact diagrams associated with proportional piling.
This methodological approach is presented in detail in Calba et al. (2015)

OASIS: Followed framework evaluation methods
","Acceptability has an influence on the levels of sensitivity and timeliness of the surveillance system

Currently, the assessment of acceptability remains challenging due to a lack of clarity related to which aspects of this attribute to take into consideration and how to evaluate them.","Participatory approaches:
(i) the acceptability of the objective(s) of the system
(ii) the satisfaction of the role and the representation of the stakeholders' utility in surveillance
(iii) the satisfaction of the consequences of the flow of information (i.e. changes in the activities and management at herd level following a suspicion or an outbreak)
(iv) the satisfaction of the relations between different stakeholders
(v) the trust in the system to fulfil its objectives.

The trust in the stakeholders involved in the bTB surveillance ( not used to directly assess the acceptability of the system, but to provide explanatory information related to the trust attributed to the system).

OASIS: Followed framework evaluation methods

- Taking partners' expectations related to the objective into account
- Effective integration of laboratories in the surveillance system
- Simplicity of the notification procedure
- Simplicity of the data collection procedure
- Acceptability of the consequences of a suspicion or case for the source or collector of data
- Feedback of the individual analyses results to field actors
- Systematic feedback of the surveillance results to field actors (excluding news bulletin)
- Frequency of meetings of the central coordinating body
- Active role of intermediary units in the functioning of the system (validation, management, feedback)
- Adequacy of material and financial resources of intermediary units
- Existence of coordination meetings at the intermediate level 
- Adequacy of material and financial resources at the field level
- Existence of an operational management structure (central unit)
- Existence of an operational steering structure that is representative of the partners (steering committee)
- Organization and operations of the system laid down in regulations, a charter, or a convention established between the partners
- Simplicity of the case or threat definition
- Adequacy of the data management system for the needs of the system (relational database, etc.)
- Initial training implemented for all field agents when joining the system
- Regular reports and scientific papers publications on the results of the surveillance",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The two approaches used to assess the acceptability of the bTB surveillance system in Belgium were based on a semi-quantitative process. With participatory approaches 6 evaluation criteria were considered, among which 5 were scored on a scale from -1 to +1. With the OASIS flash tool 19 criteria were considered, scored on a scale from 0 to 3. Some criteria were similar between these two approaches (n = 7). Some others were slightly different, but similar information could be collected (n = 5). Finally, some criteria were specific to each approach: 7 were specific to the OASIS flash tool, 2 to the process by participatory approach. 

See Table 2 for a comparison of the criteria used to assess acceptability with participatory approaches and with the OASIS flash tool.

Even compared to the complete process of an OASIS evaluation, the use of participatory approaches to assess acceptability of the surveillance has the advantage to involve of a higher number of stakeholders in the evaluation, and a higher diversity of the profiles (i.e. farmers, hunters, private veterinarians, etc.). This provides a better view of the surveillance system and leads to context-dependent recommendations. 

These two evaluation processes can thus be considered as complementary, both having advantages and limitations. They should be implemented according to the surveillance context (i.e. epidemiological, social, economic factors); but also to the evaluation context (i.e. time and resources available, evaluator(s)' skills). The use of participatory approaches to assess the acceptability provides some added value compared to more classical methods such as the OASIS flash tool. Nonetheless, this added value has to be balanced with the evaluation context. Participatory approaches could be used to assess other evaluation attributes, but could also be helpful for the data collection necessary for other tools (e.g. capture-recapture methods). Moreover, due to the fact these approaches provide information related to the context in which surveillance is implemented, they could allow to better understand some outputs of the evaluation process and to result into better recommendations.",N/A,N/A,N/A,"Due to the economic importance for Belgium to maintain the OTF status, there is a need to evaluate the quality of the evidence provided by the system by estimating its sensitivity. Surveillance systems designed to prove freedom of disease require a higher sensitivity than systems designed to assess the prevalence of an endemic disease. Sensitivity is thus the essential measure of surveillance systems efficacy in supporting a claim to disease freedom. Moreover, due to the fact that one of the objectives of bTB surveillance is the early detection of sporadic new cases, there is also a need to assess the timeliness of the system. The quality of these two attributes may be impacted by the quality of other evaluation attributes, especially by the acceptability of the surveillance by all stakeholders.

Acceptability has been listed by the Centers for Disease Control and Prevention (CDC) of the United-States as one of the main requirements for efficient surveillance.

Currently, the assessment of acceptability remains challenging due to a lack of clarity related to which aspects of this attribute to take into consideration and how to evaluate them.

The participatory methods and tools were proposed for evaluation due to the fact that perceptions and expectations of stakeholders regarding surveillance are critical elements to be considered in order to evaluate the acceptability of a system [19, 20]. This allows participants to play an active role in the definition and in the analysis of problems encountered during the mandatory participation to a surveillance programme, but also to find solutions to these problems. The use of participatory methods and tools allows collecting information to be used to assess the acceptability of the system, but also to get information related to the general context in which surveillance is implemented. Moreover, through an iterative process (i.e. providing feedback to respondents), it allows stakeholders to propose a range of recommendations to improve the system.

The flash version of OASIS, which was used in this study, is skipping the interview of local and national stakeholders. The completion of the questionnaire is then performed by national experts who have a good knowledge of the surveillance system and the scoring of the evaluation criteria is performed by a selected panel of stakeholders.

Analysis of participatory methods: A thematic analysis was implemented on the data set using the R-based Qualitative Data Analysis package (RQDA). Themes were developed in a deductive way, based on the elements of the acceptability to be assessed. For each theme, specific codes were developed in an inductive way creating useful categories, based on a latent analysis. Reading and coding of the transcripts was repeated several times until no new codes were identified. This coding allowed the identification of useful categories used to convert the data set into semi-quantitative data following the scoring criteria developed from a previous study [25]. Additional scoring criteria were developed to assess the satisfaction of the relations among stakeholders as presented in Table 1.

Analysis of OASIS methods: The OASIS tool (three separate outputs) were used and analyzed.",
cameronQuantificationSensitivityEarly2020,6980,Cameron 2020,Quantification of the sensitivity of early detection surveillance.,Quantification of the sensitivity of early detection surveillance,2020,A. R. Cameron,angus@ausvet.com.au,France,"To provide a simple approach to quantifying the sensitivity of early detection surveillance, in terms of population coverage, temporal coverage and detection sensitivity.","c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Estimate the amount of disease, for example, prevalence or incidence, in order to compare over time, space or other factors,","Support case finding, in order to respond to individual cases, for example as part of a disease control or eradication programme.","Demonstrating the absence of the disease or infection, in order to facilitate safe trade, or to confirm successful elimination",Early detection,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Objectives are public health related but focus are centred around animal health.

Five different groups of early detection surveillance and related purposes were identified in the selected papers based on differences in terms of scale (global, national, herd or individual), disease status of the population of interest (present or absent) and nature of the disease (communicable, non-communicable, invasive species). See Figure 1 venn diagram for overlapping between groups.

Group 1: New, emerging and transboundary diseases
Purpose of the surveillance: Detection of the first case of disease in a population previously free
Example methods: Clinical surveillance, syndromic pattern detection

Group 2: Case finding 
Purpose of the surveillance: Detection of new cases in an area already infected
Example methods: Clinical surveillance, tracing of epidemiological links

Group 3: Outbreak detection
Purpose of the surveillance: Early detection of an abnormal increase in the level of a disease normally present at a base level 
Example methods: Statistical analysis of case reports, syndromic pattern analysis

Group 4: Screening
Purpose of the surveillance: Screening for individual cases of non-communicable diseases
Example methods: Screening of high-risk populations

Group 5: Exotic invasive species 
Purpose of the surveillance: First detection of an invasive species in an area previously free
Example methods: Risk-based surveys, crowdsourcing",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Early detection surveillance sensitivity / Temporal sensitivity: In the context of early detection surveillance, surveillance sensitivity may be defined as the probability that the surveillance activity is able to achieve its target standard—that is, correctly detect the first (or nth) epide-
miological unit affected by a new incursion within the target time period. Equivalently, this may be thought of as the proportion of possible future incursions that are detected by the early detection system within the target time frame.","Farmer-based clinical surveillance; syndromic surveillance; periodic sampling surveys.

Note: risk and non-risk based equations are provided in the article to calculate early detection surveillance sensitivity.","Using this definition, the target sensitivity for most diseases in most countries is likely to be 100%. While this may be rarely achieved in practice, it is unlikely to be acceptable to aim for a lower sensitivity, as this implies accepting failures in early detection.

If a longer target time frame is used, the disease has a greater opportunity to epidemiological unit, making detection easier and increasing surveillance sensitivity. increase in prevalence in the first affected.

For early detection to succeed, three conditions must be met: (i) the first affected epidemiological unit must be included in the surveillance system, (ii) the unit must be examined or tested within the time frame specified and (iii) the test or examination must 
correctly detect the presence of disease. These conditions can be quantified as probabilities.",N/A,Detection sensitivity: The detection sensitivity (Sed) is the sensitivity of the test system that results in detection of the presence of disease in the unit of interest.,Farmer-based clinical surveillance; syndromic surveillance; periodic sampling surveys,"For surveillance systems based on active population sampling of people or animals within an epidemiological unit (where the unit of interest is the individual), and the use of a laboratory test, the detection sensitivity is simply the sensitivity of the laboratory test used. If one or more confirmatory tests are used, it is the combined sensitivity of the test system depending on the interpretation of the combined test results.In a farmer-based clinical surveillance system, or community-based public health surveillance system, disease detection is the result of a cascade of steps (Martin et al., 2015). For example, in the case of clinical farmer-based detection of FMD, the steps include.
* Infected animals show clinical signs of disease 
* Farmer notices affected animals 
* Farmer contacts veterinaria 
* Veterinarian suspects FMD and takes samples for laboratory confirmation 
* Laboratory tests samples for FMD 
* Test result is positive In this case, the sensitivity of the detection system is the product of the conditional probabilities of each of these steps. 
When syndromic pattern detection analysis is used, the detection sensitivity is the sensitivity of the system, including both the sensitivity of the analysis algorithm used to raise an alert and the sensitivity of the subsequent investigation used to confirm the outbreak. It is important to note that the time to detection represents the period starting when the disease becomes detectable and ending when action can be taken to prevent spread or to eradicate the disease. The regulatory requirements also play a role in time to first detection. When the new occurrence of a disease in a country has major consequences, it is important to ensure that the specificity of the detection system is extremely high, to avoid false positives.",N/A,Population coverage: Is the probability that any given unit in the population will be included in the surveillance system.,Farmer-based clinical surveillance; syndromic surveillance; periodic sampling surveys,"When surveillance is based on representative sampling, this is equal to the sample size over the population size.",N/A,"Temporal coverage: Is the conditional probability that any given unit in the population will be examined or tested within the specified time frame, given that it is under surveillance.",Farmer-based clinical surveillance; syndromic surveillance; periodic sampling surveys,"For example, if the target time frame is 7 days, but testing occurs every 4 weeks, the temporal coverage is 25%.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The equation to calculate EDSSe identifies three potential broad areas of weakness in an early detection system: population coverage, temporal coverage and detection sensitivity. 

However, the most common and significant barrier to early detection is poor detection sensitivity. Three key elements influencing the detection sensitivity of farmer-based clinical surveillance are discussed here: the expression of clinical signs, the role of the farmer 
and the role of the veterinarian.

Helping farmers make better decisions about disease, through extension, awareness or providing access to reliable information can significantly increase early detection sensitivity. 

Achieving the triple requirement of high coverage, high frequency and high detection sensitivity at affordable cost is seriously challenging.",N/A,N/A,"Dufour, B., Pouillot, R., & Toma, B. (2001). Proposed criteria to determine whether a territory is free of a given animal disease. Veterinary  Research, 32(6), 545-563. https://doi.org/10.1051/vetres:2001102","For surveillance activities aiming at quantifying the amount of disease  or at demonstrating disease freedom (items (a) and (c) above), quantitative measures of performance are well established. In order to evaluate the quality of surveillance to estimate prevalence or incidence, we  use measures of precision and validity.

In this context, an outbreak is defined as the occurrence of one or  more related cases of disease in an epidemiological unit. For the  purpose of this paper, we are assuming that the early detection  surveillance aims to identify the first outbreak caused by a disease  incursion. 

In order to quantify performance, it is first necessary to define the  objective of early detection surveillance. There are three dimensions to this definition: the outbreak, the epidemiological unit and  the timeframe for early detection.

Examples of units in livestock disease surveillance may be animals,  epidemiological units (e.g. herd, flock) or higher-level units (e.g. village,  district).

Early detection implies a target time frame for detection, and this  is the most difficult component of the definition. An operational  definition may be before spread from the first epidemiological  unit occurs', as the cost of control rises rapidly with every extra  epidemiological unit affected.

Risk may be defined as the probability of an adverse event (its use  in epidemiological measures such as the risk ratio (Dohoo et al.)), or  a combination of likelihood and consequences of an adverse event  (its use in risk analysis (Vose, 2008)). For early detection surveillance,  when identifying population strata with different levels of risk, it is  appropriate to consider both the likelihood that a first disease incursion would take place in that stratum and the relative consequences  of such an incursion (Cameron, 2012b; OIE, 2019a).

Farmer-based clinical surveillance and syndromic surveillance can affordably provide high population and temporal coverage  and achieve relatively high surveillance sensitivity. Periodic sample surveys or sentinel surveillance do not achieve  full population coverage, decreasing surveillance sensitivity. In summary, not all surveillance approaches are suitable  for the purpose of early detection of diseases not known to be  present. Farmer-based clinical surveillance and syndromic surveillance appear to perform best in this context.",
choiEnhancingGlobalCapacity2008,10996,Choi 2008,"Enhancing global capacity in the surveillance, prevention, and control of chronic diseases: seven themes to consider and build upon.","Enhancing global capacity in the surveillance, prevention, and control of chronic diseases: seven themes to consider and build upon",2008,Bernard C K Choi,Bernard_Choi@phac-aspc.gc.ca,Canada,Identify themes to help enhance global capacity for chronic disease surveillance,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,There is a role for civil society in evaluating and setting research priorities,N/A,"Evaluation must take place at multiple levels and include stakeholders throughout the process.

Involve multiple stakeholders from all walks of society in devising a comprehensive approach to surveillance, prevention and control.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Strategy,"Action plan, big picture thinking/planning, coherent response, integrative approaches, leadership, long-term funding, making the case, marketing skills, resource mobilisation, selling stories to our masters","Develop a strategy to promote and market chronic disease surveillance, prevention and control.

The seven themes are working ideas/examples of how to enhance global capacity in chronic disease surveillance. Potentially applicable to evaluation of surveillance systems?",Collaboration,"Engaging providers and users, multidisciplinary expertise, networking, partnership, promoting dialogue between countries, 2 plus 2 equals 5","Involve multiple stakeholders from all walks of society in devising a comprehensive approach to surveillance, prevention and control.

The seven themes are working ideas/examples of how to enhance global capacity in chronic disease surveillance. Potentially applicable to evaluation of surveillance systems?",Information,"Accessible information, accurate data, comparability, data standard, local needs, quality information products, relevant data, right-to-know versus right-not-to-know, timely data","Improve accuracy, timeliness, accessibility and global comparability of surveillance information to develop policies and programmes.

The seven themes are working ideas/examples of how to enhance global capacity in chronic disease surveillance. Potentially applicable to evaluation of surveillance systems?",Education,"Creating user pull not provider push, enhancing local capacity, raising awareness, training young researchers and practitioners","Inform scientists, policy-makers and the public about the current epidemiological shift from infectious to chronic diseases, and the importance of preventing these problems.

The seven themes are working ideas/examples of how to enhance global capacity in chronic disease surveillance. Potentially applicable to evaluation of surveillance systems?",Novelty,"Innovation, new ideas, new thinking, thinking outside the box","Develop novel ways of thinking about both traditional and emerging problems.

The seven themes are working ideas/examples of how to enhance global capacity in chronic disease surveillance. Potentially applicable to evaluation of surveillance systems?",Communication,"Clear message, connecting the dots, consistent message,
knowledge translation, mechanism to consult silent groups, media
relations, packaged information, simple language, timely
dissemination","Develop effective ways to convey chronic disease messages and the results and findings from surveillance to key audiences, such as policy-makers and the general public, who generally do not read scientific publications.

The seven themes are working ideas/examples of how to enhance global capacity in chronic disease surveillance. Potentially applicable to evaluation of surveillance systems?",Evaluation,"Achieving goals and objectives, built-in evaluation system, evidence-based policy, monitoring data utilisation, participatory action research, putting knowledge into action","Assess the design, implementation, utility and effectiveness of initiatives in chronic disease, with emphasis on ensuring that these efforts produce public health benefits

The seven themes are working ideas/examples of how to enhance global capacity in chronic disease surveillance. Potentially applicable to evaluation of surveillance systems?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"In this paper, chronic disease is defined as disease that has a prolonged course, that does not resolve spontaneously, and for which a complete cure is rarely achieved''. Surveillance (also called monitoring) is tracking and forecasting any health event or health determinant through the ongoing collection of data, the integration, analysis and interpretation of that data into surveillance products, and the dissemination of that resultant surveillance product to those who need to know''. Prevention is defined as promoting, preserving and restoring health when it is impaired, and minimising suffering and distress. Control is defined as ongoing operations or programmes aimed at reducing incidence or prevalence of adverse conditions, or eliminating such conditions.",
claraDevelopingMonitoringEvaluation2020,409,Clara 2020,Developing monitoring and evaluation tools for event-based surveillance: experience from Vietnam.,Developing monitoring and evaluation tools for event-based surveillance: experience from Vietnam,2020,Arunmozhi Balajee,fir3@cdc.gov,United States of America,Monitoring and evaluation tools for event-based surveillance in Vietnam,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,Vietnam,l. No framework(s) or guidance document(s) were discussed,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"An evaluation team was formed consisting of stakeholders from GDPM, RIs, CDC, and PATH and designed five data collection tools for assessment of EBS 5-9 months after implementation to document products of EBS activities, perceptions of implementers, and fidelity of implementation.",N/A,"An evaluation team was formed consisting of stakeholders from GDPM, RIs, CDC, and PATH and designed five data collection tools for assessment of EBS 5-9 months after implementation to document products of EBS activities, perceptions of implementers, and fidelity of implementation.","Within each region, provincial preventive medicine centers (PPMCs) lead surveillance and response activities within their respective provinces. Within a province, the district health centers (DHCs) coordinate public health activities in each of the districts. Districts are divided into communes, and each commune has a commune health station (CHS). The CHS is the primary healthcare unit in Vietnam [18] and is usually staffed by a physician, a nurse, and a midwife. Within each commune, village health workers (VHWs; rural areas) and health collaborators (HCs; urban areas) constitute community networks and support the CHSs in different health-promotion activities. 

To support the implementation of the EBS pilot, the MoH's General Department of Preventive Medicine (GDPM) formed an EBS Technical Working Group (TWG) with experts from the MoH (including the 4 RIs), CDC, PATH, WHO, and technical staff from the PPMCs of the participating provinces.

Thirty-three master trainers from the national, regional, and provincial level were trained on EBS. After this, all public health system staff in participating provinces were trained by the cascade training method, including VHWs/HCs, CHS staff, DHC staff, and hospital healthcare workers.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,
collineauEvaluationFrenchSurveillance2022,103,Collineau 2022,Evaluation of the French surveillance system for epidemiological surveillance of antimicrobial resistance in the community and nursing homes.,Evaluation of the French surveillance system for epidemiological surveillance of antimicrobial resistance in the community and nursing homes,2022,Lucie Collineau,lucie.collineau@anses.fr,France,Formal evaluation of the French AMR surveillance system in communities and nursing homes,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",d. One Health,France,j. OASIS: An assessment tool of epidemiological surveillance systems in animal health and food safety (Hendrikx 2011),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,External evaluators (not involved in MedQual-Ville activities but familiar with the OASIS framework),N/A,N/A,"Upon formalization of the request for evaluation by the Mission PRIMO responsible person, an evaluation team was built including three external evaluators (not involved in MedQual-Ville activities but familiar with the OASIS framework) and two internal evaluators (part of the MedQual-Ville coordination team). The inclusion of internal evaluators is typical of the OASIS approach, which aims to be participatory, in order to improve the relevance and future implementation of the recommendations provided. In that sense, OASIS differs from other audits or external evaluations.",Internal evaluators (part of the MedQual-Ville coordination team),N/A,N/A,"Upon formalization of the request for evaluation by the Mission PRIMO responsible person, an evaluation team was built including three external evaluators (not involved in MedQual-Ville activities but familiar with the OASIS framework) and two internal evaluators (part of the MedQual-Ville coordination team). The inclusion of internal evaluators is typical of the OASIS approach, which aims to be participatory, in order to improve the relevance and future implementation of the recommendations provided. In that sense, OASIS differs from other audits or external evaluations.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Overall, this study demonstrated that the OASIS framework is applicable to the evaluation of surveillance systems in the human sector. Out of the 20 criteria considered as not applicable, only one of them was because of non-relevance to the human sector. Other reasons related to specific activities and procedures that were absent in MedQual-Ville.

While the OASIS framework covered a large number of aspects related to surveillance functioning, operations and effectiveness, other aspects such as the cost-effectiveness or the level of collaboration of MedQual-Ville with other national programmes for surveillance of AMR or antimicrobial consumption were not addressed. Several frameworks for the evaluation of the level of integration or One Health-ness of surveillance systems have recently been developed and assessed;12 they appear as complementary tools to evaluation frameworks such as OASIS, and will later be explored to evaluate the level of integration of AMR surveillance in France. Additionally, two new OASIS modules evaluating respectively the cost-effectiveness and the level of collaboration of a surveillance system are currently under development.

This work demonstrated that OASIS is a suitable framework for the evaluation of human surveillance systems and that it can easily be adapted to various infectious diseases surveillance systems.",N/A,N/A,"12 Sandberg M, Hesp A, Aenishaenslin C et al. Assessment of evaluation tools for integrated surveillance of antimicrobial use and resistance based on selected case studies. Front Vet Sci 2021; 8: 620998. doi:10.3389/fvets. 2021.620998

21 WHO. Protocol for the Assessment of National Communicable Disease Surveillance and Response Systems: Guidelines for Assessment Teams. 2001. https://apps.who.int/iris/handle/10665/66787.","The OASIS evaluation framework is a semi-quantitative and generic approach for the evaluation of health surveillance systems.13 It relies on a scoring grid developed in a Microsoft Excel spreadsheet that includes 78 assessment criteria articulated around 10 sections that cover the key aspects of the surveillance process, including: (i) objectives and scope of surveillance; (ii) central institutional organization; (iii) field institutional organization; (iv) diagnostic laboratories; (v) surveillance tools; (vi) surveillance procedures; (vii) data management; (viii) training; (ix) results dissemination; and (x) evaluation and performance (Figure 1 and Table S1, available as Supplementary data at JAC-AMR Online). A score from 0 (minimum score) to 3 (maximum score) is attributed to each criterion with support from a scoring guide, according to the level of compliance of the system under evaluation in comparison with an ideal surveillance system. Justifications for each score are also provided in a comments box and form the basis for the formulation of practical recommendations for improvement. A criterion can be rated as not applicable if not relevant to the surveillance system under evaluation; in this case, the criterion has no impact on the evaluation results. Data collection required to inform the scoring grid is facilitated by a 40-page questionnaire organized around the 10 sections mentioned above. The questionnaire is completed using available literature (including annual reports, scientific publications, protocols, etc.), as well as semi-directed interviews with key actors and end users of the system.

Upon completion of the scoring grid, evaluation results are displayed using three outputs that provide a complementary view of the surveillance system. Of note, the assessment criteria are weighted in Outputs 2 and 3, while they are not in Output 1. Calculation details for each output are provided in Table S1.

High Priority Recommendations Recruitment of clinical laboratories - Strengthen the recruitment of participating laboratories in those regions currently under-represented, hence improving representativeness of national surveillance - Develop incentives to encourage and appreciate the volunteer participation of clinical laboratories. For example, a label this laboratory contributes to a national mission of public health importance' could be implemented. Continue to acknowledge the volunteer participation of clinical laboratories in every publication of MedQual-Ville - Further promotion of MedQual-Ville at the central level (by the national health authorities and agencies)

Dissemination of the results - Strengthen the consideration of MedQual-Ville surveillance data when formulating and updating the national guidelines for good antimicrobial treatment practices - Engage with regional and local partners (including CPias, regional centres for antimicrobial stewardship and/or clinical laboratories) to further disseminate surveillance results at local level (e.g. to local prescribers) - Produce a brief two-page summary sheet of key surveillance results to be easily disseminated by regional/local partners to local prescribers and laboratories - Consider communicating about MedQual-Ville activities in journals dedicated to clinical laboratories and prescribers, as well as the Weekly Epidemiology Bulletin edited by SpF (which has a very broad audience)

Performance indicators - Define and select performance indicators (max. 10) to monitor key functional and operational aspects of the surveillance system. These should include target values and corrective measures in case of deviation - Publish performance indicators in the annual activity report of MedQual-Ville, hence facilitating internal and external assessment of surveillance activities

Medium Priority Recommendations Data extraction and submission - Consider revising the list of optional variables (e.g. patient housing type, sex and age), to encourage clinical laboratories to submit all data of interest to MedQual-Ville - Wherever possible, encourage laboratories to use automated data extraction from their LIMS, hence improving timeliness and reducing the time/burden of data submission

Data visualization - Consider adding features to improve data visualization on the MedQual-Ville website, e.g. making it possible to visualize co-resistance patterns

Low Priority Recommendations Get feedback from MedQual-Ville partners - Conduct a survey to assess the clinical laboratories' level of satisfaction with the feedback and information they receive from MedQual-Ville (e.g. quarterly reports) - Conduct a survey among regional partners (e.g. CPias, regional centres for antimicrobial stewardship, regional health agencies) to assess their expectations and level of satisfaction with the information received from the MedQual-Ville - Encourage the participation of clinical laboratories to the annual survey on methods and techniques used; it will help, among others, to monitor their capacities for data extraction and submission, and identify needs for technical assistance

Steering committee - Consider adding representatives of GPs, clinical laboratories and/or AMR national reference laboratories to the steering committee",
corleyAssessingContinuumEventbased2012,1531,Corley 2012,Assessing the continuum of event-based biosurveillance through an operational lens.,Assessing the Continuum of Event-Based Biosurveillance Through an Operational Lens,2012,Courtney Corley,court@pnl.gov,United States of America,Assessment framework for the characterization of event-based biosurveillance,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Federal government agencies,"Were professionals with backgrounds in informatics, microbiology, epidemiology, operations research, and biosurveillance system development",N/A,N/A,Academic institutions researching biosurveillance detection,"Were professionals with backgrounds in informatics, microbiology, epidemiology, operations research, and biosurveillance system development",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Event attribute family,"The event family of attributes is concerned with providing a high-level characterization of the events that can be monitored by the event-based biosurveillance. The event-type attribute characterizes the causative agent, the source of the event, and the detection mode of the event-based biosurveillance. The event-type attribute is concerned with providing an overall classification of the incidents that may be detected by the biosurveillance model or system. These incidents could be biological, chemical, or radiological.","Source
Detection mode",Readiness attribute family,"Readiness describes the willingness or ability of stakeholders, users, and/or organizations to leverage the event-based biosurveillance in an operational environment and can be either a subjective judgment or an objective measure.
Readiness is characterized in 2 contexts: policy (eg, ability to share event-based biosurveillance outputs as needed) and technology (eg, validation and verification of the event-based biosurveillance).","Policy
Technology",Operational aspect attribute family,"The operational aspect family of attributes focuses on quantifying the overall operational characteristics of the biosurveillance detection model or system and falls into one of the following categories: system requirements, ability to continue tracking the event, system redundancy/reliability, operational mode (always on vs. activation required), and scalability and robustness of higher order effects.","System requirements
Ability to continue tracking an event
System redundancy/reliability
Scalability
Robustness
Consideration of higher order effects",Geographic coverage attribute family,Geographic coverage refers to the physical domain in which the event-based biosurveillance operates. The geographic coverage family of attributes evaluates the geospatial domain associated with detecting or forecasting a biosurveillance event. This family of attributes characterizes density and the input and output geography.,"Density
Input geography
Output geography",Population coverage attribute family,"The population coverage attribute family describes the underlying population that is affected by the event-detection event-based biosurveillance. Attributes include quantitative and qualitative measures of a population's size, density, and species.","Size
Density
Species",Input data attribute family,"The overarching goal of the input data family of attributes is the characterization of event-based biosurveillance according to its general and specific data requirements. This includes determining the characteristics required of the data, the availability of such data, and whether an input requirement is relevant. Input data have great bearing on operational utility and are summarized using the following attributes: accessibility, content, granularity, indicators and warnings, latency, longevity, quality, and utility.","Accessibility
Content
Granularity
Indicators and warnings
Latency
Longevity
Quality
Utility
",Output attribute family,"The output family of attributes describes event-based biosurveillance with respect to the information it produces.
While any event-based biosurveillance will produce some form of output, the fit, form, and function of that output must be relevant and usable for the specific analysis or monitoring scenario. The following attributes are key facets of this important family: accessibility, confidence, content, granularity, latency, longevity, quality, and utility.","Accessibility
Confidence
Content
Granularity
Latency
Longevity
Quality
Utility",Cost attribute family,"Cost is a largely objective measure of the total necessary input of time, money, and other resources into event-based biosurveillance. It is also a measure of whether the source of those resources can be expected to continue to provide those resources to the event-based biosurveillance. The cost family of attributes comprises 3 main attributes: sustainment of funding, research and development, and operations and human capital.","Sustainment of funding
Research, development, testing, and evaluation
Operations",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Source: The source attribute helps characterize the event origin (eg, point source or distributed), specify the status of the etiology of the event (known or unknown), and clarify the motivation (intentional or unintentional). For example, consider a contagious severe acute respiratory syndrome prior to identification of the causative virus. The source attribute would be characterized as a distributed respiratory disease of unknown etiology.",N/A,"N/A
",N/A,"Detection mode: The operational capability of event-based biosurveillance to identify or forecast an event is characterized by the detection mode attribute (eg, event detection, establish baseline, or event detection expected with no baseline). For example, are events detected that deviate from the established baseline in frequency and/or magnitude? It should be noted that the baseline fluctuates and that any excess or anomalous occurrence should be statistically characterized and should include some measure of abnormality or confidence.",N/A,N/A,N/A,"Policy: refers to the willingness or ability of stakeholders, users, and/or organizations to share outputs as needed for effective surveillance and response.",N/A,"Considerations of policy readiness include whether event-based biosurveillance output is publicly available or classified: 
- event-based biosurveillance output is shared with built-in time lag or clearance processes; 
- data sharing is prohibited by regulation; 
- a memorandum of understanding or similar document currently exists or may exist in the future.",N/A,"Technology: the technology attribute refers to a technology's readiness for operational use. The most widely used measure for this is assigning a technology readiness level, a measurement system that supports assessments of the maturity of a particular technology and enables the consistent comparison of maturity between different technologies.",N/A,"Technology readiness levels were originally developed and used by the National Aeronautics and Space Administration (NASA) for technology planning and have been widely adopted in government and industry. 
Some key aspects of technology readiness include: 
- verification and validation of the algorithms against historical data; 
- degree of rigor in testing from software, usability, and workflow perspectives; 
- level of use within an operational environment rather than in a prototype pilot or development setting; 
- basic principles and concepts of the event-based biosurveillance are defined and demonstrated.",N/A,"System requirements: The system requirements attribute specifies the requirements needed to operate the event-based biosurveillance. These requirements can be defined as information technology infrastructure (eg, desktop or supercomputer), operating systems, specific software (eg, SQL, MATLAB, registered trademark of The MathWorks), complexity (eg, qualitative requirements of components under standard operating conditions), activation (eg, real-time, 24/7, normal or nonholiday hours, during response to a crisis), and subject matter expertise (eg, infectious disease medicine, modeling, foreign language translation, plant and environmental health).",N/A,N/A,N/A,"Ability to continue tracking an event: The ability to continue tracking an event relates to the ability of the biosurveillance model or system to follow an event throughout the event life cycle. For example, an event-based biosurveillance may be quite successful in detecting or forecasting an outbreak of disease, but it may lose its sensitivity as the event progresses (eg, background level of event indicators is too high due to a media announcement).",N/A,N/A,N/A,"System redundancy: The system redundancy attribute measures the ability of the biosurveillance model or system to operate in the face of component loss or degradation. These components compose the set of requirements for event-based biosurveillance function and could include staff, information technology infrastructure, data inputs, or interagency agreements, and so forth. Without system redundancy, the loss of any one of these components would negatively affect event-based biosurveillance performance.",N/A,N/A,N/A,"Scalability: Scalability relates to how well event-based biosurveillance may be applied to various volumes of data input, levels of geographic coverage, or numbers of targets. Scalability also refers to the maximum potential effectiveness of a model were it to be transitioned to another volume of data input, geographic coverage, number of targets, and so forth. It addresses the extent to which the model or system scales with respect to input data, geographic coverage, number of targets, and so forth.",N/A,N/A,N/A,"Robustness: Robustness measures the event-based biosurveillance's fidelity under significant departures from its assumptions—that is, the degree to which the event-based biosurveillanceaccurately reproduces features of a real-world system.",N/A,N/A,"Can the event-based biosurveillance cope with low-quality data? 
Does it use multiple component algorithms (such models or systems may be resistant or sensitive to deviations in data quality, fitness, assumptions) or multiple data in aggregate with potential overlap? 
Is the system able to adapt or be adapted to as yet unknown events? 
Is the event-based bio- surveillance able to accept real-world data with possible inconsistencies and incompleteness? 
How compromised (if at all) is the analysis by breaks in the historical maintenance of the system?","Consideration of higher order effects: The first-order effects of an event include all of the consequences directly related to that event. Consideration of higher order effects, however, includes impacts indirectly caused by the event and that have some dependency on consequences directly affected by the event. This may include the cleanup of a radiological attack or the loss of consumer confidence in a food product or pharmaceutical as a result of a contamination event. Note that there might be cases when sensitivity to higher-order effects might conflict with sensitivity first-order effects.",N/A,N/A,N/A,"Density: Density, in terms of geographic coverage, represents the number of “sensors'' per domain (eg, the number of sensors per square mile, surveys). This drives confidence in a forecast of risk or condition in a geographic domain.",N/A,N/A,N/A,"Input geography: Input geography refers to the domain of the data that the event-based biosurveillance uses for event detection. For example, remotely sensed sea surface temperature increases and chlorophyll levels are inputs used to predict cholera outbreaks in Bangladesh.28 This attribute could answer whether the reports come from the local level or are geo- graphically unidentifiable. For example, it will help determine if a regional report of a specific event came from that region or if the report is about something that happened in that region.",N/A,N/A,N/A,"Output geography: The output geography attribute describes the resulting domain where the event is detected or forecast. This helps determine the location of the point source for the event detected and whether inputs need to be from the same region as the request output, and it helps determine what region-specific events may occur.",N/A,N/A,N/A,"Size: The size attribute can be either a quantitative value (eg, total spore count, size of the population of Chicago, number of homeless people exposed to tuberculosis) or a qualitative one (eg, flock, herd, family, community).",N/A,N/A,N/A,"Density: The density attribute refers to the quantitative or qualitative value for the population count per geographic area or the sampling scheme to drive the event-based biosurveillance (eg, number of samples polled to represent the population at large or the number of deaths due to disease to drive a forecast model).",N/A,N/A,N/A,"Species: The species attribute characterizes the specific population included in the event-based biosurveillance to distinguish among models and systems for human, animal, and plant health. The population's physiological status would be characterized here (eg, immune status).",N/A,N/A,N/A,"Accessibility: The input data accessibility attribute refers to the availability of the data for use in event-based biosurveillance as well as the data-gathering and management processes (eg, commodity trading logs from China). When data are accessible, they can be consistently accessed as often as needed for the event-based biosurveillance and do not prevent the scheduled operation of the event-based biosurveillance. Human and technological resources also need to be considered when evaluating input data accessibility. The accessibility of the input data may be affected by the data's availability to the event-based biosurveillance, whether the data are formatted for use in the event-based biosurveillance, and the frequency at which the data are available.",N/A,N/A,N/A,"Content: Input data content is the data specification required by the event-based biosurveillance, such as the quantity and class of data needed to produce meaningful results. The content attribute also spans the quantity and class of other data required of the event-based biosurveillance (eg, demographic, behavioral, and exposure information for the acute emergent event). Additionally, the dependence of the data on other systems or constructs may be included.",N/A,"The manner of data collection is also of interest, including the number and type of sources and the requirement to follow up or otherwise update the data.","Are the data simple case counts over time? Are the data complex (e.g., consisting of large numbers of variables and associated metadata with specific properties such that any deviation would invalidate the event-based biosurveillance results)? 
Examples of input data content may be one or more of but limited to the following: 
Diagnostic—Does the event-based biosurveillance use an independent empirical confirmation?; 
Syndromic—Does it employ surveillance using health- related data that precede or that are a proxy for diagnosis? Does it describe analysis of diagnostic result data and consider the approach to be one that looks for anomalies in “case counts'' versus seasons and geography?;
Curated data—Is the event-based biosurveillance based on data maintained in a curated format (e.g., a database or data warehouse) such that the event-based biosurveillance results are the most recent available? Does the event- based biosurveillance account for historical changes made to the underlying data (e.g., updating case definitions in archives of curated data)? Does the event-based bio- surveillance automatically update based on changes to these data?; 
Dynamic data—Is the event-based biosurveillance focused on a predetermined target of interest, or can it discover items of interest unconstrained by a particular target set (i.e., anomalies)? Are the results in a static or dynamic format (e.g., disease frequency updated dynamically in a geographic domain, real-time assessment of febrile airline passengers arriving on international flights)?","Granularity: The input data granularity attribute describes the level of detail expected in the input data sources. This attribute can be based on a single input data field, an entire data table, or the total body of all input data sources. A mismatch between the input data granularity required by the event- based biosurveillance and that of the data available for input will affect the results of the event-based biosurveillance. Data with greater detail may, with some effort, be aggregated to a less detailed level, but the reverse is not always true.",N/A,N/A,N/A,Indicators and warnings: There are 2 different types of indicators and warnings attributes. Direct indicators and warnings are unambiguous information that an event is indeed occurring.16 Indirect indicators and warnings are proxy data that indicate the circumstances wherein a biosurveillance event is likely to occur.,N/A,N/A,N/A,"Latency: Input data latency is the time between the current date and the most recent date for which data are available to the event-based biosurveillance. Latency is a function of inherent time lags in the processes of collecting, transmitting, editing, and preparing data for analysis. Additional delays may be incurred in order to obtain independent confirmation of observed manifestations of the emergent event. Input data latency is a property of the data source and associated collection methods. It should not be used to identify the refresh rate required by a system or model.",N/A,N/A,N/A,"Longevity: Input data longevity of the input data measures how long they are considered valid. In many cases, the data on which the event-based biosurveillance operate are specific to a particular time period. These data are often first reported as preliminary and then become current before finally becoming historical data that may be revised. The longevity of input data is tied to its intended use and therefore is attributed to the event-based biosurveillance that employs them. Input data longevity helps determine whether the input data expire and the length of time that the data are useful.",N/A,N/A,N/A,"Quality: The input data quality may be appraised in terms of consistency, comprehensiveness, accuracy, timeliness, and validity.",N/A,"Poor quality data might contain simple errors such as misspellings, multiple addresses for a single entity, or missing information, or it may come from a biased source. There are many factors to data quality, but perhaps the 2 most important are the validity and completeness of the data. Degradation of these 2 factors will negatively affect event-based biosurveillance performance. Example considerations include whether the data elements satisfy the needs of their intended use, whether the data are a complete and accurate portrayal of the actual phenomenon, whether there are any internal conflicts in the data, and how significantly data quality issues affect outputs.",N/A,"Utility: Input data utility is the suitability of the input data to the expected event-based biosurveillance outputs. This attribute includes the degree of preprocessing that input data require to be employed by an event-based biosurveillance. Many event-based biosurveillances rely on supplementary data beyond simple case counts, such as demographic attributes of affected populations, event details, and other exogenous threat indicators. It is the sum total of these data that determines their utility.",N/A,Example considerations include whether these data are a proxy for the optimal but unobtainable data or whether the data are a subset of other easily obtained data.,N/A,"Accessibility: The degree to which the results from an event-based biosurveillance are available to end users is captured by the output accessibility attribute. Accessibility refers to the ease of dissemination of event-based biosurveillance output. When the output information is accessible, it could potentially enable the use of model results by decision makers and planners.",N/A,"This attribute includes an assessment of the channels through which the findings are published or distributed. The accessibility of the output data may be assessed by permissions and/or rights to share the data, interagency data access, sensitivity of data (eg, personally identifiable information, Health Insurance Portability and Accountability Act information), the postprocessing that output data require prior to consumption, and the frequency of publication of output data.",N/A,Confidence: Output confidence relates to the accuracy of the event-based biosurveillance results. It is used to evaluate the likelihood that the confidence interval contains the true result. This attribute helps evaluate whether the event-based biosurveillance generates estimates at specific intervals with some degree of probability. Confidence also facilitates the evaluation of estimates for frequency and probability distributions.,N/A,N/A,N/A,"Content: The output content attribute defines what the event- based biosurveillance generates as a product. The output may be qualitative or quantitative and may include probabilities, forecasts, digests, counts, warnings, or lists of outlying observations. The content attribute also spans the quantity and class of data produced by the event-based biosurveillance. If the event-based biosurveillance output lends guidance to other systems, this should be included.",N/A,"Output may be an analytic report or document arising from subject matter expert analysis of raw and potentially disparate data types that leverage qualitative models, computational models, or both. Output content might be binary, categorical, or interval responses, and it may contain structure warnings or graded alerts. The output may contain forecasts. This may take the form of numeric forecasts, probabilities that discrete outcomes will occur, projections based on assumed scenarios, or some combination thereof.",N/A,"Granularity: Output granularity describes the level of detail provided in the output data. This attribute is based on the spectrum of output that an event-based biosurveillance may generate.
",N/A,"The output may be a single data field, an output table, or a graphic representation of the output data. It is not always possible to aggregate output containing low detail to a level of high detail. This attribute can help the model forecast a region of infection, a specific population of infection, a specific number of individuals infected (adults, children), and so forth. It also helps evaluate the level of detail for the resultant data.",N/A,Latency: Output latency describes the time between the current and the most recent date for which output is available from the event-based biosurveillance. Output latency consists of the delay between the event-based biosurveillance system's first published output and the time required to produce additional published output. An example consideration is the length of time before the results are refreshed,N/A,N/A,N/A,"Longevity: Output longevity is a measure of how long event-based biosurveillance output may be considered valid. In most cases, the information produced by the event-based biosurveillance is specific to a given time (as well as the place and set of circumstances). The output may also go through a life cycle wherein it is preliminarily reported, revised, and then completed. This attribute also addresses whether the expiration time is clearly indicated on products.",N/A,N/A,N/A,"Quality: Resultant information that fulfills the purpose of an event-based biosurveillance is measured by the output quality attribute. This event-based biosurveillance attribute encompasses the concepts of scientific accuracy and precision as well as the related concepts of sensitivity, specificity, and negative predictive value. This attribute addresses output data bias, the relevance of the output, and the usefulness of data to other event-based biosurveillances.",N/A,N/A,N/A,"Utility: The output utility attribute gauges the usefulness of the output in analysis, situational awareness, or decision support. Examples of such output include projected attack rates or the probability of a potential outcome. Many acute emergent events evolve over time. It is the event-based biosurveillance system's output at critical junctures of this evolution that determine its utility (eg, do the output data lend themselves to further use by decision makers?)",N/A,"The following are examples of the utility of an event-based biosurveillance:  analysis of consequences (i.e., what-if scenarios);  situational awareness (the output data describe events that are proximal in time and space);  decision support (biosurveillance system/results may be leveraged alongside raw data, domain knowledge, or heuristic rules to inform decisions);  the output data's usefulness as input data to other or subsequent event-based biosurveillances",N/A,"Sustainment of funding: Sustainment of funding refers to the ability of a biosurveillance model or system to continue to receive necessary resources from its funding source. The willingness of the funding source to sustain funding may be a result of the success of the event-based biosurveillance, the policy readiness of the event-based biosurveillance, or a number of other reasons.",N/A,"It is important to note that even the very best of biosurveillance models and systems cannot reliably function without a steady stream of resources. As a result, the sustainment of funding is important for all event-based biosurveillances since an organization that plans to use the event-based biosurveillance will invest much of its own time and resources in training and integrating the event-based biosurveillance with its internal work processes. This attribute can be measured both in units of time and resources.",N/A,"Research, development, testing, and evaluation: The research, development, testing, and evaluation costs relate to the construction of and the preparation of event-based biosurveillance for an operational setting. This operational setting will likely differ from the setting in which the event-based biosurveillance was developed, so additional resources will likely need to be allocated to make sure that the event-based biosurveillance is prepared for this new environment. Research, development, testing, and evaluation also include the costs of transitioning a model or system to use expanded data volume, including hiring staff and acquiring necessary hardware and software.
",N/A,"Considerations for these costs include:
 the cost to develop a prototype biosurveillance model or system from a research concept;
 the cost to make the prototype event-based biosurveillance operational;
 the cost to increase the technology readiness level.",N/A,"Operations: Operations costs are those related to the operational aspects (eg, data gathering, data processing) of a biosurveillance model or system. This attribute also includes the acquisition and retention of trained individuals and field experts and updating the model or system in order to remain current. It includes the cost of the data used by the event-based biosurveillance, the cost to retain valued staff, and the cost to update the event-based biosurveillance system to maintain performance.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"5. Hartley DM, Nelson NP, Walters RA, et al. The landscape of international event-based biosurveillance. Emerg Health Threats J 2010;3:Article e3.

8. European Centre for Disease Prevention and Control. Framework for a Strategy for Infectious Disease Surveillance in Europe (2006-2008). 2005. http://www.ecdc.europa. eu/en/activities/surveillance/documents/0806_framework_ surveillance_strategy_in_europe.pdf. Accessed November 9, 2011.

25. Buehler JW, Berkelman RL, Hartley DM, Peters CJ. Syn- dromic surveillance and bioterrorism-related epidemics. Emerg Infect Dis 2003;9(10):1197-1204.

50. Committee on Effectiveness of National Biosurveillance Systems. BioWatch and Public Health Surveillance: Evaluat- ing Systems for the Early Detection of Biological Threats. Washington, DC: National Academies Press; 2010.","Homeland Security Presidential Directive 21 (HSPD-21) defines the term biosurveillance as the process of active data gathering, with appropriate analysis and interpretation of biosphere data that might relate to disease activity and threats to human or animal health—whether infectious, toxic, metabolic, or otherwise, and regardless of intentional or natural origin—in order to achieve early warning of health threats, early detection of health events, and overall situational awareness of disease activity.

U.S. Government Accountability Office Report-10-645 expands the scope of biosurveillance to include pathogens in plants, animals, and humans; food; and the environment.''

We define a biosurveillance event to be a chemical, biological, radiological, nuclear, or high-yield explosive event with focus on the all-hazards and One Health landscape.

The continuum of event-based biosurveillance is a scientific discipline in which diverse sources of data (eg, clinical activity, syndromic surveillance, internet and media reports) are characterized prospectively (eg, in a networked information system or a biosurveillance model) to provide information on infectious disease events. Biosurveillance complements traditional public health surveillance to provide both early warning of infectious disease events as well as situational awareness. This approach can also be less specific than traditional public health surveillance, though such trade-offs may be appropriate for a network designed to provide early warning.",
crawleyUsingTimelinessMetrics2021,266,Crawley 2021,Using Timeliness Metrics to Track Progress and Identify Gaps in Disease Surveillance.,Using Timeliness Metrics to Track Progress and Identify Gaps in Disease Surveillance,2021,Adam W. Crawley,adam@endingpandemics.org,United States of America,Develop timeliness metrics for use in the evaluation of surveillance systems,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Health agencies,N/A,N/A,N/A,Nongovernmental organization,N/A,N/A,N/A,Universities,N/A,N/A,N/A,"Foundations from the human, animal, and environmental health sectors",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Timeliness Metrics (for outbreak milestones),"Outbreak milestones: predict, prevent, detect, notify, verify, diagnostic test/lab confirmation, respond, public communication, outbreak start, outbreak end, and after-action review.","Definitions for outbreak milestones have been updated to reflect a One Health approach and ensure applicability across human, animal, and environmental health sectors.
The sequence of the milestones may vary by outbreak. In some cases, a single action may represent more than 1 milestone. The definition of an outbreak may vary by disease, geography, or sector. 

The after-action review milestone is included to inspire the necessary collaborations among sectors for operationalizing One Health.
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Timeliness - Predict: Date a reliable and valid predictive alert of a potential outbreak is available (eg, increased rainfall leading to greater density of mosquitoes capable of disease transmission).

Timeliness - Prevent: Date enhanced surveillance or other intervention (eg, mass vaccination in livestock, mosquito abatement) is initiated in response to a predictive alert.

Timeliness - Detect: Date symptom onset, death, or other evidence of pathogen circulation is observed or suspected in humans or animals.

Timeliness - Notify: Date an outbreak in humans or animals is officially reported to relevant authorities (eg, local to national, national to international, cross-sector).

Timeliness - Verify: Date outbreak is confirmed by field investigation or other valid method.

Timeliness - Diagnostic test/lab
confirmation: Date outbreak is confirmed by diagnostic or laboratory test in an epidemiologically linked human or animal.

Timeliness - Respond: Date an intervention to control or manage the outbreak (eg, mass vaccination, quarantine) is initiated by a responsible authority.

Timeliness - Public communication: ate of official release of information to the public by a responsible authority.

Timeliness - Outbreak start: Date symptom onset or death occurs in the earliest epidemiologically linked human or animal (most often identified retrospectively or estimated based on available evidence).

Timeliness - Outbreak end: Date outbreak is declared closed by a responsible authority.

Timeliness - After-action review: Date after-action review is jointly conducted by relevant One Health authorities.


","Time to detect is detect - outbreak start.

Time to verify is verify - detect.

Time to respond is respond - detect.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"In the pilot studies highlighted here, the majority of country participants found the timeliness metrics to be useful for evaluating their infectious disease surveillance systems. Examining timeliness trends helped to identify gaps in surveillance capacity and data collection practices.

The timeliness metrics presented in this article are intended to help individual countries assess their progress over time rather than function as comparative metrics across countries.",N/A,"Timeliness metrics are a critical and complementary evaluation tool for pandemic preparedness. Scores from the Global Health Security Index and the JEEs have not necessarily correlated with a country's ability to respond to the COVID-19 pandemic, emphasizing the need to monitor both capabilities and performance.","8. Jajosky RA, Groseclose SL. Evaluation of reporting timeliness of public health surveillance systems for infectious diseases. BMC Public Health. 2004;4:29.

17. Chan EH, Brewer TF, Madoff LC, et al. Global capacity for emerging infectious disease detection. Proc Natl Acad Sci USA. 2010;107(50):21701-21706.

18. Kluberg SA, Mekaru SR, McIver DJ, et al. Global capacity for emerging infectious disease detection, 1996-2014. Emerg Infect Dis. 2016;22(10):E1-E6.

35. Ending Pandemics, Salzburg Global Seminar. Finding outbreaks faster: how do we measure progress? Published March 2019. Accessed March 24. 2021. http://endingpandemics.org/wp-content/uploads/2019/06/EP-Salzburg-Global-Seminar-2019.pdf

36. Ending Pandemics, Salzburg Global Seminar. The Salzburg Statement on Metrics for One Health Surveillance. Washington, DC, and Salzburg, Austria: Ending Pandemics and Salzburg Global Seminar; 2020. Accessed March 24. 2021. https://www.salzburgglobal.org/fileadmin/user_upload/Documents/2010-2019/2019/Session_641/SalzburgGlobal_Statement_641_One_Health.pdf","NOTE: outbreak milestones are listed in the themes table, however their associated timeliness metric (listed in the evaluation methods column is the more accurate theme to capture. Article did not provide detailed timeliness metrics. See Figure for an example.

A framework for assessing the timeliness of disease surveillance can complement such efforts by providing a set of quantitative performance measures for tracking progress routinely and consistently, as efforts like the JEE are implemented only on a periodic basis

Since 2014, Ending Pandemics has focused on developing definitions for outbreak milestones and corresponding timeliness metrics that can be used at the national and subnational level for monitoring performance in disease surveillance.

Guidance to support implementation of these metrics is being developed in partnership with several stakeholders.
The outbreak milestones are now included in WHO's country guidance on after action reviews and simulation exercises37 while also being used by the US Centers for Disease Control and Prevention to evaluate event-based surveillance tools.38 Furthermore, WHO has made timeliness of detection, response, and notification to WHO a key component of their methods for measuring progress toward the Thirteenth General Programme of Work goal of 1 billion people better protected from health emergencies.''",
cuttsSurveillanceExpandedProgramme1993,2683,Cutts 1993,Surveillance for the Expanded Programme on Immunization.,Surveillance for the Expanded Programme on Immunization,1993,F.T. Cutts,unknown,United Kingdom,Review of surveillance in the Expanded Programme on Immunization (EPI),"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Lead to the use of information for action to improve public health.,Should detect outbreaks in time for an effective response to be made.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The completeness of reporting has two components:
the proportion of all cases that attend the health facilities included in the surveillance system; and the proportion of these cases that are diagnosed and reported.",The proportion of cases diagnosed at health facilities and which are subsequently reported should be assessed by register reviews during supervisory visits.,"The receipt of reports from each health facility,
and the associated delays, should be monitored.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,No definition provided.,N/A,"Minimizing the number of diseases and conditions and the frequency of reporting may help to reduce surveillance costs. Managers should also consider greater use of household surveys (52, 53) or periodic reviews of hospital and clinic registers (54).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Definition not provided.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The frequency with which data are needed at different levels depends on the programme goals and on the outbreak potential of different diseases.,N/A,"Once a country has established criteria for the frequency of reporting different diseases, the timeliness of receipt of the information should be monitored.",N/A,Surveillance data should make a difference either to the formulation of health policies or to the management of intervention programmes.,N/A,"One of the criteria of a useful information system resides in evidence that some of the information gathered is used at the level of gathering, without the mediation of time-consuming referral to, and analysis by, higher levels of management. This does not mean that higher levels of management do not have a role to play; however, the immediate analysis and use of information at the most peripheral levels is characteristic of a useful information system, and thus should be encouraged. If surveillance data are available but are not used to formulate policies or improve programmes, the reasons for lack of use should be investigated.",N/A,N/A,N/A,N/A,N/A,Sensitivity and specificity of case definitions: no definition provided,N/A,"Standardized case definitions should be used for disease surveillance. The sensitivity and specificity of diagnosis can be adjusted by modifying the case definition, and usually vary inversely. Insensitive case definitions can lead to overestimates of programme impact and the failure to identify risk groups and areas; and low-specificity case definitions can lead to loss of confidence in immunization programmes because of apparently large numbers of cases.

The cost of low specificity can be high.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Evaluation of surveillance systems should assess the extent to which data are used for policy-making and programme improvement, and the simplicity, accuracy, completeness, timeliness and cost of the data. Public health surveillance has been defined as ""the ongoing systematic collection, analysis and interpretation of health data essential to the planning, implementation, and evaluation of public health practice, closely integrated with the timely dissemination of these data to those who need to know."" (1)

Efforts should be made to strengthen existing routine systems for surveillance of infec- tious diseases, rather than to develop parallel sys- tems for EPI target diseases. WHO has developed guidelines for this, with the objective of improving the surveillance and control of EPI target diseases and other infectious diseases of major public health importance.

Responsibility for managing the disease surveil- lance system, including initiation of action in response to information, should be decentralized to the district level. To achieve this, field supervision and training of district health officers in data collec- tion and management should be strengthened.

Surveillance systems should be monitored through the use of quality indicators, the main three ones being: - the timeliness/completeness of reporting; - the proportion of reported cases/outbreaks that are investigated; and - the proportion of investigated cases/outbreaks that are followed by a response.",
declichPublicHealthSurveillance1994,2657,Declich 1994,"Public health surveillance: historical origins, methods and evaluation.","Public health surveillance: historical origins, methods and evaluation",1994,S. Declich,unknown,Canada,Review of public health surveillance history and methodology,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,To describe the ongoing pattern of disease occurrence and to link with public health action,To study the natural history and epidemiology of the disease,To provide information and baseline data,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Quality of the surveillance system,Simplicity; flexibility; acceptability; sensitivity; predictive value positive; representativeness; timeliness,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Acceptability reflects the willingness of individuals and organizations to participate in the system,"Acceptability of reporting may be gauged by the proportion of persons who report cases compared with the number who should report and by the completeness of report forms. For systems that involve interviews with subjects, acceptability may also be measured by interview completeness rates. Acceptability may also be considered in terms of the intended linkage to programmes, determining whether action occurs based on the information provided by the surveillance system.","The acceptability of a system depends on the perceived public health importance of the event under surveillance, the recognition of the contribution of individuals to the system, and how much time is needed to make the reports. The surveillance method must be acceptable not only to the collectors of the data, but also to the subjects who will want assurances on the confidentiality of the data.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The cost of a system includes indirect as well direct costs, and should be measured in relation to the benefits obtained.",N/A,"All elements of the system should be included in the cost: data collection, analysis and dissemination. Since this task is quite difficult and often cannot be accomplished, at least a description of the resources that are used to operate the system (direct costs) should be done. This includes the personnel and financial resources expended by the public health community to maintain all phases of the system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Flexibility refers to the ability of the surveillance system to accommodate changes in operating conditions or information needs.,"Flexibility is probably best judged retrospectively, by observing how a system responded to a new demand.","A flexible system adapts easily to the addition of new notifiable diseases or situations or more population groups.
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"It is the proportion of reported cases which truly are cases, or the proportion of reported epidemics which are actual epidemics.",N/A,"Predictive value positive is useful in the case of rare notifiable diseases.

Assessment requires confirmation of cases reported through the system. When the main purpose of a surveillance system is case-finding, a low predictive value positive, and therefore frequent false-positive case reports, would lead to waste of resources. However, in circumstances where it is extremely important not to miss a single true case, a certain level of false positive reports may have to be accepted.",N/A,N/A,N/A,N/A,N/A,"Representativeness reflects the extent to which the surveillance system accurately portrays the incidence of the health event in the population by person, time and place.","Representativeness can be measured by comparing the surveillance data with data from another source (e.g., random sample survey). It is related to underreporting, when this is not uniform or random.
Some examples are:
- a case which results in severe illness and hospitalization is more likely to be reported than a mild case; this bias results in an inflated estimate of disease severity such as death-to-case ratio;
- a case that occurs during periods of local publicity about the disease is more likely to be reported than at other times; this bias results in an under-estimate of the baseline incidence of disease;
- a case with particular characteristics is less likely or more likely to be reported; this bias results in the systematic exclusion or inclusion of a high-risk group;
- some types of health care settings tend to have a higher reporting fraction than others.","Representativeness is important for the generalizability of the information.

Assessing the representativeness of the sytem may help identify important biases in terms of sub-populations systematically excluded by the system.",N/A,N/A,N/A,N/A,N/A,Sensitivity is the ability to detect health events which the surveillance system is intended to detect.,Sensitivity may be measured by conducting a representative survey and comparing the results with those from the surveillance system.,"The measurement of sensitivity requires validation of the findings of the system (outbreaks, trends, change in disease occurrence, etc.), verification of the quality of the data (in terms of accuracy and completeness of each case reported), and the estimate of the proportion of the total number of cases in the community being detected by the system (reporting fraction). 

Sensitivity has often been viewed as completeness of reporting, especially for notifiable diseases. In fact, the need for completeness is often considered so important that considerable cost, time, and energy are expended in attaining this goal. However, a surveillance system that does not have high completeness can be sensitive, as long as the reporting fraction remains reasonably constant. Indeed, for relatively common conditions, achieving high completeness of reporting may be expensive and accomplishes little. 

Completeness becomes a more important consideration for very uncommon diseases (e.g., Reye syndrome) or when, as a control measure progresses, a common disease becomes rare. In these situations, one purpose of surveillance is case-finding and completeness becomes synonymous with sensitivity.

The people responsible for a surveillance system should be aware of and know why underreporting occurs (e.g., asymptomatic cases, inadequate data sources, case definition requirements. For notifiable diseases, the reasons for underreporting that can be corrected include: lack of knowledge of the reporting requirement (e.g., unaware of which disease must be reported, or how or to whom to report); negative attitude towards reporting (time-consuming, too difficult, lack of incentive, lack of feedback, or distrust of the government); and misconceptions that result from lack of knowledge or a negative attitude (concern about confidentiality, or the disease is not regarded as serious, or the perception that the health department does not use or value reports).",N/A,N/A,N/A,"Simplicity should be inherent in the system as a whole, as well as each component (case definition, reporting procedures, etc.), to make it easy to understand and implement. In general, a surveillance system should be as simple as possible while still meeting its objectives. A simple system is usually more flexible, and is more likely to provide timely data with fewer resource needs than a complex system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Timeliness reflects the delay between steps in a surveillance system. It involves not only the interval between the occurrence of the event and the receipt of the report (data collection), but also the time subsequently required for identifying a problem or epidemic (analysis, interpretation of data) and the feedback (dissemination) for control measures.",N/A,"Timeliness is related to the simplicity of the system and of the case definition (e.g., whether a laboratory test is required), and it depends to some extent on the resources available. Timeliness must be considered in relation to the event concerned; for most infectious diseases, the response should be quick, whereas for a chronic disease much slower reporting may be adequate.",N/A,N/A,"The usefulness is measured by whether it meets the objectives and whether this leads to positive health outcomes.

An assessment of the usefulness of a surveillance system should begin with a review of the objectives of the system.

The assessment can be qualitative, in terms of the subjective views of those using the system, or quantitative in terms of the impact of the system on policies, interventions or the occurrence of a health event.",N/A,N/A,N/A,N/A,N/A,N/A,Importance,"Elements to evaluate Importance could be the total number of cases, severity of the illness, mortality, hospitalization, disability, potential for spread, and preventability.","The importance of a health event and the need to have that health event under surveillance can be described in several ways. Health events that affect many people or are costly clearly have public health importance. However, health events that affect relatively few people may also be important, if the events cluster in time and place or if the event has a potential to re-emerge.",N/A,Objectives and components,It can be helpful to draw a flow-chart of the system.,"Describing the objectives of the system allows the development of a framework for evaluating its specific parts, such as:
- case definition of the health events;;
- population under surveillance;; 
- data collected-time period and information collected;; 
- data sources, reporters and collectors;; 
- data handling-transferring and storing;; 
- data analysis-by whom, how, and how often;; 
- data dissemination-to whom, how, and how often.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"67. Thacker SB et al. A method for evaluating systems of epidemiologic surveillance. World health stat. qly, 1988, 41: 11-18.","""Public health surveillance is the ongoing systematic collection, analysis, interpretation and dissemination of health data.The concept of public health surveillance does not include administration of the prevention and control programs, but does include an intended link with those programs"".

At present, there is common recognition that the public interest may on certain occasion justify a breach of the principle of confidentiality, especially when the objective is to protect the health of the public (e.g., public health surveillance). For example, the medical profession in the countries of the European Economic Community generally accepts the following exceptions to the principle of confidentiality:
- when there is a clear overriding duty to society;
- when the information is required by law;
- when the information is required for purposes of medical research and it is impractical or undesirable to seek explicit consent;
- when the patient gives full, free and informed consent to disclosure .

Confidentiality is not the only ethical principle in medical investigation. There is widespread agreement that three principles form the ethical basis of biomedical studies and research.
* Respect for human subjects, which incorporates the principles of autonomy and protection of those with impaired or diminished autonomy.
* Beneficence, which includes the precept to do no harm, and the principle of non-maleficence, which is not limited to physical injury and pain, but also loss of confidentiality, public reputation, and faith in others.
* Justice, which includes the rule of distributive justice and the right to be adequately informed

When epidemiological or public health studies directly involve human subjects, the general body of rules is applicable. When epidemiological studies concern population groups as opposed to individuals, however, refinements of these rules may be applicable. Issues such as individual consent, community involvement, feedback to the communities, confidentiality, and respect for human rights are among those most related to surveillance.

Surveillance data initially should be analysed in terms of time, place and person. There are four trends to consider in the time analysis: secular trend, cyclic trend (e.g., five-year patterns), seasonal patterns, and epidemic occurrence of the disease. If the time analysis reveals an increase in disease incidence, it is important to determine where the cases are occurring. Even if time analysis is unrevealing, geographical analysis may identify a localized outbreak. The analysis of surveillance data by the affected persons' characteristics is valuable for identifying risk groups. Age and sex are provided in most reporting systems. Other variables such as nationality, level of immunity, nutrition, lifestyle, school or workplace, hospitalization, risk factors, and socio-economic status may be studied if available.

Dissemination of surveillance data to those who need to know is a critical component of a surveillance system. Recipients should include those who provide (or should provide) reports, those who collect the data, and those who need to know for administrative or programme planning and decision-making purposes. Appropriate research workers, members of the public, and the media may also be target groups.

Attributes and costs of a surveillance system are interdependent, and the attributes within themselves are interdependent. The improvement of one may improve or compromise another. Recommendations for changes in the system need to consider these interactions.
(1) Improve the awareness of providers
(2) Simplify reporting
(3) Frequent feedback
(4) Use multiple sources and methods
(5) Active surveillance
(6) Sentinel surveillance
(7) Computerization",
delriovilasHealthSurveillanceEvaluation2022,13690,DelRioVilas 2022,Health surveillance evaluation in the policy cycle,Health Surveillance Evaluation in the Policy Cycle,2022,Marisa Peyre,marisa.peyre@cirad.fr,France,"This chapter attempts to explore how evaluation could help improving the strategic relevance of animal health surveillance but also the barriers to the uptake of evaluation recommendations by policy makers, regardless of the surveillance performance itself.","a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Multiple stakeholders,N/A,"Inclusive, collaborative process 
All stakeholders participate and derive value from the process",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ideally, estimation of the impact of recommendations should be part of the evaluation plan once the identification of gaps and surveillance alternatives, to address the gaps, is concluded (see Chap. 16). These alternatives, either to increase overall surveillance capability or to maintain/reduce it in the most efficient manner, are best evaluated under a portfolio approach to account for synergies in both their costs and benefits.

We now qualify this statement further into two directions linked to the delivery of value: (i) implementation of the evaluation findings, and (ii) into the future, so that the retrospective assessment of the surveillance system is no longer the end but a means to value delivery.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"3. Del Rio Vilas VJ, Kocaman M, Burkom H, Hopkins R, Berezowski J, Painter I, Gunn J,  Montibeller G, Convertino M, Streichert LC, Honoré PA. A value driven framework for the  evaluation of surveillance systems. Online J Pub Health Informatics. 2017;9(1):e83

6. Antoine-Moussiaux N, Vandenberg O, Kozlakidis Z, Aenishaenslin C, Peyre M, Roche M,  Bonnet P, Ravel A. Valuing health surveillance as an information system: interdisciplinary  insights. Front Public Health. 2019;7:138. https://doi.org/10.3389/fpubh.2019.00138.

16. Convertino M. An information theoretic portfolio model for disease surveillance evaluation.  GEOMED 2017, Porto; September 2017.","Table 12.1 Summary of considerations towards implementation of surveillance evaluation to  inform policy decisions

# Considerations  Observations 1 Seek parsimony in the list of  surveillance evaluation  attributes. Failure to evaluate all the relevant attributes may lead to  added structural uncertainty and limited impact of the  evaluation itself. On the other hand, avoid double  counting of surveillance evaluation attributes capturing  similar underlying performance.

2 If surveillance evaluation is  the answer, what was the  question? To stress the importance of a policy-driven evaluation to  achieve strategic relevance.

3 No disease surveillance is an  island. Surveillance system evaluations are better conducted  within a strategic framework of continuous improvement  comprising all health-related capacities.

4 Surveillance evaluation is not  the end but a means to an end. Evaluation must inform a managerial decision, which, if  of quality, should lead to a commitment to action [15].

5 Surveillance evaluation must  improve things, not correct  failures. If the perceived message by the relevant stakeholders is  one of ""putting things right or correct existing failures"",  support from critical stakeholders may dwindle.  Improvements on evaluation findings may not materialize  entirely due to lack of wide support.

6 Economic benefits are  necessary but not sufficient to  ensure the implementation of  recommendations. This is due to the multi-dimensional nature of surveillance  value. Quantify value as widely as possible encompassing  as many attributes and stakeholders as required, in a  matrix design, bearing in mind that different attributes  will have different relevance to different stakeholders.

7 Quantification over  qualification. To support action via quantification of the evaluation  findings (e.g. limited sensitivity) for all variables relevant  to the epidemiology of the disease under investigation.

8 Set up regular feedback loops. They should be clearly described and timed in the  evaluation project plan.

9 Consider not just the technical complexities, but the more critical organizational ones

Surveillance evaluation focuses on measuring the value of surveillance efforts to  inform meaningful actions and relevant policy decisions. It would be restrictive to  limit surveillance value to the reduction of disease risk uncertainty, as shown for  tularemia. Value is a multi-dimensional concept and other surveillance attributes  (e.g. transparency) may be at play which could contribute value to other stakehold- ers (e.g. farmers surely appreciate ease of reporting while policy actors may allocate  greater value to transparency). Until recently, evaluation frameworks had the ten- dency to focus on effectiveness technical attributes (e.g. sensitivity) while ignoring  more qualitative functional attributes (e.g. acceptability), of difficult measurement  and aggregation. Not addressing the entire range of attributes leads to partial evalu- ations that may fail to convene sufficient support across the stakeholders' base for  surveillance improvements. 

As advocated in this book, a comprehensive evaluation framework  should therefore cover both the strategic and operational demands, and aim to quan- tify the relative contribution of each relevant operational process towards the strate- gic goals of the surveillance effort.

Table 12.2 Principles of strategic portfolio management Principle  Observations

Aligned decision forum  A dedicated environment for capacity/disease managers  to share their data, evaluation results and assumptions,  and discuss the organization's strategic aims.

Value creation focus  The goal is to find the portfolio strategy that maximizes  value generation for the organization. This must be  accepted by all capacity/disease managers.

Credible, comparable capacity/ disease evaluations To allow capacity or disease managers to make and  accept portfolio-focused decisions. Embracing uncertainty and  dynamics All uncertainties (parametric around evaluation inputs  and outputs, and those relating to implementation  success) are addressed explicitly, and updated regularly.

Clear communication and learning  between capacity/disease managers  within the portfolio Quality of data, methodologies, and other technical  aspects around capacities/diseases evaluations are  shared, and performance (of projects or portfolio) is  tracked.

Inclusive, collaborative process  All stakeholders participate and derive value from the  process.

Adapted from ""Strategic portfolio decisions. Strategic decision and risk management. Stanford  Center for Professional Development and Strategic Decisions Group, 2009""",
denteIntegratedSurveillanceRisk2018,7084,Dente 2018,Integrated surveillance and risk assessment for arbovirus infections: recommendations for enhancing One Health in the Mediterranean Region. MediLabSecure Strategic Document 2018.,Integrated surveillance and risk assessment for arbovirus infections: recommendations for enhancing One Health in the Mediterranean Region: MediLabSecure Strategic Document 2018,2018,Maria Grazia Dente,mariagrazia.dente@iss.it,not reported,"Development of a conceptual framework for integrated surveillance, in additional to recommendations for future improvements","a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,Multiple countries primarily across the Mediterranean region,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Policy and institutional level - policy level,"1. Existence of a national policy addressing integrated surveillance for this specific exposure 
2. Existence of a policy addressing integrated surveillance for this specific exposure at subnational level",N/A,Policy and institutional level - institutional level,"3. Existence of agreements among the institutions involved in human/animal/entomological surveillance for the specific exposure 
4. Existence of a coordination mechanisms among the institutions involved
5. Existence of identified focal points for each of human/animal/entomological surveillance for the specific exposure",N/A,Data collection and analysis level - Interoperability mechanisms at data collection level,"6. Existence of integrated data collection tools
7. Existence of activation mechanisms of human surveillance based on signals from animal/entomological surveillance
8. Other interoperability mechanisms at data collection level",N/A,Data collection and analysis level - Interoperability mechanisms at data analysis level,"9. Presence of DB exchange/merging/other mechanisms to facilitate joint analysis among sectors.
10. Performance of joint/integrated data analysis among the different surveillance sectors
11. Other interoperability mechanisms at data analysis level",N/A,Dissemination level,"12. Existence of joint result dissemination mechanisms (e.g., bulletins, reports, papers, media reports, websites, etc.)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Policy level,N/A,N/A,"1. Existence of a national policy addressing integrated surveillance for this specific exposure 
2. Existence of a policy addressing integrated surveillance for this specific exposure at subnational level",Institutional level,N/A,N/A,"3. Existence of agreements among the institutions involved in human / animal / entomological surveillance for the specific exposure ; 
4. Existence of a coordination mechanisms among the ; institutions involved;
5. Existence of identified focal points for each of human/animal/entomological surveillance for the specific exposure",Interoperability mechanisms at data collection level,N/A,N/A,"6. Existence of integrated data collection tools; 
7. Existence of activation mechanisms of human surveillance based on signals from animal/entomological surveillance; 
8. Other interoperability mechanisms at data collection level",Interoperability mechanisms at data analysis level,N/A,N/A,"9. Presence of DB exchange/merging/other mechanisms to facilitate joint analysis among sectors; 
10. Performance of joint/integrated data analysis among the different surveillance sectors; 
11. Other interoperability mechanisms at data analysis level",Dissemination level,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Not sure if the components and sub-components of the conceptual framework should be listed as themes or not - these concepts were extracted as domains as well as themes since their categorization was unclear.

World Bank Operational Framework-definition of One Health is: ""collaborative approach for strengthening systems to prevent, prepare, detect, respond to and recover from primarily infectious diseases and related issues such as antimicrobial resistance that threaten human health, animal health and environmental health collectively, using tools such as surveillance and reporting with an endpoint of improving global health security and achieving gains in development. While using infectious disease/AMR as a starting point, we recognize this definition and approach is expandable for wider scope (e.g., water and soil pollution which have animal and environment connections)"" (4).

In this Strategic Document, as well as in the Project's studies, we refer to integrated surveillance as synonymous of One Health Surveillance as per the definition provided  by Stark et al.:""One Health Surveillance consists of the systematic collection, validation, analysis, interpretation of data and dissemination of information collected on humans, animals and the environment to inform multisectoral decisions for more effective, evidence- and system-based health interventions"" (8).

The reinforcement of relations of trust in the region is an objective and an instrument to facilitate the impact of the initiative and support its sustainability.

Coordinating the many players involved in human, animal and environmental health is vital to meet the health challenges of tomorrow. In this context, three major international organisations - the WHO, the World Organisation for Animal Health (OIE) and the Food and the Agriculture Organization of the United Nations (FAO) - are working together to prevent and control health risks at the human-animal-ecosystems interface.

The development of a business case for One Health has also been proposed to describe the origin and expansion of this concept, with five potential areas where One Health could add value and reduce costs:

1. sharing health resources between the medical and veterinary sectors;  
2. controlling zoonoses in animal reservoirs;  
3. early detection and response to emerging diseases;  
4. prevention of pandemics;  
5. generating insights and adding value to health research and development (32).

The inter-sectoral collaborations have a key role in several aspects connected to the implementation of One Health: early warning, integrated surveillance; risk assessments; data provision and information sharing (to cope with the lack of common inter-sectoral data systems at national level). These collaborations can be enhanced by facilitating the understanding of reciprocal roles, responsibilities and needs and by setting common priorities with balanced resources allocation.

Here below we present the main recommendations to enhance the surveillance of arbovirus infections under a One Health approach. These recommendations are the outcome of a long process including studies, activities and discussions with the partners and other experts. The presented recommendations are not exhaustive and may vary in relevance with the time and the countries. 
1. Assessing the National/Local Situations (with studies, sharing of lessons learned, collaborations, etc.) and identifying priority areas for multi-sectoral efforts 
2. Enhancing competences and awareness of intersectoral collaboration and facilitating data and information sharing 
3. Facilitating operationalisation of One Health strategies 
- Describe and assess integrated surveillance systems 
- Evaluate added value of integrated systems 
- Provide an evidence based ""business case"" 
- Promote intersectoral databases 
- Promote harmonization of surveillance systems and their interaction 
4. Networking and regional strategies in synergy with international strategies",
dreweEvaluationAnimalPublic2012,1543,Drewe 2012,Evaluation of animal and public health surveillance systems: a systematic review.,Evaluation of animal and public health surveillance systems: a systematic review,2012,J. A. Drewe,unknown,United Kingdom,Systematic review of attributes and methods used to evaluate animal and public health surveillance systems,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The purpose of surveillance activities may include monitoring of endemic diseases and the impact of control measures or the identification of (re-)emerging and exotic diseases that may have a significant impact upon public health, animal health, welfare and international trade.

The output of surveillance programmes assists in setting priorities and guiding effective prevention and control strategies. It also helps to monitor the progress and success of intervention programmes and, in the animal health field, to demonstrate the infection- and hazard-free status of animals and animal-derived products [4]. Ensuring that surveillance programmes are fit for purpose is therefore paramount.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Willingness of persons and organizations to participate in the surveillance system,N/A,Assessment of acceptability should capture much of the essence of simplicity and reliability too (see simplicity and stability),N/A,N/A,N/A,N/A,N/A,Link between the different components and the development stages of a surveillance system,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Deliberate repetition in sampling the same geographical sites over time to allow trends in epidemics to be measured,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Relationship between the expected outcomes (such as the number of lives saved) and the costs of surveillance required to achieve this. May be expressed as a measure of efficiency, whereby the system operates at the least possible cost or makes the best use of available resources",N/A,The costs of obtaining surveillance information need to be balanced against the benefits derived.,N/A,N/A,N/A,N/A,N/A,Completeness and validity of the data recorded,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Extent to which the system objectives are achieved,N/A,N/A,N/A,"Link between the resources implemented and the results obtained. An efficient system will accomplish a job with minimum expenditure of time, human effort and cost",N/A,N/A,N/A,Extent to which the available means meet the system's needs. A surveillance system may be unfeasible if there are not the means to run it,N/A,N/A,N/A,"Ability to adapt to changing information needs or operating conditions with little additional time, personnel or allocated funds. Flexible systems can accommodate new health-related events, changes in case definitions or technology, and variations in funding or reporting sources",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ease with which one surveillance system can be integrated into another, in an appropriate format for people in other countries to easily use",N/A,N/A,N/A,Ratio of the probability of a surveillance system detecting an infected individual to the probability of the system incorrectly identifying them as infected when they are in fact not. Likelihood ratios do not vary with disease prevalence and so are stable expressions of system performance,N/A,N/A,N/A,Probability that infection is truly absent given that it is not detected,N/A,N/A,N/A,How well the system can be duplicated in another setting,N/A,N/A,N/A,Proportion of reported cases that actually have the infection of interest,N/A,"The three attributes sensitivity, specificity and positive predictive value all give related information and so assessment of one or two might be sufficient",N/A,N/A,N/A,N/A,N/A,"Extent to which features of the population of interest (e.g. herd size, age, location) are reflected in the surveillance data that are collected. A surveillance system that is representative accurately describes the distribution of infection in the population by place and person (or animal).",N/A,Bias reduces representativeness,N/A,Measures taken to assure authorized computer system access and to maintain confidentiality where needed,N/A,N/A,N/A,"The sensitivity of a surveillance system can be considered on two levels. For endemic infections, sensitivity refers to the proportion of cases of a disease detected by the surveillance system (this usually requires a gold standard test to indicate the actual number of cases). For non-endemic infections, sensitivity can refer to the ability of a surveillance system to detect disease outbreaks",The application of methods such as CRC and scenario-tree analysis to improve sensitivity estimates is advised,"The three attributes sensitivity, specificity and positive predictive value all give related information and so assessment of one or two might be sufficient

Because sensitivity and specificity are related, but provide different information, they ought to be estimated simultaneously taking into account the evaluation objectives

Theoretical work indicates it may be possible to incorporate sensitivity, specificity and timeliness into a single metric [111] although interpretation of the combined measure is not straightforward",N/A,"Refers to the surveillance system structure, ease of operation and flow of data through the system. Surveillance systems should be as simple as possible while still meeting their objectives",N/A,"Simplicity appears to be positively related to acceptability, with staff willingness to participate in surveillance being high if the system is simple and easy to use",N/A,"Proportion of true non-events correctly classified as such, the inverse being the false alarm rate",N/A,"The three attributes sensitivity, specificity and positive predictive value all give related information and so assessment of one or two might be sufficient

Because sensitivity and specificity are related, but provide different information, they ought to be estimated simultaneously taking into account the evaluation objectives

Theoretical work indicates it may be possible to incorporate sensitivity, specificity and timeliness into a single metric [111] although interpretation of the combined measure is not straightforward",N/A,Reliability (function without failure) and availability (operational when needed),N/A,"A reliable system (one that functions without failure, which often means absence of complex technology) is likely to have higher acceptability to users than a system that frequently fails",N/A,N/A,N/A,N/A,N/A,"Speed between steps in a surveillance system. For outbreak detection, timeliness refers to the time between exposure to the infectious agent and the initiation of interventions to control infection",N/A,"Theoretical work indicates it may be possible to incorporate sensitivity, specificity and timeliness into a single metric [111] although interpretation of the combined measure is not straightforward",N/A,"Actions taken to protect health based on the information provided by the surveillance system.
A measure of the impact of the surveillance system",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Relevance: Assessment of the how closely the outputs of a surveillance system meet its objectives.
Also referred to as pertinence",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Quantitative approaches were applied far more commonly than qualitative approaches, and this was especially true for evaluations of animal health surveillance.

Quantitative approaches:
- Calculation of percentage of complete records# 
- Comparison of one system with another
- Simulation modelling or statistical algorithms
- Scenario tree modelling
- Cost-benefit analysis
- Capture-recapture technique
- Performance indicators
- Odds ratios of disease detection probability
- Measurement of effort applied

Qualitative approaches:
- Subjective scoring system or expert opinion
- Spatial mapping
- Logic model

See Table 4 for frequency of use for each method.

The most frequently assessed attributes were sensitivity, timeliness and data quality (Fig. 2). The frequency distribution of the number of attributes assessed per article was positively skewed, with approximately half the articles (48/99) assessing one or two attributes only and very few articles assessing more than ten attributes (Fig 3). Almost a quarter (23/99) of the articles specifically stated as an objective to assess one or more of the ten attributes recommended in the CDC guidelines for evaluating public health surveillance systems.

Relationships between attributes were rarely investigated.

Five articles described the development and calculation of PIs to evaluate surveillance systems.

Four articles described three generic evaluation frameworks which could be applied to a range of diseases and situations [7, 17, 105, 107]. The generic nature of these frameworks comes about from their common structure which allows priorities to be varied according to the specific objectives of each surveillance programme. A series of core elements (such as zoonotic importance or public concern) reflect the different purposes of surveillance and may be chosen accordingly. Each of these core elements contains a selection of criteria to be evaluated (such as strength of evidence). The criteria are judged through assessment of attributes of the surveillance system. By varying the priority of the core elements depending on the surveillance objectives and choosing a different selection of criteria to be evaluated using a range of attributes each time, these frameworks appear flexible and truly generic.

Some authors have made suggestions for grouping related or comparable attributes [107, 109].
However, it may still be important to evaluate several related attributes individually. For example, a system could be extremely sensitive (detecting all cases of a disease) but if specificity was low, many of the apparently positive cases would in fact be false positives.",N/A,N/A,"107. Malecki KC, Resnick B, Burke TA. Effective environ- mental public health surveillance programs: a frame- work for identifying and evaluating data resources and indicators. Journal of Public Health Management and Practice 2008; 14: 543-551.","Disease surveillance in both animal and public health fields involves the ongoing systematic collection, analysis, interpretation and timely communication of health-related data.

The importance of ensuring that public health systems are efficient and effective is increasingly being recognized [5-7] and this applies equally to animal health surveillance systems [6, 8]. Improving the efficiency of surveillance is a key goal of the UK's Veterinary Surveillance Strategy [3]. Evaluation of surveillance programmes is essential to ensure that limited resources are effectively used to provide the evidence required for protecting animal (and human) health. Such evaluations can lead to changes in surveillance methods, resulting in considerable financial savings [9]. Evaluation of surveillance can play an essential part in establishing and maintaining international trust [10]. Quality assurance is essential to maintain credibility, which is particularly important for intercommunity and international trade with animals and animal-derived products.

Evaluation is defined as the systematic and objective assessment of the relevance, adequacy, progress, efficiency, effectiveness and impact of a course of actions, in relation to objectives and taking into account the resources and facilities that have been deployed.

PIs are time-delimited, denominator-based statistics [75] which can be used to monitor the implemen- tation of surveillance systems rather than for the periodic evaluation of surveillance activities to determine whether these activities are meeting their objectives. They allow the progress of surveillance to be monitored by providing quantitative comparisons of elements of the activity over time.

A distinct lack of standardization exists regarding the best approach for evaluating surveillance systems in order to facilitate decision-making in the fields of animal or public health. The ten attributes recommended for evaluation by CDC [17] - simplicity, flexibility, data quality, acceptability, sensitivity, positive predictive value, representativeness, timeliness, stability and usefulness - were often assessed but usually singly or in pairs rather than all ten together. An evaluation based on only one or two attributes is not likely to provide a complete, unbiased evaluation of a surveillance system since multiple indicators are needed for tracking the implementation and effects of a programme [17].

Given that evaluation is defined as the systematic assessment of the quality of something, the large proportion of articles included in this review that assessed only one or two attributes cannot be considered complete evaluations. Indeed, it could be argued that only about one quarter of the articles in this review (27/99) performed a systematic assessment, by addressing five or more attributes (Fig. 3) to form a balanced evaluation of a surveillance system. While the optimal number of attributes for assessment is likely to vary depending on the objectives of each evaluation, between five and 10 attributes per evaluation are likely to be required to provide a complete evaluation.

The objective of the evaluation process should be clearly stated and the evaluation designed accordingly, rather than being dictated by convenience. An assessment of the purpose of the surveillance activity should be included as part of the evaluation process.

Clear definitions and agreement on what each attribute, indicator or criterion actually measure is essential if surveillance evaluations are to be comparable and universally understood.

Due to the wide range of system attributes that may be assessed, methods which collapse these down into a small number of grouped characteristics by focusing on the relationships between attributes and their links to the objectives of the surveillance system should be explored further. 

A generic and comprehensive evaluation framework could then be developed consisting of a limited number of common attributes together with several sets of secondary attributes which could be selected depending on the disease or range of diseases under surveillance. If there is to be a benefit to decisionmakers, and ultimately result in maximum impact, the outputs of the surveillance need to be interpreted correctly and communicated clearly to all who make use of the system. Economic evaluation should be an integral part of the surveillance evaluation process.",
dreweSERVALNewFramework2015,1170,Drewe 2015,SERVAL: a new framework for the evaluation of animal health surveillance.,SERVAL: A New Framework for the Evaluation of Animal Health Surveillance,2015,J. A. Drewe,jdrewe@rvc.ac.uk,United Kingdom,Development of a generic evaluation framework that is applicable to all animal health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Section 1. Define the scope of the evaluation,"a. State the evaluation objective(s); 
b.Formulate the evaluation question; 
c. Indicate the motivation for the evaluation; 
d.Define the organisation of the evaluation; 
e. Identify the time and resources available for the evaluation; 
f. State what will be done with the evaluation outputs","Example provided by the article:

1a: Choose from the following list of six evaluation objectives:
i To ascertain whether a surveillance system is meeting its objectives.
ii To ascertain whether a foreign surveillance system is reliable enough to accept imports from that country, or whether a domestic surveillance system is good enough to support the export of animals or their products.
iii To ascertain whether a surveillance system is providing value for money to the funder.
iv To determine how much benefit (monetary or otherwise) a surveillance system is providing to each of its user groups.
v To identify the strengths and deficiencies of a surveillance system.
vi To identify potential measures that could improve the performance, efficiency and productivity of a surveillance system.
This list aims to cover all possible evaluation objectives but excludes higher level strategic decisions, for example to determine whether a surveillance system, or a component of it, should be stopped', which would be based on the output of the evaluation. One or more of the objectives listed here could inform such a decision, and the most relevant one(s) should be chosen

1b: Phrase the evaluation objective as a specific question in a format that the evaluation can seek to address

1c: State what prompted the evaluation to be undertaken

1d: Identify the people involved in the evaluation. In some cases, a single body may be responsible for requesting, commissioning and funding the evaluation. In other cases, the body who requests the evaluation may be different to the body who commissions it who in turn may be different to the body that funds it. Consider:
* Who requested the evaluation?
* Who commissioned the evaluation?
* Who is funding the evaluation?
* Who will do the evaluation?
* What other personnel support and administration will be required?
* Who will be responsible for communication and reporting?
* Who will benefit from the evaluation outputs?
Indicate how the engagement of each of these people will be secured

1e: Indicate the staff, funds and time available for the evaluation.
Identify the evaluation timeframe, including the start date, delivery date and any interim deadlines

1f: This should be linked with the evaluation objective(s) stated in section
1a and indicate the purposes to which the evaluation results could be put. Thought should be given to how the findings of the evaluation will be reported. Reporting of the evaluation outputs is covered later in the framework (section 5e)
",N/A,"Why is the evaluation being done?

What is expected to come out of it?

How will the evaluation be organised?",Section 2. Characterize the surveillance system to be evaluated,"a. State the name of the surveillance system to be evaluated
b.State the context of the health condition(s) under surveillance
c. Summarise the current situation
d. Identify the surveillance objective(s)
e. Specify the target population for the surveillance system
f. Describe the structure of the surveillance system
g. Describe the design of the surveillance system
h. Identify and engage the surveillance system users
i. Outline the organisational structure","2a. If just a component of the surveillance system is to be evaluated, name that component, but also indicate which other components are in the surveillance system and indicate how the components relate to each other.

2b. Provide the following information:
- Name the health condition under surveillance. This could be a disease, infection, condition or event. Most are likely to be infectious but this framework is designed to apply equally to non-infectious conditions.
- State the causal organism or factor (if known). 
- Indicate if it is zoonotic.
- Indicate the context of the health condition under surveillance. 
Possibilities include: 
i. New (or emerging) health conditions: not previously recognised; not currently recorded as present; may result from the evolution or change in an existing disease agent causing a change of strain, host range, vector, or increase in pathogenicity; or may be the occurrence of any other previously undefined condition.
ii. Re-emerging health conditions: previously defined conditions that were either absent and have recently re-appeared, or were present at a low level in the population in a defined geographical area and are markedly increasing in prevalence. 
iii. Endemic health conditions: known to be constantly present in the population of interest.
iv. Exotic health conditions: previously known conditions that cross political boundaries to occur in a country or region in which they are not currently recorded as present.

2b. Briefly summarise the current problem with the health condition under surveillance. 

- Why is it considered to be a problem?
- Briefly indicate the level of current knowledge of the condition.
- Identify the Policy objective of the surveillance programme. Examples are given below. The policy objective describes how surveillance information is used by policy makers to inform decisions about how best to support a healthy and sustainable food and farming industry in order to protect the livelihood of producers, other value chain stakeholders and public health and to contribute to national economic development. The specific decisions that surveillance information can assist policy makers with include (but may not be limited to):
i. Management of outbreaks - whether additional control measures are required to limit the spread of an emerging or exotic disease outbreak.
ii. Informing trade - whether to permit import or support export of animals or animal products based on the evidence about the prevalence and distribution of disease in the population and the risk of disease spread through the commodity being traded.
iii. Prioritisation 
- how to prioritise surveillance and control measures for different health events based on their level of occurrence and impact on animal health and welfare, public health, trade and the wider economy.
iv. Informing control - Whether the current control measures for particular diseases are effective or should be changed

2d. Choose from the following list of six surveillance objectives. This list aims to cover all possible surveillance objectives but excludes higher level aims, for example, ""safeguarding public health"" or ""maintaining animal welfare"" or ""prioritisation of threats and resources"" which would be decisions to be made at a higher level based on the output of the evaluation. These surveillance objectives are also distinct from higher level aims and policy objectives which are informed by information provided by surveillance activities. Such higher-level aims should be matched to one or more of the objectives listed here. In the example of ""prioritisation of threats and resources"", any of objectives i, iii, v, or vi might apply.
i. Monitor the prevalence of infection. While usually aimed at endemic infections, this is also applicable to new and re-emerging infections and may form part of an assessment of the impact of control programmes on infection incidence.
ii. Case finding of infected animals: detection of as many cases as possible of a known infection to facilitate control. The emphasis here is on finding those individuals who are infected in order to intervene in some way such as culling or vaccination. This will usually apply to an endemic disease.
ii. Early detection of new or re-emerging infection. Early detection could be defined as detection of infection before an outbreak becomes uncontrollable: this timeframe will vary by health condition and should be estimated. If this objective is chosen, a statement should be included to define how early the system aims to detect infection.
iv. Demonstrate freedom from infection. If this objective is chosen, a statement should be included to define the prevalence and associated confidence level which are considered to indicate disease freedom. These concepts are presented with examples in: Dufour B, et al. Proposed criteria to determine whether a territory is free of a given animal disease. Veterinary Research 32: 545-563.
v. Identify changes in the population at risk. Here, risk factors rather than an infectious agent are the target for surveillance. This might lead to Identification of new population groups at risk and in need of targeted prevention measures.
vi. Improve epidemiological understanding of a disease. Generating knowledge about a disease, for example academic research or hypothesis generation. It is anticipated that this objective will usually relate to a new health condition.

2e. This is the animal population which the surveillance system was designed to cover. Quantify it as precisely as possible including species, breed, age, sex, production type and geographical location. It may be helpful to indicate if the target population is vertically or horizontally integrated. Vertically integrated means a single producer raises animals from birth through to death (e.g. for fish this would include the hatchery, smoltery and marine pens) and therefore the one producer is a single epidemiological unit. Horizontally integrated means several producers each farm a different life stage (and therefore each is a separate epidemiological unit). 

2f. Give details of how the surveillance system works by detailing the components present in each of these four categories: 
i. Data collection (inputs); 
ii. Data management (processes); 
iii. Data analysis (outputs); 
iv. Data dissemination (outcomes). 
Consider presenting this information in flow-chart format. 

During this process it may help to think about the characteristics of the surveillance system in these three areas:

i. Agent (infectious/non-infectious, incubation time, life cycle);
ii. Host/herd (susceptibility, contacts);
iii. Sampling (test quality, sample size, sample frequency).

Data collection: Use of appropriate data sources and collection methods and the existence of a case definition and data collection protocol. 

Consider each of the following: 

- Who provides the data?
- Who collects the data?
- Where are data collected? 
- How are data collected?
- How are data recorded (e.g., on paper or electronically)?
- What type of data are being dealt with (e.g., active/passive, threat-specific/syndromic)?
- Is there a data collection protocol?
- How are staff trained to collect data?
- What is the case definition?

Data management: Use and documentation of systems for processing information, including data processing protocols and data verification procedures. 

Consider each of the following: 

- How are data managed?
- What data security measures are in place?
- How are data stored?
- How are this documented?
- Are quality assurance procedures followed?
- Are there data processing protocols?

Data analysis: Methods used for the analysis and interpretation of data.

Consider each of the following: 

- How are data analysed and interpreted?
- Are performance indicators used and if so, which ones and how are they calculated?
- Describe the data verification procedures.


Data dissemination: Methods used for information exchange between people involved at all levels of the surveillance system. 

Consider each of the following: 

- Which methods are used to exchange information between people involved in the surveillance system (providers, analysers and users of surveillance data)? These might include: case reporting cards, emails, letters, phone calls, interim reports of surveillance data, websites for disseminating information, and feedback given to the data providers.
- How frequently are data or reports disseminated?
- To date, what actions (if any) have been taken as a result of the surveillance activity? These might include: details of mitigation measures imposed; decreased incidence of diseases; use of surveillance data for policy and programme decisions; and appropriateness of outbreak response.

2g. Outline the study design and indicate how the sampling frame and testing protocol are decided.

Describe the general structure of the surveillance system including:

- origin of data (whether active, passive or enhanced passive)
- disease focus (whether hazard-specific or general)
- study design (e.g. case reports, survey or continuous collection
- sample size calculation and sampling strategy including whether a risk-based strategy is used

2h. Identify the people involved in the surveillance system that is being evaluated:

- Who pays for the surveillance?
- Who provides the surveillance data?
- Who analyses the surveillance data?
- Who uses the resulting information?
- Who benefits from any action resulting from the surveillance?
- Who pays for disease mitigation
- Who (if anyone) might lose out if disease is reported (e.g. it might be thought that famers‚ reputations may be tarnished if they declare disease in their herd)?

Identify how these people will be engaged in the evaluation process.Note that the people identified in this section may be different from the people identified in section 1d where the focus was on the people involved in the evaluation itself.

2i. Indicate who leads and manages the surveillance system being evaluated and briefly describe their roles. Identify whether there are appropriate steering and scientific committees and describe their roles and responsibilities

",N/A,"Which surveillance system is going to be evaluated?

What is that surveillance system intended to do?

How does the surveillance system operate?",Section 3. Design the evaluation,"a. Prioritise the attributes to be assessed during the evaluation using the Attribute Selection Matrix (see Table 2). The choice of attributes for assessment will vary depending on the surveillance system objective(s) identified in section 2d of the SERVAL framework (see above).
b.Identify which methods and tools will be used for data collection and analysis","Consult with experts in the relevant disease, species or epidemiology of the condition under surveillance, for assistance with selecting and assessing relevant attributes. Guidance for selection of attributes is presented below. It is not the job of the evaluator(s) to set thresholds / targets / success criteria for attributes (this is the job of higher-level decision makers).

3a. A master list of 22 attributes and their definitions appears in the Appendix. It is not necessary to assess all of these attributes in any single evaluation. The Attribute Selection Matrix (next page) provides a guide to assist the attribute selection process. Attributes have been classified as primary, secondary or tertiary attributes dependent on the surveillance objective. To enable a balanced evaluation, it is suggested that the aim should be to assess all primary attributes listed for that objective. Secondary attributes should be assessed in addition to primary attributes if data and resources allow, but are not essential to the evaluation process. 

The attribute classifications presented here should be considered as a guide rather than being prescriptive. It may be varied and the exact choice of which attributes to assess is left to the evaluator. The choice of attributes may be influenced by the purpose of the evaluation, the disease type, and the surveillance objective(s). 

Note that four attributes (benefit, communication, cost, sensitivity) are classified as primary attributes under every surveillance objective and so should be assessed as part of every surveillance evaluation.

3b. An economic evaluation should be an integral part of any surveillance evaluation. Options include:
- cost-effectiveness analysis
- cost-benefit analysis
- qualitative
- semi-quantitative
- quantitative

Information is provided by these attributes: benefit, cost, impact.

3c. Guidance for this part of the framework can be found in the Appendix at the end of this document (page 25 onwards)
",N/A,Which aspects of the surveillance system are most important to assess?,Section 4. Conduct the evaluation,"a. Assess the surveillance objective(s)
b.Collect data
c. Analyse the data
d.Assess the chosen attributes
e. Perform an economic analysis
f. Synthesise the results","4a. Are the surveillance objectives identified in section 2d clearly defined and relevant to disease situation?

4b. Guidance for this part of the framework will be provided by the outputs of Task 2.3 (additional evaluation tools).

4c. Guidance for this part of the framework will be provided by the outputs of Task 2.3 (additional evaluation tools).

4d. Present a summary measure for each attribute which contributes information on the surveillance system's performance. See guidance information for each attribute given in Section 3a

4e. Use the information collected for assessed attributes, particularly the cost, impact and benefit attributes but also those measuring other aspects of surveillance effectiveness e.g. timeliness, to perform the cost-benefit (or, if appropriate, a cost-effectiveness) analysis identified in section 3b.

4f. Draw together the results of the individual attribute assessments and the economic analysis to reach conclusions about the evaluation question(s) listed in section 1b. Identify evidence-based suggestions for possible improvements to the surveillance system.

Possible ideas for enhancing the collection of surveillance data include:

- use of portable technology (e.g., collecting data using digital devices rather than paper forms);
- risk-based requirement or sampling;
- review of sampling strategies including the sample size, pooling of samples, and integration of data from different sources.
The value of surveillance might be improved by changing the methods used to analyse or disseminate information.",N/A,How well does the surveillance system operate in each of these aspects?,Section 5. Reporting and communication,"a. Identify the target audience(s) for the evaluation outputs
b.Consider which communication medium is most appropriate
c. State what new information the evaluation has provided
d. Identify the strengths and weaknesses of the surveillance system
e. Make recommendations for improvements
f. Indicate ways for follow-up by the funder
g. Measure what effect the evaluation output had","5a. The primary audience is often (but not always) the evaluation funder. Secondary audiences are other users of the output and people involved in the surveillance system under evaluation. Ensure that all relevant people identified previously in sections 1d and 2g are included.

5b. More than one may be necessary in order to reach all affected parties. 

5c. State the level of uncertainty associated with the results summarised in section 4f and any caveats in their interpretation.

Make recommendations for any further work required to complete the evaluation of this system.

5d. Indicate the main strengths and weaknesses of the surveillance system.

5e. Make recommendations which indicate how the suggestions for improving the surveillance system identified in section 4f could be practically implemented and any recommendations for further evaluation provided in section 5c. Make it as easy as possible for the evaluation outputs to lead to actions to influence decisions and policy. Clearly communicate how the question(s) asked by the commissioners was dealt with (translated) in the evaluation process.

5f. This might include a recommendation on when next to repeat the evaluation.

5g. Assess how fully the outputs outlined in Section 1f were achieved. This may need to be done 6-12 months after the end of the evaluation.",N/A,"How well does the surveillance system perform overall?

Does the surveillance system actually do what it was designed to do?

What could be done better in the future?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Monitor the prevalence of an infection,Case finding of infected animals to facilitate control,Early detection of new or re-emerging infection,Demonstrate freedom from infection,Identify changes in the population at risk,Improve epidemiological understanding of a disease,N/A,N/A,N/A,N/A,Providers of surveillance data,"The evaluation process is likely to require input from people who work on the surveillance system being evaluated, but may be conducted by an independent evaluator.",N/A,N/A,Direct users of surveillance and evaluation information,"The evaluation process is likely to require input from people who work on the surveillance system being evaluated, but may be conducted by an independent evaluator.",N/A,N/A,Members of the scientific community with special interest or experience in surveillance evaluation,"The evaluation process is likely to require input from people who work on the surveillance system being evaluated, but may be conducted by an independent evaluator.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Participation: A description of the extent to which people in each of the user groups identifiedin section 2h of the SERVAL framework get involved in the surveillance process.Poor engagement by certain users might suggest a low level of motivation tobecome involved in surveillance. 

Alternatively, there might be a reason for them actively avoiding being involved.",N/A,"Participation (defined as Acceptability in Buehler et al 2004) examines the involvement or engagement of stakeholders in the planning, design and implementation of the surveillance activity. The efficacy of any surveillance system that is greatly dependent on voluntary participation or human behaviour (eg passive surveillance activities) will be vulnerable to problems with engagement.

An assessment of participation should include the identification of the factors likely to increase or prevent stakeholder participation and an assessment of the likely impact of these factors on levels of participation.

Qualitative or semi-quantitative social science approaches are likely to be of value in assessing participation. Consultation with all those involved in generating, analysing, reporting and using surveillance data will be valuable.

Factors that may influence participation include:

- What communication pathways exist internal to the surveillance system (eg between those collecting or providing data and those analysing and reporting the data)? Are these pathways formalised in any fashion? 
- Does information and feedback flow freely between those implementing surveillance and those using surveillance data?
- How are each of the key stakeholders represented in the planning, design and implementation stages of the surveillance activity?
- What are the incentives (e.g. compensation payments) or barriers (e.g. consequences of reporting) for participation 

Level of importance for each of the defined surveillance objectives (1 is primary, 3 is tertiary - or se Table 2)

1: 2
2: 1
3: 1
4: 1
5: 2
6: 2",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"List and quantify each of the resources required to operate the surveillance system. For example: time, trained personnel, finance, standards and guidelines, communication facilities, forms for surveillance, computers, other equipment.",N/A,"Cost and the breakdown of cost is important - also who pays - this can be considered in relation to benefits or other attributes in the economic analyses. An assessment of costs should include:c1. A listing of the areas of expenditure to be quantified; 2. Estimates of the cost of each; 3. Consideration of the distribution of costs among stakeholders, including: producers, consumers, the livestock industry or society. This list can be built upon the characterisation of the surveillance activity in section 2 of the evaluation framework. All areas of the planning and implementation of surveillance should be considered:
- Planning and design of the surveillance activity; 
- Operational management; 
- Sample collection and handling; 
- Laboratory testing or other diagnostic services; 
- Data collection, management and analysis; 
- Interpretation, reporting and dissemination of surveillance information. 
It may be helpful to distinguish between fixed and variable costs: 
- Fixed costs vary only in the long term and are incurred regardless of the level of surveillance (e.g. costs of planning, salaries of permanent staff, laboratory acilities etc); 
- Variable costs vary in the short term and with the level of surveillance (e.g. sample collection costs, test reagents etc). 
Consider also how the costs of surveillance are divided among the stakeholders (e.g. what is paid for directly by the producer, by industry levy or public funds). Considering the distribution of surveillance costs and benefits is an important part of economic analyses. Effort should be made to distinguish the costs of surveillance from costs of disease control measures but, where surveillance and control are closely integrated, this may be hard to do. Regardless, it can be useful to consider the costs of surveillance in the broader context of the costs of mitigation and the costs of disease.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ability to adapt to changing information needs or operating conditions with little additional time, personnel or allocated funds. Flexible systems can accommodate new health-related events, changes in case definitions or technology, and variations in funding or reporting sources.",N/A,"Flexible systems can accommodate new health-related events, changes in case definitions or technology, and variations in funding or reporting sources (CDC 2001). This attribute is determined more by the planning and management of the surveillance system than the operation of the system. Simpler or more generic systems are likely to be more flexible.

An evaluation of the flexibility of the system may be made by considering how the surveillance system has responded to changes in the past. Potential changes or events to consider include:

- Changes in the information needs of the users of surveillance
- Changes in relevant national or international legislation or guidelines
- Changes in the demography of the target population
- Changes in the epidemiology of disease (including outbreaks) or the emergence of new disease threats
- Changes or improvements to the methods of surveillance, including adoption of new technologies (eg development of new diagnostic methods)
- Changes to behaviour or influences on behaviour of key actors and agents in the system (eg changes to reporting behaviour or the costs of diagnostic services)

An assessment of how likely it is that such changes may occur in the future and whether the surveillance system would be able to respond to these changes should also be made.

Assessment of this attribute will be aided by consultation with key stakeholders of the system.

Level of importance for each of the defined surveillance objectives (1 is primary, 3 is tertiary - or se Table 2)

1: 3
2: 3
3: 1
4: 3
5: 3
6: 3",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Extent to which features of the population of interest are reflected in the surveillance data that are collected. Features may include herd size, herd type (e.g. breeding, fattening, milk, meat), age, sex, location. A surveillance system that is representative accurately describes the distribution of infection in the population by place and animal. Bias reduces representativeness.",N/A,"The Representativeness of a surveillance system is related to the attributes of Coverage and Bias; it is a comparison of the sample and target populations with regard to a number of key features or risk factors.

As such, the first step will be to identify and characterise key characteristics of the target population upon which to measure representativeness. These characteristics might be risk factors for the disease threat - knowledge of the associations between these characteristics, selection in the sample population and disease will inform the understanding of bias. Examples of relevant features include:

- Livestock sector or production type
- Herd/flock size
- Age, sex or purpose of animal
- Geographic location

The second consideration of assessing representativeness is whether there is sufficient and accurate data on the identified features in both the target and sample populations. 


Where sufficient data exists, representativeness might be explored through:

- simple descriptive analyses
- statistical analyses (eg cross-tabulation and regression techniques, or Capture-Recapture methods)
- spatial visualisation, exploration and analyses with GIS (Geographic Information Systems) tools 

Level of importance for each of the defined surveillance objectives (1 is primary, 3 is tertiary - or se Table 2)

1: 1
2: 2
3: 1
4: 1
5: 1
6: 2",N/A,N/A,N/A,N/A,N/A,"Sensitivity of a surveillance system should be considered on three levels:
(1) Surveillance sensitivity (case detection) refers to the proportion of individual animals or herds that have the condition of interest that the surveillance system is designed to detect; 
(2) Surveillance sensitivity (outbreak detection) refers to the probability that the surveillance system will detect a significant increase (outbreak) of disease. This requires a clear definition of what constitutes an outbreak; 
(3) Surveillance sensitivity (presence) refers to the probability that disease will be detected if present at a certain level (prevalence) in the population.",N/A,"Sensitivity is the most commonly assessed attribute of surveillance systems. Combined with timeliness, it is of particular importance to surveillance for early detection of outbreaks. With representativeness it is frequently scrutinised when evaluating surveillance activities intended to provide evidence for disease freedom. When monitoring the prevalence of endemic diseases, poor sensitivity will contribute to bias in the surveillance outputs.

Surveillance sensitivity (case detection)can be assessed by 

- Comparing prevalence estimates from multiple systems or studies (Lynn et al 2007)
- Considering biases and limitations in the data available and their likely impact on the estimate of sensitivity.
- Using statistical methods like capture recapture methods to address the issue of availability of gold standard comparison (del Rio Vilas et al 2005, del Rio Vilas and Bohning, 2008)
- Bayesian approaches can also be useful to estimate sensitivity (Branscum et al, 2006) in the absence of a reference test or population.

Surveillance sensitivity (outbreak detection) can be assessed by

- Quantifying the proportion of outbreaks of disease detected by a specific surveillance component
- Applying simulation modelling methods (Audigé and Becket 1999, Willeberg et al 2011). 
- In the public health field the methods used to assess the ability of detection algorithms to detect outbreaks have been reviewed (Buckeridge, 2007, Watkins et al 2006) These include comparing the outbreaks detected by these outbreaks to previously identified outbreaks in recorded data or to simulated outbreaks sumperimposed on surveillance data (Mandl et al 2004, Jackson et al 2007).

Surveillance sensitivity (presence) can be assessed by

- Considering whether the design of the system is likely to achieve the sensitivity specified in the design of the system 
- Using probabilistic methods or other methods (Martin et al 2007, Hood et al 2009)
- Sensitivity (presence) is usually used to assess surveillance for demonstrating freedom but can also assess performance of surveillance for early detection

Some considerations when assessing the sensitivity of surveillance include

- The probability of selection into the surveillance system must be defined and quantified. This may be a simple random sample of animals from a single homogenous population or a complex pathway of epidemiologic and behavioural factors describing the observation, reporting and subsequent investigation of notifiable disease (ie passive surveillance)
- The probability of diagnosis (ie the sensitivity of the diagnostic protocol, including that of laboratory tests)
- The choice of design prevalence (ie the expected prevalence of disease that the system is designed to detect) is a key assumption. Setting a very low design prevalence will result in a low estimate of sensitivity, placing unreasonable demand upon resources; whereas setting a high design prevalence will give an 
inflated estimate of sensitivity, thereby undermining credibility of the result. Choice of the design prevalence should be based upon understanding of the epidemiology of the disease. Sometimes legislation offers guidance on the design prevalence of surveillance for exotic diseases.

Level of importance for each of the defined surveillance objectives (1 is primary, 3 is tertiary - or se Table 2)

1: 1
2: 1
3: 1
4: 1
5: 1
6: 1",N/A,N/A,N/A,N/A,N/A,Proportion of true non-events correctly classified as such. The inverse of this is the false alarm rate,N/A,"Evaluation of the specificity of a surveillance system is especially important for surveillance activities designed to detect outbreaks and cases because it is related to the misdirection of resources: ie expenditure on disease investigation and mitigation measures that are needlessly applied. The specificity of many surveillance activities will be very high or complete (100%), because of the consequences of confirming disease; this is especially true for surveillance for exotic diseases carrying implications for trade. 

Specificity can be considered at several levels, depending upon the epidemiology of the disease and the objectives and design of the system:

- the specificity of pre-diagnostic indicators of disease (eg clinical signs)
- the specificity of screening and confirmatory diagnostic tests applied
- the rate of false-positive signals raised by detection algorithms applied to surveillance data
- the proportion of reports of suspect cases of disease that are subsequently negated (NB this metric actually concerns the Positive Predictive Value of a system; a related concept which has been assessed in some evaluations




Level of importance for each of the defined surveillance objectives (1 is primary, 3 is tertiary - or se Table 2)

1: 1
2: 1
3: 1
4: 1
5: 2
6: 1",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The time between any two defined steps in a surveillance system. The steps will vary with surveillance purpose so as to be epidemiologically meaningful and the exact definition of timeliness would then vary with surveillance purpose. For example, for outbreak detection it may be
important to consider the time from introduction to detection of the agent (or the time between when the agent should have realistically been first detected and the time when it actually was). For planning purposes, timeliness might be used to determine if a surveillance system detects and reports disease in time to initiate interventions at a time in the epidemiology of the disease such that it reduces the probability of further spread. For other surveillance purposes such as demonstration of disease freedom, it may be sufficient to consider the timeliness of the surveillance process (such as time between sampling and reporting) and place less emphasis on the infection process.",N/A,"The timeliness of a surveillance system is especially important to surveillance for the early detection of emerging or exotic disease threats - where the intention is to implement control measures as soon as possible.

The time points chosen are likely to vary depending on the purpose of the surveillance activity. For outbreak detection this can be defined using various time points including the time between exposure to the infectious agent and the initiation of risk mitigation measures or the time between when disease could have been detected and when it actually was reported. For planning purposes, timeliness can also be defined as whether surveillance detects changes in time for risk mitigation measures to reduce the likelihood of further spread.

The precise definition of timeliness chosen should be stated as part of the evaluation process.

For surveillance systems designed to detect cases of disease the CDC guidelines (CDC 2001) describe a useful approach to measuring the timeliness of a surveillance system which is focussed on the time taken to process surveillance data. In brief:

1. Map the surveillance process, from sample collection and handling, through the diagnostic process, management and analysis of data and reporting and dissemination of results. The description of the surveillance system developed in section 2 of the framework will aid in this.
2. Identify key time intervals for measurement. The timeliness measure should be aligned with the objectives of the system and in some cases more than one measure may be required to gain sufficient understanding. Some examples of relevant timeliness measures include:
a. For passive surveillance activities, the interval between observation of the first clinical signs of disease and laboratory investigation
b. For post-import testing for exotic notifiable disease, the interval between entry to the country and the return of a laboratory result
c. For ongoing active surveillance of endemic diseases, one measure might be the frequency of analysis and publication of surveillance data
3. Just as the timeliness measure may differ between systems, the criterion for timeliness will differ between disease threats. The timeliness of a system should be assessed with consideration of the epidemiology of the disease of interest (eg by comparison to the generation interval of infectious diseases)
4. When the key time intervals have been identified and fully characterised, data should be collected to measure the timeliness. Where sufficient event data exists, calculations will be relatively simple. In the absence of sufficient valid data, simulation models might be developed and applied.
5. Assessment should also consider factors which influence the timeliness of a system. For example, availability of human resources for the collection of samples of investigation of reported disease, availability of laboratory facilities, adoption of new technology to streamline laboratory investigation, adoption of automated approaches to the collation and management or the analysis and reporting of surveillance data, etc.

Examples of studies assessing the timeliness of surveillance for case detection include Jajosky and Groseclose, 2004 and Takahoshi et al 2004

For surveillance systems designed to detect outbreaks, timeliness is often assessed in combination with sensitivity (Kleinman and Abrams 2008). Guidance on the assessment of timeliness for this type of surveillance system is provided by the CDC framework (2004) which focuses more on the time taken to detect outbreaks. Timeliness for these surveillance systems has been assessed by:

- assessing the time to detect naturally occurring outbreaks (Siegrist et al, 2004) 
- assessing the time to detect simulated outbreaks (Mandl et al 2004, Jackson et al 2007) 
- using a simulation model to predict the time to detect outbreaks (Yamamoto et al, 2008)

Level of importance for each of the defined surveillance objectives (1 is primary, 3 is tertiary - or se Table 2)

1: 1
2: 1
3: 1
4: 1
5: 1
6: 2",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Benefit: Direct and indirect advantages produced by the surveillance system.
Not limited to money, benefits might include any losses avoided due to information provided by surveillance system: financial savings, better use of resources, improved animal production, improved public health, increased understanding about a disease, or increased trade.",N/A,"The benefits of a surveillance activity should be listed and, where possible, quantified. This information will be valuable to the economic evaluation in section 4 of the framework document. An evaluation of the benefits of a surveillance activity should include :

1. A complete list and characterisation of all the potential benefits of the surveillance activity 
2. Where possible, quantify market benefits in financial terms
3. Where possible, quantify non-monetary benefits by alternative methods. For example, Quality-adjusted life years for public health benefits (HM Treasury 2003, Zinsstag et al 2007) or using points-system (Dufour 1999)
4. Consider how the benefits are distributed among stakeholders, including: producers, consumers, the livestock industry or society

Points to consider whilst assessing the benefits of surveillance include:

- Surveillance and disease control are often integrated: That is to say, surveillance provides information that informs control and so many benefits of surveillance are often realised by control measures. As with costs, it is important to understand the benefits of surveillance in the broader context of disease mitigation. Benefits of surveillance may be considered as disease losses and mitigation costs avoided by detection of disease. So it may be useful to begin by listing all the losses and costs resulting from disease and disease mitigation measures. It may be difficult in some instances to distinguish between the direct benefits of surveillance and those arising from mitigation.
- The benefits of surveillance for early detection of disease outbreaks can be quantified as the losses and costs avoided through earlier detection and control
- The primary benefit of surveillance providing evidence of disease freedom is access to international markets (for both live animals and animal products). The economic value of international trade can be attributed as a benefit to surveillance. Officially recognised disease-free status often permits the disease-free country/region to maintain border security measures against introduction of the disease (eg restriction on trade and movement of animals or requirement for pre-export testing) - thus mitigation of risk of incursion is also a benefit of 
surveillance for freedom from disease..
- Surveillance for case-detection and monitoring prevalence of endemic disease provides information for the improved control and management of disease; including prioritisation of diseases and allocation of resources.
- Improved public health is an obvious advantage to surveillance for zoonoses. 
Increased consumer confidence is another - although consumer confidence may also be of significance to other high-profile, non-zoonotic diseases.
- Consider potential indirect or secondary benefits of surveillance; externalities or spill-over of benefit to other livestock sectors or industries. It may be helpful to consider potential benefits both upstream (eg animal feed producers) and downstream (eg food processors) of the production system. Examining the value chain will aid in this

Level of importance for each of the defined surveillance objectives (1 is primary, 3 is tertiary - or se Table 2)

1: 1
2: 1
3: 1
4: 1
5: 1
6: 1",N/A,Bias: The extent to which a prevalence estimate produced by the surveillance system deviates from the true prevalence value. Usually (if not always) refers to endemic diseases. Bias is reduced as representativeness is increased.,N/A,"Assessing the bias of a system is most relevant to surveillance of endemic diseases where the objective is to monitor the prevalence of a disease. Bias may lead to erroneous conclusions about the burden or distribution of disease in the population. For some surveillance activities - such as risk-based surveillance aimed at detecting cases to facilitate control - surveillance may be intentionally biased toward sub-groups of the population at higher risk of disease. So the context and objective of surveillance will determine whether bias is acceptable or not. Either way, an evaluation of bias should include: 
1. An assessment of whether any prevalence estimates produced are likely to be biased based on an assessment of the potential sources of bias in a surveillance system and its outputs; 
2. Where possible bias should be quantified and the outputs adjusted accordingly. 
Bias in epidemiology may be categorised into misclassification bias and selection bias: 
- Misclassification bias concerns the sensitivity and specificity of the case-definition (often intimate to the diagnostic protocol); - Selection bias results when the probability of being sampled is associated with the probability of disease (and therefore the probability of other factors associated with disease).In this regard the bias, sensitivity, specificity, coverage and representativeness of a surveillance system are related concepts. Bias in the prevalence estimates obtained using surveillance data may result from poor sensitivity, specificity, coverage or representativeness in the system. 
Some potential sources of bias to consider include: 
- Sensitivity/specificity of the diagnostic method; 
- Under-reporting in passive surveillance activities; 
- The sample source population: For example, sampling at abattoirs may lead to an under-estimate of the prevalence of many diseases as these animals are from a healthy (and younger) sub-population, whereas sampling fallen stock may lead to an over-estimate of burden; 
- Selection bias may also be introduced in terms of geography, production type, herd/flock size, species or age category of the animal. 
Bias in the surveillance output can be examined and quantified by several methods: 
- Simple comparison of multiple surveillance data sources examining the same population. In some instances a separate survey might be designed and implemented to specifically examine potential biases (eg a postal survey to explore under-reporting in passive surveillance activities); 
- More sophisticated statistical or simulation methods can be applied to existing data 
* Capture-Recapture (CRC) methods have been applied to make inferences about the unobserved cases and so the completeness of surveillance data (Del Rio Vilas and Bhning 2008, Guasticchi et al, 2009, ); 
* Morignat et al (2006) used simulation models to explore potential biases (identified a priori) in scrapie surveillance data; 
* Mathematical models might also be used to simulate the spread of disease and generation of surveillance data to explore potential bias in the system.If bias can be identified and measured, then it should be possible to adjust the prevalence estimate.); 
- Correcting an estimate of prevalence for incomplete test accuracy is easily achieved with knowledge of the sensitivity and specificity of the diagnostic protocol (see equation 5.16 in Doohoo et al 2003). Prevalence estimates can also be adjusted for selection bias where the strength of association (ie relative risk or odds ratio) and the distribution of the risk factors in the background population are known (Wells et al 2009, Williams et al 2009).; 
- Morignat et al (2006) uses simulation methods to both explore and partially correct of bias in surveillance data. If bias is deemed to be significant and unacceptable and cannot be satisfactorily corrected for during analysis and interpretation of the data, one might consider reviewing the design and implementation of the surveillance activity.",N/A,"Communication: An assessment of the methods and ease of information exchange betweenpeople involved at all levels of the surveillance system (providers, analysersand users of surveillance data) including an assessment of the informationprovided, timeliness, types of outputs and a description of the efforts made to disseminate the surveillance information.",N/A,"Communication concerns the dissemination of information and provision of feedback into the system. Communication in a surveillance system is often related to various other attributes, including participation, timeliness and impact. An assessment of communication should include: 
- A list of the outputs that are generated from the surveillance data; Who are these intended for and do they meet all information needs of the target audience?; 
- An assessment of who has access to the surveillance outputs; Are all stakeholders represented?; 
- An assessment of whether the surveillance outputs are produced sufficiently frequently. Do they contain up-to-date data of sufficient quality? Are the data presented with sufficient discussion of its meaning, limitations and biases from an ; epidemiological perspective?; 
- A list of other feedback provided to those contributing to the surveillance system e.g. data quality checks. Qualitative or semi-quantitative social science approaches are likely to be of value in assessing this attribute. Consultation with the key stakeholder groups of the surveillance system will be useful, including: 
- Providers of surveillance data (eg farmers, veterinarians, laboratory staff etc); 
- Those analysing and interpreting the surveillance data (ie generating information and knowledge from the data and disseminating it); 
- Users of surveillance data, including the direct customer (funder) but also other beneficiaries of the information as appropriate (eg government, the farming industry or academia)",N/A,Coverage: Proportion of the population of interest that is included in the surveillance activity.,N/A,"The Coverage of a surveillance system is often related to the Representativeness, Bias and Sensitivity. A high coverage is particularly important to surveillance for the early detection of exotic or new (emerging) diseases. An assessment of coverage should include: 
1. At the very least, the sampled and target populations should be characterised and compared qualitatively; 
2. Where sufficient data on the target population exists, simple calculations of the proportion coverage can be made (eg 75% of the national herd and 45% of cattle holdings are sampled annually).; 
3. Where sufficient information on the background population is lacking, more sophisticated statistical techniques might be employed (eg Capture-Recapture analysis). Some considerations when assessing the coverage of a surveillance activity are the target population and the unit of interest: Coverage should be measured against the population of interest (the target population) as defined in section 2 of the framework. This may not include all animals or holdings in a country that are susceptible (eg post-import testing of cattle say is focussed on a sub-population of holdings that receive livestock from overseas and not all holdings keeping cattle). At this point, it may be worth considering whether the target population has been adequately defined (ie whether the exclusion of certain animals or holdings is merited). The unit of interest—in which the level of coverage is measured—is often the unit of interest of surveillance (eg animal or holding). If insufficient data exists for this, or alternative perspectives are desired, coverage might be assessed at other aggregate levels (eg geographical areas) or relevant intermediate steps in the surveillance pathway (eg the proportion of veterinary practices submitting diagnostic samples, private laboratories submitting data or participating abattoirs or markets). In certain contexts it may be worth establishing a timeframe of reference (eg annual coverage). The choice of timeframe should reflect the epidemiology of the disease.",N/A,Data analysis: Appropriate methods used for analysis and interpretation of data.,N/A,"Surveillance systems that perform well in this attribute will use analytical methods that are appropriate to the data and the information needs of users of the data whilst exploiting the data to its fullest extent. In this regard there is a relationship between this attribute and those of Data collection, Data management, Communication and Impact. An evaluation of data analysis should include: 
1. The identification of the analysis methods applied to surveillance data: 
o No analysis 
o Basic descriptive statistics 
o Examination of trends 
o More sophisticated statistical approaches (eg time series analyses, spatial analyses); 
2. An assessment of whether the limitations of data have been understood and accounted for in statistical analyses?; 
3. An indication as to whether the body of data available being fully exploited or could further use of data be made?It may help to review demands for information made by users of the surveillance data in the past, to determine whether their needs were met by the methods applied.",N/A,Data collection: The use of appropriate data sources and collection methods and the existence of a case definition and a data collection protocol.,N/A,"A surveillance system that scores well on this attribute will have a clear and comprehensive case definition; make use of appropriate diagnostic tests; have a written protocol that describes collection of data (and samples); and the limitations of the collection methods will be clearly defined and understood. There is a relationship between this attribute and those of Data completeness, Data management and Laboratory management. Questions to consider when assessing data collection include: 
1. Is there a written case definition for this surveillance system that is clearly defined and complete with specified inclusion and exclusion criteria?; 
2. Does the case definition include relevant details of the case signalment, clinical and pathological signs and epidemiological information as appropriate?; 
3. Does the case-definition include laboratory diagnosis? a. If applicable, are the chosen diagnostic methods appropriate to the case definition, including in terms of diagnostic samples being collected and the expected pathophysiology of disease? b. Have the sensitivity and specificity of the tests been assessed?; 
4. Is there a written sample and data collection protocol and are there appropriate assurance mechanisms to ensure the protocols are followed?; 
5. Are there data collected that are not used in analysis or interpretation (redundancy)?; 
6. Are there information needs for which data are not currently collected and feasibly could be? It may help to review demands for information made by users of the surveillance data in the past, to determine whether their needs were met by the data available.",N/A,"Data completeness and correctness: Proportion of data that was intended to be collected that actually was, and the proportion of data entries that correctly reflect the true value of the data collected.",N/A,"Completeness of surveillance data is relatively simple to measure and should be considered at two levels: fields and records. Most commonly Data completeness is measured as the proportion of records with missing or invalid data in the data fields - where data fields are variables containing demographic, clinical, pathologic or epidemiological information recorded for each sample. Key data fields (eg animal id, holding of origin, diagnostic result etc) should be identified and the proportion of completeness measured. Measurement of the proportion of records or observations that have been collated in the data system may also be considered. This will require comparison with an alternative source of data (eg the sample frame or paper records of sampling and laboratory test results). Poor data completeness may indicate problems in the Data collection, Data Management or Communication and engagement attributes.",N/A,"Data management: Appropriate use and documentation of data management systems for processing information, including data processing protocols, and effective use of data verification procedures.",N/A,"Data management is a broad area concerning the collation, storage and maintenance of data, including but not limited to matters of data quality, accessibility, usefulness and security. Assessing this attribute will require an intimate understanding of the data systems employed by the surveillance activity. More detailed guidelines on assessing data management are provided in the references. An assessment of this attribute should include: 
1. Consideration of whether the database structure has been correctly designed:
- Has each field of data been tightly defined to ensure correctness, conciseness and consistency across records?;
- Have primary keys, uniquely identifying each record, been assigned?;
- Has the database been normalised, to ensure data is stored in the most parsimonious, transparent and useable way?;
- Have validation constraints, preventing the input of invalid data, and internal cross-consistency checks been applied?;
- Is the data stored in a way that allows the required interrogation and analysis? 
2. Consideration of whether documentation of the data is sufficient to facilitate interpretation and understanding of the data:
- Is there a document providing a summary overview of the data and collection methods and explaining any idiosyncrasies relevant to the analysis and interpretation of the data?; 
- Is there a data dictionary that clearly defines each field?; 
- Is there an entity relationship diagram that explains how the data relate? 
3. Consideration of whether there are adequate protocols for managing data quality and security: 
- Is the data management system covered by a data quality standard (eg ISO9000, Good Clinical Practice or Good Laboratory Practice)?;
- Are Data Protection implications defined and is the Information Asset Owner identified?;
- Are periodic data quality control checks implemented?;
- Are records management issues clearly defined, including policy on the retention of data?",N/A,Historical data: Quality and accessibility of archived data.,N/A,"Maintaining historical data is more important to surveillance activities designed to provide evidence for freedom from disease or for monitoring trends in prevalence of endemic disease. Historical data can also be valuable to epidemiological research. This attribute is related to those of Data management and Repeatability. Questions to consider include:
- How many years of data are stored? 
- How complete and reliable are the data? 
- Are the data stored in a way that allows the required interrogation and analysis?
- Is there a summary overview of the data and collection methods explaining key idiosyncrasies of the data and changes to the data or collection methods over time? 
- What use is currently made of historical surveillance data?",N/A,"Impact: A measure of the usefulness of the surveillance system. Should include details of actions taken as a result of the information provided by the surveillance system, for example changes in protocols or behaviour. Should include an assessment of the extent to which the surveillance objectives have been achieved.",N/A,"The Impact (called ‘Usefulness' in CDC 2001) of a surveillance system is related to the Benefit derived from the system where assessment should consider specific examples or events where information generated by the surveillance system has influenced disease mitigation efforts. In this regard it will be useful to measure Impact retrospectively, through consultation with relevant stakeholders of the system. As with Benefits, the Impact of surveillance in some cases may be realised through its relationship with disease control measures (Haesler et al 2011). An assessment of impact should consider: 
- How do the objectives of the surveillance system reflect the stated needs of policy and the industry it serves?; 
- How are outputs generated from the surveillance data used? Who are they intended for and how well received are they?; 
- What questions have been asked of the surveillance data previously and have these information needs been met?; 
- How has information generated by the surveillance system influenced the development of national or international disease control policy (eg changes to requirements for surveillance or control of disease)?; 
- How has information generated by the surveillance system contributed to the prioritisation of disease threats within the industry, country or globally?; 
- How has the surveillance system contributed to mitigation of endemic disease or earlier detection and control of exotic disease outbreaks?",N/A,Laboratory management: Testing carried out using appropriate methods with quality assurance scheme and timely and accurate production of results.,N/A,"Diagnostic laboratories should aim to produce reliable, accurate, unbiased results within a suitable time frame and at acceptable cost. With the emphasis on a quality service and  value for money a laboratory should have quality control procedures for monitoring the validity of tests undertaken.  Questions to consider in assessing this attribute include:  
- Does the laboratory implement a structured and systematic quality management system? 
- Does the system include internal quality control processes (eg checking that test kits and reagents are performing within specifications, ensuring regular use of internal controls and certified reference materials)? 
- Does the laboratory participate in inter-laboratory comparison or proficiency testing? 
- Is the laboratory accredited to international standards of operation (ie ISO 9001 and ISO 17025)?",N/A,Multiple utility: The ability of a surveillance system to capture information on several diseases or health conditions: a measure of how generic the system is.,N/A,"Multiple Utility in a system should always be considered when examining the cost-effectiveness of a system. Firstly one should assess the realised multiple utility of the system but it will also be of benefit to assess the potential multiple utility - an outcome of assessing potential multiple utility might be recommendations on how to add value to the system currently implemented.  An assessment of multiple utility should consider:  
- What additional information is or could be gathered during sample collection (eg on animal health or husbandry and demographics)? 
- What other types of samples are or could be collected at the time of sampling? 
- What other diseases are or could be tested for with the samples collected? 
- How long are samples stored following testing and could they be used for other purposes (including other research purposes)?  
For a surveillance system to offer value to other diseases or information needs, the objectives and processes of the system should be aligned to other systems. So it may be expected that more simple systems are likely to have more potential for multiple utility. For example, a simple random survey of holdings, repeated annually and with good coverage and representativeness could be useful for various diseases; whereas a risk-based design aimed at a specific threat may be of limited value for other diseases with differing  epidemiology.",N/A,"Precision: How closely defined a numerical estimate obtained from the study population is. A precise estimate has a narrow confidence interval. Precision is influenced by sample size, the chosen confidence level and data completeness and correctness",N/A,"Precision in surveillance activities designed to monitor prevalence is a measure of the degree of certainty around the point estimate of prevalence or incidence (ie the confidence interval or standard error). NB A related concept in surveillance designed to provide  evidence for freedom from disease is the measure of confidence in disease freedom derived from the Sensitivity of the surveillance system.  The precision of point estimates in epidemiological studies is dependant upon disease prevalence, sample size and the approach to sample selection (ie the design effect, Doohoo  et al 2003).   Precision of a surveillance activity will determine the how sensitive the surveillance system is to changes in prevalence.   The desired level of precision will be set by the epidemiology of disease, surveillance objectives and the optimal allocation of resources.",N/A,Repeatability: How consistently the study results can be reproduced over time.,N/A,"Repeatability is a concept often applied to validating diagnostic tests and is related to precision. In terms of a surveillance system, Repeatability is also related to the attributes of Historical data and Stability and sustainability. A surveillance activity that performs well in this attribute produces data that can be easily compared across years and where changes to the data and data collection methods over time are clearly defined and understood.  One might consider changes to legislation; changes to diagnostic methods, including improvements of adoption of new technology; changes to surveillance design; or influences on disease reporting behaviour in passive surveillance activities.   
- How have these impacted on the comparability of surveillance data over the time period of interest?  
- Have these influences been identified and examined and can they be accommodated in interpretation of the surveillance data?",N/A,"Stability and sustainability: Reliability (function without failure), availability (operational when needed) and sustainability (ability of the system to be ongoing in the long term).",N/A,"The Stability and Sustainability of a system is possible most pertinent to surveillance intended for early detection of new/emerging or exotic (notifiable) diseases.   This attribute can be measured retrospectively by   1. Looking at the incidence of minor and major faults over a defined period of time or 2. Giving a measure of the proportion of time that the system is fully functional  Assessment of this attribute will benefit from consultation with those involved in the generation, management and analysis of surveillance data. If performance indicators have been implemented in the surveillance process, historical data from these will give a good insight into the ongoing functioning of the system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The OASIS tool has been developed for the assessment of animal health and food safety surveillance systems (Hendrikx et al., 2011). This tool is intended to draw the general shape of the performance of a surveillance system' through a semi-quantitative assessment of surveillance systems, but it does not include any economic analysis and it may be argued that it does not provide an in-depth analysis (Hendrikx et al., 2011). OASIS appears to have limited flexibility: for example, it cannot readily accommodate different evaluation objectives by varying which criteria are assessed, and therefore the OASIS framework is unlikely to be suitable to answer diverse evaluation questions. A generic framework is needed that could be applied to any animal disease surveillance system and be flexible enough to cope with any surveillance purpose and evaluation objective.

Two experts emphasized that in order to be useful, the output of an evaluation must lead to an action or a conscious decision; otherwise, the evaluation is a waste of resources. We have designed SERVAL to make it straightforward for the outputs to lead to actions, which may include influencing funders' and policymakers' decisions. To assist this, SERVAL incorporates an optional traffic-light system whereby each attribute may be allocated a colour to indicate how well the system is performing: green (excellent or very good), amber (good, although with some room for improvement) and red (poor, in need of attention).

The output of using the framework is expected to be a written evaluation report that includes details under standardized headings along with a series of recommendations for improvements to the surveillance system being evaluated. The contents and weighting of each section can be tailored to the needs of each surveillance system and so will vary from evaluation to evaluation. The evaluation report should be circulated in an appropriately accessible format to affected parties including both those implementing the surveillance activities and those using the outputs.

A major difference between SERVAL and existing frameworks is the high number of attributes (up to 22) from which evaluators are encouraged to select a shortlist of those most appropriate to each evaluation. Guidance is offered in the choice of attributes but no prescription is made. This allows the evaluation to be easily tailored to any evaluation objective and any surveillance purpose. 

Economic evaluation is an integral part of the SERVAL framework because the costs of obtaining surveillance information should be balanced against the benefits derived.

Article provides more details and examples describing how this framework is an improvement over OASIS.",N/A,N/A,"WHO, 1997: Protocol for The Evaluation of Epidemiological Surveillance Systems. World Health Organisation, Geneva.

WHO, 2006: Communicable Disease Surveillance and Response Systems: Guide to Monitoring and Evaluating. World Health Organisation, Geneva

Dufour, B., 1999: Technical and economic evaluation method for use in improving infectious animal disease surveillance networks. Vet. Res. 30, 27-37.

Hoinville, L., 2011: Animal Health Surveillance Terminology: Final Report from Pre-ICAHS Workshop. International Conference on Animal Health Surveillance, 17 May 2011, Lyon, France. Available at: http://www.ansespro.fr/icahs/ (accessed on 28 September 2012).

Hoinville, L.J., L. Alban, J.A. Drewe, J.C. Gibbens, L. Gustafson, B. Hasler, C. Saegerman, M. Salman, and K.D.C. Stark, in review: Proposed terms and concepts for describing and evaluating animal health surveillance systems.

Malecki, K. C., B. Resnick, and T. A. Burke, 2008: Effective environmental public health surveillance programs: a framework for identifying and evaluating data resources and indicators. J. Public Health Manag. Pract. 14, 543-551.","The article did not provide the entire framework can be found here: https://www.rvc.ac.uk/Media/Default/VEEPH/Documents/SERVAL.pdf 

Animal health surveillance can be defined as the systematic, continuous or repeated, measurement, collection, collation, analysis, interpretation and timely dissemination of animal health and welfare related data from defined populations, essential for describing health hazard occurrence and to contribute to the planning, implementation, and evaluation of risk mitigation measures' (Hoinville, 2011).

The output of surveillance programmes assists in setting priorities and guiding effective prevention and control strategies. It also helps to monitor the progress and success of intervention programmes and, in the animal health field, to demonstratethe hazard-free status of animals and animal-derived products (OIE, 2010). 

Proper surveillance evaluation can play an essential part in establishing and maintaining international trust (Nabarro, 2010). Quality assurance is essential to maintain credibility, which is particularly important for inter-community and international trade with animals and animal-derived products.

Evaluation is defined as the systematic and objective assessment of the relevance, adequacy, progress, efficiency, effectiveness and impact of a course of actions, in relation to objectives and taking into account the resources and facilities that have been deployed (World Health Organisation, undated). 

A three-stage process was used to develop the SERVAL (SuRveillance EVALuation) framework: (i) technical workshop of international surveillance experts; (ii) consultation process involving providers and users of surveillance and evaluation data; and (iii) application of the new framework to selected animal health surveillance components as case studies.

The following definition of a generic framework was adopted: A structured approach to the evaluation of animal health surveillance systems which can be adapted for use in different situations in GB.

The draft framework was tested by applying it to several case studies using existing surveillance programmes in GB. These examples confirmed the flexibility of the framework because a different selection of attributes was assessed in each case study.

During the workshop, the definitions of criterion, attribute, threshold, performance measure and target were debated. There was a consensus that the focus of the framework should be on attributes. In this context, attributes is taken to refer to the many quantifiable characteristics of surveillance systems: examples would be representativeness, sensitivity and timeliness. A recommendation from the delegates' experiences of surveillance evaluation was that evaluations must be simple to conduct, be ideally low-cost, have explicit start and end points, and have a clear idea of what will be done with outputs, if they are to be useful. Further, it was agreed that an evaluation framework should ideally include an identification of the degree of uncertainty related to its findings.

A common suggestion during the consultation process was for guidance on how much time an evaluation using SERVAL would be expected to take. Our case studies indicate that a complete qualitative evaluation may be accomplished in approximately 6-8 person-days, although the exact amount of time is likely to vary depending on the system being evaluated, availability of expertise and information, and the depth of evaluation required. If data need to be collected for specific indicators, or if broader interviewing of stakeholders involved in a surveillance programme is conducted, considerably more time will be required. A longer period would also be needed in order to conduct a more detailed evaluation involving rigorous quantitative approaches.

Whilst the optimal number of attributes for assessment is likely to vary depending on the objectives of each evaluation, between five and 10 attributes per evaluation are likely to be required to provide a complete evaluation.",
elallakiConceptualEvaluationPopulation2013,1420,ElAllaki 2013,Conceptual evaluation of population health surveillance programs: method and example.,Conceptual evaluation of population health surveillance programs: Method and example,2013,Farouk El Allaki,farouk.elallaki@inspection.gc.ca,Canada,Conceptual evaluation model for public health and animal health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Step 1: Text analysis to extract Elementary Context Units (ECUs),"This first step requires an electronic written text and text analysis software. The main objective of this step is to extract the most significant structures (i.e., phrases) from the text being analyzed.","Alceste divides the text into small context units (e.g., phrases) and then clusters context units with similar lexical content into classes. Alceste provides a list of the most significant words, the most significant ECUs, the characteristic contexts of each class, and agreement. Chi-square analysis is used to determine how strongly a given word is associated with a class, thereby revealing the terms most representative of any given class. Other methods are used to supplement this analysis of classes, including cross-sorting, factorial correspondence analysis and ascending hierarchical classification. Both key words and ECUs are ranked in terms of their statistical significance, and both can be traced back to the original text to evaluate their context.",N/A,N/A,Step 2: Coding of ECUs to produce the (implicit) program conceptual model,The main objective of this step is to code the ECUs according to the theoretical standard nomenclature (dictionary) to facilitate the subsequent comparison between the program conceptual model and the theoretical conceptual model.,"Conceptual and relational analyses were used to translate the ECUs into a program conceptual model (see Table 1 and Table 2 for more detail). In conceptual analysis, a concept is selected, coded and quantified for its presence in a text. Relational analysis (also called concept mapping) builds on the conceptual analysis by examining the relationships between the identified concepts.",N/A,N/A,Step 3: Comparison of the program conceptual model to the theoretical conceptual model,"The surveillance program under evaluation is compared to a theoretical standard, using Nvivo, basing the comparison on the completeness of the concepts and the relationships between these concepts (logical and chronological relationships; Fig. 2).",N/A,N/A,N/A,Step 4: Validating interview with a technical team member,The purpose of the interview was to determine whether the technical team took into consideration concepts that were used but not present in the analyzed document,"It focused on identifying non-documented concepts and, thus, separating ""missing concepts"" from ""non-documented but present concepts"". To identify non-documented concepts, two methodologies could be used: (i) recording and transcribing the interview and then running a textual analysis (step 1 of the analysis) and recreating the surveillance model(step 2 ofthe analysis) based on the new information provided by this person and, (ii) asking the technical team member to identify the type of non-documented concepts (i.e., a ""missing"" versus ""non-documented but present"") as well as the relationships between these non-documented concepts and other documented or non-documented concepts.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Often, the concepts and assumptions underlying public health and veterinary surveillance programs are not made explicit. The value of the proposed method lies in making explicit the underlying conceptual framework being used by program designers. In addition, it analyzes the concepts for logical and chronological coherence in their interrelationships.

It requires a minimum of human involvement, thereby limiting the subjectivity inherent to the extraction of the most significant structures in the text-ECUs. While coders may introduce bias during the process, it is possible to assess the impact of such bias on the evaluation results and so decrease the subjectivity of the assessment.

Some of the attributes (e.g., sensitivity, positive predictive value, flexibility) and specific elements (e.g., program's usefulness, achieving surveillance objectives) outlined in the WHO and CDC protocols for evaluating health surveillance cannot be measured before the surveillance program is actually implemented. Therefore, the WHO and CDC's guidelines and protocols are not effective for ex-ante evaluation. The proposed conceptual evaluation method can be used for ex-ante (as in our C-EnterNet example), ongoing and ex-post evaluation.

Connecting concepts extracted from different documents (when analyzed at the same time) and justifying their relationships constitutes one of the difficulties of the proposed method essentially for external evaluators or external content analysts.

Conceptual evaluation requires skilled people and specific software to conduct the textual and content analysis. In addition, there are currently only a small number of software packages available for such analysis and this software can only analyze a handful of languages.

The availability of an explicit theoretical standard is essential for carrying out a conceptual evaluation of a surveillance program. Actually, there is no comprehensive, valid and universal theoretical conceptual model that could be used for the purpose of conceptual evaluation of veterinary and public health surveillance programs. In the literature, there is inconsistent scoping of surveillance and misunderstanding of the driving concepts which increase the difficulty in comparing surveillance results.",N/A,N/A,"World Health Organization, 1997. Protocol for the Evaluation of Epidemiological Surveillance Systems. WHO/EMC/DIS/97.2. http://whqlibdoc. who.int/hq/1997/WHO EMC DIS 97.2.pdf

Dufour, B., 1999. Technical and economic evaluation method for use in improving infectious animal disease surveillance networks. Vet. Res. 30, 27-37.

Stark, K.D.C., 2003. Quality assessment of animal disease surveillance and survey systems. In: Salman, M.D. (Ed.), Animal Disease Surveillance and Survey Systems: Methods and Applications. , 1st ed. Iowa State Press, Iowa, IA, pp. 169-176.

Klaucke, D.N., 1992. Evaluating public health surveillance systems. In: Halperin, W., Baker Jr., Monson, R.R. (Eds.), Public Health Surveillance. John Wiley & Sons, New York, NY, pp. 26-41","The proposed method can be used to improve the design and documentation of surveillance programs. It complements existing surveillance evaluation methods. Conceptual evaluation is not a performance-oriented evaluation method and so it is particularly useful for surveillance programs with a valid conceptual framework but limited technical capacity and resources. Such programs would be penalized using existing performance-based evaluation methods. Applying conjointly the conceptual evaluation along with existing performance oriented evaluation methods will better judge the worth of surveillance programs.

Evaluation helps, therefore, to demonstrate the credibility of the PHSP to stakeholders (e.g., public, decision-makers, program managers, implementers, clients, funding agencies).

The evaluation of a PHSP can be conducted before the program's implementation (ex-ante evaluation) or during the program's implementation (ongoing evaluation). Evaluation activities carried out immediately after implementation has been completed (ex-post evaluation) are less common because surveillance is an ongoing activity, although such an evaluation can be done once the surveillance process has ended or if it has been interrupted for some reason.

In addition to evaluating the performance of a surveillance program, it is important to assess the validity of its conceptual framework by uncovering and examining the theory underlying the program. This ""program theory"" comprises the fundamental concepts and the relationships between these concepts. It is widely recognized that a surveillance program's design is based on the logical reasoning, perceptions and experience of current stakeholders and not always on sound principles.

Two approaches have been proposed to assess the validity of a program theory: (i) evaluating a posteriori the achievement of the program's objectives or intended effects, and (ii) testing a priori the plausibility of the program theory.

The main objective of this paper is to propose a detailed, structured, logical, transparent and systematic method for use in evaluating the completeness and coherence of the concepts underlying a health surveillance program as compared to a theoretical standard. We also provide a practical example of conceptual evaluation.

The term ""conceptual evaluation"" refers to the systematic process of extracting concepts from a text about the program under evaluation, and then analyzing the relationships between these concepts. This produces the program's conceptual model, which is then compared to a theoretical standard in order to evaluate the program's theoretical framework. A conceptual model corresponds to an abstract representation of concepts and their relationships. All existing public health and animal health surveillance programs are based on a set of concepts, ideas about how to conduct surveillance, how the program will work and what it will achieve. We identified surveillance concepts in program documents and during an interview with the surveillance program designer to construct the program's conceptual model. 

The goal of the conceptual evaluation of a surveillance program is to assess the program's theoretical framework with respect to (i) completeness of the surveillance concepts; and (ii) coherence, both logical and chronological, of the relationships between surveillance concepts.

The conceptual evaluation method complements and facilitates the use of existing surveillance evaluation tools in the sense that it (i) improves the description (documentation) of the surveillance program under evaluation by identifying non-documented concepts, thereby, facilitating the implementation of evaluation tools like the CDC protocol and Health Canada framework to the program under evaluation, (ii) clarifies the conceptual framework of the program under evaluation, thus making the surveillance design more transparent, and (iii)identifies strengths and weaknesses in program design before the program is implemented, leading to the drafting of recommendations and action plans that will maximize the program's success. Conceptual evaluation conducted pre-implementation should be seen as complementary to an evaluation strategy that is conducted only once the surveillance program is implemented (i.e., chronological complementarity).

In order to conduct a conceptual evaluation of surveillance programs and be able to compare evaluation results it is important to develop a valid and comprehensive conceptual framework that works for complicated surveillance situations and for all surveillance programs, human, animal and environmental health, and in any country. Conceptual evaluation provides a way for surveillance programs operating with very limited resources and technical capacity to demonstrate the validity and coherence of their conceptual framework. Such programs would be at a disadvantage when evaluated using existing performance-oriented evaluation methods and protocols.

In addition to the conceptual evaluation method, many surveillance evaluation guidelines and methods exist in the scientific literature (Del Rio Vilas and Pfeiffer, 2010; Drewe et al., 2012). There is a need to develop a comprehensive surveillance evaluation framework that takes into account all existing evaluation methods and guidelines, one that can serve as a valid approach for evaluating all kinds of veterinary and public health surveillance programs based on evaluation objectives or scenarios.

The conceptual evaluation method helps improve the design and content of documentation describing a health surveillance program. It allows for standardized and less subjective evaluation and decision-making in the context of applying the Sanitary and Phytosanitary Agreement and International Health Regulations.

We recommend developing a comprehensive evaluation surveillance framework for veterinary and public health surveillance programs that integrates existing surveillance evaluation tools. Understanding how existing evaluation tools complement each other and identifying what elements to take into account when selecting the appropriate evaluation strategy (using one tool versus a combination of tools) are key to moving forward in the field of health surveillance evaluation.",
fordAdequacyExistingSurveillance2021,3257,Ford 2021,"Adequacy of existing surveillance systems to monitor racism, social stigma and covid inequities: A detailed assessment and recommendations","Adequacy of Existing Surveillance Systems to Monitor Racism, Social Stigma and COVID Inequities: A Detailed Assessment and Recommendations",2021,Chandra L. Ford,clford@ucla.edu,United States of America,"Provides recommendations for developing the type of novel surveillance system needed to monitor the intersecting pandemics of racism, stigma and COVID-19","a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001); k. Other,Additional criteria were generated based on the principles of Public Health Critical Race Praxis (PHCRP)/Critical Race Theory (CRT) (Ford 2018),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Epidemiologists,Note: an evaluation tool was not developed - stakeholder listed developed recommendations to be considered when developing a novel surveillance system.,N/A,N/A,Community health scientists,Note: an evaluation tool was not developed - stakeholder listed developed recommendations to be considered when developing a novel surveillance system.,N/A,N/A,Critical race theorists,Note: an evaluation tool was not developed - stakeholder listed developed recommendations to be considered when developing a novel surveillance system.,N/A,N/A,Policy experts,Note: an evaluation tool was not developed - stakeholder listed developed recommendations to be considered when developing a novel surveillance system.,N/A,N/A,Computer scientists,Note: an evaluation tool was not developed - stakeholder listed developed recommendations to be considered when developing a novel surveillance system.,N/A,N/A,Data scientists,Note: an evaluation tool was not developed - stakeholder listed developed recommendations to be considered when developing a novel surveillance system.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001 definition,N/A,N/A,"How complete and accurate are the data fields in the reports the system receives? 
How reliable are the data?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001 definition,N/A,N/A,To what extent can the system adapt to new circumstances or needs?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001 definition,N/A,N/A,How easy is it for users to operate the system?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001 definition,N/A,N/A,How long does it take for the system to acquire needed data and make them available?,CDC 2001 definition,N/A,N/A,To what extent does the system support the achievement of the stated goals?,N/A,N/A,N/A,N/A,Race/ethnicity data,N/A,N/A,Which race/ethnicity data are included? To what extent do they support the achievement of Project REFOCUS aims?,Stigma measures,N/A,N/A,What valid measures of stigma are included?,Racism measures,N/A,N/A,What relevant measures of racism are included?,Surveillance Implications,N/A,N/A,To what extent might the system contribute to harm of racial/ethnic minority and vulnerable populations or aid community-originated surveillance projects?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Pandemic-specific surveillance should capture data relating to racism and social stigma that contribute to health inequities.

Apply a pandemic ethics framework to monitor potential harms and protections of any newly developed system continuously.","10. Ford, C.L.; Airhihenbuwa, C.O. Commentary: Just What is Critical Race Theory and What's it Doing in a Progressive Field like Public Health? Ethn. Dis. 2018, 28, 223-230. [CrossRef] 
11. Ford, C.L.; Airhihenbuwa, C.O. The public health critical race methodology: Praxis for antiracism research. Soc. Sci. Med. 2010, 71, 1390-1398. [CrossRef] 
12. Ford, C.L.; Airhihenbuwa, C.O. Critical Race Theory, race equity, and public health: Toward antiracism praxis. Am. J. Public Health 2010, 100, S30-S35. [CrossRef] 
13. Planey, A.M. Chandra L. Ford, Derek M. Griffith, Marino A. Bruce, Keon L. Gilbert 2019. Racism: Science & Tools for the Public Health Professional. Washington, DC: American Public Health Association Press, 2019. World Med. Health Policy 2020, 12, 545-547. [CrossRef] 
14. National Academies of Sciences Engineering and Medicine. Committee on Community-Based Solutions to Promote Health Equity in the United States. In Communities in Action: Pathways to Health Equity; National Academies Press (US): Washington, DC, USA, 2017.

17. Morey, B.; Chang, R.C.; Thomas, K.B.; Tulua; Penaia, C.; Tran, V.D.; Pierson, N.; Greer, J.C.; Bydalek, M.; Ponce, N. No Equity without Data Equity: Data Reporting Gaps for Native Hawaiians and Pacific Islanders as Structural Racism. J. Health Politics Policy Law 2021. [CrossRef] [PubMed]

19. Ford, C.L.; Skrine Jeffers, K. Critical Race Theory's Anti-racism Approaches: Moving from the Ivory Tower to the Frontlines of Public Health. In Racism: Science and Tools for the Public Health Professional; Ford, C.L., Griffith, D.M., Bruce, M., Gilbert, K., Eds.; American Public Health Association: Washington, DC, USA, 2019. 
20. Boyd, R.W.; Lindo, E.G.; Weeks, L.D.; McLemore, M.R. On Racism: A New Standard For Publishing On Racial Health Inequities. In Health Affairs Blog; Affairs, H., Ed.; Health Affairs: Washington, DC, USA, 2020.

25. Stangl, A.L.; Earnshaw, V.A.; Logie, C.H.; van Brakel, W.; Simbayi, L.C.; Barré, I.; Dovidio, J.F. The Health Stigma and Discrimina- tion Framework: A global, crosscutting framework to inform research, intervention development, and policy on health-related stigmas. BMC Med. 2019, 17, 31. [CrossRef]

30. Thomas, J.C. Pandemic Ethics Dashboard. Available online: https://pandemicethics.org/about/ (accessed on 29 October 2020).

41. Choi, B.C. The past, present, and future of public health surveillance. Scientifica 2012, 2012, 875253. [CrossRef] [PubMed]","Overall, the most important contribution of COVID-19 surveillance systems is their real-time (e.g., daily) or near-real-time (e.g., weekly) reporting; however, they are severely constrained by the lack of complete data on race/ethnicity, making it difficult to monitor racial/ethnic inequities. Other public health systems have validated measures of psychosocial and behavioral factors and some racism or stigma-related factors but lack the timeliness needed in a pandemic.

Lessons learned from prior epidemics, such as the HIV epidemic, include that stigma exacerbates disease-mitigation efforts among the most vulnerable populations, contributes to mistrust of public health messages, delays accessing recommended services and reduces adherence to prescribed treatment regimens [4-6]. Anecdotal and empirical evidence exists of COVID-19-related stigma [7] and related violence against Asians and members of other groups [8,9]. Traditionally, public health surveillance is used to monitor trends in environmental conditions, disease outcomes and/or risk factors; identify hotspots where disease and/or risk are concentrated; and predict potential threats to the health of the public early in order to intervene on them. Efforts to mitigate the root causes of COVID-19 inequities among diverse vulnerable populations could be improved by developing new surveillance tools that capture the intersecting ways racism, stigma and disease co-occur; however, we are aware of no surveillance systems that do so.

The purpose of this research was to identify characteristics of existing surveillance systems that might inform the development of a novel COVID monitoring system that tracks COVID-19-outcomes in real time, as well as key forms of stigma and racism that affect them.

Draw on the strengths each of the three types of systems has to offer. Doing so provides the best opportunities for developing and sustaining a novel anti-racism COVID monitoring system. This includes the real-time nature of COVID systems, the use of validated measures of psychosocial indicators that are available in other public-health surveillance systems and the inclusion of explicit indicators of racism that key monitoring systems have been using for decades to track racism and racialized stigma.

Establish guidelines about which COVID-19-related indicators to include in any system and the best metrics for reporting them. Account for the different ways diverse types of end-users will make use of the information.

Include measures of both self-reported race/ethnicity and perceived race/ethnicity, so that end-users can identify disparities and their determinants [35,36]. 

Apply a pandemic ethics framework to monitor potential harms and protections of any newly developed system continuously. Communicate this commitment to stakeholders, especially community members. This is important for remaining accountable to community and inviting their involvement in its design [30]. The efforts used to control infectious disease pandemics raise ethical issues [26]. One notable resource, the Pandemic Ethics Dashboard [30], responded to this challenge early in the COVID pandemic by providing guidance to minimize the possibility of COVID-19 mitigation strategies inadvertently harming communities.

However well-intentioned public-health-surveillance efforts may be, it is critical to consider ways they may introduce harm to communities of color through the criminalization of communities that are monitored based in part on their race, gender, class and ability [39]. The alternative model we are pursuing is conducted in partnership with the community, using community engagement and participatory processes. Fortunately, many important collective and community-led organizations are discussing ways to proceed forward and exploring ways to promote data sovereignty, sharing, ownership, transparency and data abolition. These groups are (1) documenting how data and tech are part of a larger surveillance industrial complex that is further disenfranchising and marginalizing communities of color and (2) providing a roadmap on how data and technology can be reimagined for social justice goals.

Surveillance strategies that do not prioritize equity may place socially marginalized populations at elevated risk for inadvertent harm [40]. It is important to establish protocols to ensure system components do not inadvertently harm the very communities they are intended to serve. Needed still is a way to evaluate the potential harm. We have been developing a scoring system to evaluate these considerations, but we are aware of no system that applies it.

Apply a pandemic ethics framework to monitor potential harms and protections of any newly developed system continuously. Communicate this commitment to stakeholders, especially community members. This is important for remaining accountable to community and inviting their involvement in its design.",
garcia-vozmedianoOneHealthEvaluation2022,102,Garcia-Vozmediano 2022,"A One Health Evaluation of the Surveillance Systems on Tick-Borne Diseases in the Netherlands, Spain and Italy.","A One Health Evaluation of the Surveillance Systems on Tick-Borne Diseases in the Netherlands, Spain and Italy",2022,Aitor Garcia-Vozmediano,itor.garciavozmediano@unito.it,Italy,"One Health evaluation of surveillance systems for tick-borne diseases in the Netherlands, Spain, and Italy","b. Formal evaluation of public health, environmental, or One Health surveillance systems",d. One Health,"Netherlands, Spain, and Italy",k. Other,Network of Evaluation of One Health (NEOH) Evaluation Tool (Ruegg 2018),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Distinct stakeholder groups were not provided for each surveillance system that was evaluated.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"6. Ruegg, S.R.; Nielsen, L.R.; Buttigieg, S.C.; Santa, M.; Aragrande, M.; Canali, M.; Ehlinger, T.; Chantziaras, I.; Boriani, E.; Radeski, M.; et al. A Systems approach to evaluate One Health initiatives. Front. Vet. Sci 2018, 5, 23.

7. Ruegg, S.R.; Hasler, B.; Zinsstag, J. Integrated Approaches to Health: A Handbook for the Evaluation of One Health; Wageningen Academic Publishers: Wageningen, The Netherlands, 2018; pp. 1-255.","The evaluation method follows guidelines outlined in Ruegg et al. [7] and consists of a mixed methods approach, including a descriptive and qualitative assessment combined with a semi-quantitative scoring that measures the degree of OH that characterises the health initiative. It is based on a questionnaire that explores different operational (thinking, planning, working) and infrastructural (learning, sharing, systemic organisation) aspects within the initiative. Scores were inserted in a Microsoft Excel workbook, modelled on a template provided by Ruegg et al. [6].

Stakeholders have demonstrated strongly supporting the health initiatives when they are involved, by contributing to increase knowledge and helping to achieve main goals. For instance, in the Dutch initiative, citizens actively participated in several projects helping to monitor tick bites and LB across the national territory. Moreover, their contribution has enabled the Dutch initiative for reflexion and self-assessment, but also for measuring its impacts on health. To maintain public engagement, it is of paramount importance to give information feedbacks related to the activities in which stakeholders are involved [12]. Efficient information exchange among actors and stakeholders leads to health benefits by a prompt system reaction (response capacity) and control of the health issue. 

Surveillance systems characterised by transdisciplinary collaborations might be more effective in disease prevention and early response to emerging health threats, including tick-borne diseases.",
goutardUseParticipatoryMethods2022,13693,Goutard 2022,The use of participatory methods in the evaluation of health surveillance systems,THE USE OF PARTICIPATORY METHODS IN THE EVALUATION OF HEALTH SURVEILLANCE SYSTEMS,2022,Flavie Goutard,unknown,France,Guidance for applying participatory methods for the evaluation of acceptability in animal health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The information produced by surveillance systems supports decisions on what measures are appropriate, including prevention, control, and research.",N/A,N/A,N/A,N/A,"The selection of participants will depend on the willingness of the actors to take part in the study. Moreover, participants should not combine actors with different experience of the system in one focus group discussion where they are required to produce only one combined ranking even though they play in the same position. Best to separate them into groups with the same experience and knowledge of the surveillance system, that way will help to maintain the discussion and experience sharing without compromising the assessment goal. We should avoid situation where actors are required to discuss or rank stakeholders that they have not worked with. Some participants that hold high position in the government might struggle to provide direct response to the interview. In this case, interviewer needs to be mindful of these biases and be prepared to handle the interview at the best of his possibility. It is also essential to obtain approval from the local ethics committee and obtain informed consent from each participant before conducting interviews. In addition to representing large categories of stakeholders, caution should be exercised in the selection process to not inadvertently exclude important groups of individuals in a way that would bias the outcomes (e.g., different ethnic groups, size of the breeding operation, the membership to hunter association, etc.). Indeed, the perception of the surveillance system may vary depending on these elements.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Acceptability refers to the willingness of individuals and organizations to participate in surveillance, as well as the extent of involvement of each of these users.","Considerations for measuring the acceptability of a surveillance system, associated participatory questions and [tools]: 
Objective 
- Is the objective of the surveillance system in line with the objective expected by the actors of the device [flowchart diagram]; 
Process (role of each actor) 
- Are stakeholders satisfied with their duty within the surveillance system? [flowchart diagram]; 
Process (consequences of information flow) 
- Are stakeholders satisfied with the consequences of information flows? [Impact diagram associated with proportional piling]; 
Process (relations between actors) 
- Are actors satisfied with the relationships they have with other actors involved in the system? [Relationship diagram associated with rating smileys]; 
Trust (in the system) 
- Do the actors trust the surveillance system to achieve the objectives? [flowchart diagram associated with proportional piling]; 
Trust (in the other actors) 
- Do actors trust other actors involved in the scheme to fulfill their role in surveillance? [flowchart diagram associated with proportional piling]

Participants are asked to allocate 100 game tokens in two piles in order to highlight the trust they place in the functioning of the whole surveillance (the higher the number of tokens, the greater the trust). Then, in a second step, to distribute these tokens among the various actors identified, according to the same principle. The analysis is carried out initially for each individual interview and each group discussion. An evaluation grid has been developed presenting scoring criteria based on a semiquantitative scale with the following score according to the different element of acceptability index: ""unsatisfied = -1, medium = 0, satisfied = 1"" for their satisfaction level in the objective, the operation and the information within the system; ""weak = -1, medium = 0, good = 1"" for their level of trust. Proportional piling analysis was based on the way that participants divided 100 counters between negative and positive impacts. Based on the scoring guidelines, the scores were then categorized into three levels such as weak [0; 33], which is equal to score -1, medium [33; 66], which is equal to score 0, and good [66; 100], which is equal to score 1. The results can be presented in different formats: by type of actor, by level of surveillance (local, regional, national) or by element of acceptability, or even by the combination of these different elements.","Health surveillance systems are composed of a broad range of stakeholders, and they all have different responsibilities toward, different perceptions of, and different ways of thinking about the surveillance system. Therefore, one of the biggest challenges within the system is to bring every one of them to a position  of mutual interest. Stakeholders' willingness to support the system, their satisfaction of the operation, and of their own roles are strong pillars to an effective surveillance system. In order to limit underreporting, it is crucial to determine the stakeholders' perceptions and expectations regarding surveillance, and thus their level of acceptability. This attribute is all the more important as it can influence the performance of the surveillance system, for example, by influencing the sensitivity and responsiveness of the system. Despite this, this attribute is not always measured or when it is, the methods used (e.g., structured questionnaires) do not always make it possible to highlight the points of view and expectations of the actors.","Objective 
- Is the objective of the surveillance system in line with the objective expected by the actors of the device?; 
Process (role of each actor) 
- Are stakeholders satisfied with their duty within the surveillance system?; 
Process (consequences of information flow) 
- Are stakeholders satisfied with the consequences of information flows?; 
Process (relations between actors) 
- Are actors satisfied with the relationships they have with other actors involved in the system?; 
Trust (in the system) 
- Do the actors trust the surveillance system to achieve the objectives?; 
Trust (in the other actors) 
- Do actors trust other actors involved in the scheme to fulfill their role in surveillance?
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Calba et al. [27] have developed a method to estimate the acceptability of animal health surveillance systems based on the use of participatory approaches: the Acceptability Participatory Toolkit (AccePT). This method combines a series of participatory tools used with stakeholders to measure (i) their perception of system objectives, (ii) their perception of the monitoring process (their role, constraints, and relationships with other actors in the system), and finally (iii) their confidence in the system; three essential elements for the acceptance of the surveillance system by its actors [3, 7, 14]. The AccePT method is a standardized method for estimating the acceptability of epidemiological surveillance systems in animal health taking via participation of the diversity of actors involved in the network, by individual face-to-face interviews or focus groups of 5-10 participants. By using different participatory tools and analyzing the results in the form of a scoring grid, it is possible to determine a general level of acceptability of the system, as well as a level of acceptability by type of actors. The use of this method makes it possible to formulate recommendations that are context-specific, and most of which can be directly formulated by the participants. It also leads to a better acceptability of the evaluation thanks to the direct involvement of the actors in the process. It offers the opportunity to clearly document the general context of the surveillance and the structure of the surveillance system. It contributes to strengthening the ownership of the stakeholders in the system and provides capacity-building opportunities regarding specific diseases or epidemiological surveillance generally. The qualitative data collected during the interviews also includes valuable information for improving the surveillance system. In fact, interviews allow participants to discuss their points of view, expectations, and experiences, which are essential for improving surveillance. Follow-up events to discuss the outcome of the performance evaluation may be very valuable to further discuss the findings and involve additional actors who have not taken part in the process but who may be impacted by the results and the recommendations. Implementing the AccePT method, however, requires specific training in the use of participatory approaches. In addition, there are substantial time requirements related to the organization of interview sessions, participant recruitment, interviews facilitation, and analysis of the results. Biases related to semistructured interview approaches can also influence the outcomes and further justify the need for appropriate training in participatory approaches. The organization of the different focus group should be organized very early in the process of evaluation in order to target homogenous group to avoid power relationships within interview groups and ensure participants freedom of expression during sessions. Cultural factors, such as the tendency to avoid conflict at all cost and also not wanting others to lose face, may significantly influence the dynamic during interview sessions. Some participants may not want to be seen as being too negative toward other partners and may bias their scoring toward the least conflictual options. Particular care should be used to mitigate the influence this may have on the scoring process.",N/A,N/A,"12. Goutard FL, Binot A, Duboz R, Rasamoelina-Andriamanivo H, Pedrono M, Holl D, Peyre MI, Cappelle J, Chevalier V, Figuie M, Molia S, Roger FL. How to reach the poor? Surveillance in low-income countries, lessons from experiences in cambodia and madagascar. Prev Vet Med. 2015;120:12-26. https://doi.org/10.1016Zj.prevetmed.2015.02.014. 
15. Peyre M, Hoinville L, Haesler B, Lindberg A, Bisdorff B, Dorea F, Wahlström H, Frössling J, Calba C, Grosbois V, Goutard F. Network analysis of surveillance system evaluation attributes: a way towards improvement of the evaluation process. 2nd International Conference on Animal Health Surveillance (ICAHS), La havane, Cuba; 2014. 
26. Bryson JM, Patton MQ, Bowman RA. Working with evaluation stakeholders: a rationale, step-wise approach and toolkit. Eval Program Plann. 2011;34(1):1-12. 
27. Calba C, Peyre M, Roger F, Antoine-Moussiaux N, Hendrikx P, Saegerman C, Goutard F. Approches participatives et estimation de l'acceptabilite des systèmes de surveillance : la methode AccePT. Epidemiologie et Sante Animale. 2018;73:49-58. (This article seems to be more or less an English summary version of the original article)","Animal health surveillance systems are decision support tools defined by ""the systematic and continuous operations of collection, compilation and analysis of animal health information, as well as their dissemination within a timeframe compatible with the implementation of necessary measures."" Surveillance systems have certain limitations that influence their performance in accurately describing the epidemiological situation of a given population. These limitations are related to underreporting, reporting delays, lack of data management, limited representativeness, or imposed budgetary constraints. It is fundamental to evaluate these systems regularly and appropriately to ensure their performance, but also to determine whether the relevant stakeholders are fully engaged and the resources provided are used optimally. Current evaluation approaches are generally not very flexible and do not always consider the context in which the surveillance system is implemented. The socioeconomic aspects of surveillance are also poorly considered despite their impact on surveillance performance. To be functional, epidemiological surveillance must be based on a network of actors who share common (or at least compatible) interests, derive mutual benefit from the network operations, and have a common understanding of the circulating information. In other words, these actors must share a common perception of the disease to be monitored and give the same definition of what is a reportable case. Social factors can have important consequences on the validity and the performance of the surveillance strategies, in particular with regard to the problems of stigmatization of individuals or of a social group. It is therefore necessary to be inclusive of the multiple actors-breeders, veterinarians, consumers, traders-who contribute, more or less autonomously, in the management of risks and crisis situations associated with the emergence of diseases. Therefore, the inclusion of a social dimension not only aims to identify the human factors that promote the circulation of health information, but also supports the definition of the modalities of risk co-management. Based on local and traditional knowledge, these methods actively involve grass-roots stakeholders, mainly herders (key actors in disease reporting) to collect information on the health situation. They can be applied in addition to conventional surveillance methods in the identification of field clinical cases that are not detected by passive surveillance systems if the cases can be confirmed by specific biological tests. Their main advantages are to increase ownership of the stakeholders in the surveillance system and to increase sustainability of surveillance by relying on formal and informal stakeholder networks.

In order to improve the design and implementation of evaluations, but also to optimize the use of results in decision-making, it is important to pay particular attention to stakeholders and to involve them early on in the process. We therefore propose to shift from a top-down approach, in which no consultation processes are used, to more participatory approaches. Participatory approaches can provide the necessary flexibility for evaluation in different context and allow the collection of complementary and essential information on the socioeconomic aspects of surveillance. This process should enable discussion, communication, negotiation, knowledge sharing, and should provide a strong basis for the common identification of socially acceptable solutions. Participatory evaluation leads to stakeholder empowerment in the process, which could improve the sustainability of surveillance systems.

Animal health surveillance is carried out by a variety of stakeholders, involved at different scales, organized as networks of actors. Information such as epidemiological data and decisions on disease control measures and animal health management must flow in a multidirectional manner in these networks. Dissemination of information is thus an essential element that determines the motivation of a large number of surveillance actors.

There is a potential for participatory epidemiology to be valuable in the evaluation of other attributes, such as communication, stability, representativeness, or training provision. These methods could also be used for different issues, such as impact studies of research projects or ""One Health"" projects.
",
grosecloseEvaluatingPublicHealth2010,12387,Groseclose 2010,Evaluating Public Health Surveillance,Evaluating Public Health Surveillance,2010,unknown (it is not made clear who the authors of the book chapter are),unknown,not reported,"Provide guidance for evaluating public health surveillance systems, with focus given to attributes for assessing informatics-based surveillance information systems","a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Task A. Engage the stakeholders in the evaluation,"Early in the evaluation planning process, the system stakeholders should be engaged in a discussion to ensure that the evaluation of a public health surveillance system addresses appropriate questions and assesses pertinent attributes and that its findings will be acceptable and useful.",N/A,"Because of the collaborative nature of public health surveillance practice, stakeholders' needs and concerns must be taken into account during system design and evaluation.","In that context, we define stakeholders as those persons or organizations who use data for the promotion of healthy lifestyles and the prevention and control of disease, injury, disability, or exposure to environmental hazards. Stakeholders who might be interested in defining questions to be addressed by the surveillance system evaluation and subsequently using the findings include public health practitioners; health-care providers; data providers and users; representatives of affected communities; governments at the local, state, and federal levels; and professional and private nonprofit organizations.

As the public's demand for health information increases and as new health-related data become accessible, public health surveillance partnerships and networks might include new stakeholders expressing unique information needs (e.g., community health systems interested in supporting early public health response or pandemic preparedness, biologics and pharmaceutical manufacturers, and patient advocacy groups",Task B. Describe the surveillance system to be evaluated,"Describe the public health importance of the health-related event under surveillance

Indices of frequency

Indices of severity

Disparities or inequities associated with the health-related event

Costs associated with the health-related event

Preventability

Potential future clinical course in the absence of an intervention

Public interest

Describe the purpose and operation of the surveillance system

Purpose and objectives of the system

Planned uses of the data from the system

Health-related event under surveillance, including case definition

Legal authority for data collection

Organizational location of the system and system governance or management

Level of organizational, informatics, or data integration with other systems

Flow chart of system

System inputs and outputs

Stakeholder organizations and roles

Information and technical architecture

Components of system

Population under surveillance

Period of time of data collection

Data collection methods

Reporting sources of data

Data management protocols

Information technology(ies) used to support surveillance processes

Data analysis and dissemination protocols

Surveillance monitoring indicators and protocol

Patient privacy, data confidentiality, and system security

Records management and data release protocols

Describe the resources used to operate the surveillance system

Funding source(s)

Personnel requirements

Information technology resources

Other resources","The first step in evaluating a surveillance system is to answer the question, ""Should this health event be under surveillance?"" This question should be answered from a perspective external to the surveillance system itself (see also Chapters 2 and 3 ). It should also be asked when deciding whether to start a new system or before conducting a detailed evaluation of an existing one. This is done primarily to assess the public health importance of a health event. Once a health event is identified of high priority, it is important to consider both the options for data sources and surveillance methods, feasibility, and cost of conducting surveillance for that event. If this assessment leads to a decision to discontinue or not to start a surveillance system, a detailed evaluation of that system becomes superfluous.

Parameters measuring the importance of a health-related event—and therefore the public health surveillance system with which it is monitored—can include:

- indices of frequency (e.g., the total number of cases and/or deaths; incidence rates, prevalence, or mortality rates)
- summary measures of population health status (e.g., disability-adjusted life years [DALYS])
- indices of severity (e.g., case-fatality rates, hospitalization rates, disability rates)
- disparities or inequities associated with the health-related event
- costs associated with the health-related event
- preventability
- beneficial health effects of programs that must be sustained to protect health (e.g., immunization programs)
- public interest

Listing the discrete steps that are taken in processing the health event reports by the system and then depicting these steps in a flow chart is often useful (e.g., Fig. 8-1 ). The roles and surveillance process responsibilities of the stakeholders that support the system could be included in this chart (e.g., What is the workflow? What tasks are performed and by whom?) (36). The depiction of the system's information architecture and data flow should be detailed sufficiently to explain all of the system's operational characteristics, including average times between process steps and data transfers.

The influence of information technology on system performance should be described, including the hardware environment, software tools, user interface, data security, and use of standard data formats and coding to facilitate efficient data interchange, linkage, or de-duplication within the system or to other systems. Additional considerations for evaluation of informatics attributes of the system are discussed in the next section.

The data analysis description might indicate who analyzes and interprets the data, how often analyses are performed, the objective(s) of the analysis (e.g., burden assessment, trend monitoring, outbreak detection, or identification of high-risk subpopulations), and the types of data output generated. This description could also address the data analysis and visualization methods used and how the system ensures that appropriate methods are used to analyze the data","The public health importance of a health event and the need for surveillance of that health event can be described in a variety of ways. Health events that affect many people or require large expenditures of resources are clearly important in a public health context. However, health events that affect relatively few persons might also be important, especially if the events cluster in time and place (e.g., a limited outbreak of a severe disease). At other times, public concerns might focus attention on a particular health event, creating or heightening the sense of importance associated with it (e.g., enhanced surveillance during high-profile community events) (16,17). In addition, the public health importance of a health event is influenced by its preventability and the ability of public health action to prevent or control the event.

Measures of importance used should account for the effect of previously implemented prevention strategies on the occurrence of the health event.

Preventability can be defined at several levels, including primary prevention (i.e., preventing the occurrence of disease or other health-related event), secondary prevention (i.e., early detection and intervention with the aim of reversing, halting, or at least retarding the progress of a condition), and tertiary prevention (i.e., minimizing the effects of disease and disability among persons already ill). For infectious diseases, preventability can also be described as reducing the secondary attack rate or the number of cases transmitted to contacts of the primary case. From the perspective of surveillance, preventability reflects the potential for effective interventions at any of these levels.

The need for surveillance might also be affected by factors other than those mentioned above. Political and public pressure might affect whether surveillance is undertaken—or, at the other extreme, forbidden—for a specific health event. Regulations, laws, and public health programs might be implemented on the basis of considerations other than those listed above. However, it is still important to make the surveillance objectives and scientific criteria for evaluation as clear and explicit as possible. Even when using quantitative measures, judgment is necessary to decide which criteria are most relevant for assessing the importance of each condition. It is important to make these judgments as explicit—and as early—as possible. 

The evaluation should address the following questions:

What is the population under surveillance? What subgroups, if any, are excluded?

What is the period of data collection?

What data are collected and how are they collected?

What are the reporting sources of data for the system?

How are the system's data managed (e.g., the transfer, entry, editing, transformation, storage, and back-up of data)? Does the system comply with applicable standards for data formats and coding schemes? If not, why?

What information technologies are used to support surveillance data collection, reporting, analysis, interpretation, and dissemination?

How are the system's data analyzed and disseminated? How frequently? To whom? For what purpose?

What policies and procedures are in place to ensure patient privacy, data confidentiality, and system security?

What is the policy and procedure for releasing data? Do these procedures comply with applicable laws, statutes, and regulations? If not, why?

Does the system comply with an applicable records management program? For example, are the system's records properly audited, archived, and/or disposed of?

With limited public health funding for detection and response, assessment of resources devoted to surveillance is critical. Different types of costs might be determined during a surveillance evaluation depending on the evaluation design and purpose and include:

Direct costs: those personnel and material resources required for operation of surveillance (e.g., data provider or public health system person-time expended per year of operation [by discipline and associated salary and benefits cost], travel, training, information dissemination, information technology hardware, software, and support);

Indirect costs: those costs that result from preparedness and response to surveillance findings (e.g., follow-up diagnostic laboratory tests; community information, education, and communication activities; case management; and outbreak response) (37); and

Prevention benefits or costs from societal perspective: cost estimates of the effect of the system and the information generated on decision making, treatment, care, prevention, education, or research (e.g., cost of responding to false alarms; cost of missing outbreaks; and productivity losses averted) (38).

The assessment of the system's operational resources should not be done in isolation of the program or initiative that relies on the public health surveillance system.

However, because of the complexity of the public health surveillance and response processes, it is usually difficult to define indirect costs attributable to surveillance activities or to model cost-savings in the presence (or absence) of surveillance programs. Therefore, assessment of surveillance resources typically focuses on only those personnel and material resources required for the operation of the system (i.e., direct costs).

If evaluating a system early in its developmental lifecycle, it is useful to differentiate direct costs associated with the system development and implementation phases from ongoing operating costs to provide insight into system feasibility and sustainability. When considering the cost or acceptability of surveillance systems, it is also relevant to consider whether the system serves more than one function—does it allow the monitoring of multiple health outcomes (i.e., marginal cost perspective), or can it be used for both routine notifiable disease surveillance and outbreak detection.
","The purpose of the surveillance system indicates why the system exists; its objectives relate to how the data are used for public health action. 

Each public health surveillance system requires a clear case definition for the health-related event or exposure under surveillance (see Chapter 4 ). The case definition of a health-related event can include clinical manifestations (i.e., symptoms and signs); laboratory, radiologic, or other diagnostic clinical findings; and epidemiologic information (e.g., person, place, and time). Case definitions may also be further specified based on level of certainty (e.g., confirmed/definite, probable/presumptive, or possible/suspected). The specification and use of a standard case definition increases the specificity of reporting and improves the comparability of the health-related event reported from different sources of data and from different geographic areas. When the health event can be monitored using different data sources, case definitions should be specified for each data source to categorize the health event using each source's information data type (e.g., by ICD-9-CM code representation, self-reported survey question responses, or reported clinical and laboratory information, as illustrated by the asthma surveillance case definitions outlined in Table 8-3 )

When possible, a public health surveillance system should use an established surveillance case definition, and if it does not, an explanation should be provided. Case definitions should be modified whenever new knowledge on the epidemiology, pathogenesis, or other relevant factors becomes available.

The evaluation of the public health surveillance system needs to include an accurate and reliable description of the system's operation and the business processes conducted to accomplish its purpose and objectives. Understanding how well the system is meeting its objectives is important to provide evidence for prevention and control efforts, including policy decisions. The description of the system should discuss its organizational location and governance, its linkages to or dependence on other information systems or processes, and its processes and functions supporting public health action.

In addition to the surveillance system characteristics described above, the system description should:

Cite any legal authority for the data collection.

Describe the organization(s) sponsoring and contributing to the system, including the political, administrative, geographic, or social context in which the system evaluation will be done.

Describe the level of organizational, informatics, or data integration with other systems (33). Organizational integration refers to the structures and policies that govern information management and those system features that promote a public health enterprise- or systems-wide perspective to align, streamline, and improve surveillance and monitoring processes within the organization (34). Informatics integration refers to the system's use of information technologies and other informatics standards and best practices that promote interoperability, improve data quality or timeliness, support surveillance processes, and enhance surveillance efficiency. Data integration refers to the system's use of data standards or data mapping, transformation, or linkage methods to support sharing of data between surveillance information systems to create new knowledge.

Describe system inputs and outputs, data flow, and surveillance processes and associated stakeholders' roles through use of a system flow chart (e.g., Fig. 8-1 ). A description of system inputs might include specification of types of data reported, surveillance data sources, or data variables and formats; outputs include indicator monitoring, data quality, or descriptive epidemiology reports. If one is evaluating the informatics aspects of the surveillance system, then a more detailed description of surveillance tasks, roles and responsibilities, and system functionality should be provided to allow identification of business processes amenable to performance improvement (see below). A surveillance business process is a set of related work tasks designed to address a desired surveillance objective or support a required surveillance process or activity

The public health surveillance system should operate in a manner that allows effective dissemination of health data so that decision makers at all levels can readily understand the implications of the information (see Chapter 7 ). Audiences for public health surveillance data and information include public health practitioners, health-care providers, members of affected communities, professional and voluntary organizations, policymakers, the press, and the general public. Dependent on the audience, options for disseminating data or information from the system include electronic data interchange; public-use data files; the Internet; press releases; newsletters; bulletins; routine and special-focus surveillance reports; secure peer-to-peer collaboration networks; publication in scientific, peer-reviewed journals; and poster and oral presentations, including those at individual, community, and professional meetings. Periodic surveys of users of the system's data and information products can assess how and by whom they are being used and might identify additional information requirements.

The protection of patient privacy (recognition of a person's right not to share information about him or herself), data confidentiality (assurance of authorized data sharing), and system security (assurance of authorized system access) are essential to maintaining the credibility of any surveillance system. Physical, administrative, operational, and computer safeguards for securing the system and protecting and releasing its data must allow authorized access while denying access by unauthorized users. Such safeguards and associated policies should be reviewed as part of the evaluation and judged for adequacy. To ensure that data are used to their full potential, that work is not duplicated, and that funds are not spent unnecessarily, surveillance data should be released or shared in accordance with the objectives and conditions under which the data were collected or obtained. The surveillance system's policies and procedures for data release should be obtained and reviewed.",Task C. Focus the evaluation design,"Determine the specific purpose and scope of the evaluation

Identify stakeholders who will receive the findings and implement recommendations of the evaluation

Consider what will be done with the information generated from the evaluation

Specify the questions that will be answered by the evaluation

Determine standards for assessing the performance of the system",N/A,"Recent public health surveillance evaluation guidance has described evaluation of core surveillance processes, support functions, and system attributes within the public health system. Although comprehensive evaluation requires consideration of each of these domains, each evaluation should be individually tailored because surveillance systems vary in scope, methods, and objectives. 



Standards for assessing how the public health surveillance system performs establish what the system must accomplish to be considered successful in meeting its objectives. Ideally, system users specify the target performance standards for the system's attributes during system design (e.g., what levels of timeliness or representativeness are relevant for the system, given its objectives?). If target performance standards are not available, define them before initiating the evaluation. Information useful for defining relevant standards for assessment of the surveillance system's performance can be derived from a review of the current scientific literature on the health-related event under surveillance or via interview of system stakeholders to define systematically the key surveillance tasks, information needs, and required system functionality. 

Evaluation data might be obtained by the evaluation team using a mix of qualitative approaches (e.g., key informant interviews and observations) and quantitative methods (e.g., measuring the average elapsed time in surveillance processes to determine timeliness).","Depending on the specific purpose of the evaluation, its design could be straightforward or complex. An effective evaluation design is contingent on (1) its specific purpose being understood by all of the stakeholders in the evaluation; (2) detailed knowledge of the information needs of stakeholders and surveillance business processes that must be supported; and (3) the commitment of stakeholders to use the information generated from it. In addition, when multiple stakeholders are involved, agreements that clarify their roles and responsibilities prior to and following the evaluation might need to be established among those who are implementing the evaluation.",Task D. Gather credible evidence regarding the performance of the surveillance system,"Indicate the level of usefulness

Describe each surveillance system attribute

Simplicity

Flexibility

Data quality

Acceptability

Sensitivity

Predictive value positive

Representativeness

Timeliness

Stability

Describe informatics characteristics of surveillance information system

Information quality

System quality

User experience and service quality",N/A,"A literature review can be helpful in determining which attributes are relevant in evaluating the system. Yet, attributes must be measured in context, such as using the relevant gold standard or referent (e.g., review of medical records or registry data) in determining what is timely or acceptable when calculating sensitivity and PVP (Table 8-5 ). Qualitative measurement of some attributes (e.g., acceptability, flexibility, or simplicity) might be necessary.

System attributes are related to each other. Data of poor quality make the system less acceptable and its data less representative of the population under surveillance. Strengthening one system attribute could adversely affect another attribute of a higher priority. The points at which bias can enter a surveillance system and decrease representativeness are illustrated in Figure 8-2 . Efforts to improve sensitivity, PVP, representativeness, timeliness, and stability can increase the cost of a surveillance system, although savings in efficiency through use of information technology (e.g., electronic reporting) might offset some of these costs. As sensitivity and PVP approach 100%, a system is more likely to be representative of the population with the event under surveillance. However, as sensitivity increases, PVP might decrease.","A public health surveillance system has attributes that characterize its role in public health action. Credible evidence of the system's performance includes quantitative and qualitative indicator data that determine strengths and weaknesses. The interdependence of the system's attributes reflect the public health mission of the system, and some attributes might be more important than others.","Task E. Justify and state conclusions, and make recommendation","The conclusions should state whether the surveillance system is addressing an important public health problem and is meeting its objectives. The qualitative and quantitative findings should be linked to the system's defined evaluation metrics and interpreted in collaboration with system stakeholders. 

Recommendations should address the modification or continuation of the public health surveillance system.",N/A,N/A,"Conclusions from the evaluation can be justified through appropriate analysis, synthesis, interpretation, and judgment of the gathered evidence regarding the performance of the public health surveillance system (Table 8-7 ).

Involvement of stakeholders in the review of evaluation findings and definition of recommendations should increase the likelihood of their participation in surveillance performance improvement.

Before recommending modifications to a system, the evaluation should consider the interdependence of the system's costs and attributes (49). If a system is to be integrated into an organization or existing information environment, the readiness for change and attitudes of people affected by the introduction of the system should be assessed. Evaluation findings might require articulation of recommendations regarding ethical obligations in operating the system, (e.g., modifying procedures to ensure personal privacy (see also Chapter 9 ) or more timely and effective use of data for preparedness and response).",Task F. Ensure use of evaluation findings and share lessons learned,"Regardless of the evaluation strategy and methods used, an evaluator's comments will be of little use if they are not communicated in a clear, focused, credible evaluation report that directly addresses the purpose of the evaluation. Deliberate effort is needed to ensure that the evaluation findings are used and disseminated appropriately.",N/A,N/A,"During the implementation of the evaluation, considering political sensitivities and how potential findings (particularly negative findings) could affect decisions made about the surveillance system is often necessary. When conclusions from the evaluation and recommendations are made, follow-up is necessary to prevent lessons learned from being lost or ignored.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Public health practitioners,N/A,"Ideally, both surveillance system sponsors and other stakeholders participate as active partners in the evaluation process—motivated to champion evaluation activities and to improve their processes based on the findings.

The six stakeholders provided were not explicitly recommended to be involved in the evaluation, however their potential interest in involvement was stated.",N/A,Health-care providers,N/A,"Ideally, both surveillance system sponsors and other stakeholders participate as active partners in the evaluation process—motivated to champion evaluation activities and to improve their processes based on the findings.

The six stakeholders provided were not explicitly recommended to be involved in the evaluation, however their potential interest in involvement was stated.",N/A,Data providers and users,N/A,"Ideally, both surveillance system sponsors and other stakeholders participate as active partners in the evaluation process—motivated to champion evaluation activities and to improve their processes based on the findings.

The six stakeholders provided were not explicitly recommended to be involved in the evaluation, however their potential interest in involvement was stated.",N/A,Representatives of affected communities,N/A,"Ideally, both surveillance system sponsors and other stakeholders participate as active partners in the evaluation process—motivated to champion evaluation activities and to improve their processes based on the findings.

The six stakeholders provided were not explicitly recommended to be involved in the evaluation, however their potential interest in involvement was stated.",N/A,"Governments at the local, state, and federal levels;",N/A,"Ideally, both surveillance system sponsors and other stakeholders participate as active partners in the evaluation process—motivated to champion evaluation activities and to improve their processes based on the findings.

The six stakeholders provided were not explicitly recommended to be involved in the evaluation, however their potential interest in involvement was stated.",N/A,Professional and private nonprofit organizations,N/A,"Ideally, both surveillance system sponsors and other stakeholders participate as active partners in the evaluation process—motivated to champion evaluation activities and to improve their processes based on the findings.

The six stakeholders provided were not explicitly recommended to be involved in the evaluation, however their potential interest in involvement was stated.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Information quality,"Accuracy

Completeness

Relevance

Consistency","Article did not provide definitions for these attributes, however their definition/target can be implied from the provided criteria. See Q18 for criteria.",System quality,"Usability

Availability 

Adaptability

Response time

Functionality

Data quality

Portability

Improved data capture

Error reduction

Use of standards

Security","Article did not provide definitions for these attributes, however their definition/target can be implied from the provided criteria. See Q18 for criteria.",User experience and service quality,"Reliability 

Responsiveness

Assurance

Empathy","Article did not provide definitions for these attributes, however their definition/target can be implied from the provided criteria. See Q18 for criteria.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Reflects the willingness of persons and organizations to participate in the system.,"Measures for determining acceptability include: Subject or agency participation rate; interview completion rates and question refusal rates; completeness of reporting forms; physician, laboratory, or hospital/facility reporting rate; and timeliness of data reporting. A special study or survey may be required to obtain quantitative and qualitative data.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Are all required surveillance or information system data elements collected?; How complete are the valid responses for required data elements?,N/A,N/A,N/A,N/A,Consistency,N/A,N/A,Are data unchanged when replicated or interchanged between surveillance partners?; Are data transformations well-documented?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Efforts to improve sensitivity, PVP, representativeness, timeliness, and stability can increase the cost of a surveillance system, although savings in efficiency through use of information technology (e.g., electronic reporting) might offset some of these costs.",N/A,Refers to the completeness and validity of the data recorded in the system.,"Measures for determining data quality include percentages of ""unknown,"" invalid, and missing responses to items on data collection forms. In addition, data quality can be measured by applying edits for consistency in the data. However, a full assessment may require a special study.",Data of poor quality make the system less acceptable and its data less representative of the population under surveillance.,"For informatics: Do the data take only defined values?; Are data elements cross-checked (e.g., zip codes correspond to counties, males are not coded as “pregnant = yes”)?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ability to adapt to changing information needs or technological operating conditions with little additional time, personnel, or allocated funds.","Probably best evaluated retrospectively by observing how a system has responded to new demand, such as changes in case definitions, information technology, funding, or reporting sources.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Are the system’s technical architecture, hardware configuration, or software adaptable for use by other jurisdictions?; Can components of the system be re-used elsewhere (e.g., by other surveillance systems managed within the organization’s information architecture)?",The proportion of reported cases that actually have the event under surveillance.,"Sensitivity and predictive value positive provide different perspectives regarding how well the system is operating. Assessing predictive value positive whenever sensitivity has been assessed might be necessary. In Table 8-5 , predictive value positive is represented by A / (A + B). In assessing this attribute, primary emphasis is placed on case confirmation, and records might be kept of investigations prompted by information obtained form the system. More than one measurement of predictive value positive might be necessary.","The calculation of sensitivity and PVP typically requires the collection of, or access to, data external to the surveillance system. Yet the measurement of these attributes is often based on the best available data from the system. Examples of data types used as gold standards for estimating surveillance information sensitivities and PVPs include data from medical records, health claims logs, other health registries, vital statistics records, unduplicated databases from merging multiple data sources, telephone interviews, enhanced surveillance (such as follow-up of cases), and physical examinations. For a variety of health events under surveillance (e.g., birth defects, injuries, poliomyelitis, sexually transmitted diseases, and tetanus) total cases have been estimated, for example, using capture-recapture methods.

As sensitivity increases, PVP might decrease.",N/A,N/A,N/A,N/A,N/A,Ability to accurately describe the occurrence of a health-related event over time and its distribution in the population by place and person.,"Representativeness is assessed by comparing the characteristics of the reported events to all such actual events. Although the latter information is generally not known, knowledge of the characteristics of the general population, clinical course of the disease or event, and prevailing medical practices, as well as collection of data from multiple sources, can be used to assess this attribute. Special studies based on samples of cases might be used. Also, the choice of an appropriate denominator for rate calculations should be given careful consideration.","Case ascertainment bias and information bias (information about the cases) can decrease representativeness.

As sensitivity and PVP approach 100%, a system is more likely to be representative of the population with the event under surveillance.",N/A,N/A,N/A,N/A,"Are security levels and procedures for data or system access defined and enforced?; 
Is a data use and release policy and protocol available?; 
Is access to the application to perform specific functions (e.g., to read or modify the data) controlled?","Can be considered on at least two levels. At the level of case reporting, sensitivity refers to the proportion of cases of a disease (or event) detected by the system. On another level, it can refer to the ability to detect outbreaks over time. In evaluation of surveillance systems, ""completeness"" is often synonymous with sensitivity.","Assuming that reported cases are correctly classified, the primary emphasis in assessing sensitivity is to estimate the proportion of the total number of cases in the population under surveillance being detected by the system, represented by A / (A + C) in Table 8-5 . The capacity for a system to detect outbreaks might be enhanced if detailed diagnostic tests are used. The measurement of sensitivity requires collection of or access to data usually external to the system to determine the true frequency of the condition and validation of data collected by the system. Also, the calculation of more than one measurement of the attribute might be necessary.","The calculation of sensitivity and PVP typically requires the collection of, or access to, data external to the surveillance system. Yet the measurement of these attributes is often based on the best available data from the system. Examples of data types used as gold standards for estimating surveillance information sensitivities and PVPs include data from medical records, health claims logs, other health registries, vital statistics records, unduplicated databases from merging multiple data sources, telephone interviews, enhanced surveillance (such as follow-up of cases), and physical examinations. For a variety of health events under surveillance (e.g., birth defects, injuries, poliomyelitis, sexually transmitted diseases, and tetanus) total cases have been estimated, for example, using capture-recapture methods.

As sensitivity increases, PVP might decrease.",N/A,Refers to the system's structure and ease of operation. Systems should be as simple as possible.,"Measures for determining simplicity include but are not limited to: Amount and type of data necessary to establish occurrence of the health-related event; amount and type of other data on cases; number of organizations involved in receiving case reports; integration with other systems; data collection, management, analysis, and dissemination procedures; amount of follow-up to update case data; staff training requirements; and time spent on maintaining the system.",N/A,N/A,N/A,N/A,N/A,N/A,"Refers to the system's reliability (ability to collect, manage, and provide data without failure) and availability (ability to be operational when needed). (See also informatics-based attributes Table 8-6 .)","Measures for determining stability can include the number of unscheduled outages and down times for computer system; the costs involved with any computer repair; the percentage of time the system is operating fully; and the desired and actual amount of time required for the system to collect, manage, and release data.",N/A,"N/A
",Use of standards,N/A,N/A,"Are data standards used to represent data elements (e.g., Logical Observation Identifiers Names and Codes [LOINC]) for representing lab test type?; Are data interchanged electronically using standard data interchange protocols (e.g., Health Level 7)?",Reflects the speed between steps in a system.,"The time interval linking any of the steps in a system can be examined; these steps can include event occurrence, event recognition by reporting source, event reported to surveillance system, and control and prevention activities with feedback to stakeholders. The most relevant time interval might vary with the type of event under surveillance.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Accuracy,N/A,N/A,"Do the data express meaning clearly and unambiguously?; 
Does the coding system selected for each data element express the intended domain of meaning?; 
Is the information captured at a specific-enough level of detail to support all needed analysis?",Relevance,N/A,N/A,Are data available to system users when needed for surveillance purposes?; Has the system been assessed to eliminate the collection or storage of unnecessary or redundant data elements?,Usability,N/A,N/A,"Is the system understandable and useable by the intended user community?; 
How much user training is required prior to system use?; 
Is the sequence of actions involved in operation of the system sensible and understandable to the user community?; 
Does the system mirror common workflow?",Availability,N/A,N/A,"Is the system available at all needed times? From all needed locations? For all intended users?; 
Can the system be accessed in multiple ways using various technologies?",Adaptability,N/A,N/A,"Can the system be modified in response to changing information needs, data structures, functional requirements, or changes in workload?; 
Is the system able to add new connectivity or interfaces to support system or information integration?",Response time,N/A,N/A,"What is the desired and actual amount of time required for the system to generate data for public health action?; 
Is the system able to provide its indicated services in a timely manner?;
Can the system handle the workload with sufficient throughput for data processing, analysis, report generation, or data interchange?",Functionality,N/A,N/A,"Does the system support users in accomplishment of their various tasks and responsibilities?; 
Is the system configured or architected to support introduction of changes in functionality (e.g., creation of new data views to support emerging analytic needs, or receipt, de-duplication, linkage, and translation of new data types)?; 
Does the system have sufficient storage capacity?",Improved data capture,N/A,N/A,"Based on context of surveillance system, does the system use best available technology (whether electronic or hardcopy) for data collection to avoid duplicate data entry and to reduce data entry error?; 
Does system support multiple modalities for data collection, importing, or interchange?; 
Do procedures exist for validating timeliness, completeness, and accuracy of all data entry?",Error reduction,N/A,N/A,"Can the system operate despite adverse conditions such as operator error, bad data, device failure, or partial network outages?; 
Is the system free of internal defects that cause it to cease operation?",Reliability,N/A,N/A,"Does the system perform the intended surveillance support functions under the conditions defined by system users?; 
Is the information system dependable?",Responsiveness,N/A,N/A,"Do users receive prompt service when requesting assistance on the system?; 
Do users report that system support staff are willing to respond to user questions and to provide support services?",Assurance,N/A,N/A,"Are surveillance information system support staff knowledgable?; 
Is all required training provided to enable effective use of system?; 
Are support staff able to inspire trust and confidence in system users?",Empathy,N/A,N/A,"Are system change requests derived from user feedback managed in a responsive manner?; 
To what degree do the system designers, developers, or implementers base technological solutions and approaches on the business needs of public health surveillance and of the system stakeholders (e.g., achieving objectives or improving surveillance attribute performance)?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Assessing the Informatics Attributes of the System:
As information technologies are increasingly used to support public health surveillance, one must consider the impact of informatics and information technology on surveillance processes and public health practice. Public health informatics is defined as the systematic application of information and computer science and technology to public health practice, research, and learning (52). It follows then that information science and technology attributes relevant for surveillance information collection, management, interchange, and use can be defined and described in addition to more traditional surveillance evaluation attributes, such as timeliness or sensitivity.
As in a traditional surveillance system evaluation, an informatics-focused evaluation of surveillance systems requires consideration of the population under surveillance, the public health importance and epidemiology of the condition under surveillance, and the ethical, legal, organizational, fiscal, and political context (53). In addition, surveillance evaluations that include an informatics perspective must consider the range of feasible information technology options that can support surveillance processes and enhance system performance.

Informatics attributes of surveillance systems can be considered across the range of information technologies—from pencil-and-paper systems to computerized systems supporting remote data collection, real-time electronic data interchange, and data integration. Introducing information technologies within public health systems almost invariably results in a variety of impacts on the design of the public health surveillance system.

The evaluation should assess how well the public health surveillance system is integrated with other surveillance and health information systems (e.g., does the surveillance system rely on primary data collection or use protocols for data transformation and interchange to allow use of data that might be collected for other appropriate public health purposes [i.e., data re-use]?; is the system's information content represented using standard codes to support data interchange?). Evaluation of the processes of data collection and reporting might identify related information system protocols and surveillance processes that can be shared or standardized as the public health surveillance environment moves toward system interoperability and data integration.

Evaluation of the informatics aspects of surveillance information systems should identify the human and organization changes required to maximize the public health benefits afforded by information technology. When new information technology is introduced, its impact on system processes should be monitored to determine if proposed benefits have been realized. In communities with fixed public health funding, the costs of implementing new information and communication technologies must be weighed against the benefits of direct support for public health preparedness and response activities. Additionally, failure of new information technologies (e.g., inability to access or analyze key data elements) can lead to negative effects on the community and staff.",
grosecloseEvaluationSyndromicSurveillance2013,8518,Groseclose 2013,Evaluation of syndromic surveillance systems that use healthcare data.,Evaluation of syndromic surveillance systems that use healthcare data,2013,Samuel L. Groseclose,unknown,United States of America,Guidance for evaluating syndromic surveillance systems that use healthcare data,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Evaluation Step A: describing the existing or proposed system,"Surveillance system purpose and objectives

Responsibility for managing the system

Data sources and core data elements

 Legal authorities, confidentiality policies, and terms of collaboration

 Data transmission, storage, and security

 Syndrome definitions

Accommodating delayed information from clinicians

Statistical methods for aberration detection

 Determining alert notification criteria

 Display methods

 Response to alerts",Clearly state the purpose and objectives of the system; this information is often available from system planning documents and key informants familiar with the system.,"Responsibility for managing the system Who are the parties involved in managing the system?

Data sources and core data elements
What are the key automated healthcare data sources? Is healthcare access and standards change over time, it is important to evaluate how they affect the data source. Has the demographic or socioeconomic status of the patient population changed? Similarly, does the stage of epidemic illness or variable disease severity result in a shift in care from an outpatient to an inpatient care setting? What data elements are collected?

Legal authorities, confidentiality policies, and terms of collaboration
Under what legal authority are data collected, stored, and used? What policies are in place to protect against inappropriate or unauthorized release? Are data collection and management procedures compliant with applicable privacy or confidentiality laws? To what extent are data de-identified? Have agreements been established regarding access to additional information, including possible follow-back to patients, when investigations are warranted? When systems involve collaborations between health departments and university-based or commercial partners, how are data-sharing arrangements defined so that health departments can execute their legal mandate to investigate suspected epidemics?

Data transmission, storage, and security
How are data transmitted, including the frequency and timing of data transmission? What procedures are used to encrypt or otherwise protect data security during transmission? How are computer systems secured to protect against unauthorized access? Are system users with different roles (e.g., staff at facilities that provide data, public health officials in local or state governments) granted different degrees of access to detailed information? How is system access governed?

Syndrome definitions
How are indicators aggregated into syndrome categories? Among participating healthcare providers, does the manner in which the health information supporting syndrome classification [i.e., text-based chief complaint or International Classification of Diseases, 9th revision, Clinical Modification (ICD-9-CM) codes] is collected: (1) affect the sensitivity and specificity of the syndrome definition or (2) restrict the ability to classify information from a single healthcare encounter into more than one syndrome category? To what extent have syndrome classification criteria been validated? Is health outcome information for a single visit classified in only one or more than one syndrome category?


Accommodating delayed information from clinicians
Routine measurement and review of surveillance system performance indicators (e.g., the number of participating clinical sites reporting on a daily basis), timeliness of reporting (e.g., the interval between the patient's clinical encounter and report to the public health authority), and the completeness of reporting by facility or data element should be conducted.

Statistical methods for aberration detection
What statistical tests are employed? Do these methods test for temporal abnormalities alone or for temporal and geospatial clustering? Are epidemiologically relevant date types [e.g., date of first symptom(s) vs. date of data entry] available for analysis? What geographic data type (e.g., place of treatment, residence, exposure) and level of detail (e.g., three- or five-digit zip code) are available for analysis? How are thresholds set for triggering alerts?

Determining alert notification criteria
Health departments need to make three kinds of decisions about the types of alerts they wish to receive; each requires a value judgment. First, it is necessary to decide on alerting thresholds. It is necessary to decide which health department responders should receive notice of initial alerts, and who (if anyone) should receive the additional related alerts. Finally, it is necessary to determine the time interval considered when evaluating a potential outbreak period. 


Display methods
Effective visualization of the large amount of multidimensional data available from automated healthcare data sources is challenging. How are trend results, geographic patterns, and statistical alerts displayed? How is the user's attention focused on the key information provided by the system? How frequently are reports updated? To what extent does the system interface allow users to probe reported data in follow-up to an alert, e.g., review of individual records that constitute the alert signal? With effective data display methods and experienced epidemiologists routinely reviewing data analyses, many statistical alerts can be dismissed quickly.

Response to alerts
What procedures or policies have been established to determine whether, when, and to what extent follow-up investigations are conducted? Are findings from one data source interpreted in concert with findings from others? How is responsibility for human oversight assigned? Is sufficient information reported to allow follow-back to the reporting facility and patient for signal investigation and verification? Whois responsible for follow-up investigations? What has been the experience with investigations triggered by alerts? To what extent have epidemics detected by other means also been recognized by the system?","The purpose of the surveillance system indicates why the system exists; its objectives relate to how the data are used for public health action. The purpose and objectives of the system establish a frame of reference for evaluating specific system components.

 In 2010, the International Society for Disease Surveillance convened a workgroup of public health surveillance experts to define the current syndromic surveillance business processes and the minimum electronic health record-derived data elements to support core syndromic surveillance practice (Table 38.1).",Evaluation step B: assessing the attributes and performance of the system,"Simplicity 

Flexibility 

Data quality 

Acceptability

Sensitivity

Predictive value

Representativeness

Timeliness 

Stability",See Q18,See Q18,"Surveillance evaluation guidelines list a series of criteria (Table 38.2) that describe desirable attributes of surveillance. It is impossible for any system to achieve highest performance for all of these attributes, since some are mutually antagonistic.

The cost of conducting syndromic surveillance will be shaped by how these attributes are valued, and costs of systems may vary widely depending on the scope of data collection.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Objectives of syndromic surveillance for infectious disease syndromes:
- Identify in near real time cases and clusters of disease syndromes of public health importance
- Provide data for estimating the size, spread, and duration of outbreaks
- Support fast epidemiologic investigation, case management, and contact tracing
- Provide reassurance regarding the health effects of a recognized event (i.e., lack of signals in the presence of a known event)
- Provide ongoing, timely intelligence on public health threats or health conditions of interest (situation awareness)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"CDC 2001 [i.e., ""Acceptability reflects the willingness of persons and organizations to participate in the surveillance system"" ] / Groseclose 2010 [i.e., ""Reflects the willingness of persons and organizations to participate in the system""]",N/A,N/A,"From the perspective of data providers, are procedures for obtaining data non-intrusive and are the data useful for institution-specific purposes? For the public and policy-makers, is syndromic surveillance perceived as a wise investment of public resources and a warranted exercise of governments' authority to access health records?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Direct costs include the salary of personnel who operate the system and expenses associated with computing resources, establishing connections to data sources, and other operational expenses. Information on direct costs may be available from budgets submitted to funding agencies. There may be costs borne voluntarily by collaborating organizations, such as hospitals or others who provide data for syndromic surveillance, or these entities might require at least partial reimbursement for their efforts in establishing links with public health agencies. 

When syndromic surveillance systems produce alerts, there are indirect costs associated with follow-up efforts, both for pubic health agency staff and for staff at collaborating healthcare institutions, and these costs will be heightened by frequent false alarms. Some costs are intangible, such as potential loss of credibility for public health agencies if false alarms are excessive or if the promise of syndromic surveillance is unfulfilled.

Benefits of syndromic surveillance might include early indication of situations that herald epidemics, assurance that outbreaks are not occurring if rumors arise or if environmental sampling detects the presence of a suspect agent in air samples, and flexibility to monitor a spectrum of health threats beyond infectious disease.",N/A,CDC 2001 / Groseclose 2010,N/A,N/A,"Are the source data of sufficient quality and consistency to assure reliable use for the intended purpose?
Are variations in data quality apt to increase the likelihood of alerts that do not represent actual disease trends or decrease the likelihood of alerts when meaningful changes in actual trends occur?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001 / Groseclose 2010,N/A,N/A,"How readily can the system be adapted to meet changing information needs or priorities?

To what extent can users customize system utilities to suit local information needs or display preferences?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2001 / Groseclose 2010,N/A,N/A,"When systems send statistical alerts, what is the probability that alerts represent events that public health agencies are seeking to detect?",N/A,N/A,N/A,N/A,CDC 2001 / Groseclose 2010,N/A,N/A,To what extent is the pattern of disease detected by syndromic surveillance representative of the health of the population within a public health jurisdiction?,N/A,N/A,N/A,N/A,CDC 2001 / Groseclose 2010,N/A,N/A,"What percentage of epidemics or outbreaks targeted for detection are detected by the system?

Is the cost of syndromic surveillance justified by greater sensitivity (or timeliness or predictive value) than other epidemic detection methods?",CDC 2001 / Groseclose 2010,N/A,N/A,"To what extent is the system easy to access and use, from the perspectives of various users?",N/A,N/A,N/A,N/A,CDC 2001 / Groseclose 2010,N/A,N/A,Does the surveillance operation assure that observed trends reflect community health or health-seeking behavior and not variations in how data are collected or managed?,N/A,N/A,N/A,N/A,CDC 2001 / Groseclose 2010,N/A,N/A,Does the syndromic surveillance system provide alerts early enough to allow timely investigations and effective public health interventions?,N/A,N/A,N/A,"Assessing the usefulness of syndromic surveillance system: does the system . . .

- Detect trends indicating changes in occurrence of disease syndromes?
 Support early identification or ruling out of public health threats, conditions of public health importance, or suspected incident(s)?
- Detect outbreaks without duplicating findings from other surveillance activity (e.g., tracking and monitoring of non-reportable disease outbreaks)?
- Support estimation of the magnitude of morbidity and mortality related to the health condition(s) under surveillance?
- Stimulate investigations likely to enhance prevention and control?
- Assist in characterizing population groups at greatest risk?
- Assist in assessing the severity and magnitude of possible threat(s) and the effectiveness of control measures?
- Facilitate improved preparedness skills in health department staff through knowledge gained by establishing syndromic surveillance system, appropriate contacts, and health information exchange?
- Provide opportunities to establish relationships between health and public health sectors (e.g., generate information useful to alert physicians to unusual patterns in illnesses commonly seen in the community or inform diagnostic and therapeutic decisions)?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"8 Stoto MA, Dempsey JX, Baer A, et al. Expert meeting on privacy, confidentiality, and other legal and ethical issues in syndromic surveillance. Adv Dis Surveill 2009;7:2","Syndromic surveillance refers to the detection and monitoring of disease syndromes or manifestations (e.g., medication purchases, work or school absenteeism, emergency department use for specific clinical syndromes) that may be identified before diagnoses are established [1-3] (see also Chapter 32). 

Public health situation awareness has been defined as ""monitoring disease trends or other markers of community health in situations where there is a need for prompt information"" and refers to the public health authority's access to and use of the right information at the right time to enable effective response to emerging event.

Surveillance systems function best when data are routinely analyzed and interpreted (so that staff become familiar with system performance and learn through experience how to interpret signals), when stakeholders actively participate in the surveillance process and find value from their participation, and when action is taken in response to surveillance findings (demonstrating the value of surveillance).

Syndromic surveillance therefore continues to fill a niche for early detection of large epidemics, but practitioners are increasingly aware that this technology is better suited to characterizing, as opposed to detecting, outbreaks that generate weak signals.

Questions that syndromic surveillance evaluations should consider include the following:
- What types of epidemics can be detected?
- What is the frequency of routine analyses of the syndromic surveillance data? What is the nature of the routine analysis?
- Which syndrome definitions and statistical alert criteria are used to assure the earliest possible event detection?
- Do the participating healthcare data sources provide adequate coverage of the population of interest to allow detection of emerging events or effective monitoring during response to a public health threat?
- What is the frequency of false alarms generated by the system? Is the false-positive alarm rate acceptable to assure that the event is not missed before it would otherwise be recognized?
- Do actions triggered by system alerts represent an effective use of public health resources?
- Has the automated nature of the data source and surveillance system resulted in changes to public health practice, e.g., automated data quality review or analysis and visualization?
 In anticipation or the presence of a public health threat, can the health outcomes monitored by the system be modified to better reflect the expected adverse health effects? Has this been done?
- How has information derived from syndromic surveillance been shared with the healthcare providers? What are their perspectives on the utility of these data?
- Does the system provide data for estimating the size, spread, and duration of public health threats?
- How has the information gathered been used in practice during various crises or events?
- Is the system providing the necessary information to support public health preparedness and response to emerging infectious disease threats?

This chapter focused on strategies for evaluating the utility of syndromic surveillance for early event detection and characterization and enhanced situation awareness. Evaluators should use their judgment in determining which questions raised in the chapter are most important for a particular evaluation. Given continued investments in syndromic surveillance and continued uncertainties about its value for early outbreak detection, further evaluation is needed to better define population, outbreak, and surveillance parameters associated with the sensitivity and timeliness of outbreak detection and the predictive value of system alerts. As the application of syndromic surveillance extends beyond epidemic detection and situation awareness to include other uses, new evaluation strategies utilizing qualitative and quantitative methods to compare surveillance attributes between systems will be necessary.",
groseclosePublicHealthSurveillance2017,890,Groseclose 2017,Public Health Surveillance Systems: Recent Advances in Their Use and Evaluation.,Public Health Surveillance Systems: Recent Advances in Their Use and Evaluation,2017,Samuel L. Groseclose,sgroseclose@cdc.gov,United States of America,Summary and guidance for evaluating public health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Guide immediate action for cases of public health importance (e.g., initiating investigations or interventions)","Measure the burden of a disease (or other health-related event) and monitor trends over time, including changes in incidence and the identification of high-risk populations",Support early detection and response to outbreaks or new or emerging health concerns,"Guide the planning, implementation, and evaluation of programs to prevent and control disease, injury, disability, or exposure to environmental hazards",Provide reassurance during periods of perceived increased risk that incidence of a health condition is not increasing,Evaluate public policy,Detect changes in health practices and the effects of these changes,Prioritize the allocation of health resources,Describe the clinical course of disease,Provide a basis for epidemiologic research,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ultimately, public health surveillance systems should produce information to guide public health decisions in many areas, including disease prevention, prevention program planning and management, health promotion, quality improvement, and resource allocation.

From a societal perspective, public health surveillance systems should increase the efficiency and effectiveness of the public health system, which is a primary determinant of population health.

From the perspective of the public health system, surveillance systems support all three essential functions of public health—assurance, assessment, and policy development (39).

These objectives should be tailored to the outcomes under surveillance, the intended uses of the information generated by the system, and the level (e.g., local, regional, national) of the public health system at which the surveillance system is functioning. 

Explicitly documented objectives for the surveillance system are also important for planning the system, evaluating system performance, and enabling continuous improvement of data and system quality. Surveillance objectives and budget should determine the number and type of data variables to be collected (e.g., demographic or behavioral data variables), including the required level of resolution of the data, the population under surveillance, the required timeliness of information for effective action or response, the frequency of data analysis and interpretation, and the resources required to support the surveillance system. Similarly, surveillance objectives should influence decisions about data collection, management, analysis, integration, dissemination, security, and privacy. It is best to identify inconsistencies between the objectives (and their implications for system design and performance) and resources at the planning stage so that one or the other can be adjusted accordingly.

Ultimately, a public health surveillance system's objectives indicate how the data are intended to be used for public health action.

-Surveillance systems have also been developed recently to monitor the presence, emergence, or evolution of infectious agents in the environment.
-The use of surveillance systems has also expanded in relation to communicable diseases, for example to monitor the impact of vaccination programs on viral evolution in order to inform vaccine design and maintain vaccine effectiveness.
-Many public health agencies have also chosen to actively monitor health communications and news media—especially during a public health emergency—both to refine the public health response and to inform decisions about the creation, alteration, or refinement of health or risk communication messages. Recognition that public health law and policy influence community health has led some organizations to establish surveillance systems to monitor the impact of public health laws and policies on communities, environments, and individuals.",N/A,N/A,Public health practitioners,N/A,N/A,N/A,Health care providers,N/A,N/A,N/A,Policy makers,N/A,N/A,N/A,Members of affected communities,N/A,N/A,N/A,Academia,N/A,N/A,N/A,Professional association,N/A,N/A,N/A,Private industry,N/A,N/A,N/A,Not-for-profit advocacy organizations,N/A,N/A,N/A,General public,N/A,"Increasingly, the general public can be considered a partner in the surveillance process.",none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Willingness of persons and organizations to participate in the surveillance system,N/A,"May be indicated by the participation rate of data providers, completeness of case report data, timeliness or frequency of data reporting, or responsiveness to requests for supplemental information on reported health events. Acceptability can be influenced by the time and effort required to complete and submit surveillance reports or by perceptions of the benefits derived from participation in the surveillance system.

Data of poor quality make the system less acceptable and potentially less representative of the population under surveillance.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Relationship between the expected outcomes and the costs of surveillance to achieve these outcomes.
Surveillance system costs include direct costs (personnel and material resources), indirect costs (resulting from preparedness and response to surveillance findings), and prevention benefits or costs from a societal perspective (e.g., effects of the information generated on decision making and population health).",N/A,"Assessment of surveillance resources typically focuses on direct costs. Because of the complexity of surveillance and response processes, it is usually difficult to define indirect costs. For some infectious disease surveillance systems, investigators have modeled the expected future costs of strategies for continued vaccination, surveillance, and other public health activities (82, 83).

Efforts to improve sensitivity, positive predictive value, representativeness, timeliness, and stability can
increase the cost of a surveillance system.",N/A,N/A,N/A,N/A,N/A,Completeness and validity of data in the surveillance system.,N/A,"Can be measured as the proportion of data intended to be collected that was actually collected (completeness) and the proportion of data entries that correctly reflect the true value of the data collected (validity). Includes proportion of unknown, invalid, and missing values for reported data elements. Validity may be estimated by the proportion of errors in surveillance system data compared to analogous data from one of the system's data sources.

Data of poor quality make the system less acceptable and potentially less representative of the population under surveillance.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ability of the surveillance system or its processes to adapt with little additional time or resources to changing epidemiologies, information needs, technologies, or clinical practices.",N/A,"Is best evaluated retrospectively by observing how the system has responded to new requirements or changes in surveillance processes or environment (e.g., new health-related events, case definition changes, modification of policies affecting the patient population eligible to receive care from participating reporting sources, or introduction of new information technologies).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Proportion of cases reported to the system that actually have the health condition under surveillance. For event-based surveillance, PVP represents the probability that a detected outbreak is of public health significance and requires response.",N/A,"Cases reported to the system must be investigated to determine if they represent true or confirmed cases of the health event under surveillance. Low PVP may be addressed by case definition revision, request of additional data, or staff training to increase reporting accuracy. For event-based surveillance, criteria denoting a real outbreak should be defined and the outcomes of investigations of potential outbreaks identified by the system should be monitored and characterized per outbreak definition criteria.

As sensitivity and positive predictive value approach 100%, a system is more likely to be representative of the population with the event under surveillance. However, as sensitivity increases, predictive value positive might decrease.",N/A,N/A,N/A,N/A,N/A,Ability of the system to accurately describe the occurrence of a health condition under surveillance over time and its distribution in the population by place and person.,N/A,"Representativeness is assessed by comparing the reported cases or events to all actual cases/events. Information on all cases/events is seldom available, but surveillance data representativeness can be described in terms of geographic coverage, demographic distribution, and clinical manifestation of the health conditions under surveillance that were reported to the surveillance system. For example, is there uneven distribution of reported cases/events based on our understanding of the epidemiology of the health condition in the population
under surveillance?

Data of poor quality make the system less acceptable and potentially less representative of the population under surveillance.",N/A,"Processes and methodologies to keep surveillance data and information confidential, available, and accurate.",N/A,Surveillance system security policies and practices should be reviewed to ensure that security levels and procedures for surveillance system data or system access are defined and enforced; data use and release policy and protocol is available; and access to the surveillance system software application is controlled.,N/A,"Sensitivity of a surveillance system to (a) case detection (proportion of individuals who have the condition of interest), (b) outbreak detection (probability that the surveillance system will detect a significant increase in a health condition in time or space), and (c) case definition (ability of the case definition criteria to accurately represent the health condition of interest and classify the cases to which it is applied).",N/A,"Case detection sensitivity can be measured by the number of cases reported to the surveillance system divided by the number of cases in the population under surveillance. Outbreak detection sensitivity may be estimated retrospectively (e.g., were outbreak cases reported to the system? Was the temporal or spatial association of the cases noted prior to outbreak recognition from some other data source?) or prospectively (e.g., is an observed increase in case reports indicative of an outbreak requiring response?). Simulated or authentic data may be used to determine the characteristics of outbreaks that can be identified by the system (e.g., some absolute number of cases in time and space) or statistically derived thresholds (e.g., based on standard deviations). Sensitivity of the case definition depends on (a) the health condition under surveillance; (b) our knowledge of the epidemiology of the condition; (c) our ability to describe the condition based on clinical signs and symptoms, laboratory criteria, or epidemiological criteria; and (d ) the availability of relevant data elements in the surveillance system's data sources.

As sensitivity and positive predictive value approach 100%, a system is more likely to be representative of the population with the event under surveillance. However, as sensitivity increases, predictive value positive might decrease.",N/A,Structure and ease of operation of the system across the surveillance process cycle from data collection to use. Systems should be as simple as possible while still meeting their objectives.,N/A,"May be characterized in terms of (a) availability, amount, and type of data elements needed to characterize health events under surveillance; (b) number and type of organizations providing and using the data monitored; (c) number and type of data interchanges and transformations within the system; (d ) data provider and system operator training requirements; and (e) type of information technologies used by the system.",N/A,N/A,N/A,N/A,N/A,"Ability to collect, manage, and provide data without failure (reliability) and to be operational when needed (availability).",N/A,"Measures for determining stability can include the number or duration of unscheduled outages of the information system(s) supporting the surveillance system; the comparison of the desired and actual amount of time or resources required for the system to collect, manage, analyze, interpret, and release data from the system; or the presence or absence of continuity of operations procedures intended to maintain system performance.",N/A,"Use of data exchange, messaging, or other information technology standards by a surveillance system that enhances the ability of the system and its software applications to communicate, exchange data, and use the information that has been exchanged.",N/A,"Determine whether the system uses data standards (e.g., ICD, LOINC, or SNOMED)b as valid values for appropriate data variables or has the ability to translate its variable values to data standard concepts; determine whether the system uses standard data interchange protocols (e.g., Health Level 7) to exchange data with other information systems.",N/A,Time between any two steps in the surveillance process. Steps in the surveillance process will vary by system. The relative importance of timeliness of surveillance process intervals varies by surveillance objective and health event under surveillance.,N/A,"For systems aiming for early detection of events of public health concern, timeliness assessment should focus on the detection of the hazard or agent causing the health condition or the identification of symptomatic individuals when they first seek care. For other systems, timeliness measures may indicate time to initiate interventions based on information derived from the system or time to accumulate sufficient information on which to develop risk communications or clinical guidance. Timeliness is influenced by surveillance methods and data source(s).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"27. Eur. Cent. Dis. Prev. Control. 2014. Data Quality Monitoring and Surveillance System Evaluation: A Handbook of Methods and Applications. Stockholm, Swed.: Eur. Cent. Dis. Prev. Control. http://ecdc.europa. eu/en/publications/publications/data-quality-monitoring-surveillance-system-evaluation-sept-2014.pdf

66. Presley D, Reinstein T, Webb-Barr D, Burris S. 2015. Creating legal data for public health monitoring and evaluation: Delphi standards for policy surveillance. J. Law Med. Ethics 43:27-31","Public health surveillance systems generate information that drives action, and the data must be of sufficient quality and with a resolution and timeliness that matches objectives.

Surveillance, a core function of public health practice, is defined as ""the ongoing, systematic collection, analysis, and interpretation of health data essential to the planning, implementation, and evaluation of public health practice, closely integrated with the timely dissemination of [this information] to those who need to know"" and act upon that information. 

A surveillance system, in turn, is a collection of processes and components that enable public health practitioners to conduct surveillance. Surveillance processes include data collection, data quality monitoring, data management, data analysis, interpretation of analytical results, information dissemination, and application of the information to public health programs. A surveillance system, in turn, is a collection of processes and components that enable public health practitioners to conduct surveillance. Surveillance processes include data collection, data quality monitoring, data management, data analysis, interpretation of analytical results, information dissemination, and application of the information to public health programs. 

Surveillance processes include data collection, data quality monitoring, data management, data analysis, interpretation of analytical results, information dissemination, and application of the information to public health programs. The enabling components of surveillance systems may include laboratory diagnostics to detect or confirm health conditions; information technologies to support the surveillance processes of data collection, analysis, and dissemination; clinician consultation and reporting; clinician, public health, and laboratory worker education and training; legislation, regulations, and policies that support the conduct of surveillance; systems and directories for disseminating alerts, bulletins, clinical guidelines, and prevention recommendations; program administration and management; and human factors (e.g., multisector communications and relationships) (54). Ultimately, public health surveillance systems should produce information to guide public health decisions in many areas, including disease prevention, prevention program planning and management, health promotion, quality improvement, and resource allocation. 

Public health organizations often conduct surveillance under a legal mandate, but to maintain the public's trust, they must conduct surveillance in a manner that is responsible and of sufficient quality to inform population health improvement. The substantial public and private sector investment in surveillance also demands that the data collected by surveillance systems be used and that stakeholders perceive the system to be useful. Stakeholders may contribute data or resources to a surveillance effort, act upon the information generated, or use surveillance information to advocate for prevention and control efforts to improve population health. 

Engaging with a variety of system stakeholders during system planning, design, implementation, and evaluation encourages broad-based ownership of the surveillance activity and allows the economic, social, and cultural factors that influence prevention and control to be identified and addressed, increasing the likelihood that the information generated by the system will be useful.

For surveillance systems to achieve their greatest impact, it is necessary to identify system stakeholders, understand their roles (e.g., contributing data or advocating for assistance to those affected by the health outcome under surveillance), and engage them throughout the surveillance process (21). Prior to the initiation of surveillance, the stakeholder input, such as the information sought for decision making, may inform the definition of system objectives. When the surveillance system is active, stakeholders can help interpret the reported data based on their knowledge of the health outcome or the environment in which the data are collected. They may also respond to the information generated by the surveillance system and recommend and influence surveillance system evaluation to ensure the system is meeting its objectives.

Surveillance data analysis and interpretation should directly support the surveillance system objectives and be performed in alignment with surveillance system processes. The content and structure of a valid surveillance system should be defined and monitored to ensure that quality data are received and available for analysis. For example, surveillance data quality review should be initiated as data arrive and conducted at each data update.

Performance monitoring and the evaluation of surveillance systems are complementary processes conducted by public health practitioners and other surveillance system stakeholders. Surveillance system performance is monitored through the ongoing assessment of surveillance processes, such as by following the completeness and timeliness of data collection and reporting. Evaluation focuses on whether the system is meeting its objectives and making effective use of its resources. Both monitoring and evaluation can identify opportunities for surveillance system performance improvement, and both provide information on performance to aid the interpretation of data.

Key surveillance attributes [e.g., sensitivity, positive predictive value, and representativeness (Table 3)] influence the relevance, effectiveness, and impact of the surveillance system. The attributes of public health surveillance systems are related to one another; strengthening one system attribute could adversely affect another attribute of a higher priority. 

Informatics offers to enhance data quality and system efficiency and effectiveness.

Quantifying the costs and the effectiveness of innovations in public health surveillance systems would provide decision makers with highly relevant evidence to guide the allocation of resources.

Informatics offers the opportunity for development of controlled terminologies and ontologies for public health surveillance and public health practice in general - allowing for the establishment of common terminologies to facilitate comparative research. Informatics also offers the opportunity to enhance public health surveillance by enabling new ways to engage the public. Another novel use of informatics to enhance surveillance is through social media. Much of the research on this approach has focused on passive monitoring of social media data, such as Twitter, to measure disease activity, health behaviors, or adverse events.
",
hallSettingStandardsEvaluation2007,1987,Hall 2007,Setting standards and an evaluation framework for human immunodeficiency virus/acquired immunodeficiency syndrome surveillance.,Setting Standards and an Evaluation Framework for Human Immunodeficiency Virus/Acquired Immunodeficiency Syndrome Surveillance,2007,H. Irene Hall,unknown,United States of America,Setting standards and developing an evaluation framework for HIV/AIS surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,CDC activities,Develop technical guide and data quality standards in collaboration with the CSTE. Assess (1) data quality by using outcome standards and (2) processes by using process standards. Provide assessment results to state/local surveillance program. Conduct training and technical assistance on the basis of technical guide and needs determined from assessment of data and processes,N/A,N/A,N/A,State/local health department activities,"Collect information on HIV/AIDS cases.

Enter and edit data.

Submit data to the CDC.

Strengthen processes on the basis of assessment results.",N/A,N/A,N/A,Expected short-term outcomes,Data meet standards,N/A,N/A,N/A,Expected long-term outcomes,"Data disseminated in surveillance reports provide accurate picture of HIV transmission and disease burden.

Data are used to better target prevention efforts and appropriately allocate CARE Actb funds.

Prevention and care lead to decreased HIV transmission, longer survival, and increased quality of life among HIV-infected persons.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The evaluation framework allows for continual quality improvement to meet data standards, encompassing (1) technical guidance to improve data; (2) measurement of performance; (3) reporting of assessment results to state and local health departments and review by the CDC; and (4) based on findings, training, and technical assistance to surveillance programs and integration of any changes needed into the technical guidance to improve processes.

The evaluation framework is a tool for improving surveillance programs and, therefore, improving the data collected by these programs. Outcome standards are set to indicate the minimum level at which data can be reliably used for analyses; the data are evaluated for each diagnosis year at the specified time for all cases that meet the case definition for HIV infection or AIDS. These tools allow comprehensive assessments of whether reported HIV case data are adequate, reliable, and sufficiently accurate for determining CARE Act funding and priority populations for HIV prevention interventions and funding.

Article is not very clear and framework appears to rather broad and simple.",
harperImprovingAboriginalHealth2011,1659,Harper 2011,Improving Aboriginal health data capture: evidence from a health registry evaluation.,Improving Aboriginal health data capture: evidence from a health registry evaluation,2011,S. L. HARPER,harpers@uoguelph.ca,Canada,Evaluate the health registry's utility and system attributes using CDC 2001 guidelines,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",a. Public Health,Canada,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Health registries and surveillance systems that monitor health events are critical to public health practice for estimating the magnitude of a health problem, detecting outbreaks, understanding the natural history of a disease, examining disease distribution and spread, and evaluating control measure.",N/A,Health officials from community and regional levels,N/A,N/A,"Seven key E-Book stakeholders were invited for confidential in-person, on-site, interviews. The interview guide was pre-tested for content with epidemiologists and academics, and for context with health professionals in the region.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Willingness to participate in the system,Qualitative: key-informant interview,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Completeness of data recorded; Validity of data recorded
",Qualitative: key-informant interview,"Paper-based systems, such as the E-Book registry, are more prone to human error, and can result in illegible, missing, and incomplete entries

An electronic system could increase data quality. Moreover, conversion to an electronic system would improve the timeliness, accessibility, and usability of captured data, as well as allow greater flexibility in responding to health events in a community",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Ability to adapt to changing information needs or operating conditions,Qualitative: key-informant interview,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The proportion of reported true cases,Not evaluated (was no other appropriate source of IGI data in northern Labrador with which to compare the IGI data captured by the E-Book registry),N/A,N/A,N/A,N/A,N/A,N/A,The ability to describe a health event's distribution in the population by place and time,Qualitative: key-informant interview,N/A,N/A,N/A,N/A,N/A,N/A,The proportion of true cases detected by the system,Not evaluated (was no other appropriate source of IGI data in northern Labrador with which to compare the IGI data captured by the E-Book registry),N/A,N/A,"System design; System ease of operation
",Qualitative: key-informant interview,N/A,N/A,N/A,N/A,N/A,N/A,Reliability to operate without failure; Availability of information to be used by system stakeholders,Qualitative: key-informant interview,N/A,N/A,N/A,N/A,N/A,N/A,Speed between steps in the system,Qualitative: key-informant interview,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The CDC's Guidelines were used in this evaluation because of the clear focus on stakeholder engagement.,N/A,N/A,N/A,"Evaluations of health data collection systems used in Aboriginal populations are especially critical due to a recognized lack of good quality health data in some communities. In some countries health databases and registries do not capture ethnicity/cultural# data that would allow for targeted investigations of their Aboriginal population's health. Furthermore, even when ethnicity/cultural information is collected in population health databases, the quality of data captured on Aboriginal health can be compromised by lack of uniform reporting, incomplete records, high monetary costs of patient follow-up, and lack of coding validity.

The CDC guidelines recommend examining nine system attributes (Table 1), two of which, sensitivity and positive predictive value, were not evaluated because there was no other appropriate source of IGI data in northern Labrador with which to compare the IGI data captured by the E-Book registry.

ICD training for nurses, PCAs, and clerks in these communities in order to make coding easier to understand and more efficient is seen as critical in avoiding coding errors and compromising data quality. Furthermore, training courses should be designed to be accessible and appropriate, especially in the context of training in remote communities. Involvement of multiple stakeholders in the design of training modules is needed to ensure cultural respect, local relevance, appropriate language(s), suitable learning platforms and pedagogy (e.g. in-person vs. online training), and accessibility and affordability to all end-users and trainees.",
haworth-brockmanOneHealthEvaluation2021,238,Haworth-Brockman 2021,"One Health Evaluation of Antimicrobial Use and Resistance Surveillance: A Novel Tool for Evaluating Integrated, One Health Antimicrobial Resistance and Antimicrobial Use Surveillance Programs.","One Health Evaluation of Antimicrobial Use and Resistance Surveillance: A Novel Tool for Evaluating Integrated, One Health Antimicrobial Resistance and Antimicrobial Use Surveillance Programs",2021,Margaret Haworth-Brockman,margaret.haworth-brockman@umanitoba.ca,Canada,"Development of a One Health Evaluation of Antimicrobial Use and Resistance Surveillance (OHE-AMURS) tool to evaluate progress toward integrated, One Health surveillance of antimicrobial resistance (AMR) and antimicrobial use (AMU) as a complex system in Canada","a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Common program sustainability elements,Funding; organizational capacity; partnerships; program adaptability; communications; strategic planning; enabling policy,"The matrix for the One Health Evaluation—Antimicrobial Use and Resistance Surveillance (OHE-AMURS) tool ranks each common program sustainability element based on the stage of implementation. The five stages are 1-Exploration, 2-Program adoption, 3-Initial implementation, 4-Full operation, 5-Sustainable operation. Only the example rankings for 5-sustainable operation were extracted for Q18.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Funding,N/A,N/A,"Permanent, dedicated funding that enables long-term program planning (not time-limited)",Organizational capacity,N/A,N/A,"Permanent, dedicated resources to effectively manage program over long-term",Partnerships,N/A,N/A,"Long-term, formal connections in place",Program adaptability,N/A,N/A,"Program can improve, expand, and respond to emerging threats",Communications,N/A,N/A,"Strategic and timely dissemination of program outcomes and activities with stakeholders, decision-makers and public",Strategic planning,N/A,N/A,"Program direction, goals and strategies in place and subject to regular review",Enabling policy,N/A,N/A,Policy allows for effective and efficient data sharing and standardization among F/P/T; respects and includes all relevant stakeholders,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"One potential weakness is that in a few instances our evaluation criteria ranked program components highly, but in fact the components were not comprehensive by our own assessment. It became clear that our evaluation tool was missing a means to assess the scope and comprehensiveness of program elements. Some elements ranked highly when using the stage of development definitions, but ultimately were too limited in scope to be considered truly comprehensive and integrated for national AMR/AMU surveillance for Canada. We recommend that for future applications, every program element be evaluated for scope and comprehensiveness using a ranking system such as: Sufficient, Partial, or Insufficient. The criteria should be defined as part of the evolution of this novel tool for future AMR/AMU
surveillance program evaluations.",N/A,N/A,"1. McGill E, Marks D, Vanessa E, Penney T, Petticrew M, Egan M. Qualitative process evaluation from a complex systems perspective: a systematic review and framework for public health evaluators. PLoS Med. (2020) 17:e1003368. doi: 10.1371/journal.pmed.1003368

22. Aenishaenslin C, Hasler B, Ravel A, Parmley EJ, Mediouni S, Bennani H, et al. Evaluating the integration of one health in surveillance systems for antimicrobial use and resistance: a conceptual framework. Front Vet Sci. (2021) 8:611931. doi: 10.3389/fvets.2021.611931

27. Home Page. CoEvalAMR. Available online at: https://coevalamr.fp7-risksur.eu/ (accessed May 25, 2021).","Program Requirements and their Components for Integrated, One Health AMR/AMU surveillance in Canada:

1. National integrated AMR/AMU surveillance -system
- Federally coordinated, cross-sectoral, integrated system of AMR/AMU surveillance
- Standardized surveillance definitions, metrics, and performance indicators across provinces, territories, and federally
- Support for integrated provincial and territorial initiatives

2. Maintain and increase resources for existing AMR/AMU surveillance programs
- Resources/funding: multi-sector plan for comprehensive surveillance

3. National AMR data warehousing initiative
- AMR data warehouse (AMR NET; based on the EU model)

4. National human AMR and AMU surveillance 
- AMR surveillance (Human nosocomial pathogens CNISP; foodborne pathogens in humans CIPARS)
- AMR surveillance for other human pathogens (e.g., pathogens not covered by CNISP/CIPARS, community-acquired pathogens)
- Centralized collation of hospital AMU data (CNISP is the only AMU program evaluated)
- Human antimicrobial distribution And prescribing data (IQVIA data)
- Non-CNISP point prevalence surveys of AMR and AMU in hospitals (CNAPP, academia, pharmaceutical, and WHO projects)

5. National animal AMR and AMU surveillance
- Collaborative national working group on animal AMR/AMU surveillance
- CIPARS—antimicrobial sales/distribution data for animals
- CIPARS Farm-level AMR/AMU surveillance—swine, broilers, chickens and turkeys
- CIPARS Farm-level AMR/AMU surveillance—feedlot cattle (Canadian fed-cattle (feedlot cattle) antimicrobial surveillance program—CanFASP).
- Canadian dairy network for antimicrobial stewardship and resistance—farm-level AMR/AMU data
- Farm-level AMR/AMU surveillance—cow-calf
- Veterinary or farm-level AMR/AMU surveillance for remaining food and companion animals (small animals, equine)
- Department of fisheries and oceans collection of AMU data from aquaculture producers in Canada
- CIPARS animal clinical, abattoir and retail AMR components
- AMR Surveillance of veterinary pathogens
- Reporting requirements for antimicrobial susceptibility data from vet labs (AMR Net)
- AMR Surveillance in soil and water
- CIPARS Crop AMU surveillance
- CIPARS Aquaculture AMU surveillance

6. Collection of antimicrobial use indication data 
- Swine/broiler chicken/turkey on-farm programs provide indication data (CIPARS)
- Beef feedlot indication data (CIPARS)
- Canadian dairy network for antimicrobial stewardship and resistance (CaDNetASR)
- Veterinary prescribing surveillance (CVMA project)
- Human antimicrobial indication data (primarily CARSS IQVIA data: other sources under consideration)

7. Timely and integrated national reporting of AMR/AMU data
- CARSS—human and animal AMR/AMU report
- CIPARS—human and animal AMR/AMU report
- CIPARS Interactive display dashboard for human and animal AMR/AMU reporting

8. Formal recognition of one health policy for antimicrobial stewardship
- Policy to recognize ""One Health"" as a priority for Canada
- Legislated requirement for animal antimicrobial sales reporting by all manufacturers, importers and compounders of 2019
- Elimination of the ""Own Use Importation"" provision for medically important antimicrobials
- Elimination of non-approved ""active pharmaceutical ingredient"" use and importation of medically important antimicrobials

We identified a public health framework developed by Schell et al. to assess the ""sustainability capacity"" of public health program components (24). Schell et al. defined sustainability capacity as, ""the existence of structures and processes that allow a program to leverage resources to effectively implement and maintain evidence-based policies and activities"" (emphasis added).

We combined the five elements of program sustainability with the seven stages of program development (Figure 1) into a final OHE-AMURS matrix with and developed definitions for each (Table 3). This novel matrix allowed us to assess progress made toward the eight requirements for national, integrated AMR/AMU surveillance in Canada.

The common program elements for evaluation are in the left column and the rankings for stages of program development are in the top row. Criteria for every element-stage combination rank are defined. Criteria are adapted from Parathon et al. and rankings are adapted from Schell et al. F/P/T, federal/provincial/territorial. Only the example rankings for 5-sustainable operation were extracted for Q18.

The tool allowed us to assess every component of the eight recommendations for integrated AMR/AMU surveillance with the granularity needed. There was, for example, clear utility in defining a temporal rank of ""stage of development,"" which also provided a built-in ""road map"" for what progress would look like and illuminates ultimate goals. The matrix is complex but it allowed us to conduct a nuanced assessment that was robust for iterative review. We found it was ultimately an exacting tool and a way to engage with stakeholders while ensuring transparency in our methods and in the results.",
hendrikxOASISAssessmentTool2011,5216,Hendrikx 2011,OASIS: An assessment tool of epidemiological surveillance systems in animal health and food safety,OASIS: an assessment tool of epidemiological surveillance systems in animal health and food safety,2011,P. HENDRIKX,pascal.hendrikx@anses.fr,France,Evaluation framework for animal health and food safety epidemiological surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Output1,"Output 1 is based on the SNAT method, some sections of which were modified.","A list of 78 assessment criteria describing the situation and operation of a surveillance system was produced (Table 1). These assessment criteria were divided into ten sections according to the structure and activities of a surveillance system. Each criterion was scored on a scale from 0 to 3 according to the level of compliance of the system under examination. Criteria were rated not applicable if not relevant to the surveillance system considered, this criterion was then not considered in the synthesis. Scoring was done according to a guide detailing, for each individual score, the situation in which that score should be awarded.
An example of a scoring guide for one criterion is given in Table 2.","Output 1 is based on the SNAT method, some sections of which were modified.","Three graphical assessment outputs were generated using a specific combination of the scores. Output 1 is a general overview through a series of pie charts synthesizing the scores of each section. Output 2 is a histogram representing the quality of eight critical control points. Output 3 is a radar chart representing the level reached by ten system attributes.
",Output 2,Output 2 is based on the CCP assessment method.,"A list of 78 assessment criteria describing the situation and operation of a surveillance system was produced (Table 1). These assessment criteria were divided into ten sections according to the structure and activities of a surveillance system. Each criterion was scored on a scale from 0 to 3 according to the level of compliance of the system under examination. Criteria were rated not applicable if not relevant to the surveillance system considered, this criterion was then not considered in the synthesis. Scoring was done according to a guide detailing, for each individual score, the situation in which that score should be awarded.
An example of a scoring guide for one criterion is given in Table 2.",Output 2 is based on the CCP assessment method.,"Three graphical assessment outputs were generated using a specific combination of the scores. Output 1 is a general overview through a series of pie charts synthesizing the scores of each section. Output 2 is a histogram representing the quality of eight critical control points. Output 3 is a radar chart representing the level reached by ten system attributes.
",Output 3,Output 3 is based on the surveillance system attributes developed by the CDC and WHO.,"A list of 78 assessment criteria describing the situation and operation of a surveillance system was produced (Table 1). These assessment criteria were divided into ten sections according to the structure and activities of a surveillance system. Each criterion was scored on a scale from 0 to 3 according to the level of compliance of the system under examination. Criteria were rated not applicable if not relevant to the surveillance system considered, this criterion was then not considered in the synthesis. Scoring was done according to a guide detailing, for each individual score, the situation in which that score should be awarded.
An example of a scoring guide for one criterion is given in Table 2.",Output 3 is based on the surveillance system attributes developed by the CDC and WHO.,"Three graphical assessment outputs were generated using a specific combination of the scores. Output 1 is a general overview through a series of pie charts synthesizing the scores of each section. Output 2 is a histogram representing the quality of eight critical control points. Output 3 is a radar chart representing the level reached by ten system attributes.

",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Epidemiologists,N/A,N/A,N/A,Developers and users of assessment methods,N/A,N/A,N/A,Surveillance system managers,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Objectives and scope of surveillance,N/A,N/A,"1.1 Relevance of surveillance objectives
1.2 Level of detail, precision and formalization of the objectives
1.3 Consideration of partners' expectations
1.4 Consistency of diseases under surveillance with the health situation (existing/exotic diseases or dangers)",Central institutional organization,N/A,N/A,"2.1. Existence of an operational management structure (central unit); 
2.2. Existence of an operational steering body representative of the surveillance partners (steering committee); 
2.3. Existence of a technical and scientific committee of the surveillance system; 
2.4. Organization and operation of the system as planned in the regulation, a charter or a formal agreement between partners; 
2.5. Frequency of central coordination meetings; 
2.6. Implementation of supervision activities by the central level over intermediate units; 
2.7. Adequacy of financial and material resources at the central level",Field institutional organization,N/A,N/A,"3.1. Existence of formalized intermediate units over the whole territory; 
3.2. Active role of the intermediate units in the operation of the system (validation, management, feedback); 
3.3. Implementation of supervision activities by the intermediate level; 
3.4. Harmonization of the activities of intermediate units; 
3.5. Adequacy of financial and material resources at the intermediate level; 
3.6. Existence of coordination meetings at intermediate level; 
3.7. Exhaustiveness or representativeness of coverage of the target population by agents in the field; 
3.8. Adequacy of financial and material resources of agents in the field",Laboratory,N/A,N/A,"4.1. Effective integration of the laboratory in the surveillance system; 
4.2. Adequacy of human, material and financial resources for diagnostic needs; 
4.3. Use of quality assurance for the laboratory analysis; 
4.4. Quality of work standardization between the different laboratories; 
4.5. Proportion of analyses subjected to inter-laboratory assay; 
4.6. Existence of an investigation unit to support agents in the field; 
4.7. Relevance of diagnostic techniques; 
4.8. Sensitivity of diagnostic techniques; 
4.9. Specificity of diagnostic techniques; 
4.10. Control of laboratory reagents; 
4.11. Technical level of data management in the laboratory; 
4.12. Laboratory analysis time period (formalization, standardization, verification, transfer of results to the central unit); 
4.13. Quality of returned results.",Surveillance tools,N/A,N/A,"5.1. Existence of a formalized surveillance protocol for each disease or danger under surveillance; 
5.2. Standardization of collected data; 
5.3. Relevance of measuring tools (excluding the laboratory tools); 
5.4. Sensitivity of case or danger definition; 
5.5. Specificity of case or danger definition; 
5.6. Simplicity of case or danger definition; 
5.7. Quality of completion of the investigation questionnaires; 
5.8. Relevance of samples; 
5.9. Standardization of samples; 
5.10. Quality of collected samples; 
5.11. Respect of the time period between notification of case or danger and returned result; 
5.12. Simplicity of the notification procedure; 
5.13. Simplicity of the data collection procedure; 
5.14. Acceptability for the data source or data collector of the consequences of a suspicion.
",Surveillance procedures,N/A,N/A,"6.1. Suitability of the surveillance procedures to the system objectives; 
6.2. Existence of passive (event-based) surveillance showing exhaustive and representative results; 
6.3. Existence of activities for the sensitization of data sources in passive surveillance; 
6.4. Relevance and suitability of active surveillance protocols; 
6.5. Surveillance of susceptible wildlife; 
6.6. Surveillance of vectors; 
6.7. Representativeness of sampling of targeted populations in active surveillance; 
6.8. Precision of results on active surveillance samples; 
6.9. Level of satisfaction of active surveillance completion rate.",Data management,N/A,N/A,"7.1. Suitability of data management to the needs of the surveillance system; (relational database, etc.); 
7.2. Time period of data entry in agreement with the objectives and; use of the results of the system; 
7.3. Specific, available and qualified personnel for data acquisition,; management and analysis; 
7.4. Adequacy of material and financial resources for data management and analysis; 
7.5. Efficient and formalized data verification and validation procedures; 
7.6. Complete descriptive data analysis; 
7.7. Exploitation of the data aligned with the needs of the system; (if possible regular and multidisciplinary);",Training,N/A,N/A,"8.1. Satisfactory level of graduation in epidemiology of the central unit members; 
8.2. Initial training implemented for all agents in the field on entering the system; 
8.3. Objectives and contents of the initial training for agents in the field aligned; with the operational needs for the surveillance; 
8.4. Regular refresher training organized; 
8.5. Adequacy of human, material and financial resources for training.",Communication,N/A,N/A,"9.1. Reports and scientific publications on the results of the surveillance published regularly; 
9.2. Feedback of the results of the individual analyses to the agents in the field; 
9.3. Regular distribution of a news bulletin; 
9.4. Systematic distribution to field agents of reports on the results of the system; (except bulletins); 
9.5. Existence of a communication system organized transversally and vertically; between the agents in the field (email, web, telephone, etc.); 
9.6. Consistent external communication policy; 
9.7. Adequacy of human, material and financial resources for communication.",Evaluation,N/A,N/A,"10.1. System performance indicators developed and validated by the managers of the system; 
10.2. Performance indicators regularly calculated, interpreted and distributed; 
10.3. External evaluation implemented; 
10.4. Implementation of corrective measures following evaluation.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Such a complete evaluation process needs to be further developed, especially in order to guide the users of the tool in the interpretation of its different outputs.
The scoring of each criterion and the use of the scoring guide clearly help to highlight the improvement margin and to formulate specific recommendations.
All these practical considerations validate the applicability and ease of use of a unique list of criteria to produce the various graphical outputs of the system. Nevertheless this decision needs to be analysed in relation to each output and the initial process that produced it. The relevance of the use of three different outputs also needs to be discussed.

No cost or cost-benefit analysis is proposed at this stage. Further development of the tool could, as a first stage, provide a system to quantify the cost of the improvements proposed in order to make it possible to simulate the cost-benefit of any improvement to be implemented.",N/A,N/A,"5. Lefrancois T, et al. CaribVET : Animal Disease Surveillance Network in the Caribbean. International Meeting on Emerging Diseases and Surveillance, Vienna, Austria, 2009, p. 127. 
6. Squarzoni C, et al. Epidemiological surveillance networks in 13 West African countries of the PACE: situation and evaluation of their operation in 2004. Epidemiologie et Sante Animale 2005; 69-80. 
7. Dufour B. Technical and economic evaluation method for use in improving infectious animal disease surveil- lance networks. Veterinary Research 1999; 30: 27-37. 
8. Dufour B, et al. Evaluation of the epidemiological surveillance network in Chad. Epidemiologie et Sante Animale 1998; 133-140.

11. World Health Organisation. Protocol for the evaluation of epidemiological surveillance systems. Geneva: WHO, 1997.

16. Centers for Disease Control. Guidelines for evaluating surveillance systems. Morbidity and Mortality Weekly Report 1988; 37: 1-18

18. World Health Organisation. Protocol for the assessment of national communicable disease surveillance and response systems. Guidelines for assessment teams. Geneva: WHO, 2001. 
19. World Health Organisation. Overview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases. Weekly Epidemiological Record 2004; 79: 322-325.","Three types of current assessment methods were used as a basis for the development of OASIS: (i) the Surveillance Network Assessment Tool (SNAT) developed in the Caribbean [5, 13], (ii) the CCP assessment method developed by Dufour [7] and (iii) the guidelines for evaluation of surveillance systems developed by the CDC and WHO [9, 11].

While Output 3 is directly useful for understanding the quality of a system (e.g. a lack of sensitivity clearly highlights a problem), Output 2 shows which CCPs could explain this situation and what margins there are for improvement, whereas Output 1 indicates what part and structure of the system needs to be targeted to modify this situation.

The OASIS package comprises a questionnaire, a list of assessment criteria, a scoring guide and a spreadsheet for scoring integration and the production of outputs. The complete assessment process for the implementation and interpretation of the outputs of the tool still needs to be developed.

The OASIS package is described here, however no supplemental files were provided. A link to the package was provided within the text but has since expired. Additionally, their package is not freely acceptable on their website. Their website is now centred around receiving training on the OASIS tool.",
heridaEconomicEvaluationsPublic2016,1010,Herida 2016,Economic Evaluations of Public Health Surveillance Systems: a Systematic Review.,Economic Evaluations of Public Health Surveillance Systems: a Systematic Review,2016,Magid Herida,m.herida@invs.sante.fr,France,Systematic review of economic evaluations of public health surveillance systems,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Among these, conjoint analysis (CA) could overcome to some extent the limitations and methodological issues discussed above. The theory behind this approach is that any product or good or service can be described by a set of characteristics and that the extent to which an individual places value on a product is determined by the level of these characteristics.34 CA asks individuals to state a preference by presenting competing scenarios with both desirable and undesirable characteristics of a product or a service. CA has been applied to health care and public health interventions such as HIV vaccine and cancer control strategies.35,36 More recently, CA was performed to prioritize zoonotic diseases of public health concern.37 CA has been also used to derive utility weight for QALY or to estimate willingness to pay for CB analysis.38 To our knowledge, the method has not been used for a PHSS and may be worth exploring. Indeed, this type of economic evaluation could help policy makers and health professionals elicit preferences and help estimate their willingness to pay for a surveillance system according to different system characteristics and performance. This technique may also be useful for estimating the non-use value of a surveillance program.39 This information could be useful to public health agencies and could help them to prioritize surveillance in a context of limited resources.",N/A,N/A,"14 World Health Organization. Evaluating the Costs and Benefits of National Surveillance and Response Systems: Methodologies and Options. Geneva: World Health Organization, 2005.

26 Huserau D, Drummond M, Petrou S, et al. Consolidated health economic evaluation reporting standards (CHEERS) statement. BMC Med 2013;11:80. doi: 101186/1741-7015-11-80.

33 McNabb SJ, Chungong S, Ryan M, et al. Conceptual framework of public health surviellance and action and its application in health sector reform. BMC Public Health 2002;2: 
34 Ryan M, Farrar S. Using conjoint analysis to elicit preferences for health care. BMJ 2000;320:1530-3.","Three main approaches, -cost-effectiveness, cost-utility and costbenefit analyses- were used for economics evaluations of PHSS in the studies selected in this review. Studies focusing on surveillance system's cost-effectiveness or cost-utility provide valuable information for comparing several surveillance strategies and ranking these same strategies among other medical or public health interventions.30 However, the benefit measured in these studies was limited to the number of health outcomes prevented by one surveillance strategy compared with another one.

The cost-benefit analysis studies reviewed here, all evaluated the benefits of surveillance by assessing the number of cases or deaths the particular system prevented, assigning a monetary value per case prevented or life saved. Classically, if the expenditures for installing and operating the surveillance system are equal to or less than those for treating patients then the system is considered cost-beneficial.31 This approach implies not only knowledge of the costs of the disease in both its acute phase and for chronic disease over the long term, but also a consideration of all clinical presentations from the mildest to most severe. Besides, assigning a monetary value to a live saved implies obtaining this information from the literature or implementing an ad hoc study Review Table 1 and Table 2 for overview of each included economic analysis.

 In this review, discrepancies were found between the different studies examined with respects to the type of costs included and with the definition of scope of the surveillance and/or response activities they considered. This highlights the practical obstacles to making standardized costs estimations of PHSS. The above mentioned WHO report14 suggests including both the costs of surveillance and response as the ultimate purpose of surveillance information is to inform public health decision-making and to guide response and control activities. A conceptual framework of public health surveillance and action comprising six surveillance core activities such as detection, confirmation or analyses and two public health actions (acute and planned responses) and four support activities such as communication and training has recently been developed.33 This framework aims at assessing the performances of PHSS and could also be useful for conducting standardized cost analysis for PHSS.

In this review, several of the studies examined included surveillance and response activities where the authors estimated the benefits of surveillance through the number of cases or deaths prevented by response activities. Nevertheless, this approach cannot be applied when the primary objective of the surveillance activities is not linked to immediate response as illustrated in the study of HIV cost-effectiveness. Although information coming from surveillance is crucial to guide prevention activities and to allocate funds, in that study the authors underlined their difficulties in quantifying the surveillance-specific benefits of the surveillance from all the benefits provided by the a wide range of prevention activities implemented in the specific public health HIV program.21

With respect to the CDC guidelines mentioned above for evaluating PHSS,12 costs and benefits of a surveillance system should be estimated in the light of many other criteria including the objectives and the utility as well as several technical performance attributes. The methods used in the selected studies did not take into account all these parameters and could therefore have led to an underestimation or an overestimation of the benefits of the surveillance if, for example, the objectives were not been reached or if some technical attributes such as timeliness did not meet the quality standards.",
hoinvilleProposedTermsConcepts2013,1353,Hoinville 2013,Proposed terms and concepts for describing and evaluating animal-health surveillance systems.,Proposed terms and concepts for describing and evaluating animal-health surveillance systems,2013,L.J. Hoinville,Linda.hoinville@ahvla.gsi.gov.uk; lindahoinville@ntlworld.com,United Kingdom,Proposed terms and concepts for describing and evaluating animal health surveillance systems,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Stakeholders include national and international veterinary authorities, livestock-industry and farmer organisations, and those responsible for designing and carrying out surveillance.

The intention was to gather a group of international experts in animal-health surveillance, including representatives from as many of the groups currently working on the development of surveillance methods as possible. We aimed to include experts with knowledge of different sectors, scientific disciplines and geographical locations - while limiting the number of participants to ensure that effective interaction was possible.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Support functions,"Organisation and management
Training provision
Performance monitoring and evaluation
Resource availability",N/A,System processes,"Data collection
Sampling strategy
Data storage and management
Communication and dissemination
Laboratory management
Data analysis",N/A,System function,"Stability and sustainability
Acceptability and engagement
Simplicity
Flexibility
Repeatability",N/A,Inclusion,"Coverage
Representativeness
Multiple utility (inclusion of multiple hazards hazards)",N/A,Data quality,"Data Completeness & correctness
Historical data",N/A,Evidence quality,"Sensitivity
False alarm rate
Timeliness
Bias
Precision",N/A,System performance,"Cost
Impact
Economic efficiency
Benefit",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ability to adapt to changing information needs or operating conditions with little additional time, personnel or allocated funds. Flexible systems can accommodate new health-hazards, changes in case definitions or technology, and variations in funding or reporting sources.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The extent to which the features of the population of interest are reflected by the population included in the surveillance activity. These features may include herd size, production type, age, sex or geographical location or time of sampling (important for some systems e.g. for vector-borne infection)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Sensitivity of a surveillance system can be considered on three levels. 

Surveillance sensitivity (case detection) refers to the proportion of individual animals or herds in the population of interest that have the health-related condition of interest and that the surveillance system is able to detect 

Surveillance sensitivity (outbreak detection) refers to the probability that the surveillance system will detect a significant increase (outbreak) of disease. This requires a clear definition of what constitutes an outbreak. 

Surveillance sensitivity (presence) -refers to the probability that disease will be detected if present at a certain level (prevalence) in the population.",N/A,N/A,N/A,"Refers to the surveillance system structure, ease of operation and flow of data through the system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Timeliness can be defined in various ways

This is usually defined as the time between any two defined steps in a surveillance system. The time points chosen are likely to vary depending on the purpose of the surveillance activity. For outbreak detection this can be defined using various time points (e.g. the time between exposure to the infectious agent and the initiation of risk-mitigation measures, or the time between when disease could have been detected and reported and the time when it actually was reported).

For planning purposes timeliness can also be defined as whether surveillance detects changes in time for risk-mitigation actions to reduce the likelihood of further spread.

The precise definition of timeliness chosen should be stated as part of the evaluation process.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Economic efficiency: Whether the surveillance system produces the desired effect without wasting resources. Three levels of economic efficiency can be defined:
- Optimisation: maximising the net benefit to society achieved by the allocation of scarce resources to animal-health surveillance and intervention to avoid losses resulting from animal diseases.
- Acceptability: ensuring that the benefits generated by a mitigation policy at least cover its costs. This is commonly assessed using cost-benefit analysis.
- Cost-minimisation: ensuring that a technical target for disease mitigation (e.g. time to detection) is achieved at minimum cost without quantifying the benefit in monetary terms. This can be assessed using cost-effectiveness or least-cost analysis.",N/A,N/A,N/A,False-alarm rate: Proportion of negative events (e.g. non-outbreak periods) incorrectly classified as events (outbreaks). This is the inverse of the specificity but can be more easily understood than specificity.,N/A,N/A,N/A,"Organisation and management: An assessment of organisational structures include whether the objectives are relevant and clearly defined and the existence of steering and technical committees whose members are representative of the surveillance stakeholders. The members of these committees should have appropriate expertise, clearly defined roles and responsibilities; these member should hold meetings (with minutes taken and kept)regularly to oversee the function of the system.",N/A,N/A,N/A,Training provision: Provision of adequate initial training and an ongoing program of training for those implementing the surveillance system,N/A,N/A,N/A,Performance monitoring and evaluation: Whether performance indicators are routinely used to monitor system performance and periodic external evaluations are used to assess the system outputs in relation to its objectives,N/A,N/A,N/A,Resource availability: An assessment of the financial and human resources available for implementing the surveillance activity including the expertise and capability of personnel,N/A,N/A,N/A,Data collection: The use of appropriate data sources and collection methods including automation of data collection where appropriate and the existence of a case definition and a data collection protocol,N/A,N/A,N/A,Sampling strategy: Use of appropriate sampling strategies including the use of risk-based approaches (i.e. risk-based requirement calculation or risk-based sampling) and pooled sampling where appropriate. The basis of the risks used in the design of the risk-based sampling strategy should be  assessed.,N/A,N/A,N/A,"Data storage and management: Appropriate use and documentation of data management systems for processing information, including data processing protocols, and effective use of data verification procedures and of data storage and back-up procedures",N/A,N/A,N/A,"Communication and dissemination: An assessment of the methods used and ease of information exchange between people involved at all levels of the surveillance system (providers, analysers and users of surveillance data). Include an assessment of the data and information provided and of the timeliness and types of outputs produced. The efforts made to disseminate these outputs including the use of web-based systemsshould also be assessed. The methods used to provide feedback to data providers and to increase their awareness about hazards and surveillance activities should also be assessed.Internal communication and dissemination is directed at those working within the surveillance network or system. External communication and dissemination is directed at those outside the surveillance network or system (e.g. international organisations).",N/A,N/A,N/A,Laboratory management: Whether testing is carried out using appropriate methods with quality assurance scheme and timely and accurate delivery of results,N/A,N/A,N/A,Data analysis: Whether appropriate methods are used for the analysis and interpretation of data at an appropriate frequency,N/A,N/A,N/A,"Stability and sustainability: The ability to function without failure (reliability), the ability to be operational when needed (availability) and the robustness and ability of the system to be ongoing in the long term (sustainability).",N/A,N/A,N/A,"Acceptability and engagement: Willingness of persons and organisations to participate in the surveillance system, and the degree to which each of these users is involved in the surveillance process including the participation of stakeholders in the steering and technical committees. Could include an assessment of stakeholder awareness of the system and their understanding of it. Could also assess their beliefs about the benefits or adverse consequences of their participation in the system including the provision of compensation for the consequence of disease detection",N/A,N/A,N/A,Repeatability: How consistently the study results can be reproduced over time.,N/A,N/A,N/A,Coverage: The proportion of the population of interest (target population) that is included in the surveillance activity,N/A,N/A,N/A,Multiple utility: Whether the system captures information about more than one hazard.,N/A,N/A,N/A,Data completeness and correctness: The proportion of data that were intended to be collected that actually was collected and the proportion of data entries that correctly reflect the true value of the data collected.,N/A,N/A,N/A,Historical data: Quality and accessibility of archived data.,N/A,N/A,N/A,"Bias: The extent to which a prevalence estimate produced by the surveillance system deviates from the value of the true prevalence. 
Bias is reduced as representativeness is increased.",N/A,N/A,N/A,"Precision: How closely defined a numerical estimate is. A precise estimate has a narrow confidence interval. Precision is influenced by prevalence, sample size and surveillance system quality.",N/A,N/A,N/A,"Cost: The evaluation should list and quantify each of the resources required to operate the surveillance system and identify who provides each resource. These resources could include: time, personnel, financial input and equipment.",N/A,N/A,N/A,"Impact: This indicates the changes that have been made based on the results of the surveillance providing a measur of the usefulness of the surveillance system in relation to its aims. This should include details of actions taken as a result of the information provided by the surveillance system (e.g. changes in protocols or behaviour, changes in mitigation actions and especially changes in disease occurrence.",N/A,N/A,N/A,Benefit: Direct and indirect advantages produced by the surveillance system. This does not need to be limited to financial savings and better use of resources but can also include any losses avoided due to the existence of the system and the information it provides. These avoided losses may include improved animal production; maintenance of a structured network of actors able to react appropriately against a future threat; improved public health; increased understanding about a disease; maintained or increased trade; or improved ability to react in case of an outbreak of disease.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"A complete list of all the proposed definitions including lists of characteristics that can be used to describe surveillance activities and attributes for evaluation of surveillance is available in the workshop report (available at http://www.defra.gov.uk/ahvla-en/disease-control/surveillance/icahs-workshop/). See supplemental file for definitions for common surveillance terms and characteristics - all attributes have been extracted. Attributes in grey shaded boxes in supplemental file were deemed more important.

Surveillance: The systematic, continuous or repeated, measurement, collection, collation, analysis, interpretation and timely dissemination of animal health and welfare related data from defined populations. These data are then used to describe health hazard occurrence and to contribute to the planning, implementation, and evaluation of risk mitigation actions.

Monitoring: The systematic, continuous or repeated, measurement, collection, collation, analysis and interpretation of animal health and welfare related data in defined populations when these activities are not associated with a pre-defined risk mitigation plan although extreme changes are likely to lead to action.

See Figure 1 to view the relationship between surveillance evaluation attributes - attributes in each outer circle tend to influence the value of those attributes in inner circles. Domains work in a hierarchical manner: support functions > system processes > system function > inclusion > data quality > evidence quality > system performance.

Agreed-upon definitions of surveillance terms will contribute to enhancing transparency and facilitating the exchange of data. Agreement upon key terms should facilitate comparative evaluation of surveillance activities and the selection of effective and efficient surveillance approaches for different purposes and situations. If stakeholders understand the value of the data collected and the impact of surveillance on animal and human health, this should lead to improved design of surveillance activities, enhanced compliance with data collection, increased likelihood of investment, and (ultimately) an increased probability of achieving the overall goal of the surveillance.

The provision of information about the purpose, methods and benefits of surveillance activities will be facilitated by the development of clear, agreed-upon definitions. This attempt to encourage the use of consistent terms in public- and animal-health will facilitate the communication required to allow the development of the ""one health"" approach (http://www.onehealthinitiative.com).",
innesEnhancingGlobalHealth2022,105,Innes 2022,Enhancing global health security in Thailand: Strengths and challenges of initiating a One Health approach to avian influenza surveillance.,Enhancing global health security in Thailand: Strengths and challenges of initiating a One Health approach to avian influenza surveillance,2022,Gabriel K. Innes,ginnes@arizona.edu,United States of America,Formal evaluation of a One Health avian influenza surveillance system in Thailand,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",d. One Health,Thailand,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001); k. Other,Three additional metrics developed by the authorship team and used to evaluate the surveillance system.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Robust surveillance systems support efforts to disrupt infectious disease transmission through early warning signals, disease control activities information, and contextual basis for contact tracing investigation.",N/A,"Animal sector (government agencies, academia, and the private sector)",N/A,N/A,"Key informants were identified by a roundtable discussion with experts from Thailand's Ministry of Public Health (MoPH) to ensure representation from all One Health and technical surveillance entities. The interviewees represented three divisions of the MoPH's Department of Disease Control (DDC), the Public Health Lab oratory (PHL) at the National Institute of Health (NIH), the National Institute of Animal Health (NIAH) Laboratory, the Department of Live stock Development (DLD), the Department of National Parks Wildlife and Plant Conservation (DNP), a collaborating private poultry corporation, and the MoPH-U.S. CDC Collaboration (TUC). Within the MoPH DDC, the Division of Epidemiology (DoE), the Office of International Cooperation (OIC), and the Coordinating Unit for One Health (CUOH) 
were interviewed. One leader involved with the surveillance system from each agency was interviewed.","Human sector (government agencies, academia, and the private sector)",N/A,N/A,"Key informants were identified by a roundtable discussion with experts from Thailand's Ministry of Public Health (MoPH) to ensure representation from all One Health and technical surveillance entities. The interviewees represented three divisions of the MoPH's Department of Disease Control (DDC), the Public Health Laboratory (PHL) at the National Institute of Health (NIH), the National Institute of Animal Health (NIAH) Laboratory, the Department of Livestock Development (DLD), the Department of National Parks Wildlife and Plant Conservation (DNP), a collaborating private poultry corporation, and the MoPH-U.S. CDC Collaboration (TUC). Within the MoPH DDC, the Division of Epidemiology (DoE), the Office of International Cooperation (OIC), and the Coordinating Unit for One Health (CUOH) 
were interviewed. One leader involved with the surveillance system from each agency was interviewed.","Environmental sector (government agencies, academia, and the private sector)",N/A,N/A,"Key informants were identified by a roundtable discussion with experts from Thailand's Ministry of Public Health (MoPH) to ensure representation from all One Health and technical surveillance entities. The interviewees represented three divisions of the MoPH's Department of Disease Control (DDC), the Public Health Laboratory (PHL) at the National Institute of Health (NIH), the National Institute of Animal Health (NIAH) Laboratory, the Department of Livestock Development (DLD), the Department of National Parks Wildlife and Plant Conservation (DNP), a collaborating private poultry corporation, and the MoPH-U.S. CDC Collaboration (TUC). Within the MoPH DDC, the Division of Epidemiology (DoE), the Office of International Cooperation (OIC), and the Coordinating Unit for One Health (CUOH) were interviewed. One leader involved with the surveillance system from each agency was interviewed.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Willingness to contribute to the surveillance system outside organization/sponsoring agencies,N/A,"Challenges:
* Lack of political will at the local level in other provinces without pre-existing collaborations",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Completeness and validity of data,N/A,"Challenges:
* Lacking integrated database(s) which hinders data sharing 
* Data from mobile application not automatically ingested into existing database 
* Potential introduction of errors from paper to digital entry",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Adaptability of the system is to modify practices with changes to information and technology,N/A,"Challenges:
* Human and animal laboratory networks encounter resource obstacles in surge situations (e.g. epidemics and pandemics) 
* Laboratory structure is currently vertically based upon pathogen type and species",N/A,N/A,N/A,N/A,N/A,Ability and ease for information to cross intra- and inter-agency boundaries,"The measure of a surveillance system's interoperability can be evaluated by multiple characteristics such as the interoperability of data from different sentinel hospitals collecting influenza data, stakeholders such as the government and private industry, and species such as humans and poultry.","Challenges:
* Surveillance data systems are not yet interoperable between species, geographic units, and pathogens 
* Multiple applications and programs exist both within agencies (from epidemiology to laboratory to administrative) and between agencies 
* No consistent formal communication technologies and pathways 
* Most information dissemination is paper based 
* Existence of three surveillance-related mobile phone applications that are unable to easily integrate data",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Accuracy of health related events described over time and distribution in population,N/A,"Challenges:
* Environmental sampling of water sources and of high- risk transmission environments are currently not conducted 
* Swine species are not monitored or surveyed 
* Only public hospitals conduct sentinel surveillance",N/A,Protective mechanisms to prevent data compromise,N/A,"Challenges:
* Paper data sources used for some system components 
* Hardcopy data can be easily compromised 
* Electronic systems do not have multiple layers of security",N/A,Ability of a system to detect a health event,N/A,"Challenges:
* Gaps in data to systematically measure sensitivity",N/A,Intuitive structure of surveillance system and ease of operation,N/A,"Challenges:
* Multiple formal and informal data sources for multiple species enter the system 
* Lacking an integrated, interoperable data system 
* Low level of integration of laboratories, non- human resources, and data 
* Effort and time to manage and disseminate samples and data are high",N/A,N/A,N/A,N/A,N/A,"Reliability of operations, especially under system stress",N/A,"Challenges:
* Human resources are limited at the laboratory level 
* Sample cold chain not always reliable across surveillance network 
* System lacking surge capacity, highlighted by the COVID-19 pandemic 
* Relies on external funding cycles",N/A,N/A,N/A,N/A,N/A,Estimated time between steps and timescale of system,N/A,"Challenges:
* Gaps in data to systematically measure timeliness 
* Samples may need to travel long distances to regional and central laboratories delaying reporting 
* Intensive laboratory assays delay surveillance processes (e.g. sample plating to viral isolation results may take up to 12 working days)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Transparency: Extent to which information can be and is shared across member agencies,N/A,"Challenges:
* Data is not consistently shared in real-time or on a scheduled basis apart from low frequency meetings",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Governments and international health organizations [22] have started to adopt One Health surveillance approaches to tackle global health security threats and support pandemic preparedness efforts. 
Surveillance systems that monitor influenza, a disease that experts have projected to be a leading zoonotic pathogen to cause future pandemics [27 - 29], should incorporate a One Health approach due to the pathogen's capacity to infect many animal species, demonstrated spillover, and potential for significant morbidity and mortality","[1] Institute of Medicine (US) Forum on Microbial Threats, Ethical and Legal  Considerations in Mitigating Pandemic Disease: Workshop Summary. 3 Strategies  for Disease Containment, Washington, DC. https://www.ncbi.nlm.nih.gov/books/  NBK54163/, 2007 (accessed December 15, 2020).

[19] A. Ruckert, K. Zinszer, C. Zarowsky, R. Labont, H. Carabin, What role for one  health in the COVID-19 pandemic? Can. J. Public Heal. 111 (2020) 641-644,  https://doi.org/10.17269/s41997-020-00409-z.","Successful surveillance systems benefit from strong collaborations between the laboratory and epidemiology sectors to ensure effective and rapid sample collection, pathogen identification, and the quantification of disease in a population. Surveillance systems evolve in parallel to public health threats and technologies, and these three new metrics facilitate assessing emerging surveillance system components that are critical to digital data collection, storage, and communication. 
Thailand's AI surveillance system structure can be further divided into five sequential components that monitor, analyze and respond to potential AI threats: 1) surveillance triggering events, 2) sample collection, 3) laboratory analysis, 4) data interpretation and sharing, and 5) communication and response activities. 
Thailand's AI surveillance system evaluation results were synthesized into re commendations with five areas of focus and specific aims for system strengthening (Table 2). 
The focus areas include: 
1) Integrate surveillance reporting and communication from the local (village, district, and province) to national levels 
* Adopt a unified One Health data management and surveillance system that integrates human, animal, and environmental health domains 
2) Increase integration between human and animal laboratories 
* Integrate laboratory resources and stakeholders through a One Health approach to build collaborations; optimize laboratory space, protocols, and equipment 
* Build partnerships between animal, human, and environmental laboratories 
3) Strengthen pathogen detection capabilities, flexibility, and resilience 
* Integrate rapid and multiplex pathogen detection technologies in the laboratory and the field 
* Increase throughput capacity of human resources, surveillance, and laboratory activities 
* Streamline data flow to increase surveillance capacity at local hotspots 
* Expand influenza surveillance to swine and potential environmental sources 
* Broaden pathogen detection to other critical zoonotic pathogens 
4) Implement an interoperable data management system 
* Adopt a reliable, easily accessible data integration and management system to improve data repositories and interoperability of One Health surveillance data 
* Allow for system to be implemented in all related sectors, including government, private, intergovernmental, non-profit, and academic stakeholders 
5) Sustainability and capacity building 
* Outline and commit to shared data and hardware ownership through cooperative or data- use agreements 
* Devote renewable monetary funds and human resources to shared surveillance system 
* Ownership may consist of a primary owner the permanent location of the system, shared- ownership, or rotating ownership with specified time periods 
* Empower current and future workforces at all levels 
* Integrate technologies that support recommendations, lower burden on workforces, and improve surveillance capabilities",
jajoskyEvaluationReportingTimeliness2004,2246,Jajosky 2004,Evaluation of reporting timeliness of public health surveillance systems for infectious diseases.,Evaluation of reporting timeliness of public health surveillance systems for infectious diseases,2004,Ruth Ann Jajosky,Jajosky@cdc.gov,United States of America,Review of literature and evaluation of reporting timeliness for a public health surveillance system,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,United States of America,l. No framework(s) or guidance document(s) were discussed,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Reasons for conducting public health surveillance can include the need to assess the health status of a population, establish public health priorities, and reduce the burden of disease in a population by appropriately targeting effective disease prevention and control activities.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Reporting timeliness,"To facilitate future comparisons of reporting timeliness across jurisdictions, studies should include an explicit description of the public health surveillance reporting process and the surveillance process interval being measured. Additionally, surveillance information systems must support the collection of appropriate reference dates to allow the assessment of the timeliness of specific surveillance processes.","Surveillance system timeliness depends on a number of factors and its assessment should include a consideration of how the data will be used and the nature of the condition under surveillance (e.g., for infectious diseases, this includes the communicability of the disease

If the data are to be used to implement immediate disease control and prevention activities for infectious diseases that are acute, severe, and highly transmissible, timeliness is critical. 

Timeliness requirements for a surveillance system might vary by different levels of public health system (e.g., local, state, or national), on the basis of the intended uses of the surveillance data at that level (Table 1).

Electronic reporting may increase reporting timeliness.

In addition to reporting timeliness, other surveillance system attributes are important to assess (e.g., completeness of reporting).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Public health surveillance is defined as the ""ongoing systematic collection, analysis, and interpretation of data essential to the planning, implementation, and evaluation of public health practice, closely integrated with the timely dissemination of these data to those who need to know"".

Timeliness is a key surveillance system metric and should be periodically evaluated because it can reflect the time delay between any number of response steps in the public health surveillance process. 

Before data can be used for public health action, health-related data must be collected by the public health system, analyzed, and disseminated to those responsible for taking action.

In seven of the eight papers, timeliness was calculated as the median reporting delay between the date of disease occurrence (e.g., disease onset date, diagnosis date, or laboratory result date) and the date the public health system was notified or as the proportion of cases reported to the public health system in a specific time interval. In one study [10], epidemic curves were compared for two influenza surveillance systems and timeliness was assessed as the time interval between the epidemic peaks noted in each system. In addition, two studies described the factors associated with delayed reporting.

The definition of reference dates used in the timeliness evaluations varied. The initial date associated with the case varied among date of disease onset, date of diagnosis, and date of positive culture result. The ending date for the timeliness studies evaluated was the date the case report was received by the public health system, whether at the local, state, or national level. This time period corresponds to the sum of Intervals 1 and 2 or Interval 2 alone for local or state timeliness studies (Figure 1). For national evaluations of timeliness, the time period assessed was the sum of Intervals 1, 2, 3, and 4 or only Intervals 2, 3, and 4 (with or without inclusion of Intervals 5, 6, 7, and 8, dependent upon state protocol).

Timeliness of reporting varied by disease and date type (Table 3). 

Few published studies evaluating surveillance systems presented timeliness measures. When timeliness was evaluated, standard methods were not used. Information collected by public health surveillance systems should support the quantitative assessment of timeliness by various steps in the pubic health surveillance process. Public health programs should periodically assess timeliness of specific steps in the surveillance system process to ensure that the objectives of the surveillance system are being met. A more structured approach to describing timeliness studies should be considered.

Published papers describing local or state surveillance system reporting timeliness generally do not explicitly describe the surveillance system processes contributing to the timeliness measure, such as processing and analyzing the data or implementing a public health action before data are reported from a state to CDC. To facilitate future comparisons of reporting timeliness across jurisdictions, studies should include an explicit description of the public health surveillance reporting process and the surveillance process interval being measured. Additionally, surveillance information systems must support the collection of appropriate reference dates to allow the assessment of the timeliness of specific surveillance processes.

A more structured approach to describing timeliness studies could include a description of the following characteristics: 1) the level of the public health system being assessed (e.g., local, state, or national), 2) the purpose of the surveillance evaluation, 3) goals of the surveillance system, 4) the surveillance interval being measured and a description of the reference dates that define the upper and lower boundaries of the surveillance interval, 5) the surveillance steps (processes or activities) that contribute to the surveillance interval being measured, 6) whether the measured timeliness met the needs of the surveillance step being evaluated, and 7) whether the timeliness met the goals of the surveillance system. No single timeliness measure will achieve the purpose of all evaluations or meet all the goals of the surveillance system. In addition, if the goal of the surveillance evaluation is to identify ways to improve timeliness, the analysis should identify factors associated with delayed reporting, such as the role of specific case ascertainment sources.

Other factors that might have contributed to reporting delay in our study included: the patient's recognition of symptoms; the patient's acquisition of medical care; the use of confirmatory laboratory testing; reporting by the health care provider or the laboratory to the local, county, or state public health authority; the volume of cases identified in the state; case follow-up investigations to verify the case report or to collect additional case information; periods of decreased surveillance system activity due to variable staffing levels; computer system down-time for maintenance, upgrades, or new application development; and data processing routines, such as data validation or error checking.

This highlights the importance of evaluating completeness and timeliness and other surveillance system attributes concurrently, before contemplating any changes to a surveillance system based on the assessment of a single attribute.",
lucero-obusanPublicHealthSurveillance2022,193,Lucero-Obusan 2022,Public health surveillance in the U.S. Department of Veterans Affairs: evaluation of the Praedico surveillance system.,Public health surveillance in the U.S. Department of Veterans Affairs: evaluation of the Praedico surveillance system,2022,Cynthia Lucero-Obusan,cynthia.lucero@va.gov,United States of America,Formal evaluation of the public health Praedico surveillance system with benchmarking against other systems,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",a. Public Health,United States of America,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,To analyze large data sets to discover patterns or trends which ultimately serve to facilitate the prevention or control of diseases.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Surveillance data are used to plan and implement health policy, evaluate public health practice, track diseases, disseminate information and monitor naturally occurring or intentional biological and environmental threats.

Principle objectives of the Praedico system include surveillance for known diseases of interest (both infectious and non-infectious), syndromic surveillance, emerging infections and to facilitate epidemiologic investigations conducted by PHPO.",N/A,"Epidemiologists who are subject matter experts in infectious diseases, surveillance, and public health informatics",N/A,N/A,"A national public health surveillance strategy calls for cooperation on a federal, state, and local level in combination with private sector entities and non-governmental organizations.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Acceptability refers to the willingness of persons and organizations to participate in the surveillance system.,N/A,"Features [of Praedico] that contribute to acceptability among users of the system are simplicity, speed, flexibility, and other key attributes described earlier, such as alerting, automation, analytic and visualization capabilities, and a straightforward user interface. 

One additional element [of Praedico] that increases acceptability is the user workspace. Here users can run and save queries that span multiple datasets, set alerts, request and share reports, and more. Saved queries can be executed, modified, duplicated, deleted, or shared. Workspaces are customizable, creating a dynamic dashboard that organizes queries in user-defined groupings.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Data quality measures the completeness and validity of the data in a system.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Flexibility reflects the way a system adapts to changing information needs, technology, or operating conditions.",N/A,"Highly flexible systems adapt with relatively little time, personnel or additional funds and can be integrated with other systems.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,PVP describes the proportion of disease cases in a system that are true cases.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Representativeness refers to how well a system accurately describes occurrence of health events over time, and distribution in the population.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,Sensitivity is best described as the proportion of cases of a disease that the system identifies as well as the ability of the system to detect outbreaks or monitor changes in cases over time.,N/A,N/A,N/A,Simplicity refers to structure and ease of system operation.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Stability focuses on reliability and availability of the surveillance system,N/A,Stability is also reflected in resilience to system changes,N/A,N/A,N/A,N/A,N/A,Timeliness considers the speed between steps in the system and how quickly data is made available.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The CDC 2001 public health surveillance systems evaluation guidelines [19] remain a valuable framework for assessing surveillance systems. Now that 20years have passed, it would be beneficial to have additionally updated and expanded guidelines. First, a more comprehensive list of attributes with greater flexibility, prioritization, and guidance as to how to select the best complement of attributes for review would be helpful. This would allow the review process to better align with objectives of the evaluation and to consider nuances or constraints of a system as well as stakeholder-specific system needs that impact which attributes are most relevant to evaluate and optimize. or example, an assessment of value (including IT and system costs, funding, and impact) would have been useful for this evaluation. Additionally, effectiveness including an assessment of how well the system can identify meaningful correlations between different data sets or data domains, would be another important area for evaluation in our system. These along with organizational assessments (such as data management and security) and additional functional assessments (such as inter-agency data sharing), we would recommend for inclusion in future evaluations of Praedico.",N/A,N/A,N/A,"Public health surveillance involves the ongoing collection, analysis, and interpretation of health-related data.

To facilitate inter-agency cooperation, systems need to be able to adapt to and integrate disparate data sources and technologies and handle big data. Such a system must be flexible, simple to use, reliable, timely, accurate, and intelligent.

The purpose of public health surveillance systems is to analyze large data sets to dis-cover patterns or trends which ultimately serve to facilitate the prevention or control of diseases. Key to this are systems deemed to be flexible, easy to use, secure, reliable and cost-effective to give decision makers timely access to the data they need. 

Surveillance data meets the definition of big data, due to the large volume of data to be evaluated, the wide variety of structured and unstructured data sources, and the rate at which data are generated and needed for analysis.

Praedico enables VHA public health decision makers to react to a health crisis in a timely manner and share information with key stakeholders, while accessing data reliably and securely.",
maderOASISEvaluationFrench2021,267,Mader 2021,OASIS evaluation of the French surveillance network for antimicrobial resistance in diseased animals (RESAPATH): success factors underpinning a well-performing voluntary system.,OASIS evaluation of the French surveillance network for antimicrobial resistance in diseased animals (RESAPATH): success factors underpinning a well-performing voluntary system,2021,R. Mader,rodolphe.mader@anses.fr,France,Formal evaluation of French animal AMR surveillance system,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",d. One Health,France,j. OASIS: An assessment tool of epidemiological surveillance systems in animal health and food safety (Hendrikx 2011),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Follow AMR trends in pathogenic bacteria of animals,Collect and store a panel of isolates that can be needed for in-depth molecular investigations,Provide solid technical and scientific support to field laboratories,"Enable comparisons of animal and human AMR data through the French national observatory for epidemiology of bacterial resistance to antimicrobials (ONERBA), to which RESAPATH is federated",N/A,N/A,N/A,N/A,N/A,N/A,Objectives provided are those specific to the surveillance network being evaluated.,N/A,N/A,N/A,Public and private diagnostic laboratories,N/A,N/A,N/A,The ministry in charge of agriculture,N/A,N/A,N/A,Veterinary professional organisations,N/A,N/A,N/A,"Microbiologists and epidemiologists from the French Agency for Food, Environmental and Occupational Health & Safety (ANSES)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The OASIS tool proved successful with fruitful exchanges and a strong acceptability of its results and recommendations. Despite being a qualitative method, its detailed scoring guide limited the opportunity for subjective answer.

However, OASIS remains a generic tool and some debates have occurred on the relevance and interpretation of some of its evaluation criteria in the specific case of a passive laboratory-based AMR surveillance system. For example, should the data collection be evaluated from the laboratory stage and/or from the veterinary stage? The review group succeeded in taking consensual decisions, but this can slightly hinder the comparability of subsequent evaluations if such decisions are not consistent in time (this was namely the case for several criteria between this evaluation and the one performed in 2010). We recommend having at least one external assessor being experienced with the OASIS method to advise such decisions, as it was the case during our study, and to record decisions for future evaluations. As a qualitative method, OASIS does not enable the quantitative measurement of performance attributes, such as sensitivity or timeliness of a system nor does it look at its economic efficiency. Moreover, it does not investigate multisectoral collaboration, something of particular value for One Health issues such as AMR. To find the most appropriate method, depending on the evaluation question and surveillance attributes to evaluate, assessors may follow the steps suggested in the RISKSUR EVA tool, a framework providing guidance in the planning, implementation and reporting of evaluations [3]. Regarding multisectoral collaboration, a specific tool called ECoSur was recently developed to allow for an in-depth analysis of the organisation and functioning of collaboration taking place in a multisectoral surveillance system [21].
Of note, a method specifically dedicated to the assessment of national AMR surveillance systems has been developed since 2015 by the Food and Agriculture Organization of the United Nations (FAO). It was based on the FAO Surveillance Evaluation Tool, itself inspired by OASIS [22], and on the FAO Laboratory Mapping Tool [23], adapted to assess the specific issues linked to AMR. This method uses the FAO Assessment Tool for Laboratories and AMR Surveillance Systems (FAO-ATLASS) [24], which consists of two complementary modules (laboratory and surveillance) covering the key components of a national AMR surveillance system in the food and agriculture sectors. It also includes a Progressive Improvement Pathway scoring system, designed to assist policymakers in prioritising actions for building reliable national AMR surveillance systems for the sectors assessed. As such, conducting an FAO-ATLASS assessment could complement our results by providing a more global picture of the performance of France in terms of AMR surveillance in both animal and  environmental sectors.",N/A,N/A,"22. Food and Agriculture Organization (2020) EMPRESTOOLS: Surveillance Evaluation Tool (SET). Available at http://www.fao.org/ag/againfo/ programmes/en/empres/tools_SET.html (Accessed 15 January 2020). 
23. Food and Agriculture Organization (2014) FAO to Release Laboratory Mapping Tool on the Web, March 2014. Available at http://www.fao. org/ag/againfo/programmes/en/empres/news_130514.html (Accessed 15 January 2020). 
24. Food and Agriculture Organization. FAO Assessment Tool for Laboratories and AMR Surveillance Systems (FAO-ATLASS). Available at http://www.fao.org/antimicrobial-resistance/resources/tools/fao-atlass/en/ (Accessed 15 January 2020).","Article says to reference scoring guide to further understand OASIS methodology, however the link provided is expired.

The most important one referred to data management and a lesson to learn would be to always consider scalability, a parameter that is often overlooked at the setup of a system. Taking into account the limited IT capacities of laboratories is key to maintaining a strong volunteer network, but this requires a lot of flexibility from the coordination team and can be very time-consuming. Another weakness of RESAPATH lies in its possible sampling biases, as a passive laboratory-based surveillance network that does not integrate the sampling stage in its procedures. However, these possible biases were not considered as having a major impact on representativeness in this evaluation. On the other hand, the current organisation of RESAPATH brings a lot of simplicity, which is key to its sustainability.",
marbusExperienceEstablishingSevere2020,132,Marbus 2020,Experience of establishing severe acute respiratory surveillance in the Netherlands: Evaluation and challenges.,Experience of establishing severe acute respiratory surveillance in the Netherlands: Evaluation and challenges,2020,S.D. Marbus,Sierk.Marbus@rivm.nl,Netherlands,Formal evaluation of SARI surveillance systems in Netherlands,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",a. Public Health,Netherlands,b. Updated guidelines for evaluating public health surveillance systems: recommendations from the Guidelines Working Group (CDC 2001); f. Data Quality Monitoring and Surveillance System Evaluation - A Handbook of Methods and Applications (ECDC 2014); k. Other,Authors developed sustainability attribute on their own.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Infectious disease consultant,N/A,N/A,N/A,Medical doctor/epidemiologist,N/A,N/A,N/A,Senior epidemiologist,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The willingness of persons and organisations to participate in the system,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The completeness and validity of the data recorded in the surveillance system, including the addition of microbiological diagnostics",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The ability to adapt to changing information needs or technological operating conditions,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The ability to accurately describe the occurrence of an event over time, place and person",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The system's structure and ease of operation,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The system's reliability (ability to collect, manage and provide data without failure) and availability (ability to be operational when needed)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The speed between steps in a surveillance system, from event occurrence, recognition, report, to control and prevention activities",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Sustainability: The ongoing maintenance and support of a routine epidemiologic and/or microbiologic surveillance system,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Established public health surveillance systems may be more extensively evaluated based on other surveillance system attributes, such as level of usefulness, sensitivity, and positive predictive value. We chose a limited amount of evaluation criteria which are applicable and available for the current surveillance systems and datasets that could potentially be used for SARI surveillance in the Netherlands. In addition, costs for developing a SARI surveillance system are not included in this evaluation. With limited public health funding in many countries, this might be a critical first obstacle in setting up SARI surveillance.
We have also not considered possible legal constraints for national public health agencies in obtaining data for surveillance. For example, because of the implementation of General Data Protection Regulation (GDPR) in the EU in 2018, DHD stopped providing case-based hospital discharge data to the RIVM and other organisations.",N/A,N/A,N/A,"To asses each evaluation criterion, the 4 authors (2 infectious disease consultants, 1 medical doctor/epidemiologist, 1 senior epidemiologist) independently assigned the qualification good, moderate, or poor. A semi-quantitative score for the surveillance system or dataset was obtained by attributing three points for each evaluation criterion rated ""good"", two points for each evaluation criterion rated ""moderate"" and one point to each evaluation criterion rated ""poor"".

Besides virological laboratory and SARI sentinel surveillance, all evaluated surveillance systems or datasets have in common that they lack diagnostic specificity. Adding microbiology diagnostics to syndromic surveillance improves both timeliness and completeness of a SARI surveillance system.

Based on our experience and evaluation, improving sustainability is crucial for establishing a robust SARI surveillance system. In terms of sustainability, several challenges play an essential role. Firstly, the administrative burden associated with surveillance should be addressed. In a demanding hospital setting with increasing registration burden for hospital staff, our experience from SARI sentinel surveillance indicated that additional workload associated with surveillance should be decreased as much as possible. Thus, to improve timeliness, simplicity, and acceptability of a SARI surveillance system, we believe that implementation of a passive, fully or semi-automated, SARI surveillance system is required. Secondly, a different appreciation of the value of epidemiological surveillance data by data providers, such as clinicians, laboratories or hospitals, should be taken into account. We experienced that stakeholders withdrew their participation in SARI surveillance after a year, because of different appreciation of the value of epidemiological surveillance data. Therefore, we believe it is essential that a SARI surveillance system serves both a public health and a patient care goal.",
mitchellDevelopmentEvaluationFramework2009,5256,Mitchell 2009,The development of an evaluation framework for injury surveillance systems,The development of an evaluation framework for injury surveillance systems,2009,Rebecca J Mitchell,r.mitchell@unsw.edu.au,Australia,Evaluation framework for injury surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Epidemiologists and public health professionals residing in Australia who had authored or co-authored papers relating to the evaluation of data collections.,Expert panel members were selected based on seven criteria: (i) working in the field of injury prevention; (ii) familiarity with the evaluation of surveillance systems; (iii) awareness of the strengths and limitations of surveillance systems; (iv) published on the evaluation of a surveillance system; (v) awareness of quantitative evaluation methods; (vi) familiarity with Australian injury data collections; and (vii) willingness to contribute.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Data quality characteristics,"Five characteristics were identified to assess the data quality of an injury surveillance system, including: data completeness, sensitivity, specificity, positive predictive value, and representativeness.",N/A,Operational characteristics,"Nine characteristics were identified to assess the operation of an injury surveillance system, including: system purpose and objectives, data collection process, case definitions, timeliness, quality control measures, data confidentiality, individual privacy, system security, and uniform classification systems.",N/A,Practical characteristics,"Four characteristics were identified to assess the practical capability of an injury surveillance system, including: data accessibility, routine data analysis, guidance material to aid interpretation, and usefulness.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Data completeness: Data completeness will refer to an assessment of the proportion of: (i) missing; (ii) 'not known'; (iii) 'other specified'; and (iv) 'unspecified' data recorded for key characteristics of the injured population (i.e. WHO's core minimum data set for injury surveillance).,N/A,N/A,"There is no missing, not known, other specified or unspecified data and this is considered to be very high.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The PPV will refer to the number of correctly identified true injury cases divided by the total number of cases that are identified (correctly and incorrectly) as an injury case from the target population.,N/A,N/A,PPV is in the range 90 to 100% and is considered to be very high.,N/A,N/A,N/A,N/A,Representativeness will refer to the ability of the collection to provide an accurate representation of the distribution of key characteristics of the injured population (i.e. WHO's core minimum data set for injury surveillance) in a sample of the target population.,N/A,N/A,"Appropriate statistical tests (e.g. Chi squared test, Fisher's Exact test) confirm there is no significant difference in the distribution of key characteristics of the injured population1 between data in the surveillance system being evaluated to a gold standard (or other) data collection and the data is considered representative of the target population.",System security: The data access requirements (e.g. password protection) that safe guard against the disclosure of confidential information should be described.,N/A,N/A,"If there are data access procedures in place (e.g. password protection) to safe guard against the disclosure of confidential information, it rates as very high.",Sensitivity will refer to the ability to correctly detect all cases of true injury events that the data collection intended to detect in the target population.,N/A,N/A,Sensitivity is in the range 90 to 100% and is considered to be very high.,N/A,N/A,N/A,N/A,Specificity will refer to the ability to correctly detect all non-injury cases that the data collection should not have detected as injury cases in the target population.,N/A,N/A,Specificity is in the range 90 to 100% and is considered to be very high.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Timeliness will refer to the time taken to accomplish each of the three surveillance phases of: (i) data collection; (ii) data analysis and interpretation; and (iii) dissemination.,N/A,N/A,"If the time taken to complete data collection, data analysis, interpretation and dissemination is daily to monthly, it rates as very high.",Usefulness will refer to the ability to contribute to the identification of potential key areas for preventive action in terms of the ability to: (a) identify new and/or emerging injury mechanisms; (b) monitor injury trends over time; and (c) describe key characteristics of the injured population (i.e. WHO's core minimum data set for injury surveillance).,N/A,N/A,"If the data collection contains 76 to 100% of variables in the core minimum and optional data sets for injury surveillance, it rates as very high.",N/A,N/A,N/A,N/A,"Purpose and objectives: The purpose of the injury surveillance system, the reason why the system exists, and objectives of the injury surveillance system, what the information from the system is used for, should be described.",N/A,N/A,"If the purpose and/or objectives of the data collection include injury surveillance, it rates as very high.",Data collection process: The method of data collection for an injury surveillance system and the number of steps involved in data collection should be examined using a data collection flow chart.,N/A,N/A,"If the data collection process takes one to three steps to complete, it rates as very high.",Case definition: The injury case definition adopted by an injury surveillance system to identify cases should be described.,N/A,N/A,If variables in the data collection can identify the injury cases of interest it rates as very high.,"Uniform classification systems: The classification system(s) used to record information in the injury surveillance system for  variables in the WHO's core minimum and optimal data sets for injury surveillance should be identified.
",N/A,N/A,"If standard classification systems are used to record  information for 76 to 100% of variables in the core  minimum and optional data sets for injury  surveillance, it rates as very high.",Quality control measures: The quality control measures regularly utilised by the agency responsible for the injury surveillance system should be identified.,N/A,N/A,"If quality control measures are in place and are conducted, it rates as very high.",Confidentiality and privacy: The methods by which an individual's information in  the injury surveillance system is safe guarded against  disclosure should be described.,N/A,N/A,"If data users are required to sign a confidentiality and/or data security agreement, it rates as very high.",Data accessibility: The method by which potential data users access data from the injury surveillance system should be reported.,N/A,N/A,"If data is accessible for data users in unit  record format from an internet-based interface  and/or data warehouse (or similar), it rates as  very high.",Data analysis: The routine data analyses conducted using  data from the injury surveillance system by the  agency responsible for the surveillance system  should be described.,N/A,N/A,"If data analysis is conducted daily to monthly or on request and results of this analysis are  available for all data users, it rates as very high.",Guidance material to aid data interpretation: he availability of guidance material on the interpretation of data from the injury surveillance system should be described.,N/A,N/A,"If there is an up-to-date data dictionary,  manual or data user's guide and routine  contact with data users regarding data analysis  issues to aid data interpretation, it rates as very  high.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"It could be argued that the standards adopted for including characteristics in the EFISS were too high and that some additional characteristics should be included. Indeed the core set of characteristics could be enlarged to an optional additional set to include all or some of the ten characteristics that had been previously excluded. This would involve one additional data quality (i.e. LR+), five additional operational (i.e. legislative requirement for data collection, data adequacy for injury surveillance, simplicity, flexibility, and system integration) and four additional practical (i.e. acceptability, potential for data linkage and geocoding, and routine dissemination) characteristics. However, the definitions of some of these (e.g. flexibility and acceptability) would need further refinement, and a number of these characteristics were rated as low in importance and had little consistency between raters (e.g. legislative requirement for data collection, and adequacy of data for injury surveillance). 

While it can be used in its current form, it could certainly be developed further. For example, the EFISS could include a weighting system to adjust for the importance of different EFISS characteristics. In addition, the interrelationships between characteristics may also be considered within the rating system.Further testing may result in more precise and hence more useful definitions of problem characteristics like acceptability.",N/A,N/A,"1. Holder Y, Peden M, Krug E, Lund J, Gururaj G, Kobusingye OC: Injury Surveillance Guidelines. Geneva: World Health Organization; 2001.

35. Klaucke D: Evaluating public health surveillance systems. In Public Health Surveillance Edited by: Halperin W, Baker E. John Wiley & Sons Inc: New York; 1992:26-41.
36. Romaguera R, German R, Klaucke D: Evaluating public health surveillance. In Principles and Practice of Public Health Surveillance Second edition. Edited by: Teutsch S, Churchill R. Oxford University Press: Oxford; 2000:176-193. 

37. Klaucke D: Evaluating public health surveillance.  In Principles and Practice of Public Health Surveillance Second edition. Edited by: Teutsch S, Churchill R. Oxford University Press: Oxford; 2000:158-174.","The characteristics were first categorised and then reviewed using SMART criteria (described below). The SMART criteria are based on goal-setting theory [12] and have been used in a wide range of settings to aid decision-making [13-15]. The SMART criteria were adapted so as to apply to evaluating characteristics of an injury surveillance system. Each characteristic was evaluated against the five criteria of the SMART framework, defined as:
* Specific - the characteristic should be as detailed and specific as possible;
* Measurable - it should be possible to objectively assess or monitor the characteristic;
* Appropriate - the characteristic should be suitable to assess an injury surveillance system and provide information central to injury surveillance;
* Reliable - the characteristic should be able to provide information that is consistent and reliable; and
* Time-consistent - it should be possible to measure or monitor the characteristic consistently over time.

The framework adopted to create the rating scales for each EFISS characteristic was the same framework used by the evidenced-based medicine (EMB) field [27,28]. This framework was chosen as the hierarchical structure of this framework and its use of clearly defined rating criteria have been successfully applied in other areas, such as public health interventions [53].

The rating scales developed for the EFISS are based on the (limited) previous research and the authors' professional judgment. A four-level rating scheme is proposed for most characteristics, composed of I 'very high', II 'high', III 'low', and IV 'very low'. For five characteristics a dichotomous scale is proposed using I and IV. These are set out in Tables 5, 6 and 7.

Table 1 and Table 3 include the characteristics listed in article that were dropped from final framework.",
morbeyEvaluatingMultipurposeSyndromic2021,112,Morbey 2021,Evaluating multi-purpose syndromic surveillance systems - a complex problem.,Evaluating multi-purpose syndromic surveillance systems - a complex problem,2021,Roger Morbey,roger.morbey@phe.gov.uk,United Kingdom,Provides considerations for evaluating multi-purpose syndromic surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"A multi-purpose syndromic surveillance service may have multiple objectives:
* Early warning of unexpected events, e.g. bioterrorism, emerging new diseases, outbreaks;
* Early warning of aberrant trends by monitoring endemic or seasonal diseases, e.g.scarlet fever or seasonal influenza;
* Reassurance and monitoring during mass gatherings e.g. Olympic and Paralympic Games;
* Situational awareness during pre-identified outbreaks or environmental incidents, e.g. COVID-19, an influenza pandemic or heat wave;",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,PPV (also called precision) can be defined by the proportion of positive tests that come from patients with the disease,"PPV = True Positives / (True Positives + False Positives)
(for evaluating a multi-purpose syndromic surveillance system)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Sensitivity (also called recall) can be defined as the proportion of patients with disease correctly identified by a positive test,"Sensitivity = True Positives / (True Positives + False Negatives)

(for evaluating a multi-purpose syndromic surveillance system)",N/A,N/A,N/A,N/A,N/A,N/A,Specificity can be defined as the proportion of tested patients without a disease with a negative test result,"Specificity = True Negatives / (True Negatives + False Positives)

(for evaluating a multi-purpose syndromic surveillance system)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Timeliness can be defined as the time between a sample being taken and the laboratory report being available,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"There are advantages and disadvantages for using real historical events or using synthetic events, historical events may be rare whilst synthetic events may be unrealistic. The main disadvantage of using synthetic events is that they require modelling assumptions, for example, healthcare seeking behaviours for a range of diseases need to be estimated from other research, which is not straightforward. A commonly used approach is to inject synthetic simulations of events into real historic syndromic data. Furthermore, real scaled events can be injected to reduce modelling assumptions about the relationship between outbreak size and syndromic indicators. However, results will still depend upon assumptions about the lag between exposure, symptom onset and whether a person presents to health care.",N/A,N/A,N/A,"Ideally, simple clear quantitative measures should be provided to describe a multi-purpose service's detection capabilities. However, published quantitative estimates for detection capabilities have usually been restricted to single diseases or to the automated part of a service. For example, it is much easier to deliver estimates structured as ""the algorithm had a sensitivity of 98% and a specificity of 84% for simulated influenza outbreaks"" rather than ""this syndromic service resulted in appropriate action 85% of the time, with 20% of actions subsequently found  to be unnecessary"". 

It is important that syndromic services are evaluated across the full range of event types and different sizes of event. However, for some types of event there may be no historical data available or only a limited range of outbreak sizes, locations etc. Therefore, synthetic simulated data are often used to evaluate syndromic systems. To evaluate a syndromic service, the list of events to be detected must be comprehensive and exclusive (Figure 3).

Whilst it is relatively straightforward to define the detection parameters for statistical algorithms, it becomes more complex when we consider the whole syndromic surveillance service. Firstly, we need to consider how the service reports detection, which may depend on its surveillance objective. Secondly, we need to decide how to link detection to events in the context of multi-purpose syndromic surveillance.

Much of the published research evaluating syndromic surveillance focuses either on just one type of event or on the detection capabilities of statistical algorithms. We have reflected on and highlighted the complexities of evaluating and quantifying the detection capability of a multi-purpose syndromic service, which may explain the lack of published evidence on this subject. However, to address questions from users of syndromic surveillance about detection capabilities, we need to avoid over-simplifications and provide descriptions which directly address the complexities and wide-ranging utility of these services. Therefore, we argue that syndromic surveillance service evaluations need to measure separately different types of event that the service aims to detect and to consider all surveillance stages. Whilst the authors support the use of the CDCs framework for evaluation of surveillance systems, we also believe the complexity of multi-purpose systems needs to be considered in such frameworks. Firstly, separate answers are needed for different types of event both to address users' specific questions and because different types of events will require different methods for evaluation. Crucially, these separate evaluations should be done in the context of a multi-purpose service where other types of events can affect detection capabilities and the ability to identify causes is also addressed. Secondly, syndromic services should be evaluated beyond the generation of statistical alarms to provide results that inform public health action. Service evaluations should include consideration of the routine surveillance messages and the  impact of public health actions for different event types.",
muellnerSurFInnovativeFramework2018,715,Muellner 2018,SurF: an innovative framework in biosecurity and animal health surveillance evaluation.,SurF: an innovative framework in biosecurity and animal health surveillance evaluation,2018,Jonathan Watts,Jonathan.Watts@mpi.govt.nz,New Zealand,Evaluation framework for biosecurity and animal health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,I. Motivation for the evaluation,"A. Evaluation trigger: 
Describe evaluation triggers. A trigger, or a series of triggers over time could lead to the decision to conduct a surveillance evaluation. For example evaluation can be planned or unanticipated. 
* Planned evaluation is required, for example, if the legal basis of surveillance activities requires evaluation to take place at regular intervals. This can also be due to quality assurance or other administrative processes implemented by the competent authority or its partners. 
* Unanticipated evaluation can be triggered by changes in the risk landscape, changes in the industry, or international triggers such as changes to World Organisation for Animal Health (OIE) or International Standards for Phytosanitary Measures (ISPM) rules or criteria of trading partners. 
Other factors include: the emergence of a disease or risk organism; changes in diagnostic techniques; concerns about the acceptability or representativeness of reporting; failure of the system to detect an outbreak or incursion; and inability of the system to properly quantify a problem. Declining resources or a requirement to link to other surveillance systems can also trigger an evaluation.  
B. Context: Describe the context of the surveillance system to illustrate why surveillance is conducted and what drives its design. This may, where applicable, include: 
Why is surveillance required? 
* Characterisation of the risk organism(s). 
* Epidemiological profile of the diseases or risk organisms under surveillance. 
* A description of the population-at-risk and/or host range. Situational analysis (both national and international). 
* Current situation. 
- Why is the organism or disease considered a problem? 
- Briefly indicate the level of current knowledge. 
* Brief overview of historical situation",N/A,N/A,"As a first step before starting the evaluation process the surveillance system should be named.

Describing the evaluation trigger(s) is important as it clarifies the thinking around the most important factors driving the undertaking of the evaluation and may have a significant impact upon which attributes are chosen for evaluation.",II. Scope of the evaluation,"A. Evaluation objective
As a first step towards narrowing down the evaluation question, one or more of the evaluation objectives suggested below could be selected:
* To ascertain whether or not a surveillance system is meeting its current objectives or a proposed change in objective. If this is the objective of the evaluation then the objective of the surveillance should be stated.
* To ascertain whether or not a foreign surveillance system is reliable enough to accept imports from that country, or if a domestic surveillance system is good enough to support export of animals, plants or their products.
* To ascertain whether or not a surveillance system is providing value for money to the funder. 
* To determine how much benefit (monetary or otherwise) a surveillance system provides to its user groups. 
* To identify the strengths and deficiencies of a surveillance system. 
* To identify potential measures that could improve the performance, efficiency and productivity of a surveillance system. 

B. Evaluation question(s)
Phrase the evaluation objective(s) into a specific question that can be answered by the evaluation (i.e. the main question to be answered by the evaluation). Where an evaluation is seeking to determine whether or not a surveillance system meets its objectives, the relevant surveillance objective should be clearly stated within the evaluation question. Specific expectations should be identified (e.g. surveillance should cost less). 

Examples of evaluation questions:

* Is/are the surveillance activity(ies) or system(s) capable of meeting a technical objective or target?
* How can specific surveillance attributes be improved?
* What is the overall performance of the surveillance system?
* What are the strengths and weaknesses of the surveillance system?
* Is the surveillance system meeting its objective to?

C. Time and resources
Specify the staff, funds and deadlines for the evaluation. The evaluation time plan may be impacted by other deadlines such as budget decisions, ministerial meetings etc. Identify the evaluation time frame, including the start date, delivery date and any interim deadlines with associated deliverables. Good practices as applied in general project management are applicable.

D. Evaluation intensity
Determine the expected evaluation intensity.The level of detail of the evaluation will depend on:
* Motivation for the evaluation.
* Evaluation objectives (see above).
* Aspects that are intentionally excluded or considered out-of-scope (e.g. economics).
* Available time and resources (see above)

E. Evaluation organization and composition of evaluation team
Describe the organisation of the evaluation and composition of the evaluation team as well as their responsibilities.
* Is this evaluation internal or external? Evaluation can be conducted in-house or contracted externally. The latter might be required when independence needs to be assured.
* Describe the necessary knowledge and competencies required in the evaluation team. In particular, assessment of some of the technical attributes might require assistance, for example by an epidemiologist or other subject matter expert. Are individuals or organisations available to provide peer-review?
- Leading and coordinating the evaluation (project manager, project secretary).
- Providing input information (surveillance experts).
- Clarification, interpretation and discussion of evaluation findings (stakeholders).
- Dissemination of evaluation results.
* Specify the roles and responsibilities within the project, e.g. who will make decisions. Roles can include the following:
* Identify the people/organisations involved in and affected by the evaluation to identify communication needs.

F. Status of evaluation outputs
Specify the classification of evaluation data and results, e.g. some outputs might be confidential and access limited, while others should be accessible to a wide range of stakeholders. Specify the communication channels that will be used to disseminate the findings.",N/A,N/A,"The scope of the evaluation is informed by the motivation for the evaluation. In this phase, the objective of the evaluation should be specified and made explicit to ensure it is consistent with the motivation. A key task in this phase is to define and agree upon the evaluation question(s)
and to agree upon an evaluation project plan. Depending on the motivation for the evaluation, the intensity should also be discussed. This is particularly relevant in the context of resources. 
Intensity and resources need to be aligned. If resources are limited, it may not be possible to conduct a full evaluation. The intensity will also depend directly on the motivation for the evaluation.

Organisational questions also need to be clarified in this phase of the evaluation. An evaluation can be conducted in-house or externally. This decision will depend on the regulatory context but also on budget considerations and on in-house capacity and evaluation competency. If the evaluation is to be tendered, this will impact on the time plan. In a scenario where the evaluation will be commissioned, most of the points listed below will be relevant and specified as part of the call for tenders.",III. Evaluation design and implementation,"Design of the evaluation
A. Select attributes from master list
Select attributes from master list. All core attributes should be included, unless they are excluded for a specific, documented reason. The choice of additional attributes lies with the assessor.

B. Choose methods to assess attributes
Decide which attribute is best assessed by which approach, once an overview of available information is established. This will also determine whether the attribute will be assessed with qualitative or quantitative approaches. The SurF Methods Catalogue (Appendix 1) lists a series of references describing methods of assessment for the different attributes used in SurF.

C. Make an inventory of available information sources about the system
Prepare an inventory of available information sources.
* Information sources can consist of documents such as legislation, guidelines, reports, meeting protocols or previous audits or evaluations. Surveillance data should also be included. If the latter are used, additional time and specific competencies are required in the evaluation team.
* Identify relevant individuals to interview. All individuals involved and affected by a surveillance system are potentially relevant. It should be considered which perspective of the evaluation they could cover and to which attribute this would contribute.

D. Identify missing information
Based on the selected attributes and the available information sources, identify possible gaps and how the evaluation aims to address these gaps. The feasibility of information and data collection for the evaluation should also be considered in light of available resources.

Implementation of the evaluation
A. Describe the surveillance system under evaluation
Describe the surveillance system. The level of detail depends on the existing requirements and knowledge. It is suggested to keep this summary brief, typically not exceeding one page. Reference can be made to other existing and more detailed documents. 

This typically includes the following:
* Name, legal status.
* Evaluation objective and question as defined in Sections II.A and II.B.
* Define the level at which the evaluation is being conducted:
- Is the evaluation being conducted at the activity, programme, system or portfolio, level?
--If applicable, describe its components and how they relate to each other. 
- Where desired and resources are available the MPI Intervention Logic Model (ILM) could be used to describe the surveillance under evaluation. Further information on this approach can be provided by the MPI Assurance and Evaluation Group.

B. Describe the surveillance system's objective(s)
Describe the surveillance system's objective(s). 
* Are the surveillance objectives clearly defined and relevant to the actual situation of the disease or risk organism?
* Choose one or several from the following list of six surveillance objectives:
- Monitor the prevalence of a disease or risk organism: While usually aimed at endemic diseases or risk organisms, this is also applicable to new and re-emerging diseases and risk organisms and can form part of an assessment of the impact of control programmes on infection incidence. 
- Finding cases of a disease or risk organism: 
--Detection of as many cases as possible of a known infection to facilitate control. The emphasis here is on finding those individuals, or locations, that are infected, or where the organism occurs, in order to intervene in some way, such as by culling, vaccination or delimitation surveillance. This will usually apply to an endemic disease or organism, i.e. an organism that is already present in the country. 
- Early detection of new or re-emerging disease or risk organism(s): Early detection could be defined as detection of infection before an outbreak or incursion becomes uncontrollable; this timeframe will vary by disease or risk organism(s) and should be estimated. If this objective is chosen, a statement should be included to define how early the system aims to detect infection. 
- Demonstrate freedom from a disease or risk organism: If this objective is chosen, a statement should be included to define the prevalence and associated confidence level, which are considered to indicate disease or risk organism freedom. 
- Identify changes in the population-at-risk or an organism range or host expansion:
-- Here, risk factors, rather than a disease or risk organisms, are the target for surveillance. This might lead to identification of new population groups at risk or range/host expansion of an organism; targeted prevention measures could be considered. 
- Improve epidemiological understanding of a disease or risk organism: Generating knowledge about a disease or risk organism, for example academic research or hypothesis generation. 

C. Describe the organizational structure
Describe who leads and manages the surveillance system being evaluated and briefly describe their roles. Identify whether there are suitable steering and scientific committees, where appropriate, and describe their roles and responsibilities. How are decisions being made?

D. Identify and engage surveillance system users
Identify and engage system users.
* Identify the people involved in the surveillance system that is being evaluated: 
- Who pays for the surveillance?
- Who provides the surveillance data?
- Who analyses the surveillance data?
- Who uses the resulting information?
- Who benefits from any action resulting from the surveillance?
- Who pays for risk organism or disease mitigation?
- Who (if anyone) might lose out if a risk organism or disease is reported (e.g. it might be thought that famers' reputations could be tarnished if they declare disease in their herd or growers might lose millions in export markets if a new risk organism is discovered)?
* Engage stakeholders and users: 
The engagement of stakeholders is essential and needs to be secured early in the process. A range of formats can be used to disseminate information on the conduct and objectives of an evaluation. For example, by using leaflets, email, or presentations at meetings. Identify how engagement will be secured. 
* Ensure to include surveillance system managers and implementing personnel.

E. Identify the target population and geographical coverage
Describe the target population, with reference to the population-at-risk, and the geographical coverage.

F. Describe the design of the surveillance system
Describe the design of the system.
* Outline the surveillance design.
* Describe the sampling frame. How is it decided?
* Describe the general structure of the surveillance system including: 
- Origin of data (whether active, passive or enhanced passive). 
- Focus (whether disease or risk organism-specific, or general).
- Survey design (e.g. case reports or continuous collection).
- Sample size calculation and sampling strategy, including whether a risk-based strategy is used.
- Where applicable describe calculation or statement of confidence and coverage/inference.

G. Describe the processes
* Processes
Describe field operations/sampling and laboratory processes. Are quality control and assurance procedures (e.g. SOPs) followed and are audits/evaluations conducted?
* Data
Describe processes related to data collection, data management, data analysis and data dissemination.
- Data collection.
Assess use of appropriate data sources and collection methods and the existence of a case definition, where applicable, and data collection protocol. Consider each of the following: 
- Who provides the data?
- Who collects the data?
- Where/when are data collected (space-time)?
- How are data collected?
- How are data recorded (e.g. on paper or electronically)?
- What types of data are being dealt with (e.g. active/passive, threat-specific/syndromic)?
- Is there a data collection protocol?
- Are quality control and assurance procedures followed and are audits/evaluations conducted?
- How are staff trained to collect data?
- Is there a case definition? If so, please describe it.
- Data management.
Use and documentation of systems for processing information, including data processing protocols and data verification procedures.
Consider each of the following: 
- How are data managed?
- What data security measures are in place?
- How are data stored?
- How is data management documented?
- Are quality control and assurance procedures followed and are audits/evaluations conducted?
- Are there data processing protocols?
- Describe the data verification procedures. 
- Data analysis.
Methods used for the analysis and interpretation of surveillance data. 
Consider each of the following: 
- How are data analysed and interpreted?E.g. predictive models, risk factor analysis, prevalence estimation, summary measures.
- Are performance indicators used and if so, which ones and how are they calculated? E.g. numbers of reports received or samples collected per time unit, trend analysis or comparisons with results from other systems.
- Data dissemination.
Methods used for information exchange between people involved at all levels of the surveillance system. 
Consider each of the following: 
- Which methods are used to exchange information between people involved in the surveillance system (providers, analysers and users of surveillance data)? These might include: case reporting cards, emails, letters, phone calls, interim reports of surveillance data, websites for disseminating information, and feedback given to the data providers. 
- How frequently are data or reports disseminated?
- Do methods used (e.g. reports) adequately report the outputs from data collection, data management and data analysis? Is sufficient interpretation provided?
- To date, what actions (if any) have been taken as a result of the surveillance activity? These might include: details of mitigation measures imposed; decreased incidence of diseases or risk organisms; use of surveillance data for policy and programme decisions; and appropriateness of outbreak or incursion response.
* Consider presenting the structure of the system in a flow-chart format. 

H. Collect data and information
Use the formats and sources identified previously, i.e. document review, interviews.

I. Assess the included attributes
Use the selected methods to provide quantitative or qualitative results (see Section 4 for details)

",N/A,N/A,The design and implementation of the evaluation will be strongly driven by decisions taken in the previous phase.,IV. Reporting and communication of evaluation outputs,"A. State target audience
Identify target audience(s) for evaluation outputs

B. Report main findings
Reporting of main findings; will include descriptive parts as well as additional analyses. Results can be listed by attributes or by evaluation question(s)

C. Summarize and synthesize results
Summarise and synthesise results:
* Describe the extent to which the system meets its objectives.
* Identify the strengths and weaknesses of the surveillance system under evaluation.
* Address the evaluation question(s).

D. Provide guidance for interpretation of results
Provide guidance for interpretation:
* Assess system limitations, interfaces to other relevant activities such as interventions and control measures.
* State information gaps, bias, uncertainties and assumptions.
* Make recommendations to improve future evaluations

E. Make recommendations
Depending on the evaluation objective, evidence-based suggestions for possible improvements to the surveillance system can be included (e.g. use of portable technology, risk-based requirement or sampling, review of sampling strategies including the sample size, pooling of samples, and integration of data from different sources. The value of surveillance might also be improved by changing the methods used to analyse or disseminate information).

F. Facilitate plain reporting
Provide plain English summary to support reporting of results to non-technical audience.
",N/A,N/A,"The output of the evaluation is typically captured in a written report that includes detailed descriptions of each of the sections listed above as well as results of attribute assessments. Information captured using the SurF Evaluation template (Section 7) will provide the basis for the report. In addition, the report provides the attribute evaluation results (see Section 4). All findings need to be discussed, interpreted and presented such that the reader is able to reach the conclusions related to the evaluation objective.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,A. Organization & management,"Attributes in Group A are used to assess management and organisation of the surveillance system. They do not cover technical aspects of the system.

1. Flexibility
2. Organization and management*
3. Performance indicators and evaluation*","*Core attributes assess essential aspects common to all surveillance systems, and it is recommended that they be included in all evaluations. If for any reason this has not been done, justification should be provided.

While it is recommended that core attributes are included in all assessments, the choice of accessory attributes is left to the evaluator and is not specified in SurF. The choice will ultimately be situation- and sector-specific and may be influenced by factors such as the evaluation question, the surveillance objective or the surveillance system's design.",B. Processes,"Group B attributes assess surveillance processes including the design of the surveillance system. They aim to provide a structured understanding of the methods and practices applied (e.g. during sampling or data analysis, as well as the technical competence and resources that support the surveillance system)

4. Data analysis
5. Data and information collection*
6. Data management and storage
7. Field and laboratory services
8. Resource availability
9. Technical competence and training*","*Core attributes assess essential aspects common to all surveillance systems, and it is recommended that they be included in all evaluations. If for any reason this has not been done, justification should be provided.

While it is recommended that core attributes are included in all assessments, the choice of accessory attributes is left to the evaluator and is not specified in SurF. The choice will ultimately be situation- and sector-specific and may be influenced by factors such as the evaluation question, the surveillance objective or the surveillance system's design.",C. Technical implementation,"Attributes in Group C focus on technical aspects of surveillance and include characteristics such as timeliness, participation and coverage.

10. Acceptability and engagement
11. Coverage
12. Data completeness and correctness*
13. Interoperability
14. Multiple utility
15. RARR
16. (Reliability, availability, repeatability and robustness)
16. Timeliness*","*Core attributes assess essential aspects common to all surveillance systems, and it is recommended that they be included in all evaluations. If for any reason this has not been done, justification should be provided.

While it is recommended that core attributes are included in all assessments, the choice of accessory attributes is left to the evaluator and is not specified in SurF. The choice will ultimately be situation- and sector-specific and may be influenced by factors such as the evaluation question, the surveillance objective or the surveillance system's design.",D. Outputs,"Group D attributes assess the outputs of surveillance, to gain an understanding of their limitations and qualities.

17. Historical data
18. Negative predictive value
19. Positive predictive value
20. Precision
21. Representativeness and bias*
22. Sensitivity*
23. Specificity*","*Core attributes assess essential aspects common to all surveillance systems, and it is recommended that they be included in all evaluations. If for any reason this has not been done, justification should be provided.

While it is recommended that core attributes are included in all assessments, the choice of accessory attributes is left to the evaluator and is not specified in SurF. The choice will ultimately be situation- and sector-specific and may be influenced by factors such as the evaluation question, the surveillance objective or the surveillance system's design.

At least one of the two attributes Sensitivity and Specificity should be included.",E. Impact,"Attributes in Group E focus on the assessment of surveillance impact, considering the benefits provided by the system and what data and information are communicated to stakeholders.

24. Benefit
25. Decision support
26. Efficiency
27. External communication and dissemination
28. Internal communication
29. Utility*","*Core attributes assess essential aspects common to all surveillance systems, and it is recommended that they be included in all evaluations. If for any reason this has not been done, justification should be provided.

While it is recommended that core attributes are included in all assessments, the choice of accessory attributes is left to the evaluator and is not specified in SurF. The choice will ultimately be situation- and sector-specific and may be influenced by factors such as the evaluation question, the surveillance objective or the surveillance system's design.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Link between the resources implemented and the results obtained. An efficient system will accomplish a job with minimum expenditure of time, human effort and cost.",N/A,"Conducting surveillance incurs costs, for example, salaries, consumables, travel. These costs can be compared against the outputs from surveillance such as reports, disease or organism detections and notifications, or other signals. A surveillance system can be considered efficient if there is an optimal balance between economic investments and its output, the latter achieving the desired quality attributes (e.g. precision, timeliness). Risk-based surveillance can - where appropriate in terms of the surveillance objective - provide efficiency gains in surveillance systems",N/A,N/A,N/A,N/A,N/A,"Ability to adapt to changing information needs or operating conditions with little additional time, personnel or allocated funds",N/A,"Flexible systems can accommodate new events, changes in case definitions or technology, and variations in funding or reporting sources (CDC 2001). This attribute is determined more by the planning and management of the surveillance system than by the operation of the system. Simpler or more generic systems are likely to be more flexible. An evaluation of the flexibility of the system may be made by considering how the surveillance system has responded to changes in the past. Potential changes or events to consider include: 
* Changes in the information needs of the users of surveillance.
* Changes in relevant national or international legislation or guidelines.
* Changes in the demography of the target population.
* Changes in the epidemiology of disease (including outbreaks), host range of an organism or the emergence of new disease or organism threats.
* Changes or improvements to the methods of surveillance, including adoption of new technologies (e.g. development of new diagnostic methods).
* Changes to behaviour or influences on behaviour of key actors and agents in the system (e.g. changes to reporting behaviour or the costs of diagnostic services).
* An assessment of how likely it is that such changes may occur in the future and whether the surveillance system would be able to respond to these changes should also be made. Assessment of this attribute will be aided by consultation with key stakeholders of the system.",N/A,N/A,N/A,N/A,N/A,Compatibility with and ability to integrate data from other sources and surveillance components.,N/A,"This is only relevant where such interfacing is a requirement to assure utility. Most technical requirements for interoperability are nowadays standard characteristics of databases and information systems. Record keys are required to assure correct merging of records. These can for example be animal or sample IDs, holding IDs, postal codes.",N/A,N/A,N/A,N/A,N/A,The probability that no disease/risk organism is present given that none is detected by the system.,N/A,"The negative predictive value expresses the chances of missing the presence of a disease or risk organism. It can therefore be considered a reflection of the risk of false-negative surveillance outcomes. False negative results can be very costly, for example in export testing. Most surveillance systems therefore aim to maximise the negative predictive value (ideal value is 1). This attribute is mainly influenced by the test characteristics (sensitivity and specificity) as well as the prevalence of disease. Alternatively, where applicable, negative predictive value can be influenced by the methods of surveillance and the density and geographic spread of the risk organism.",N/A,N/A,N/A,N/A,N/A,Probability that a disease/risk organism is present given that it is detected by the system.,N/A,"The positive predictive value expresses the probability that a disease/risk organism is present, given that that it has been detected by the surveillance system. It can therefore be considered a reflection of the risk of false-positive surveillance outcomes. Such false positive results can be costly. However in the situation of a very severe outcome (e.g. highly contagious diseases such as FMD or the presence of a voracious pest such as Carcinus maenus), they are often acceptable as long as the control measures and trade disruptions can be managed. The ideal value of the positive predictive value is 1. This attribute is mainly influenced by the test characteristics (sensitivity and specificity) as well as the prevalence of disease. Alternatively, where applicable, positive predictive value can be influenced by the methods of surveillance and the density and geographic spread of the risk organism.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Proportion of true events correctly classified as such.,N/A,"Evaluation of the sensitivity of a surveillance system is especially important for surveillance activities designed to detect outbreaks and incursions. Sensitivity of a surveillance system should be considered according to the objective of the surveillance activity: 

* Surveillance sensitivity (case detection) refers to the proportion of individual units (e.g. animals, plants) that have the condition of interest that the surveillance system is designed to detect that are correctly identified as such,
* Surveillance sensitivity (outbreak or incursion detection) refers to the probability that the surveillance system will detect a significant event. 
This requires a clear definition of what constitutes a significant event (e.g. an outbreak, incursion, or host expansion).
* Surveillance sensitivity (presence) refers to the probability that an event will be detected if present at a certain level (prevalence) in the population.
Sensitivity is the most commonly assessed attribute of surveillance systems. Combined with timeliness, it is of particular importance to surveillance for early detection of outbreaks or incursions. Along with representativeness it is frequently scrutinised when evaluating surveillance activities intended to provide evidence for disease or risk organism freedom. When monitoring the prevalence of endemic diseases or risk organisms, poor sensitivity will contribute to bias in the surveillance outputs. 

Some considerations when assessing the sensitivity of surveillance include:

* The probability of selection into the surveillance system must be defined and quantified. This may be a simple random sample of animals from a single homogenous population or a complex pathway of epidemiologic and behavioural factors describing the observation, reporting 
and subsequent investigation of a notifiable disease or risk organism (i.e. passive surveillance).
* The probability of diagnosis (i.e. the sensitivity of the diagnostic protocol, including that of laboratory tests).
* The choice of design prevalence or assumed density (i.e. the expected prevalence of disease or density of a risk organism that the system is designed to detect) is a key assumption.
* In ecology, when the main aim is detection of a single pest organism, search efficiency (ability to detect the organism if it is there) could be taken into account",N/A,N/A,N/A,N/A,N/A,Proportion of true non-events correctly classified as such.,N/A,"Evaluation of the specificity of a surveillance system is especially important for surveillance activities designed to detect outbreaks or incursions and cases because it is related to the misdirection of resources: i.e. expenditure on a disease or risk organism investigation and mitigation measures that are needlessly applied. The specificity of many surveillance activities will be very high or complete (100%), because of the consequences of confirming disease; this is especially true for surveillance for exotic diseases carrying implications for trade. 

Specificity can be considered at several levels, depending upon the epidemiology of the disease or organism and the objectives and design of the system: 

* The specificity of pre-diagnostic indicators of disease (e.g. clinical signs).
* The specificity of screening and confirmatory diagnostic tests applied.
* The rate of false-positive signals raised by detection algorithms applied to surveillance data.
* The proportion of reports of suspect cases of a disease or risk organism that are subsequently negated (NB: this metric actually concerns the Positive Predictive Value of a system; a related concept which has been assessed in some evaluations).

Assessment of specificity should include the false alarm rate, i.e. the proportion of wrongly suspected outbreaks or incursions. False alarm rate is the inverse of the specificity (i.e. the proportion of true non-events correctly classified as such) but is by some more easily understood than specificity.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The time between any two defined steps in a surveillance system.,N/A,"The steps will vary according to the surveillance objectives so as to be epidemiologically or biologically meaningful.
Commonly timeliness relates to the time interval between a relevant event/signal and its recording by the surveillance system.

The timeliness of a surveillance system is especially important to surveillance for the early detection of emerging or exotic disease or organism threats - where the intention is to implement control measures as soon as possible. 

For example, for outbreak or incursion detection it might be important to consider the time delay from introduction to detection of the agent, or the time between when the agent should have realistically been first detected and the time when it actually was reported. On the other hand, for planning purposes, timeliness might be used to determine if a surveillance system detects and reports disease or risk organisms in time to initiate effective interventions before disease or risk organisms become widespread. 

Timeliness can be defined in various ways 

* This is usually defined as the time between any two defined steps in a surveillance system; the time points chosen are likely to vary depending on the purpose of the surveillance activity. 
* For planning purposes timeliness can also be defined as whether surveillance detects changes in time for risk mitigation measures to reduce the likelihood of further spread. 

The precise definition of timeliness chosen should be stated as part of the evaluation process.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Organization and management: How surveillance is organised and managed.
",N/A,"This attribute is based on an assessment of organisational structures of the surveillance system, including whether the objectives are relevant and clearly defined.
Where applicable, describe existing formal steering and technical committees. 

Where committees exist their members should have appropriate expertise, clearly defined roles and responsibilities and should communicate regularly to oversee the function of the system. Members should also be representative of surveillance stakeholders. This also includes 
assessments of complexity and efficiency in meeting surveillance objectives.",N/A,Performance indicators and evaluation: Whether performance indicators are routinely used to monitor system performance and whether periodic external evaluation is used to assess the system outputs in relation to its objectives.,N/A,This attribute depends on whether performance indicators are  routinely used to monitor system performance and whether  periodic external evaluation is used to assess the system  outputs in relation to its objectives. If indicators are used they  should be named and described. Also any available results  should be presented.,N/A,Data analysis: Appropriate methods are used for analysis and interpretation of data.,N/A,"The analysis is conducted with appropriate frequency and utilises suitable descriptive and analytical methods to produce valid results. Surveillance systems that perform well in this attribute will use analytical methods that are appropriate to the data and the information needs of users of the data whilst exploiting the data to its fullest extent.
An evaluation of data analysis should include: The identification of the analysis methods applied to surveillance data: * No analysis * Basic descriptive statistics * Examination of trends * More sophisticated statistical approaches (e.g. time series analyses, spatial analyses); 
An assessment of whether the limitations of data have been understood and accounted for in statistical analyses?; 
An indication as to whether the body of data available is being fully exploited or could further use of data be made? It may help to review requirements for information made by users of the surveillance data in the past, to determine whether their needs were met by the methods applied.",N/A,"Data and information collection: The use of appropriate data and information sources, sampling strategy and data collection methods.",N/A,"A surveillance system that scores well on this attribute will  have a clear and comprehensive case definition and risk  organism description; make use of appropriate diagnostic  tests; have a written protocol that describes collection of data  (and samples); and the limitations of the collection methods  will be clearly defined and understood.   Questions to consider when assessing data and information  collection include:     
* Is there (if applicable) a written case definition/organism  description for this surveillance system that is clearly  defined and complete, with specified inclusion and  exclusion criteria? If so  
- Does the case definition/organism description include relevant details of the case signalment,  clinical and pathological signs and epidemiological  information as appropriate?  
- Does the case definition include laboratory  diagnosis? Alternatively does the organism  description include taxonomic ID?  
- Are the chosen diagnostic/taxonomic methods  appropriate to the case definition/organism description, including in terms of samples being  collected? 
- Are syndromes used and - if yes - defined in an  appropriate way? 
- In those sectors where symptomatic surveillance is  
* Is there (if applicable) a written case definition/organism  description for this surveillance system that is clearly  defined and complete, with specified inclusion and  exclusion criteria? If so undertaken, are symptoms clearly defined for  when samples need to be taken? 
* Is there a written sample and/or data collection protocol  and are there appropriate assurance mechanisms to  ensure the protocols are followed?  
* Have the sensitivity and specificity of the tests used been  assessed (where relevant)? 
* Are there data collected that are not used in analysis, interpretation or surveillance management (redundancy)?  
* Are there information needs for which data are not  currently collected and feasibly could be?  
* Are appropriate sampling strategies used, including the  use of risk-based approaches and pooled sampling? This  could include risk-based requirement calculations or risk- based sampling. The basis of the risks used in the design  of the risk-based sampling strategy should be reviewed. Data collection methods should be clearly documented.  It may help to review demands for information made by users  of the surveillance data in the past, to determine whether their  needs were met by the data available.",N/A,Data management and storage: How surveillance data is managed and stored.,N/A,"Appropriate use and documentation of data management systems for processing information, including data processing protocols and effective use of data verification procedures, data storage and back-up protocols. Measures taken to assure authorised computer system access and to maintain confidentiality where needed. Is there a dedicated custodian? Data management is a broad area concerning the collation, storage and maintenance of data, including but not limited to matters of data quality, accessibility, usefulness and security. Assessing this attribute will require an intimate understanding of the data storage and management systems employed by the surveillance activity. More detailed references on assessing data management are provided in the Methods Catalogue of this document (Appendix 1). An assessment of this attribute should include: 
1.Consideration of whether the database structure has been correctly designed: 
*Has each field of data been tightly defined to ensure correctness, conciseness and consistency across records? 
*Have primary keys, uniquely identifying each record, been assigned? 
*Has the database been normalised, to ensure data is stored in the most parsimonious, transparent and useable way? 
*Have validation constraints, preventing the input of invalid data, and internal cross-consistency checks been applied? 
*Is the data stored in a way that allows the required interrogation and analysis?; 
2.Consideration of whether documentation of the data is sufficient to facilitate interpretation and understanding of the data: 
*Is there a document providing a summary overview of the data and collection methods and explaining any idiosyncrasies relevant to the analysis and interpretation of the data? 
*Is there a data dictionary that clearly defines each field? 
*Is there an entity relationship diagram that explains how the data relate?; 
3.Consideration of whether there are adequate and documented protocols for managing data quality and security: 
*Is the data management system covered by a data quality standard (e.g. ISO9000, Good Clinical Practice or Good Laboratory Practice)? 
* Are periodic data quality control checks implemented? 
*Are records management issues clearly defined, including policy on the retention of data? 
* Are data back-up and storage protocols in place?",N/A,Field and laboratory services: Field and laboratory activities  are carried out using  appropriate methods with  quality assurance and timely  and accurate production of  results.,N/A,The tests used should have the required test sensitivity and specificity and be performed by accredited laboratories or personnel. Sampling should follow SOPs.,N/A,Resource availability: An assessment of the financial  and human resources available  and required for implementing  the surveillance system.,N/A,The personnel have the required expertise and capability for  conducting their tasks. There is sufficient laboratory capacity to allow turn-around of samples and reporting within  acceptable (defined) time periods. Responsibilities for  providing resources are clearly documented. Available  resources match current requirements.,N/A,"Technical competence and training: Technical skills of the  personnel involved in the  surveillance system,  including access to relevant  training.",N/A,"The team providing technical management, guidance and day- to-day operation of the surveillance system should have adequate technical skills in relevant disciplines (such as epidemiology or ecology) to be able to perform the relevant  analysis, interpretation and information dissemination.  This includes the provision of adequate initial training and an on-going programme of training for those implementing the  surveillance system, particularly those collecting the data.",N/A,Acceptability and engagement: Willingness of persons and organisations to participate in the surveillance system and the degree to which each of these users is engaging in the surveillance.,N/A,"Acceptability/Participation examines the involvement or  engagement of stakeholders in the planning, design and  implementation of the surveillance activity.  Poor engagement by some users might suggest a low level of  motivation to become involved in surveillance activities, or a  perceived lack of benefit. Technical, financial or knowledge  issues could be other reasons for low levels of engagement.  Reasons for low levels of engagement should be identified and  described. The efficacy of any surveillance system that is  greatly dependent on voluntary participation or human  behaviour (e.g. passive surveillance activities) will be  vulnerable to problems with engagement.  This attribute could include an assessment of stakeholder  awareness of the system and their understanding of it. One  could also assess their beliefs about the benefits or adverse  consequences of their participation in the system, including the  provision of compensation for the consequence of disease/risk  organism detection. Communication is known to be a key  driver of engagement.  This attribute includes an assessment of participation including identification of the factors likely to increase or decrease  stakeholder participation and an assessment of the likely  extent of impact of these factors on levels of participation.  Qualitative or semi-quantitative social science approaches are  likely to be of value in assessing participation. Consultation  with all those involved in generating, analysing, reporting and  using surveillance data will be valuable.   Factors that may influence participation include:   
* What communication pathways exist internal to the  surveillance system (e .g. between those collecting or  providing data and those analysing and reporting the  data)? Are these pathways formalised in any fashion?  
* Does information and feedback flow freely between  those implementing surveillance and those using  surveillance data?  
* How are each of the key stakeholders represented in the  planning, design and implementation stages of the  surveillance activity?  
* What are the incentives (e.g. compensation payments) or  barriers (e.g. consequences of reporting) for  participation?",N/A,Coverage: Proportion of the population of  interest (target population) or  proportion of areas of interest  (e.g. specific habitats or high- risk sites) that is included in the  surveillance activity.,N/A,"The coverage of a surveillance system is related to  representativeness, bias and sensitivity. Coverage can be particularly important in surveillance for the early detection of  exotic or new (emerging) diseases or risk organisms.  An assessment of coverage could include:  
* Characterisation and qualitative comparison of the  sampled and target populations. Alternatively, comparison of sampled areas or habitats versus areas or  habitats of interest. 
* Where sufficient data on the target population/areas or  habitats of interest exists, simple calculations of the  proportional coverage can be made (e.g. 75% of the  national herd and 45% of cattle holdings are sampled  annually or 30% of the marine ports).  
* Where sufficient information on the background population,  or high-risk areas or habitats respectively, is lacking, more  sophisticated sampling designs might be employed (e.g. capture-recapture analysis or drop camera surveillance).  
* Considering whether the target population, or area of  interest, has been adequately defined (i.e. whether the  exclusion of certain animals or holdings or sites is  merited). 
* The unit of interest - the level at which coverage is  measured - is often the unit of interest of surveillance  (e.g. animal, holding, high-risk site or specific marine  habitat). If insufficient data exist, alternative perspectives  might be desired. Coverage might then be assessed at  other aggregate levels (e.g. geographical areas) or  relevant intermediate steps in the surveillance pathway  (e.g. the proportion of veterinary practices submitting  diagnostic samples).  
* In certain contexts it may be worth establishing a  timeframe of reference (e.g. annual coverage). The  choice of timeframe should reflect the epidemiology of the  disease or life history of a risk organism.",N/A,Data completeness and correctness: How complete and correct is the data obtained and recorded by surveillance.,N/A,"Assessment of the proportion of data that was intended to be  collected that actually was, and the proportion of data entries  that are complete (i.e. include all variables) and correctly reflect  the true value of the data collected. Includes assessment of data  quality and documents if data validation is occurring.  Completeness of surveillance data is the percentage of  complete entries and should be considered at two levels: fields  and records. Most commonly data completeness is measured  as the proportion of records with complete and valid data in  the data fields - where data fields are variables containing  (where applicable) demographic, morphometric, taxonomic, clinical, pathologic or epidemiological information recorded for  each sample. Key data fields (e.g. animal ID, holding of origin,  test result etc.) should be identified and the proportion of  completeness measured.   Measurement of the proportion of records or observations that  have been collated in the data system may also be  considered. This will require comparison with an alternative  source of data (e.g. the sample frame or paper records of  sampling and test results).   Poor data completeness may indicate problems in the  following attributes: ""data and information collection"", ""data  management"" or ""internal communication"" and ""acceptability  and engagement"".",N/A,"Multiple utility: The ability of a surveillance system to capture information on several diseases, syndromes or risk organisms.",N/A,"This is a measure of how generic a surveillance system is. For  example, the collection of slaughterhouse records can provide  information on the presence/absence of several diseases and  risk organisms.  Multiple utility in a system should be considered when  examining the cost-effectiveness of a system. It may also be of  benefit to assess the potential multiple utility which may  provide recommendations on how to add value to the system  currently implemented.   
An assessment of multiple utility could consider:   
* What additional information is or could be gathered during  sample collection (e.g. on animal health or husbandry and  demographics; or other endemic/native/cryptogenic/non- native organisms that are present or absent)?  
* What other types of samples are or could be collected at  the time of sampling (e.g. environmental)?  
* What other diseases/risk organisms are or could be  tested for with the samples collected?  
* How long are samples stored following testing and could  they be used for other purposes (including other research  purposes)?  For a surveillance system to offer value to other diseases/risk  organisms or information needs, the objectives and processes of  the system should be aligned to other systems. So it may be  expected that more generic systems are likely to have more  potential for multiple utility. For example, a simple random  survey of holdings or geographical locations, repeated annually  and with good coverage and representativeness could be useful  for various diseases/risk organisms; whereas a risk-based  design aimed at a specific threat may be of limited value for  other diseases/risk organisms with differing epidemiology,  host-range, life history or habitat preferences",N/A,"RARR (Reliability, availability, repeatability and robustness): How reliable, available,  repeatable and robust is the  surveillance system  Reliability means ""does the system function without failure"" and  availability means ""is the system operational when needed"".  Repeatability means ""can the surveillance component  performance be maintained consistently over time"" or  ""how consistently can the results be reproduced over time"".   Robustness means ""the ability to obtain comparable results over  time"".",N/A,"Reliability means ""does the system function without failure"" and  availability means ""is the system operational when needed"".  
These attributes can be measured retrospectively by   
* Looking at the incidence of minor and major faults over a  defined period of time or  
* Measuring the proportion of time that the system is  fully functional.  
Assessment of these attributes will benefit from consultation  with those involved in the generation, management and  analysis of surveillance data. If performance indicators have  been implemented in the surveillance process, historical data  from these will give a good insight into the ongoing functioning  of the system.  Repeatability means ""can the surveillance component  performance be maintained consistently over time"" or  ""how consistently can the results be reproduced over time"".  Repeatability is often considered when validating diagnostic  tests. A surveillance activity that performs well in this attribute  produces data that are comparable across years and where  changes to the data and data collection methods over time are  clearly defined, understood and documented.   In this context, one might consider changes to legislation;  changes to diagnostic methods and sampling techniques, including improvements through adoption of new technology;  changes to surveillance design; or influences on disease or  risk organism reporting behaviour in passive surveillance  activities.   
* How have these impacted on the comparability of  surveillance data over the time period of interest?  
* Have these influences been identified and examined and  can they be accommodated in interpretation of the  surveillance data?  Robustness means ""the ability to obtain comparable results over  time"". It covers the ability of the surveillance system to produce  acceptable outcomes over a range of assumptions about  uncertainty by maximising the reliability of an adequate outcome.",N/A,Historical data: Quality and accessibility of archived data.,N/A,"Maintaining historical data is more important to surveillance  activities designed to provide evidence for freedom from  disease or risk organisms or for monitoring trends in  prevalence of endemic disease or risk organisms. Historical  data can also be valuable for research and trend analysis.   This attribute is related to ""data management and storage"" and  ""RARR"". Questions to consider include:   * How many years of data are stored?  * How complete and reliable are the data?  * Are the data stored in a way that allows the required  interrogation and analysis?  * Is there a summary overview of the data and collection  methods explaining key idiosyncrasies of the data and  changes to the data or collection methods over time?  * What use is currently made of historical  surveillance data?",N/A,Precision: How certain a numerical  estimate obtained from the  study population is or - alternatively - how large  the uncertainty of an  estimate is,N/A,"A precise estimate has a narrow confidence interval. Precision  is influenced by sample size, the chosen confidence level and data completeness and correctness.  Precision in surveillance activities designed to monitor  prevalence or density is a measure of the degree of certainty  around the point estimate of prevalence, incidence or density (i.e. the confidence interval or standard error).   NB: A related concept in surveillance designed to provide  evidence for freedom from disease or risk organism is the  measure of confidence in disease or risk organism freedom  derived from the sensitivity of the surveillance system.   The precision of point estimates in epidemiological studies is  dependent upon disease or risk organism prevalence, sample  size and the approach to sample selection (i.e. the design effect).  In ecological studies the precision of the estimates is dependent  on the area covered (sample size) and the search methodology  (e.g. search efficiency).   The precision of a surveillance activity will determine how  sensitive the surveillance system is to changes in prevalence or density.   The desired level of precision will be defined by the  epidemiology of the disease or risk organism, the surveillance  objectives, the risk that the disease or risk organism poses and the availability of resources.",N/A,Representativeness and bias: Extent to which the  frequency of features of  the population of interest  are correctly reflected in  the surveillance data that  are collected.,N/A,"A surveillance system that is representative accurately  describes the distribution of disease/risk organisms in the  population or area of interest. Bias describes the extent to  which a prevalence or population density estimate produced  by the surveillance system deviates from the true prevalence or population density value. Bias is reduced as  representativeness is increased.  The representativeness of a surveillance system is related to coverage and bias; it is a comparison of the sample and target  populations or specific areas of interest with regard to a  number of key features or risk factors. Features taken into  account when considering representativeness could include,  for example, production type, species, geographic location,  habitat preferences and environmental parameters.  Bias can be divided into two main types: information and  selection bias. Information bias results from systematic  differences in the way information is collected, for example on  the presence or absence of a disease or a risk. Selection bias  occurs when there is a systematic difference between the  individuals/samples/transects included and those that are not.   
Some potential sources of bias to consider include:   
* Sensitivity/specificity of the methods applied. 
* Under-reporting in passive surveillance activities. 
* The sample source population: For example in animal  surveillance, sampling at abattoirs may lead to an under-estimate of the prevalence of many diseases as these  animals are from a healthy (and younger) sub-population,  whereas sampling fallen stock may lead to an over- estimate of burden. Similarly, in marine surveillance  sampling a receiving location may lead to an  underestimate of risk organism incursions, whereas  sampling vectors or pathways will provide an over estimate of invasion success. 
*  Selection bias may also be introduced in terms of  geography, habitat, population size, organism traits,  species, age, sex or purpose. As such, the first step will be to identify key characteristics of  the target population or areas of interest upon which to  measure representativeness. These characteristics might be  risk factors for the disease or organism threat - knowledge of  the associations between these characteristics, selection in  the sample population/environment and disease/organism will  inform the understanding of bias. Examples of relevant  features include:   
* Species 
* Population or group size (e.g. herd size) 
* System type or focus (e.g. production type) 
* Age, sex or purpose  
* Geographic location  
* Habitat 
* Presence/absence or frequency of vectors  
The second consideration in assessing representativeness is  whether there are sufficient and accurate data on the  identified features in both the target and sample populations.   Bias may lead to erroneous conclusions about the burden or  distribution of disease in the population or an organism in an  environment. For some surveillance activities - such as risk- based surveillance aimed at detecting cases to facilitate  control - surveillance may be intentionally biased toward sub- groups of the population at higher risk of disease or  geographic locations and habitat strata where the occurrence  of risk organisms is more likely. So the context and objective  of surveillance will determine whether bias is acceptable or  not. Bias in the surveillance output can be examined and  quantified by several methods (see Methods Catalogue:  Appendix 1).  If bias is deemed to be significant and unacceptable and  cannot be satisfactorily corrected for during analysis and  interpretation of the data, one might consider reviewing the  design and implementation of the surveillance activity.",N/A,Benefit: Direct and indirect advantages  provided by the information  generated by the surveillance  system.,N/A,"The benefit of surveillance quantifies the monetary and non- monetary positive direct and indirect consequences produced  by the surveillance system and assesses whether users are  satisfied that their requirements have been met. This includes  financial savings, better use of resources and any losses  avoided due to the existence of the system and the information  it provides.   
These avoided losses may include the avoidance of:  
* Primary industry production losses  
* Human mortality and morbidity  
* Economic losses 
* Decrease in consumer confidence  
* Threatened livelihoods  
* Harmed ecosystems  
* Utility loss 
* Loss of sociocultural values  Often, the benefit of surveillance estimated as losses avoided  can only be realised by implementing an intervention. Hence, it  is necessary to also assess the effect of the intervention and  look at surveillance, intervention and loss avoidance as a  three-variable relationship.   Further benefits of surveillance include maintained or  increased trade, improved ability to react in case of an  outbreak of a disease or incursion of a risk organism, maintaining a structured network of professionals able to react  appropriately against a (future) threat, maintaining a critical  level of infrastructure for disease/risk organism control,  increased understanding about a disease or risk organism,  and improved ability to react in case of an outbreak of a  disease or incursion of a risk organism.   The benefits of a surveillance activity should be listed and,  where possible, quantified. 
An evaluation of the benefits of a  surveillance activity may include:   
* A characterisation of all the potential benefits of the  surveillance activity 
* A description of benefits as perceived by the relevant  stakeholders 
* Where possible, quantify market benefits in financial  terms 
* Where possible, quantify non-monetary benefits by  alternative methods  
* Consider how the benefits are distributed among  stakeholders, including: producers, consumers, the livestock industry or society.  
Points to consider whilst assessing the benefits of  surveillance include:   
* Surveillance and disease or risk organism control are often integrated: That is to say, surveillance provides  information that informs control and so many benefits of  surveillance are often realised by control measures. As  with costs, it is important to understand the benefits of  surveillance in the broader context of disease or risk  organism mitigation. Benefits of surveillance may be  considered as disease or risk organism losses and  mitigation costs avoided by detection of a disease or risk  organism. So it may be useful to begin by listing all the  losses and costs resulting from a disease or risk  organism, and disease or risk organism mitigation  measures. It may be difficult in some instances to  distinguish between the direct benefits of surveillance and  those arising from mitigation.  
* The benefits of surveillance for early detection of disease  or risk organism outbreaks can be quantified as the losses  and costs avoided through earlier detection and control. 
* The primary benefit of surveillance providing evidence of  disease or risk organism freedom is access to  international markets. The economic value of  international trade can be attributed as a benefit to  surveillance. Officially recognised disease or risk  organism-free status often permits the disease or risk  organism-free country/region to maintain border security  measures against introduction of the disease (e.g.  restriction on trade and movement of risk goods or  requirement for pre-export testing) - thus mitigation of  risk of incursion is also a benefit of surveillance for  freedom from disease or risk organisms. 
* Surveillance for case-detection and monitoring  prevalence of endemic disease or presence of risk  organisms provides information for the improved control  and management of disease and risk organisms;  including prioritisation of diseases and risk organisms and  allocation of resources.  
* Improved public health is an obvious advantage to  surveillance for zoonoses. Increased consumer  confidence is another  - although consumer confidence  may also be of significance to other high-profile, non- zoonotic diseases.  
* Consider potential indirect or secondary benefits of  surveillance; e.g. externalities or spill over of benefit to  other sectors or industries. It may be helpful to consider  potential benefits both upstream (e.g. animal feed producers) and downstream (e.g. value-added producers) of the production system. Examining the value chain will aid in this.",N/A,Decision support:  The direct link between the  information created by  surveillance and decision-making.,N/A,"Includes an assessment of the availability of the information  created by surveillance to relevant decision-makers. For  example, describes how surveillance infrastructure is used to  provide decision-support during outbreaks or incursions or is  used for priority setting. Includes assessment of reporting of  surveillance outputs to decision-makers.",N/A,External communication and dissemination: An assessment of the data and  information provided to relevant  stakeholders outside of the  surveillance system.,N/A,"An assessment of the data and information provided to those  outside the surveillance system including the timeliness and  types of output produced. The efforts made to disseminate  these outputs including the use of web-based systems should  also be assessed.  Communication concerns the dissemination of information and  provision of feedback into the system. Communication in a  surveillance system is often related to various other factors  such as participation, timeliness, stakeholder interest and  system impact.   
Relevant to the assessment of both ""internal communication""  and ""external communication and dissemination"" an  assessment of communication should consider:   
* A list of the outputs that are generated from the  surveillance data; who are these intended for and do they  meet all information needs of the target audience?  
* An assessment of who has access to the surveillance  outputs; are all stakeholders represented?  
* An assessment of whether the surveillance outputs are  produced sufficiently frequently. Do they contain up-to- date data of sufficient quality? Are the data presented  with sufficient discussion of its meaning, limitations and  biases from an epidemiological perspective?  
* A list of other feedback provided to those contributing to  the surveillance system e.g. data quality checks.  Qualitative or semi-quantitative social science approaches  (e.g. stakeholder interviews, focus group discussions) are  likely to be of value in assessing this attribute.
Consultation  with the key stakeholder groups of the surveillance system will  be useful, including:   
* Providers of surveillance data (e.g. farmers, veterinarians,  laboratory staff, taxonomists, field workers etc.).  
* Those analysing and interpreting the surveillance data  (i.e. generating information and knowledge from the data  and disseminating it). 
* Users of surveillance data, including the direct customer  (funder) but also other beneficiaries of the information as  appropriate (e.g. government, industry or academia)",N/A,Internal communication: An assessment of the data and  information provided to relevant  stakeholders inside the  surveillance system.,N/A,"An assessment of the methods used and ease of information exchange between all those involved in providing, managing, analysing and disseminating information for the surveillance system. The methods used to provide feedback to data providers and to increase their awareness about hazards and surveillance activities should also be assessed.

Relevant to the assessment of both ""internal communication"" and ""external communication and dissemination"" an assessment of communication should consider: 

* A list of the outputs that are generated from the surveillance data; who are these intended for, do they meet all information needs and are they are at the required level for the target audience? 
* An assessment of who has access to the surveillance outputs; are all stakeholders represented? 
* An assessment of whether the surveillance outputs are produced sufficiently frequently. Do they contain up-to-date data of sufficient quality? Are the data presented with sufficient discussion of its meaning, limitations and biases from an epidemiological perspective? 
* A list of other feedback provided to those contributing to the surveillance system e.g. data quality checks.

Qualitative or semi-quantitative social science approaches (e.g. stakeholder interviews, focus group discussions) are likely to be of value in assessing this attribute. Consultation with the key stakeholder groups of the surveillance system will be useful, including: 

* Providers of surveillance data (e.g. farmers, veterinarians, laboratory staff or taxonomists). 
* Those analysing and interpreting the surveillance data (i.e. generating information and knowledge from the data and disseminating it).
* Users of surveillance data, including the direct customer (funder) but also other beneficiaries of the information as appropriate (e.g. government, industry or academia).",N/A,"Utility: Describes how useful, profitable, or beneficial surveillance is in relation to its objectives and describes the changes that have been made based on the outputs provided by the surveillance system.",N/A,"This attribute consists of an integrated appraisal of the actions   ataken as a result of the information provided by the  surveillance system, e.g. changes in protocols or behaviour  and changes in mitigation measures and particularly changes  in disease or risk organism occurrence. Even not taking action can be considered a valid conclusion based on surveillance  information provided. The attribute is mostly assessed in a descriptive (qualitative) way. However, more comprehensive assessments are possible, including the simulation and  economic assessment of outbreaks and incursions that may  have been avoided thanks to surveillance-based interventions.  The attribute describes the extent to which surveillance  objectives are achieved and includes an assessment of  stakeholder uptake and acceptance. Stakeholder input is relevant to this attribute.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"While the standardised assessment of core attributes provides consistency between the assessments of different systems, the choice of accessory attributes allows users to tailor the evaluation to the individual context. SurF is a very generic framework, which allows a large amount of flexibility around attribute selection and as such differs from recently published animal surveillance frameworks, which emphasise alignment of attributes with specific surveillance objectives e.g. freedom from disease (Drewe et al. 2015; EVA 2013, 2015). Further, a substantial number of attributes are included to accommodate the diversity and unique context of MPI's surveillance systems.",N/A,N/A,"European Centre for Disease Prevention and Control (ECDC). Data quality monitoring and surveillance system evaluation - A handbook of methods and applications (2014). Available at: http//www.ecdc.europa.eu/en/publications/Publications/Data-quality-monitoring-surveillance-system-evaluation-Sept-2014.pdf; last accessed 16 February 2015.

Stark, K. D. C. (2012). Evaluating surveillance programmes: Ensuring value for money. Veterinary Record, 171, 421-422. https://doi.org/10.1136/vr.e7124","The terminology proposed by Hoinville et al. (2013) was used wherever possible to align with existing standards.

The attributes, their definitions and recommended methods for assessment build on existing frameworks, in particular SERVAL and EVA, but also the review of Drewe et al. (2015) and the CDC and ECDC guidelines on surveillance evaluation and monitoring. SurF also includes some additional attributes, which were developed with the objectives and scope of SurF in mind. Furthermore, some previously proposed attributes were modified to give the framework sufficient flexibility to be used across the whole spectrum of New Zealand's biosecurity surveillance portfolio. 

Traffic-light coding is used to provide a summary appraisal in SurF for each of the attributes, using the following standardised coding approach: excellent or very goos; good, though room for improvement; in need of attention.

A wide range of qualitative and quantitative methods are available to assess individual attributes and the choice of method will always be situation-specific and dependent on the available data and information as well as the resource capacity of the assessor(s). Performance indicators, i.e. measures that are typically quantifiable and can be used as a proxy for surveillance performance, can be used for selected attributes. SurF provides references to recommended methods (details provided in Appendix 1 and case studies (Appendix 2)) to guide users in their assessment, but does not prescribe specific methods for attribute assessment. Not all methods will be applicable to specific surveillance objectives and/or contexts.

Attribute assessment by SurF is supported by a visual output (Figure 4). At the individual evaluation level this allows quick assessment of a system's strengths and weaknesses and, in addition to the case report form, standardises the reporting of SurF results across different evaluations.",
paternosterDegreeOneHealth2017,926,Paternoster 2017,"The Degree of One Health Implementation in the West Nile Virus Integrated Surveillance in Northern Italy, 2016.","The degree of One Health implementation in the west nile virus integrated surveillance in Northern Italy, 2016",2017,Giulia Paternoster,giulia.paternoster@gmail.com,Italy,To assess the degree of One Health implementation of the West NileVirus surveillance system in three North Italian regions,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",d. One Health,Italy,k. Other,A Systems Approach to Evaluate One Health Initiatives (Ruegg 2018),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Not clear - however they mentioned that animal, public health, and environmental health representatives are stakeholders of the initiative, in additional to the general public.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,OH Planning,"Positioning of the entomological traps (active surveillance) 
Collecting mosquito traps and transfer to laboratories (active surveillance)
Wild birds collection (trap/shoot) and transfer to the laboratories (active surveillance)
Passive surveillance on wild birds found dead 
Passive surveillance in horses: reporting of suspect cases of WND (neurologic symptoms)
Passive surveillance in horses: sampling of suspect cases of WND (neurologic symptoms)
Active surveillance on horses 
Laboratory tests on horses, wild birds, and mosquitoes incl. species-ID 
Surveillance of neoroinvasive disease in humans 
Laboratory tests on blood and organ donations, and on human suspects (West Nile neuroinvasive disease) samples
Data sharing and communication",Evaluation description and methodology was unclear - not sure if the aspects relating to each domain should be considered attributes or potential evaluation criteria.,OH Learning,N/A,N/A,OH Sharing,N/A,N/A,Transdisciplinarity & Leadership,"Presentation of the societal problem within One Health (5) 
Assessing broadness to further classify the initiative (3) 
Assessing integration (10) 
Assessing reflection, learning, and adaptation (3) 
Assessing efficiency and effectiveness of the case study's problem solving (2)
Assessing management, social and leadership skills (5) 
Assessing team structure (well-structured vs. pseudo team) (8) 
Actors and competencies (2) 
Problem formulation, focus, goals, and criteria of success (6)",Evaluation description and methodology was unclear - not sure if the aspects relating to each domain should be considered attributes or potential evaluation criteria.,OH Thinking,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"This quantitative evaluation of OH-ness, also in combination with other evaluation approaches (e.g., a process evaluation or a cost-benefit evaluation) enables the detection of strengths and weaknesses of the surveillance system and may thus be a basis for fine-tuning and implementing the initiative in a more OH-oriented perspective.",N/A,N/A,NEOH framework is not listed in the references but should be pulled if not already identified.,"In accordance with the evaluation protocol developed by NEOH, we first defined and later scored the five different aspects considered to be essential for a perfect OH approach: OH thinking, OH planning, Transdisciplinarity and leadership, OH sharing, and OH learning. Scores ranged from 0 (=no OH approach) to 1 (=perfect OH approach) and were allocated corresponding to the scoring key provided by the respective evaluation tool.

The evaluation protocol developed by NEOH and applied in the present study represents an innovative tool to assess the degree of OH implementation of a health-related initiative. To our knowledge, transdisciplinarity, collaboration, and communication aspects have not been specifically addressed in other studies. Researches so far mainly focused on performances or economic aspects of integrated WNV surveillance systems. 

As regards our case-study, an ongoing process evaluation will provide a more detailed analysis of the surveillance planning  and implementation. Evaluation results could (i) be the basis for developing shared recommendations, (ii) be used by Animal and  Public Health decision makers at national or regional level, and (iii) provide insights on the efficacy of integrated health systems  for zoonoses mitigation.

Evaluation description and methodology was unclear - not sure if the aspects relating to each domain should be considered attributes or potential evaluation criteria. The article also only provided aspects relating to some domains, not all.",
pavlinSyndromicSurveillanceInfectious2013,11999,Pavlin 2013,Syndromic surveillance for infectious diseases,Syndromic surveillance for infectious diseases,2013,Julie A. Pavlin,unknown,United States of America,Review of syndromic surveillance,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Examples of syndromic surveillance objectives:
Rapid recognition of a disease outbreak; improved speed of data transmission and analysis; integration with other surveillance systems; access to more detailed information to assist with outbreak investigations; determining location of exposure using geographic information systems; targeting needed areas for medical countermeasures; evaluation of prevention measures; and providing historical trend data for baseline comparisons and long-term monitoring

Situational awareness; confirming or ruling out an event; supporting traditional epidemiologic investigations; case finding; and analyzing trends. Others have used syndromic surveillance for notification of reportable diseases and to determine predominant symptoms during an outbreak to let physicians know how a particular disease is presenting

To monitor situations with widespread health effects; to affirm the absence of any adverse health events after a natural disaster or known airborne contamination",N/A,N/A,N/A,N/A,"Partners in syndromic surveillance include: owners of data sources; commercial and academic institutions that develop the methods for data transfer, manipulation, analysis and output; public health institutions that use the data in making public health decisions; and government organizations that use these decisions to target limited resources for public health action.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"It is important to understand how well the syndromic surveillance system represents the population under surveillance. Some syndromic surveillance systems do not have the coverage needed to detect all outbreaks.

Poorer socioeconomic areas may be at higher risk for certain disease outbreaks and their residents less likely to attend a clinic with electronic data, shop at a grocery store or pharmacy that electronically inventories their sales, work at a company that tracks absenteeism electronically, or have a mobile device in which to report illnesses in their community (see below). Until there is a universal EHR, syndromic surveillance programs will only be as good as their population coverage.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"States that the CDC 2004 guidelines are applicable to the evaluation of syndromic surveillance systems and provides a summary of the CDC 2004 framework sections.

The CDC defines syndromic surveillance as ""a system that uses individual and population health indicators that are available before confirmed diagnoses or laboratory confirmation to identify outbreaks or health events and monitor the health status of a community."" 

When deciding which data are the best for a particular system, there are a number of factors to consider, including timeliness, reliability, completeness, quality, flexibility, investigability, and overall usefulness in meeting the goals of the particular surveillance system.

Each health department that is running a syndromic surveillance system should evaluate its own definitions to ensure that they are the most sensitive and specific to detect the syndromes of interest. Analyses have shown that many diagnoses contribute more noise than signal.

To assist with determining detection performance, Buckeridge et al. [31] have developed a unified model of aberrancy-detection algorithms and software called Biological Space-Time Outbreak Reasoning Module or BioSTORM.

To maximize the potential benefits of a syndromic surveillance system, the following recommendations should be considered during the development of the system and its integration into routine public health practice:
- Use existing data and repurpose it to fit local public health needs. Be aware of the emerging availability of the EHR and, if possible, work with the developers to ensure that specific information of public health importance is readily available.
- Find data sources with representative coverage of the population. If a portion of a community is not covered, then look for other ways to ensure that important public health issues are not missed.
- Determine goals for the syndromic surveillance system up front, especially as data sources are incorporated. Ensure that these data can provide the information needed.
- Do not rely on experience with all systems to be the same. Evaluate the system continuously and make sure that the results obtained are appropriate. Just because one data stream works for one community does not mean it will be as sensitive in others.
- Be careful about relying on automated alerting. Do research on what algorithms may work best for your data. Do not forget the importance of the epidemiologist in determining when something is unusual and warrants investigation.
- Investigate other potential uses of the system besides outbreak detection and situational awareness. The system might also be used to provide baseline data for other analyses, to track reportable diseases, to assist with investigations, to determine presenting symptoms in an outbreak, and to provide feedback to clinicians when a health alert is issued.
- Use syndromic surveillance systems to augment traditional systems. Find out where there are gaps in timeliness or coverage of regions or diseases that might be filled with data from syndromic surveillance.
- Do not forget the need for a public health response when planning syndromic surveillance programs. Ensure that protocols for monitoring and investigating aberrations are written and periodically re-evaluated.",
pelicanSynergisingToolsCapacity2019,509,Pelican 2019,Synergising tools for capacity assessment and One Health operationalisation.,Synergising tools for capacity assessment and One Health operationalisation,2019,K. Pelican,pelicank@umn.edu.,United States of America,Provides guidance on One Health evaluation tool selection,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Pull any relevant evaluation tools that have not already been identified from the scoping review.,"See Table 1 for descriptions and comparisons of included evaluation tools.

Additionally, as part of the TZG development effort, the Tripartite, with input from other organisations, including the Centers for Disease Control and Prevention (CDC), developed a review document that summarises and links existing One Health-related processes and activities (e.g. regulations, standards, guidance, manuals, tools, assessments, evaluations and conventions) (internal document available upon request). This review encompasses approximately 50 tools, processes and activities that the Tripartite authors broadly considered One Health-related. This comprehensive list served as a resource to the authors in determining tools for inclusion in this paper and building a conceptual model of how these tools could work together more effectively.

While much progress has been made in developing and implementing various One Health tools and processes, to date there has been limited effort in sharing lessons learned and best practices on how to synergise or link these for maximal benefit at the national level.

Although not exhaustive, the information presented in this paper should help countries to gain a clearer understanding of the One Health tools that are available, how and when tools and processes can be applied for maximal benefit, and how these tools can be used to support national and international standards and goals for One Health, including goals concerning preparedness, planning, response, operations, workforce development and other capacity-building activities.

While previous efforts have brought partners together to promote collaboration and describe specific One Health tools, this paper seeks to provide information on how selected tools might be used together for greatest effect and better outcomes. This paper also presents a more in-depth review of the unique characteristics and applications of operational tools that have been used to assist countries and regions.

A conceptual model was generated representing the authors' consensus on the links and synergies between the 12 tools for advancing One Health implementation (Fig. 1). This flow diagram depicts one way in which tools and their outputs might be used to inform and strengthen outputs from other, subsequently or concurrently, implemented tools. In addition, the model can help countries to select appropriate tools according to the specific output they seek to strengthen. As the conceptual model was being developed, the tools fell into five categories: Assessment, Prioritisation, Action Planning, Implementation and Monitoring. Together they created an implementation cycle that fits an overarching conceptual framework that could inform future tool use (Fig. 2).

As the authors developed the conceptual model, a flexible conceptual framework emerged that could help countries in implementing One Health tools at the national level in a more systematic way to maximise outcomes and impact. This framework places tools into one (or more) of five operational categories of work: Assessment, Prioritisation, Action Planning, Implementation and Monitoring. This conceptual framework is intended to inform tool implementation and support country One Health mechanisms to ensure strong synergy and that the outputs of tool implementation are used effectively to support the achievement of overall country goals.",
peyreRISKSUREVATool2019,488,Peyre 2019,The RISKSUR EVA tool (Survtool): A tool for the integrated evaluation of animal health surveillance systems.,The RISKSUR EVA tool (Survtool): A tool for the integrated evaluation of animal health surveillance systems,2019,Marisa Peyre,marisa.peyre@cirad.fr,France,Evaluation tool for animal health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",e. Other,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Step 1: Plan,"Manage/engage: 
-Stakeholder mapping,
-Develop evaluation plan; 
Define: 
-Define the object, 
-Program theory/the theory of change, 
-Identify potential unintended results; 
Frame: 
-EVA purposes, 
-EVA questions, 
-Judgement value",N/A,Scale and complexity of different levels of health surveillance system evaluation: technical (looking at the performance of the system); process (looking at the factors affecting system performance); comprehensive (looking at the value of the system) (Fig 2).,See Fig 4 and Fig 5 for more details. Exact framework sections and plan is somewhat unclear.,Step 2: Implement,"Describe:
-Sampling
-Indicators
-Type pf data (qualitative, quantitative)

Analyse (address the evaluation question):
- Causal
-Counterfactual
-Alternative explaination",N/A,Scale and complexity of different levels of health surveillance system evaluation: technical (looking at the performance of the system); process (looking at the factors affecting system performance); comprehensive (looking at the value of the system) (Fig 2).,See Fig 4 and Fig 5 for more details. Exact framework sections and plan is somewhat unclear.,Step 3: Report,"Synthesis:
-Single EVA
-Across EVA
-Generalised

Report:
-Requirement
-Accessibility
-Recommendations
-Support",N/A,Scale and complexity of different levels of health surveillance system evaluation: technical (looking at the performance of the system); process (looking at the factors affecting system performance); comprehensive (looking at the value of the system) (Fig 2).,See Fig 4 and Fig 5 for more details. Exact framework sections and plan is somewhat unclear.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Freedom from disease,Early detection,Case detection,Prevalence,Risk-based surveillance,Economic evaluation,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Functional,"Attributes aimed to evaluate the system function

Acceptability and engagement; Availability; Sustainability; Compatibility; Flexibility; Multiple hazard; Risk-based criterion definition; Simplicity","Assess how well surveillance functions, the function of surveillance will influence its effectiveness and value.

Functional attributes are of critical importance to generate meaningful recommendations for all stakeholders.",Organisational,"Attributes aimed to evaluate the system management and process

Surveillance system organization; Risk based criterion definition","Assess the overall structure and processes of surveillance which will have an impact on the function, effectiveness and value of surveillance.",Effectiveness,"Attributes aimed to evaluate the system performance

Bias; Coverage; False alarm rate (inverse of specificity); Negative predictive value (NPV); Positive predictive value (PPV); Precision; Representativeness; Robustness; Sensitivity (/detection probability/detection fraction); Timeliness","Assess how effectively the surveillance achieves its objectives, the effectiveness of surveillance influences its value.",Value,Cost; Benefit,Assess the value of surveillance for stakeholders.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Flexibility, adaptability: The ability to adapt to changing information needs or operating conditions with little additional time, personnel or allocated funds. The extent to which the system can accommodate collection of information about new healthhazards or additional/alternative types of data; changes in case definitions or technology; and variations in funding sources or reporting methods should be assessed.","Qualitative assessment methods:
-Opinion survey
-Semi-structured interviews; inspections; descriptive analysis

Semi-quantitative assessment methods:
-Structured questionnaire survey
","Impact	other attributes (positive correlation): Sustainability, cost",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The probability that no health event is present given that no health event is detected.,N/A,"Impact	other attributes (positive correlation): Sensitivity

",N/A,N/A,N/A,N/A,N/A,Probability that health event is present given that health event is detected.,N/A,Impact	other attributes (positive correlation): Sensitivity,N/A,N/A,N/A,N/A,N/A,"The extent to which the features of the population of interest are reflected by the population included in the surveillance activity, these features may include herd size, production type, age, sex or geographical location or time of sampling (important for some systems, e.g. for vector borne disease).","Quantitative assessment methods:
-Unilist CRC
-Multilist CRC
-Spatial evaluation
-Use of outputs from other surveillance components

Semi-quantitative assessment methods:
-Structured questionnaire survey
",Impact	other attributes (positive correlation): Robustness,N/A,N/A,N/A,N/A,N/A,"Sensitivity (detection probability and detection fraction): Sensitivity of a surveillance system can be considered at three levels.
* Surveillance sensitivity (case detection probability) refers to the proportion of individual animals or herds in the population of interest that have the health-related condition of interest that the surveillance system is able to detect.
Sensitivity could be measured in terms of detection fraction (number of cases detected divided by the coverage level) in a context of non-exhaustive coverage.
* Surveillance sensitivity (outbreak detection) refers to the probability that the surveillance system will detect a significant increase (outbreak) of disease. This may be an increase in the level of a disease that is not currently present in the population or the occurrence of any cases of disease not currently present.
* Surveillance sensitivity (presence) -refers to the probability that disease will be detected if present at a certain level (prevalence) in the population.","Quantitative assessment methods:
-Multilist CRC
-Unilist CRC
-Stochastic modelling
-Stochastic scenario tree modelling
-Stochastic scenario trees modelling using matrix algebra and Bayesian belief networks
-Ratio of number cases captured by the active surveillance and total number of cases captured
-Epidemiological approach
-Assessment of syndromic surveillance outputs using another surveillance component as a ""gold standard"" (derived approach)
-Simulation approach
-Bayesian Network Model
-Data-driven mathematical model
-In situ observation

Semi-quantitative assessment methods:
-Structured questionnaire survey","Impact	other attributes (positive correlation): False alarm rate, cost, NPV, PPV",N/A,"Refers to the surveillance system structure, ease of operation and flow of data through the system.",N/A,"Impact	other attributes (positive correlation): Acceptability, sustainability, flexibility, timeliness",N/A,N/A,"Quantitative assessment methods:
-Use of outputs from other surveillance components
-Epidemiological approach
-Simulation approach
-Bayesian Network Model

Semi-quantitative assessment methods:
-Structured questionnaire survey 

",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Timeliness can be defined in various ways
* This is usually defined as the time between any two defined steps in a surveillance system, the time points chosen are likely to vary depending on the purpose of the surveillance activity.
* For planning purposes timeliness can also be defined as whether surveillance detects changes in time for risk mitigation measures to reduce the likelihood of further spread

The precise definition of timeliness chosen should be stated as part of the evaluation process. Some suggested definitions are;

For early detection and demonstrating freedom
* Measured using time - Time between introduction of infection and detection of outbreak or presence by surveillance system
* Measured using case numbers - Number of animals/farms infected when outbreak or infection detected

For case detection to facilitate control
* Measured using time - Time between infection of animal (or farm) and their detection
* Measured using case numbers - Number of other animals / farms infected before case detected

For detecting a change in prevalence
* Measured using time - Time between increase in prevalence and detection of increase
* Measured using case numbers - Number of additional animals/farms infected when prevalence increase is identified.","Quantitative assessment methods:
-Analysis of the surveillance historical data
-Analysis of the surveillance historical data
-Epidemiological approach
-Use of outputs from other surveillance components
-Bayesian Network Model
-Data-driven mathematical model
-In situ observation

Semi-quantitative assessment methods:
-Structured questionnaire survey
",Impact	other attributes (positive correlation): Acceptability and engagement,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Availability and sustainability: The ability to be operational when needed (availability) and the robustness and ability of system to be ongoing in the long term (sustainability).,"Qualitative assessment methods:
-Opinion survey
-Structured questionnaire survey",Impact	other attributes (positive correlation): Acceptability and engagement,N/A,"Acceptability and engagement: Willingness of persons and organisations to participate in the surveillance system, the degree to which each of these users is involved in the surveillance. (Could also assess their beliefs about the benefits or adverse consequences of their participation in the system including the provision of compensation for the consequence of disease detection.","Qualitative assessment methods: 
-Opinion survey; 
-Participatoryapproach. 
Semi-quantitative assessment methods: 
-Structured questionnaire survey; 
-Participatoryapproach; 
-Participatory approach (AccePT). 
Quantitative assessment methods: 
-Conjoint analysis
","Impact other attributes (positive correlation): Sustainability, timeliness, sensitivity",N/A,Compatibility: Compatibility with and ability to integrate data from other sources and surveillance components e.g. One Health surveillance (part of data collection and data management).,N/A,"Impact other attributes (positive correlation): Sustainability, precision, flexibility",N/A,Multiple hazard: Whether the system captures information about more than one hazard.,"Qualitative assessment methods: Opinion survey
","Impact other attributes (positive correlation): Acceptability and engagement, sustainability, cost, flexibility",N/A,Risk-based criteria definition: Validity and relevance of the risk criteria selected and the approach/method used for their identification.,"Qualitative assessment methods: EVARISK
","Impact other attributes (positive	correlation): coverage, representativeness, sensitivity, acceptability, cost",N/A,"Surveillance system organization: An assessment of the organisational structures and management of the surveillance system including the existence of clear, relevant objectives, the existence of steering and technical committees whose members have relevant expertise and clearly defined roles and responsibilities, stakeholder involvement and the existence of effective processes for data management and dissemination of information.","-SWOT (Strenghts/Weaknesses/ Opportunity/ Threats); 
-Structured questionnaire survey (OASIS); 
-SERVAL; 
-System mapping",Impact other attributes (positive correlation): All evaluation attributes,N/A,Coverage: The proportion of the population of interest (target population) that is included in the surveillance activity.,N/A,"Impact other attributes (positive correlation):  Precision, robustness, representativeness, sensitivity",N/A,False alarm rate (inverse of specificity: Proportion of negative events (e.g. non-outbreak periods) incorrectly classified as events (outbreaks). This is the inverse of the specificity but is more easily understood than specificity.,N/A,"Impact other attributes (positive correlation):  Sensitivity, cost",N/A,Bias = Accuracy: The extent to which a prevalence estimate produced by the surveillance system deviates from the true prevalence value. Bias is reduced as representativeness is increased.,"Quantitative assessment methods: 
-Multilist CRC; 
-Unilist CRC; 
-Data-driven mathematical model",Impact other attributes (positive correlation): False alarm rate,N/A,"Precision: How closely defined a numerical estimate is. A precise estimate has a narrow confidence interval. Precision is influenced by prevalence, sample size and surveillance approach used.",Quantitative assessment methods: Multilist CRC,N/A,N/A,Robustness: The ability of the surveillance system to produce acceptable outcomes over a range of assumptions about uncertainty by maximising the reliability of an adequate outcome. Robustness can be assessed using info-gap models.,N/A,Impact other attributes (positive correlation): Precision,N/A,"Cost: The concept of economic cost includes 1) the losses due to disease (e.g. reduced milk yield, mortality), and 2) the resources required to detect the disease by a system (e.g. time, services, consumables for surveillance). In economic evaluation, the resources used to detect disease are compared with the disease losses with the aim to identify an optimal balance where a higher economic efficiency is achieved. Estimation of the total economic cost stemming from losses and expenditures is called a disease impact assessment. Estimation of the resource expenditures only is called a cost analysis.","*Least cost analysis; 
*Average cost-effectiveness ratio; 
*Incremental cost-effectiveness ratio; 
*Marginal cost-effectiveness ratio;
*Investment appraisal; 
*Inclusion of direct market Impacts; 
*Inclusion of multi-market Impacts; 
*Valuation of non-market components of the Economic impact of Surveillance",N/A,N/A,"Benefit: The benefit of surveillance quantifies the monetary and non-monetary positive direct and indirect consequences produced by the surveillance system and assesses whether users are satisfied that their requirements have been met. This includes financial savings, better use of resources and any losses avoided due to the existence of the system and the information it provides. These avoided losses may include the avoidance of, Animal production losses, Human mortality and morbidity, Decrease in consumer confidence, Threatened livelihoods, Harmed ecosystems, Utility loss Often, the benefit of surveillance estimated as losses avoided can only be realised by implementing an intervention. Hence, it is necessary to also assess the effect of the intervention and look at surveillance, intervention and loss avoidance as a three-variable relationship. Further benefits of surveillance include maintained or increased trade, improved ability to react in case of an outbreak of disease, maintaining a structured network of professionals able to react appropriately against a (future) threat, maintaining a critical level of infrastructure for disease control, increased understanding about a disease, intellectual capital, social capital and improved ability to react in case of an outbreak of disease.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Strengths and limits of evaluation methods for each attribute are available at: https://survtools.org/wiki/surveillance-evaluation/doku.php?id=assesment-methods

To ensure adequate framing of the evaluation and define the specific evaluation question, critical elements of the evaluation context need to be captured. The expert workshops highlighted the critical importance of the evaluation context (especially the surveillance objective and the evaluation needs) and the evaluation question to define the relevance of evaluation attributes to be included in the evaluation process.The conceptual model of the EVA tool addressed these needs by defining the four fundamental steps: what is my situation; why am I doing an evaluation; what to evaluate and how.",N/A,N/A,"Calba, C., Comin, A., Conraths, F., Drewe, J., Goutard, F., Grosbois, V., Hasler, B., Horeth-Bontgen, D., Hoinville, L., Lindberg, A., Peyre, M., Pfeiffer, D., Rodriguez Prieto, V., Rushton, J., Staerk, K., Schauer, B., Traon, D., Vergne, T., 2013a. Evaluation Methods of Surveillance Systems and Current Practices. RISKSUR Deliverable 1.2. Available at: http://www.fp7-risksur.eu/progress/public-deliverables (Accessed on 29th September 2017). .

Calba, C., Drewe, J., Goutard, F., Grosbois, V., Hasler, B., Hoinville, L., Peyre, M., Pfeiffer, D., Vergne, T., 2013b. The Evaluation Attributes Used for Evaluating Animal Health Surveillance Systems. RISKSUR Deliverable 1.3. Available at:http://www.fp7-risksur.eu/progress/public-deliverables(Accessed on 29th September 2017). 

Comin, A., Hasler, B., Hoinville, L., Peyre, M., Dorea, F., Schauer, B., Snow, L., Stark, K., Lindberg, A., Brouwer, A., van Schaik, G., Staubach, C., Schulz, K., Bisdorff, B., Goutard, F., Ferreira, J., Conraths, F., Cameron, A., Martínez-Avilés, M., Pfeiffer, D., 2016. RISKSUR Tools: Taking Animal Health Surveillance into the Future Through Interdisciplinary Integration of Scientific Evidence. https://www.researchgate.net/publication/299393001_RISKSUR_tools_taking_animal_health_surveillance_into_the_ future_through_interdisciplinary_integration_of_scientific_evidence.

Hasler, B., Howe, K., Peyre, M., Vergne, T., Calba, C., Bisdorff, B., Comin, A., Lindberg, A., Brouwer, A., Snow, L., Schulz, K., Staubach, C., Martínez-Avilés, M., Traon, D., Hoinville, L., Stark, K., Pfeiffer, D., Rushton, J., 2015. Economic evaluation of animal health surveillance—moving from infancy to adolescence? In: ISVEE. November 3-7, 2015 Merida, Yucatan, Mexico.

Peyre, M., Hendrikx, P., Do Huu, D., Goutard, F., Desvaux, S., Roger, F., et al., 2011. Evaluation of surveillance systems in animal health: the need to adapt the tools to the contexts of developing countries, results from a regional workshop in South East Asia. Epidémiologie Santé Anim. 59, 415-417.

Peyre, M., Hoinville, L., Haesler, B., Lindberg, A., Bisdorff, B., Drea, F., Wahlstrom, H., Frossling, J., Calba, C., Grosbois, V., Goutard, F., 2014. Network analysis of surveillance system evaluation attributes: a way towards improvement of the evaluation process. In: Proceedings of the 2nd International Conference on Animal Health Surveillance (ICAHS2). The Havana, Cuba, 7-9 May.

Peyre, M., Haesler, B., Goutard, F., 2015. Case Study Selection for Economic Evaluation Framework Development and Validation. RISKSUR Deliverable 5.20. Available at: http://www.fp7-risksur.eu/progress/public-deliverables. (Accessed on 4th January 2016). http://www.animalhealthsurveillance.org/index.php?n=Main.ConferenceProgram.","IMPORTANT: 
-The EVA tool is freely available online (https://survtools.org) - need to make an account to access. I've tried multiple time but am unable to validate my account.
-The tool is linked to the surveillance evaluation Wiki (https://survtools.org/wiki/surveillance-evaluation/) - Data extracted here is only from this article and related information from the EVA Tool Wiki.
-The design framework is also complemented by a web interface and a Wiki classroom (https://survtools.org/wiki/surveillance-design-framework/) - this appears to be complementary to the EVA Tool, therefore information relating to this was not extracted here.

The evaluation question is the most important aspect of the evaluation process. Evaluation is intrinsically linked to action; it makes little sense, and is of limited interest, to perform an evaluation without a specific objective for action or at least the willingness to consider action (the outcome may be to decide that no action is currently needed). In order to guide the evaluator in the selection of an appropriate evaluation question, a list of evaluation question was developed along with a selection guidance pathway and integrated within the EVA tool. However, this list might not be exhaustive and could be reviewed based on feedback from users of the tool and/or comments made in the EVA wiki.

Currently available frameworks for evaluation of surveillance systems in animal or human health often treat technical, process and socio-economic aspects separately instead of integrating them. The surveillance evaluation (EVA) tool, a support tool for the evaluation of animal health surveillance systems, was developed to provide guidance for integrated evaluation of animal health surveillance including economic evaluation. In the long term, the EVA tool is expected to increase professional evaluation capacity and help optimising animal health surveillance system efficiency and resource allocation for both public and private actors of the surveillance systems.

Evaluation is an essential step in the policy cycle and allows transparent interpretation of outputs, more objective decision-making and resource allocation as well as improvements in system design and enhanced acceptance of system out-puts by stakeholders.

There are always three main parts in the evaluation process of surveillance: planning, implementation and reporting (Calba et al., 2015a). Guidance and support is needed for those three parts, and especially for the definition of the evaluation plan, involving: i) the description of the surveillance system/component under evaluation; ii) the socio-economic context and the rationale for evaluation of the surveillance; iii) the definition of a precise evaluation question, and iv) the choice of evaluation attributes to be measured. The choice of evaluation attributes and methods to measure them will depend on the type of evaluation considered (e.g. evaluation of the process vs. evaluation of the outputs of surveillance) and on the surveillance system and its socio-economic context (e.g. availability of resources, the structuring of the animal production industry, political will to develop or sustain animal breeding and production, etc).

The RISKSUR surveillance design framework complement the EVA tool to support the design, review and documentation of surveillance system - see website for more information on the RISKSUR surveillance design framework.

The tool has been organized into three main sections to capture all the elements critical to an evaluation process as highlighted by the experts during the iterative development process of the tool (Fig. 5): Section 1) a general introduction to the tool and essential information on evaluation concepts, including evaluation attributes and economic methods to promote the understanding of the evaluation process and economic evaluation; Section 2) guidance on how to define an evaluation plan based on Steps 1 and 2 with data entry on the evaluation context and the evaluation question and Steps 3 and 4 where the tool facilitates the selection of relevant evaluation attributes and assessment methods (including economic analysis); and Section 3) guidance on how to perform the evaluation and how to report the outputs of the evaluation to decision makers.

Detailed guidance and a roadmap on how to report the evaluation outputs to decision makers has been integrated in the EVA tool and the evaluation Wiki.

See supplemental file for weighting of each attribute's importance with respect to various animal surveillance system objectives.

Table 2. List of evaluation context elements included in the EVA tool and their relevance in the framing of the evaluation process.
Context elements
Relevance

-Surveillance objective 
Impacts on the selection of evaluation attributes

-Hazard name 
Provides information about the disease under evaluation which will impact the complexity of the evaluation (e.g. between animal disease and zoonotic diseases)

-Geographical area 
Provides information about the scale of the evaluation

-Legal requirements 
Provides information about the need to meet an effectiveness target or not

-Strengths and weaknesses of the current approach 
Provide summary information about the rationale behind the decision to evaluate - help the evaluator to frame the evaluation question

-Stakeholder concerns about current approach 
Provide information about the involvement and interest of decision makers in the evaluation process - help the evaluator to frame the evaluation question

-Alternative strategies to consider 
Provides information about the type of evaluation required (based on a counterfactual or not)

-Do you want to evaluate or change the system or some components in the system ?
Provide information about the level of evaluation

-How many components will you include in this evaluation? 
Provides information about the number of counterfactual considered

-Are you considering risk-based options? 
Relevant for the inclusion of the attribute risk-based criteria definition in the evaluation plan

-Will you consider the costs of surveillance in your evaluation? 
Provides information about the interest of economic evaluation

-Do you know the current cost of your system and/or components?
 Provides information about the data required

-Do you have a budget constraint? 
Provides information for the economic evaluation (meeting a budget target or not)


Table 3. List of evaluation questions developed within the EVA tool and evaluation criteria and methods linked to each question.
Evaluation question 
Evaluation criteria 
Evaluation method

Evaluation at the component level
Q1. Assess whether one or more surveillance component(s) is/are capable of meeting a specified technical effectiveness target
Effectiveness 
Effectiveness attribute assessment

Q2. Assess the technical effectiveness of one or more surveillance components
Effectiveness, Cost
Least cost assessment

Q3. Assess the costs of surveillance components (out of two or more) that achieve a defined effectiveness target, where effectiveness is already known
Effectiveness, Cost 
Least cost assessment

Q4. Assess the costs and effectiveness of surveillance components (out of two or more) to determine which achieves a defined effectiveness target at least cost, the effectiveness needs to be determined
Effectiveness
Effectiveness attribute assessment

Q5-Q7. Assess whether a surveillance component generates a net benefit, the biggest net benefit or the the biggest under a budget constraint for society, industry, or animal holder(s):
Benefit to be measured in monetary terms 
Effectiveness, Monetary benefit, Cost
Cost benefit assessment

Benefit to be measured in non-monetary terms or to be expressed as an effectiveness measure 
Effectiveness, Non-monetary benefit, Cost
Cost effectiveness assessment

Benefit to be measured in both monetary and non-monetary terms (or to be expressed as an effectiveness measure)
Monetary benefit, Non-monetary, benefit/effectiveness, Cost
Cost benefit and cost effectiveness assessment

Evaluation at the system level
Q8. Assess the functional aspects of surveillance which may influence effectiveness 
Effectiveness 
Functional attribute assessment

Q9. Assess the technical effectiveness of one or more surveillance components and the functional aspects of surveillance that may influence effectiveness
Effectiveness
Effectiveness and functional attribute assessment

Q10. Assess the technical effectiveness of the surveillance system 
Effectiveness
Effectiveness attribute assessment

Q11. Assess the surveillance structure, function and processes 
Effectiveness
Process assessment",
peyreSynthesisevaluateBetterInform2022,13691,Peyre 2022,Synthesis-evaluate to better inform: A way to strengthening health surveillance systems,Synthesis-evaluate to better inform: A way to strengthening health surveillance systems,2022,Marisa Peyre,marisa.peyre@cirad.fr,France,Factors affecting acceptability among all surveillance system actors,d. Other,d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"2. Goutard FL, Binot A, Duboz R, Rasamoelina-Andriamanivo H, Pedrono M, Holl D, Peyre MI, Cappelle J, Chevalier V, Figuié M, Molia S, Roger FL. How to reach the poor? Surveillance in low-income countries, lessons from experiences in Cambodia and Madagascar. Prev Vet Med. 2015;120:12-26. https://doi.org/10.1016/j.prevetmed.2015.02.014.

5. Peyrel M, Hendrikx P, Thanh HPT, Huu DD, Goutard F, Desvaux S, Roger F. Evaluation of surveillance systems in animal health: the need to adapt the tools to the contexts of developing countries, results from a regional workshop in South East Asia, pp 415-417; 2011.","In this regard, integrated evaluation, taking into consideration technical but also socio-economic issues in surveillance, should be promoted. This way, evaluation could be used as a programming tool, and in a participatory way to codevelop solutions with field actors to better inform decision-making in both animal and one health surveillance strategies.

The official declaration of disease cases often leads to strong social and economic constraints to farmers and other local surveillance actors: uncertainties related to compensation, limited confidence in risk management skills by the official authorities, impact on sales opportunities, stigma in the community, stress related to slaughter and loss of genetic material, etc. he health information exchange networks and the socio-economic constraints of the different actors are closely linked to the level of structuring of the production chains, playing a determining role in the performance of the surveillance. These elements are critical and must be accounting for when making decisions about optimizing health surveillance systems. 

Recent studies have highlighted a recurring lack of acceptability of surveillance systems by its actors, and its consequences in terms of underreporting both in LMIC and high-income countries (HIC). Trust issues between field private actors and the health authorities strongly impact health surveillance performances, independently from the economic context and the development level of the country. Similar trust issues also exist within the official surveillance system process, involving conflicts of interest often linked to a dual public and private activity of the system's stakeholders. Regulatory compliance in terms of health surveillance by farmers in HIC seems more prevalent than in LMIC, the control bodies being more present and organized in the former, forcing farmers to better comply with good practices. In LMIC, it is very clear that the priority for local veterinarians is to maintain a privileged relationship with the farmers and members of the community to which they belong and not to maintain declaration at all cost.

The private sector plays a central role in the surveillance and management of animal and zoonotic diseases at the local level. These private systems operate in parallel with official systems, due to the lack of public-private partnerships in the majority of situations in LMIC. However, these public-private partnerships seem to lack transparency and cooperation and could themselves be strengthened. This again highlights the issues of trust between the two sectors.

The work presented throughout this book and summarized here highlights the importance of an integrated evaluation of health surveillance systems—accounting for social, economic, and technical aspects—to ensure their efficiency, sustainability, and impact. This type of evaluation, favored by the SurvTool decision support tool, along with all the innovative methods presented here would allow to better address decision-makers' needs in order to promote meaningful evaluation and recommendations to improve the current systems.

New or improved health surveillance systems (or components within these systems) ideally should be codeveloped with all the actors of the system, from the field actors who are at the source of the data to the decision-makers in charge of defining the national strategies. Companion modeling, described in the following section, seems to be an interesting approach to foster this co-construction. 

The utility of the system for its actors needs to be better understood to inform the development of improved health surveillance systems. When evaluated, the value of the systems has been characterized by its cost-effectiveness or cost-benefit that look at the balance between the cost of the system and its performances and/or its consequences at a given level. These econometric analyses still neglect all too often the socioeconomic and socioecological aspects and only give a partial view of the agricultural system considered. Indeed, the issues of surveillance and control of animal health go far beyond the scope of health risk issues and require a more interdisciplinary approach. To answer this interdisciplinary challenge, the concept of utility, relating to the well-being economy, seems to be a field of investigation for research in animal health with a view to dialogue between epidemiology, economics, geography, and sociology
 
Traditionally applied in areas such as human health or agriculture, the utility approach is concerned with decision-making in situations of uncertainty. The approach accounts for the attitude or preferences of individuals facing risks in specific socioeconomic and cultural contexts. Accounting for the diversity of the utilities of a surveillance system, the evaluation makes it possible to comprehend the different distribution of costs and benefits linked to animal health surveillance decision for the various actors concerned. It reveals the diversity of interests and therefore interest-bearing that the surveillance system favors. This characterization can foster a space for negotiation between these actors, and lead to a more inclusive governance of the monitoring system (and therefore to its better acceptability). There are various tools to measure these preferences, including the declared preference method but also multicriteria analysis methods associated for example with grading grids that allow weighting the different criteria. In their application, these approaches need to go beyond the health disciplinary field to consider the utility of animal health within its broader con-text of agriculture.

This could only work by ensuring strong collaboration between private and public actors involved in the system and by promoting a mixed approach: merging top-down and bottom-up strategies to ensure that the needs of all actors are accounted for and efficiency and sustainability of the system (Fig. 16.1c).

The work presented in this chapter highlights the key role of the private sector in the management (surveillance and control) of animal diseases, with often limited interactions with national surveillance systems. It is essential to account for these issues and strengthen the links between private and public surveillance. In order to strengthen it, we propose to consider animal disease surveillance as a PPP where public and private actors share resources, responsibilities, and risks to meet a common goal and achieve shared benefits: the control of animal diseases. The surveillance of animal diseases represents the continuous collection of data from private actors (breeders, private veterinarians) to inform public decision-makers (veterinary services) to act (household investigation, control measures, etc.). The private sector thus plays a central role in the surveillance and management of animal diseases at the local level, but with often limited interactions in practice with national surveillance systems.

As we have seen before, in the majority of situations in LMIC, private surveillance systems operate in parallel with formal systems, due to a lack of collaboration and limited trust between sectors. The situation is different in HIC where the state gives a mandate to the private sector to implement health surveillance; however, these PPPs sometimes lack transparency and cooperation and could themselves be strengthened. It is therefore essential to strengthen the links between private and public surveillance. Consideration of the constraints and needs of the actors involved in monitoring, which are not often accounted for, is essential for their commitment and the improvement of systems. Sustainability of the actions can only be ensured by the commitment of the actors of the system; there is a real need to reinforce the links, the communication and the trust between the private actors of the surveillance systems and the public actors. The challenges of these private-public partnerships must be correctly identified, characterized for each type of actors, in order to propose recommendations adapted to this strengthening of collaborations.",
reintjesBenchmarkingNationalSurveillance2007,2043,Reintjes 2007,Benchmarking national surveillance systems: a new tool for the comparison of communicable disease surveillance and control in Europe.,Benchmarking national surveillance systems: a new tool for the comparison of communicable disease surveillance and control in Europe,2007,Ralf Reintjes,ralf.reintjes@rzbd.haw-hamburg.de,Germany,Benchmarking of national communicable disease surveillance systems for comparison within Europe,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,"Across Europe: England and Wales, Finland, France, Germany, Hungary, and The Netherland",m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Step 1: Selection of the process or function to be benchmarked,Identification of 10 criteria for the description of surveillance systems and transformation of benchmarks,Benchmarking criteria were adpated from the attributes from the CDC 2001 guidelines and the Communicable Disease Control Handbook.,N/A,N/A,Step 2: Understand the existing process or function,Development of a uniform language and agreement about processes and functions,N/A,N/A,Numerous round-table discussions in the introduction period of the project were used to develop a uniform language between the partners and establish common descriptions for the identified objects and criteria (see table 2).,Step 3: Identify benchmarking partners,"Selection of six countries (England and Wales, Finland, France, Germany, Hungary, and The Netherlands)",N/A,N/A,The selection was made on the basis of best practices in different areas of communicable disease surveillance and control and because of existing contacts to experts at national public health institutes of these countries.,Step 4: Collect data and information,Collection of qualitative and quantitative data,"A questionnaire regarding the necessity of benchmarking of national surveillance systems, possible indicators, evaluations of surveillance systems, strengths and weaknesses of components of surveillance systems, and available data sources for benchmarking was designed and used.",It is very important to collect comparable data.,N/A,Step 5: Identify gaps and reasons for them,Descriptive comparison,N/A,N/A,"The selected measurements quantify differences in execution and the purposeful questions identify the reasons of the differences. In order to analyse the data, the key features for each component were brought into a format, which allows a descriptive assessment of the contents and use of data.",Step 6: Develop programmes to implement findings,Recommendations for policy and experts,N/A,N/A,"We looked for best practices in the six countries under investigation, in order to give policymakers a short description of good performances in different areas of communicable disease surveillance and to develop a set of recommendations to improve the quality of the system.
",Step 7: Implement changes and monitor results,Suggestions for regular evaluations by relevant European institutions,N/A,N/A,The recommendations include suggestions for comparative evaluations of the surveillance systems of all EU member states.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Notifiable diseases,N/A,N/A,"Content of existing listings

Financial incentives for notifiers",Case definitions,N/A,N/A,"General use: Relation to the three-tiered system (confirmed, probable, possible) of the EU recommended case definitions",Timeliness following disease onset,N/A,N/A,"Health event reported to local, regional, and national PH system; Estimated times to inform local, regional, and national levels",Formats of reporting,N/A,N/A,Reporting sources,Data use,N/A,N/A,Use of standardised data collection; Time series analysis; Regional distribution; Description of effected population groups,Early warning applications,N/A,N/A,Use of early warning applications,Outbreak investigation,N/A,N/A,Performance of descriptive and analytical investigation,Data dissemination,N/A,N/A,Frequency and dissemination format of national bulletins; Existence of web-based information systems for the public,Vaccination programmes,N/A,N/A,"Current immunisation schedule; 
Vaccination coverage for MMR at 24 month; 
Incidence data for vaccine preventable diseases",Evaluation,N/A,N/A,Existence of evaluation structures,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Completeness or sensitivity is an important issue regarding the quality of a surveillance system. Nevertheless, this is also very difficult to be compared. One widely accepted method to estimate the completeness is the so-called capture-recapture method. Even though it is used in various settings, currently only for a few diseases in a selected number of countries data are available. Based on the fact that the sensitivity of reporting for a given disease varies between different surveillance systems (even within one country) and that the sensitivity of reporting for various diseases within the same surveillance system varies greatly it is currently not realistic to compare national surveillance systems for this component. Being very well aware of these issues we decided not to use completeness or sensitivity as a benchmark.

Timeliness of reporting was one of the most difficult criteria to be investigated because of differences between and within national surveillance systems.

Although benchmarking has been shown to be suitable to answer the research question, some limitations have to be considered. The current study tried to address all relevant factors for the benchmarking process although the available resources were limited. Because of these limitations, the data analysis could only be short and descriptive.",N/A,N/A,N/A,"Training and practice of leading PH experts in analytical epidemiology for outbreak investigations is a necessary component for disease control, especially for new or unknown health problems. In cooperation with European networks (e.g. EPIET) and partners in other member states, establishment of training is recommended.

For the first study of this kind, this could only be achieved to a limited extent. Based on this several recommendations were given to Hungarian stakeholders via a benchmarking report in order to improve the national surveillance system in Hungary. Nevertheless, the current study provides several operationalised benchmarks that should be the basis for benchmarking processes of surveillance systems in the future. 

Key points
- There are different strengths and weaknesses in various national surveillance systems of communicable disease control. Huge heterogeneity exists in areas like case definitions, timeliness of reporting, or outbreak investigations.
- International benchmarking of surveillance systems proved to be useful because of best practices in different areas of each national surveillance systems for communicable diseases and the availability of data in these countries.
- All countries need to share ideas on how to increase the quality of national and common European surveillance systems.

Attributes/criteria provided may not be entirely comparable to other studies as they were designed for benchmarking.",
romanoEvaluationSyndromicSurveillanceRelated2022,211,Romano 2022,An Evaluation of Syndromic Surveillance-Related Practices Among Selected State and Local Health Agencies.,An Evaluation of Syndromic Surveillance-Related Practices Among Selected State and Local Health Agencies,2022,Sebastian Romano,wwj5@cdc.gov,United States of America,Provide recent information about syndromic surveillance systems and practice characteristics among a group of state and local health departments,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,United States of America,l. No framework(s) or guidance document(s) were discussed,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The contribution of syndromic surveillance to strengthen public health situational awareness and to improve capabilities to respond to public health concerns has been recognized previously.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"It should be noted that despite the potential utility of this study, certain limitations remain. Responses to questions are subject to perceptions of the respondent and may not fully represent the actual practices within these organizations. While questions were clarified upon request, respondents could have misinterpreted questions, leading to inaccuracies in their responses. In addition, the participants of our study are not a representative sample of all state and local health departments and therefore the findings of our study may not be generalizable to other state and local health departments across the United States.",N/A,N/A,N/A,"A framework published in 2004 supplemented the existing guidelines for evaluating public health systems and provided further guidance on evaluating a system for early detection for disease-related events, including syndromic surveillance systems.15 This framework organized important evaluation issues and questions under 3 focus areas: (1) a system description focusing on purpose, stakeholders, and operations; (2) an understanding of outbreak detection capabilities, focusing on data timeliness, validity, and quality; and (3) system experience accrued through system use by public health practitioners, focusing on system utility, flexibility, acceptability, portability, stability, and costs. 

Our assessment attempted to address several components outlined in this framework. It provides descriptions of jurisdictional systems, outbreak response detection capabilities (specifically regarding timeliness and data quality), and system experience through our analysis of system data use.

Data timeliness and data quality are crucial factors that impact the effectiveness of surveillance systems.

The survey consisted of 11 open- and closed-ended questions around key aspects of syndromic surveillance practice including:
* Jurisdictional experience with syndromic surveillance;
* System characteristics including analysis tools and data sources;
* Data processing and data quality practices;
* Data sharing, both within and outside of the jurisdiction;
* Use of syndromes and subsyndromes of importance; and
* Future needs for strengthening syndromic practice.

See supplemental material for survey questions relating to periodicity, data sharing, and partnerships. Not extracted as it is not entirely clear what attributes the survey aims to measure.",
rueggGuidanceEvaluatingIntegrated2022,5807,Rüegg 2022,Guidance for evaluating integrated surveillance of antimicrobial use and resistance.,Guidance for evaluating integrated surveillance of antimicrobial use and resistance,2022,Simon R. Rüegg,srueegg@vetclinics.uzh.ch,Switzerland,Provides guidance on One Health evaluation tool selection,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,1. Introduction to surveillance evaluation,N/A,N/A,N/A,"The audience for the guidance is personnel working in public, private, and non-governmental organisations, from public health, animal health, plant health and environmental health, at local, national and international levels.",2. Evaluation of surveillance for AMU and AMR,N/A,N/A,N/A,"The audience for the guidance is personnel working in public, private, and non-governmental organisations, from public health, animal health, plant health and environmental health, at local, national and international levels.",3. Evaluation tools,N/A,N/A,N/A,"The audience for the guidance is personnel working in public, private, and non-governmental organisations, from public health, animal health, plant health and environmental health, at local, national and international levels.",4. Support for selecting an evaluation tool,N/A,N/A,N/A,"The audience for the guidance is personnel working in public, private, and non-governmental organisations, from public health, animal health, plant health and environmental health, at local, national and international levels.",5. Case studies,N/A,N/A,N/A,"The audience for the guidance is personnel working in public, private, and non-governmental organisations, from public health, animal health, plant health and environmental health, at local, national and international levels.",6. Directory of existing tools,N/A,N/A,N/A,"The audience for the guidance is personnel working in public, private, and non-governmental organisations, from public health, animal health, plant health and environmental health, at local, national and international levels.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"To warrant comprehensive coverage, the consortium consisted of people with expertise in surveillance evaluation and/or AMR/AMU and/or system thinking and working in various professional fields, that is government, academia, research institutes, international organisations and professional organisations.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Technical operations of surveillance,"Questions on technical features of surveillance operations (surveillance design, laboratory capacities, management of specimens, tests applied, data management and analysis, etc.), their quality management (SOP, traceability, etc.), and the assessment of their performance (sensitivity, specificity etc.","How representative of the target population is the surveillance system? (Extracted from Serval)
The sensitivity of the case or threat definition. (Extracted from OASIS)",Resources,"Questions quantitatively addressing human, physical and financial resources. Questions on the training level of human resources are also considered in this category.","Are resources for rapid response during public health emergencies of national or international concern accessible? (Extracted from IHR)
Adequacy of the central level's material and financial resources (Extracted from OASIS)",Output and use of information,"Questions on surveillance outputs that are provided to inform public and private stakeholders, their use to inform decision-making and the benefits from this use (expected, perceived or measured).","Consider how the benefits are distributed among stakeholders, including producers, consumers, the livestock industry or society. (Extracted from SurF)
How do OH outputs (OH team, information, and network) impact on decision-making? (Extracted from ISSE)",Integration,"Questions considering three levels of integration:
integration of data systems (within organisations and at national, regional or international level, data systems interoperation, and adherence to international testing and data standards) integration between sectors and disciplines (knowledge integration, shared decision-making and planning, and formulation of common goals) integration in the national and international context motivating the need for surveillance (link to decision-making, shared decision-making and planning between countries).","How is the interaction between people organised to foster collaboration across the initiative? (Extracted from NEOH)
Are there official agreements with labs outside of the country for specialised testing, not available in-country? (Extracted from JEE)",Collaboration,"Questions on the framework of collaboration (organisation of roles and responsibilities) and the object of collaboration (exchange of data, information and knowledge, sharing of capacities). This category also covers questions about the inclusive participation of stakeholders (e.g. considering gender).","The formalisation of roles and responsibilities of surveillance actors involved in collaborative modalities. (Extracted from ECoSur)
Does the multi-sectoral coordination mechanism have a current One Health Strategy developed in a participatory manner with its stakeholders? (Extracted from OH-APP)",Progress and adaptivity,"Questions on any structural elements allowing for the surveillance system to adapt and evolve. This may include tools, plans and agreements to evolve (e.g. continuous learning programs, external evaluation, etc.), as well as the features of management and governance allowing for regular evaluation and adaptation of operations (e.g. frequency of meeting, regularity of progress reports, etc.).","How flexible is the project design and timeline to respond to internal or external changes at long-term? (Extracted from NEOH)
Implementation of supervision by the intermediary level. (Extracted from OASIS)",Surveillance items specific to AMU/ AMR,"Questions that are specifically addressing AMU (recording and management) or AMR (occurrence, prevention or response).","Which structure is responsible for AMR data collection, analysis and interpretation? (Extracted from ATLASS)
Are data available on the magnitude and trends of antimicrobial resistance? (Extracted from IHR)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,See Table 8 for a SWOT-like analysis of six different evaluation tools.,N/A,N/A,To pull all relevant evaluation tools not previously identified by scoping review.,"For this project, an international consortium of experts from multiple fields called CoEvalAMR was formed with the objectives to study user needs, characterise and compare existing tools for the evaluation of integrated AMU and AMR surveillance, apply them to case studies, and elaborate guidance on the purpose-fit selection and the use of the tools.

Antimicrobial resistance (AMR) resulting from antimicrobial use is a threat to human and animal health and may have unknown impacts on the environment. To understand how governance and human behaviour relate to AMR, it is important to implement integrated surveillance across the human, animal and environmental sectors. In this work, we describe the development of guidance on how to evaluate such surveillance, what the available tools cover and what gaps remain.

One of the key elements for a better understanding and management of AMU and AMR is to develop effective and efficient integrated surveillance systems that consider the complex epidemiology of these issues and the impacts of resistance on humans, animals and the environment. 

The capacity for knowledge integration or OH-ness is determined by six dimensions, namely (1) systems thinking, (2) holistic planning, (3) transdisciplinary working, supported by an enabling environment to allow for (4) sharing, (5) learning, endorsed through and (6) a systemic organisation (Rüegg et al., 2018).

Table 2. Alphabetical list of identified tools which were relevant for the evaluation of the surveillance of AMU and AMR. Some tools were not considered in the present study for the reasons indicated in the footnotes.
Acronym 
Name of the tool (authors) 
References

ATLASS 
Assessment Tool for Laboratory and AMR Surveillance 
Systems (FAO)
http://www.fao.org/antimicrobial-resistance/resources/tools/atlass/en/

EcoSur 
Evaluation of collaboration for OH surveillance tool (CIRAD) https://www.frontiersin.org/articles/10.3389/fvets.2019.00109/full

HACHAIa 
WHO-OIE Handbook for the assessment of capacities at the human-animal interface (WHO and OIE)
https://www.who.int/ihr/publications/handbook_OMS_OIE_HD.pdf

HSFATb 
Health Security Financing Assessment Tool (World Bank Group)
https://www.ghsagenda.org/docs/default-source/default-document-library/archive---vietnam-zdap-files/day-1/s3-3---wbg_zdap-conference-in-vietnam--hsfat_final.pdf

ISSE 
Evaluation framework for Integrated Surveillance Systems for AMR (Aenishaenslin et al.)
https://www.frontiersin.org/articles/10.3389/fvets.2021.611931/full

IHR 
International Health Regulations core capacity monitoring framework (WHO)
https://www.who.int/ihr/publications/WHO_HSE_GCR_2015.8/en/

JEE 
Joint External Evaluation tool (2nd edition, WHO) 
https://extranet.who.int/sph/joint-external-evaluation-tool-2nd-edition

NEOH 
OH-ness tool of the Network for Evaluation of OH evaluation framework (multiple mainly research institutions)
https://www.wageningenacademic.com/doi/book/10.3920/978-90-8686-875-9 and http://neoh.onehealthglobal.net/

OASIS 
Outil d'Analyse des Systmes de Surveillance (CIRAD) 
https://www.jstor.org/stable/41262696?seq=1""\l""page_scan_tab_contents and https://www.plateforme-esa.fr/sites/default/files/images/documents/oasis/rapport_oasis_maj2013.pdf

OH-APP 
OH Assessment for Planning and Performance (USAID) 
https://www.onehealthapp.org/about

OH-SMARTc
OH Systems Mapping and Analysis Resources Toolkit (University of Minnesota and USDA)
https://vetmed.umn.edu/centers-programs/global-one-health-initiative/one-health-systems-mapping-and-analysis-resource-toolkit

OHTd 
OH Tool (WHO) 
https://www.who.int/choice/onehealthtool/en/

PMP-AMR 
Progressive Management Pathway for AMR (FAO) 
http://www.fao.org/europe/events/detail-events/en/c/1197882/

PVS 
Tool for the Evaluation of the Performance of Veterinary Services (OIE)
http://www.oie.int/fileadmin/Home/eng/Support_to_OIE_Members/pdf/A_PVS_Tool_Final_Edition_2013.pdf

SERVAL 
Surveillance Evaluation Framework (RVC, AHVLA - now APHA, SAC)
https://www.rvc.ac.uk/Media/Default/VEEPH/Documents/SERVAL.pdf

SETe 
Surveillance Evaluation Tool (FAO) 
http://www.fao.org/AG/AGAInfo/home/en/news_archive/2017_FAO_Surveillance_evaluation_tool-SET.html

SURV-TOOLSf
Surveillance Tools—previously called RISKSUR (multiple, mainly research institutions)
https://survtools.org/user/login

SurF 
Surveillance Evaluation Framework (New Zealand Ministry for Primary Industries)
https://www.mpi.govt.nz/dmsdocument/18091/send

aExcluded, because considered through the IHR framework.
bExcluded, because it does not cover AMU or AMR.
cExcluded, because designed for facilitation, not suitable for evaluation.
dExcluded, because it is a health financing tool without relation to one health.
eExcluded, because derived from ATLASS.
fExcluded, because derived from SERVAL

Functional aspects used to report user experience with evaluation tools: User-friendliness 
- Meets evaluation needs/requirements 
- Efficiency 
- Overall appearance 
- Generation of actionable evaluation outputs 
- Allows evaluation of One Health-aspects 
- Workability in terms of required data 
- Workability in terms of required people to include 
- Workability in terms of analysis to be done 
- Time taken for application of tool 

Gaps for integrated surveillance of AMU and AMR:
- Standardisation of evaluations across sectors 
- Guidance to aid in choosing an appropriate evaluation tool for integrated AMU and AMR surveillance, depending on the evaluation goals
- Simple, clear and detailed training for the evaluation process 
- Gaps remain for all aspects of AMU and AMR, from the measurement of impact to integration across sectors

The final web platform (https://guidance.fp7-risksur.eu/) comprises six main sections: (1) Introduction to surveillance evaluation, (2) Evaluation of surveillance for AMU and AMR, (3) Evaluation tools, (4) Support for selecting an evaluation tool, (5) Case studies and (6) Directory of tools. 

This project has contributed an important point of reference in the complex and critical space of evaluation of integrated surveillance systems for AMU and AMR. The tools differ, for example regarding objectives, and no single tool is comprehensive, and some critical gaps remain. The field is challenged by opposing needs for reduction and simplicity to generate scientific knowledge, and for the synthesis of that knowledge to sufficiently reflect the complexity of AMU and AMR ecology for real-world decisions. The CoEvalAMR web platform allows a better understanding of the different evaluation tools and assists users in the selection of an approach that corresponds to their evaluation needs.",
sahalCommunicableDiseasesSurveillance2009,5354,Sahal 2009,Communicable diseases surveillance lessons learned from developed and developing countries: Literature review,Communicable diseases surveillance lessons learned from developed and developing countries: Literature review,2009,N. SAHAL,hsahal@health.sdu.dk,Denmark,Review of lessons learned from communicable disease surveillance in developed and developing countries,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,"Surveillance structure 
","* Laws, legislation
* IHRa compliance 
* Surveillance 
* Data flow between levels 
* Networking/partnership","Domains overview taken from the ""Overview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases"" (WHO 2004).","Core functions
","* Case detection 
* Registration 
* Confirmation 
* Reporting Notification 
* Data analysis/interpretation 
* Epidemic preparedness 
* Response and control 
* Feedback","Domains overview taken from the ""Overview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases"" (WHO 2004).","Support functions
","* Standards and guidelines 
* Training 
* Supervision 
* Communication 
* Resources (including logistics) 
* Coordination","Domains overview taken from the ""Overview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases"" (WHO 2004).","Surveillance quality
","* Timeless
* Completeness
* Usefulness
* Sensitivity 
* Specificity
* Simplicity
* Flexibility 
* Acceptability 
* Reliability
* Positive predictive value 
* Representativeness","Domains overview taken from the ""Overview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases"" (WHO 2004).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Completeness of CDSS continues to be a necessary
part of public health surveillance quality indicators,
enabling more accurate interpretation of surveillance
information for disease control and prevention.

Inaccuracy due to
frequent errors may the usefulness of a system.

The relative completeness of communicable diseases
data is one of the major indicators for the quality of
surveillance but it is not easy to achieve.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Sensitivity is the probability that a surveillance system will correctly identify the agent in a population when the agent is truly present.,"The sensitivity of a surveillance system can be evaluated on two levels, by the proportion of cases with a disease detected, or by its ability to detect outbreaks.",Surveillance systems with higher serious diseases as a norm had higher sensitivity. An increase in the disease seriousness is related to an increase in its surveillance data quality.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Timeliness of CDSS can vary by disease, intended use of the data, and public health system level. Long reporting lags can limit the usefulness of the system data in detection and control of outbreaks in the country.

Timeliness of CDSS can be affected by the way and type of surveillance.

Use of electronic reporting systems might improve the timeliness of surveillance data mainly in developed countries where the systems are well established. But it might not be realistic for developing countries where most of the systems are still under construction.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Most of the studies conducted in developed countries to evaluate the CDSS tackled the quality issue and not the core and supportive function issues.

Most of the studies conducted in developing countries for the assessment of CDSS considered the issues of core and supportive functions.",N/A,N/A,"Pan American health organization. An integrated approach to communicable disease surveillance. Epidemiol Bull 2000;21(1):1-4. Available online from: http://www.paho. org/English/SHA/EB_v21n1.pdf (accessed 14 September, 2007)","Review shows that there are difference evaluation focuses in developed versus developing countries - framework to reflect this.

The success of single CDSS raises questions like: does the CDSS benefit more if each disease has its own surveillance system or is an integrated system a better strategy? Is a single disease surveillance system the best choice for a developed country when resources are available? Is integrated diseases surveillance the choice where the resources are not available?

Even a well functioning CDSS will not be complete unless it has a well functioning feedback system, which acts as a strong motivator for health care providers to ensure their adherence to the system.

Most of the studies conducted to evaluate the CDSS tackled the quality issue and not the core and supportive function issues.

An effective system requires two-directional information flow between data providers and data users.

Take-aways from developing countries: Overall, the existing systems need to be strengthened with more effective coordination. The study also raises an important issue of political support, which may impact the success of a surveillance system. Decentralization of CDSS at all levels is recommended for the success of the system as it assists in the coordination of surveillance activities at different levels. Lacking trained staff in the area of outbreak investigation and response resulted in a negative impact in epidemic identification and response.

Based on the results of this review we have suggested recommendations which may help in improving the CDSS in developing and developed countries: 
- Strengthening the idea of IDSR as bases for CDSS in developing countries mainly as it suits their resource situation. 
- Strengthening the involvement of stakeholders in the system. 
- The surveillance system must be evaluated on a routine basis. 
- Modern technology for efficient data collection, analysis, and interpretation must be used. 
- Strengthening the CDSS timeliness and completeness by using modern electronic methods.  
Decentralization of CDSS. 
- Involvement of the private sector in CDSS for the success of systems especially in developing countries.",
sandbergAssessmentEvaluationTools2021,119,Sandberg 2021,Assessment of Evaluation Tools for Integrated Surveillance of Antimicrobial Use and Resistance Based on Selected Case Studies.,Assessment of Evaluation Tools for Integrated Surveillance of Antimicrobial Use and Resistance Based on Selected Case Studies,2021,Marianne Sandberg,marsan@food.dtu.dk,Denmark,Provides guidance on One Health evaluation tool selection,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Ideally, combatting AMR requires engagement from actors within all sectors of animal health, food safety, environmental protection, plant health, and human health. All sectors need to be involved in surveillance to identify emerging resistance, understand the AMR epidemiology, and develop effective policies for AMU and AMR reduction.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,AMU and AMR,"Questions that are specifically addressing the case of AMR (occurrence, prevention, or response) or AMU (recording and management)",N/A,Collaboration,"Questions on the framework of collaboration (organization of roles and responsibilities) and the object of collaboration (exchange of data, information, and knowledge and sharing of capacities). This category also covers questions about the inclusive participation of stakeholders (e.g., considering gender)",N/A,Resources,"Questions quantitatively addressing human, physical, and financial resources. Questions on the training level of human resources are also considered in this category",N/A,Output and use of information,"Questions on surveillance outputs that are provided to inform public and private stakeholders, their use to inform decision making, and the benefits from this use (expected, perceived, or measured)",N/A,Integration,"Questions considering three levels of integration:
* integration of data systems (within organizations and at national, regional, or international level; data systems interoperation; and adherence to international testing and data standards)
* integration between sectors and disciplines (knowledge integration, shared decision making and planning, and formulation of common goals)
* integration in the national and international context motivating the need for surveillance (link to decision making, shared decision making, and planning between countries)",N/A,Governance*,"Questions related to the legislative framework as well as the steering and coordinating mechanisms for the surveillance system: legislation, steering, and criteria (limits and goals for reduction)",*Governance was included as a separate theme in this study but is not a separate theme on the https://guidance.fp7-risksur.eu/welcome/decision-support/,Adaptivity,"Questions on any structural elements allowing for the surveillance system to adapt and evolve. This may include not only tools, plans, and agreements to evolve (e.g., continuous learning programs and external evaluation) but also the features of management and
governance allowing for regular evaluation and adaptation of operations (e.g., frequency of meeting and regularity of progress reports)",N/A,Technical operations,"Questions on technical features of surveillance operations (surveillance design, laboratory capacities, management of specimens, tests applied, data management, and analysis), their quality management (SOP, traceability), and the assessment of their performance (sensitivity and specificity)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"According to Stark et al. (4), OH surveillance describes the systematic collection, validation, analysis, interpretation of data, and dissemination of information collected in humans, animals, and the environment to inform decisions for more effective, evidence-based interventions. 

Identification of the optimal levels of integration to obtain the information needed for decision making is an important task in OH surveillance systems.

Aenishaenslin et al. (7) suggested that the value of OH surveillance for AMR can be conceptualized and measured across a selection of different outcomes that can be classified in three dimensions, namely, (i) immediate, (ii) intermediate, or (iii) ultimate. Immediate outcomes include increased understanding of the AMR epidemiology at the human, animal, and environment health interface, and the value would lie in the intellectual or social capital generated. Intermediate outcomes include changes in policy or behaviors, and the expected value is the reduction in AMU and AMR that results from these changes.
Ultimate outcomes include tangible benefits such as improved animal, human, and environmental health and associated socioeconomic benefits. 

The Assessment Tool for Laboratories and AMR Surveillance Systems (ATLASS) is a tool designed by the FAO for assessing and defining targets to improve national AMR surveillance systems in the food and agriculture sectors. The Evaluation of Collaboration for Surveillance (ECoSur) tool aims at evaluating the organization, functioning, and functionalities of collaboration taking place in a multi-sectoral surveillance system. The AMR integrated surveillance system evaluation project (ISSEP) tool is a conceptual tool developed in Canada with the aim to structure an evaluation of the added value of integrated surveillance systems for AMR. The Network for Evaluation of One Health (NEOH) tool is part of a framework resulting from the EU COST Action ""Network for Evaluation of One Health"" to provide science-based guidance for the evaluation of One Health and other integrated approaches to health. The Progressive Management Pathway tool for AMR (PMP-AMR) tool is a self-assessment tool designed by the FAO to provide guidance to countries for implementation of their National Action Plans (NAP) for AMU and AMR. SURVTOOLS was developed as a part of the EU FP7-funded project RISKSUR: risk-based animal health surveillance systems.

Six different evaluation tools were assessed after being applied to AMU and AMR surveillance in eight countries: (1) ATLASS: the Assessment Tool for Laboratories and AMR Surveillance Systems developed by the Food and Agriculture Organization (FAO) of the United Nations, (2) ECoSur: Evaluation of Collaboration for Surveillance tool, (3) ISSEP: Integrated Surveillance System Evaluation Project, (4) NEOH: developed by the EU COST Action ""Network for Evaluation of One Health,"" (5) PMP-AMR: The Progressive Management Pathway tool on AMR developed by the FAO, and (6) SURVTOOLS: developed in the FP7-EU project ""RISKSUR."" Each tool was scored using (i) 11 pre-defined functional aspects (e.g., workability concerning the need for data, time, and people); (ii) a strengths, weaknesses, opportunities, and threats (SWOT)-like approach of user experiences (e.g., things that I liked or that the tool covered well); and (iii) eight predefined content themes related to scope (e.g., development purpose and collaboration). PMP-AMR, ATLASS, ECoSur, and NEOH are evaluation tools that provide a scoring system to obtain semi-quantitative results, whereas ISSEP and SURVTOOLS will result in a plan for how to conduct evaluation(s). ISSEP, ECoSur, NEOH, and SURVTOOLS allow for in-depth analyses and therefore require more complex data, information, and specific training of evaluator(s). PMP-AMR, ATLASS, and ISSEP were developed specifically for AMR-related activities—only ISSEP included production of a direct measure for ""integration"" and ""impact on decision making."" NEOH and ISSEP were perceived as the best tools for evaluation of One Health (OH) aspects, and ECoSur as best for evaluation of the quality of collaboration. PMP-AMR and ATLASS seemed to be the most user- friendly tools, particularly designed for risk managers. ATLASS was the only tool focusing specifically on laboratory activities. Our experience is that adequate resources are needed to perform evaluation(s). In most cases, evaluation would require involvement of several assessors and/or stakeholders, taking from weeks to months to complete. This study can help direct future evaluators of integrated AMU and AMR surveillance toward the most adequate tool for their specific evaluation purpose.",
sosinDraftFrameworkEvaluating2003,2312,Sosin 2003,Draft framework for evaluating syndromic surveillance systems.,Draft Framework for Evaluating Syndromic Surveillance Systems,2003,Daniel M. Sosin,unknown,United States of America,Developing a draft framework for evaluating syndromic surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,A. System description,"A thorough description of the system (e.g., purpose, stakeholders, how the system works)","1. Purpose: What is the system designed to accomplish?
2. Stakeholders: Who is the system serving?
3. Operation: How does the system work?
a. Use by stakeholders
b. Case definitions
c. Process model
d. Data model
e. Interoperability
f. Detection algorithm
g. Privacy/confidentiality
h. Communication",N/A,N/A,B. Experience,"System performance experience (e.g., usefulness, acceptability to stakeholders, generalizability to other settings, operating stability, costs)","1. Usefulness: In what ways has the system demonstrated value relevant to public health?
2. Acceptability: Have stakeholders been willing to contribute to and use the system?
3. Generalizability: How readily can the system be duplicated in another location?
4. Stability: How consistent has the system been in providing access to reproducible results?
5. Cost: What are the resource requirements to deploy and maintain the system?",N/A,N/A,C. Outbreak detection,"Capacity for outbreak detection (e.g., flexibility to adapt to changing risks and data inputs, sensitivity to detect outbreaks, predictive value of system alarms for true outbreaks, timeliness of detection)","1. Flexibility: How adaptable is the system to changing needs and risk thresholds?
2. Sensitivity and predictive value positive: What proportion of true cases and outbreaks are detected by the system? What proportion of alarms triggered by the system are desired alarms (true positives)?
3. Timeliness: How early in the disease process or outbreak is the event detected?",N/A,N/A,D. Data quality,"Assessment of data quality (e.g., representativeness of the population covered by the system, completeness of data capture, reliability of data captured over time)","1. Representativeness: How well does the system reflect the population of interest?
2. Completeness: What percentage of data is present for each record?
3. Reliability: Are data captured consistently across the system and over time?","Data quality includes the traditional surveillance evaluation attributes of representativeness, completeness, and reliability. The importance of representativeness is debatable; however, skewed samples may be relevant to early detection, beyond the loss of sensitivity in an incomplete sample.",N/A,E. Conclusions and recommendations for use and improvement of the syndromic surveillance system,Conclusions and recommendations,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Capturing the first or one of the early cases of disease caused by terrorism,Finding aberrant patterns of disease in the context of a widespread exposure,"Tracking a proxy syndrome (e.g., fever and rash) during a known outbreak (e.g., smallpox) to identify possible cases and characterize the geographic and temporal spread of the outbreak",Provide reassurance that evidence of terrorism has not been found,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Public health surveillance allows stakeholders to estimate the magnitude of public health problems, describe the natural history of a disease, determine the distribution and spread of illness, detect outbreaks, stimulate research, evaluate public health practice, monitor changes in disease agents, detect changes in health practices, and facilitate planning.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Experience attributes,Usefulness; acceptability; generalizability; stability; cost,N/A,Outbreak detection attributes,Flexibility; sensitivity and PVP; timeliness,N/A,Data quality attributes,Representativeness; completeness; reliability,See measurement considerations in framework section.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Have stakeholders been willing to contribute to and use the system?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,What percentage of data is present for each record?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"System costs have been highlighted in this framework because they are a key factor in understanding the value of these experimental surveillance systems. Startup costs (e.g., for computers, software, analytic methods development) should be distinguished from ongoing costs to run the system (e.g., staff, contractual relationships for data, software licenses). Costs that can be modified (e.g., number of reporting sources, analysis and investigation resources) should specify the intensity of the resources for the given cost.",What are the resource requirements to deploy and maintain the system?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Flexibility refers to the adaptability of the system to meet new data collection needs and to respond to changing priorities for detection,N/A,"In periods of high risk or high concern, the detection threshold in a flexible system can be lowered to increase the detection of outbreaks at an earlier stage, albeit with the risk of more false alarms",How adaptable is the system to changing needs and risk thresholds?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Generalizability,N/A,N/A,How readily can the system be duplicated in another location?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Are data captured consistently across the system and over time?,N/A,N/A,N/A,How well does the system reflect the population of interest?,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,How consistent has the system been in providing access to reproducible results?,N/A,N/A,N/A,N/A,N/A,N/A,"Timeliness is a central attribute for outbreak detection, and efforts to improve timeliness affect all system attributes. There is considerable variability in how timeliness is measured, and the terminology and measurement of this key attribute need to be standardized. Measures of timeliness must account for the time that is needed from data arrival at the health department until a data alarm response decision is made. Large volumes of data can be transmitted instantaneously, yet the time and effort to manage, analyze, and interpret those data increase with the volume and complexity of the data. Simply measuring how long it takes to transfer data from an external database into a health department database is insufficient for understanding the timeliness of the system.",How early in the disease process or outbreak is the event detected?,N/A,N/A,"The usefulness of a syndromic surveillance system is as difficult to measure as it is for traditional disease surveillance. Ideas for measurement are suggested in the framework, but more evaluation is needed to improve the systematic measurement of usefulness. Some points that should be considered in evaluation of system usefulness are (1) the purpose(s) of the system, (2) the system's application to control of naturally occurring outbreaks, (3) the performance of traditional surveillance for the stated purpose(s), (4) a clear definition of reassurance when this is considered a product of the system, and (5) the limited ability of most syndromic surveillance systems to detect small outbreaks.",In what ways has the system demonstrated value relevant to public health?,N/A,N/A,N/A,N/A,"Sensitivity and predictive value positive: The proportion of outbreaks in a jurisdiction that are captured by the system, and the proportion of detected events that represent outbreaks of interest",N/A,"These two attributes are combined in this framework because their measurement is related, and the relationship between these attributes allows comparisons of system performance

The system must be able to detect cases of the condition of interest and recognize patterns in the data to detect outbreaks","What proportion of true cases and outbreaks are detected by the system? What proportion of alarms triggered by the system are desired alarms (true positives)?

What proportion of true cases and outbreaks are detected by the system? What proportion of alarms triggered by the system are desired alarms (true positives)?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"This draft framework describes a range of measurements important for understanding and comparing the performance of syndromic surveillance systems. The draft framework, however, provides limited guidance on standard measurements for performance that allows for system comparisons and estimation of value. Evaluation of surveillance system performance for outbreak detection is a key area for scientific investigation. Validated and standardized components of syndromic surveillance systems are needed to enhance comparisons (e.g., case definitions, detection algorithms, analysis and investigation procedures). Another area of exploration is improving and standardizing the use of simulations and test data sets to assess how well a system will detect relevant scenarios for terrorism outbreaks.",N/A,N/A,N/A,"The full draft document (www.cdc.gov/epo/dphsi/phs/syndromic.htm) gives a detailed description of the evaluation framework, which is only highlighted in this document. This link no longer point to the draft framework, however I believe that the finalized version may be ""Framework for Evaluating Public Health Surveillance Systems for Early Detection of Outbreaks"" (CDC 2004).

Public health surveillance is the ongoing, systematic collection, analysis, and interpretation of health-related data essential to the planning, implementation, and evaluation of public health practice.

Ultimately, the value of evaluation comes from the conclusions and recommendations drawn from and shared by the data-driven evaluation process. Strengths and weaknesses should be listed, recommendations for how to use or improve the system should be explicit, and information gaps and research or demonstration needs should be clearly described.",
tegegneOHEpiCapSemiquantitativeTool2023,47,Tegegne 2023,OH-EpiCap: a semi-quantitative tool for the evaluation of One Health epidemiological surveillance capacities and capabilities.,OH-EpiCap: a semi-quantitative tool for the evaluation of One Health epidemiological surveillance capacities and capabilities,2023,Viviane Hénaux,viviane.henaux@anses.f,France,Generic framework and benchmarking tool for evaluating One Health capacities and capabilities within surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The OH-EpiCap tool was designed to serve as a support for discussion and scoring of the OH aspects by a panel of representatives from the different sectors across the entire surveillance system of a specific hazard. We recommend to identify up to 8-10 participants who have a good knowledge of the system and encompass a range of disciplines and experiences regarding the functioning of collaborations among institutes and programs. 

Experts were selected based on previous and ongoing involvement in research activities on OH aspects (e.g., One Health—European Joint Project (OH-EJP) program; Convergence in evaluation frameworks for integrated surveillance of AMR (CoEvalAMR) project) in national veterinary, public and/or environmental health institutes and from EFSA.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,1. Organisation,"The organization of the collaborative system

1.1 Formalisation: focuses on the common aim of the system, support documentations, coordination roles, and leadership in the OH surveillance system

1.2 Coverage / transdisciplinary: addresses whether the surveillance covers all relevant sectors, disciplines, actors, geography, populations and hazards

1.3 Resources: addresses aspects related to financial and human resources, sharing of the available operational resources, and training

1.4 Evaluation and resilience: focuses on internal and external evaluations, implementation of corrective measures, and the capacity of the OH surveillance system to adapt to changes","N/A

",2. Operational activities,"The nature and functioning of collaborations for operational activities

2.1 Data collection / methods sharing: concerns the level of multi-sectoral collaboration in the design of surveillance protocols, data collection, harmonization of laboratory techniques and data warehousing

2.2 Data sharing: addresses data sharing agreements, evaluation of data quality, use of shared data, and the compliance of data with the FAIR principle

2.3 Data analysis and interpretation: addresses multi-sectoral integration for data analysis, sharing of statistical analysis techniques, sharing of scientific expertise, and harmonization of indicators

2.4 Communication: focuses on both internal and external communication processes, dissemination to decision-makers, and information sharing in case of suspicion",N/A,3. Impact,"The impact of collaborations on surveillance

3.1 Technical Outputs: concerns the timely detection of emergence, knowledge improvement on hazard epidemiological situations, increased effectiveness of surveillance, and reduction of operational 

3.2 Collaborative added values: addresses strengthening of the OH team and network, international collaboration and common strategy (road map) design

3.3 Immediate and intermediate outcomes: addresses advocacy, awareness, preparedness and interventions based on the information generated by the OH surveillance system

3.4 Ultimate outcomes: focuses on research opportunities, policy changes, behavioral changes and better health outcomes that are attributed to the OH surveillance system",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Common aim
",N/A,N/A,Is the aim of the OH surveillance system defined from the expectations of all stakeholders including surveillance actors and end-users?,"Support documentations: The following items are expected to be described in the documents: 
- The objectives of the OH surveillance system; 
- The actors involved and their role in the steering of the OH surveillance system  (governance, coordination, technical/scientific support, ...); 
- The modalities of organization and functioning of the collaborations; 
- The mechanism for allocation of financial, human, and material resources for collaboration (ex: national specific budget, budget allocated per each institution...); 
- The processes that should be followed to ensure coordination of the OH surveillance system and the traceability of changes.
",N/A,N/A,Does the supporting documentation of the OH surveillance system includes information about the points below and are the documents shared with all actors?,"Shared leadership: The steering committee provides support, guidance and strategic oversight. Steering  Committee: is a composed of representatives from all sectors involved in the OH  surveillance and responsible for the overall coordination and oversight the surveillance  including establishing strategies, prioritizing, funding allocations and mobilizing  resources. The members of these committees should have appropriate expertise,  clearly defined roles and responsibilities. The committee should hold meetings  regularly to oversee the function of the system. 
",N/A,N/A,Is the leadership of the OH surveillance system fully operational with a steering committee shared among all sectors?,Coordination,N/A,"All the points listed below should be met at all surveillance levels (central, intermediate, and field levels): 
- The mandates of the coordination committee are defined at all levels; ; 
- The coordination is shared between sectors; ; 
- The coordination is shared between disciplines; ; 
- The human resources from each actor and sector involved in the OH surveillance system are identified; ; 
- The roles and responsibilities of each actor are defined; 
- The financial and material resources allocated are identified;  
- The modalities of organization and functioning of the coordination committee are defined; 
- The coordination committee is operational and effective (e.g. meetings at a ; regular frequency, information sharing, participation rate, production of clear ; guidance for collaboration, etc.)","Are the coordination committees (at central, intermediate and field levels) fully operational, with their roles and composition clearly defined (based on the following items) and shared between sectors?",Sectors,N/A,"Non-exhaustive list of potential relevant sectors: human, animal, environment, food, etc",Are all the relevant sectors to the hazard under surveillance included in the OH surveillance system?,"Disciplines: Disciplines to be considered depends on the OH system under study and may evolve over time. Potential disciplines include human medicine, veterinary medicine, clinical laboratory science, public health, animal health, environmental health, food safety, epidemiology, animal production, microbiology, immunology, biology, biostatistics (including geographic mapping), bioinformatics, economics, social sciences, etc. This list is not exhaustive.
",N/A,N/A,Are the disciplines relevant to the hazard under surveillance identified and included in the OH surveillance system?,"Actors: Potential actors include private firms, academia, research institutes, regulatory bodies, the general public, etc.
",N/A,N/A,Are all types of actors relevant to the hazard under surveillance identified and included in the OH surveillance system?,"Geographic, population and hazards: 
A) All geographic areas relevant to the hazard under surveillance; 
B) The entire human population (including people who might otherwise be excluded or marginalized), the animal populations relevant to the hazard (including livestock/animal production, domestic/pet animals, semi-ranging animals, and wildlife) and the environment; 
C) Surveillance systems of hazards of the same category (antimicrobial resistance and antimicrobial use; mosquito-borne diseases; abortive cattle diseases, etc.).",N/A,N/A,Does the coverage of the OH surveillance system encompass all of the following points?,"Budget 
",N/A,N/A,Is a sufficient and sustainable budget allocated for the steering and operational activities of the OH surveillance system?,"Human resources 
",N/A,N/A,Are sufficient and sustainable human resources (i.e. personnel and time) assigned to the OH surveillance system?,"Shared resources: Potential resources include relevant materials (ex. raw data), equipment (ex. software, analysis tools, etc.), etc.
",N/A,N/A,Are resources shared in the OH surveillance system?,Training,N/A,N/A,Is the training (including soft skills training) in OH approaches sufficient (in terms of the number of persons trained and frequency/continuity of organization) and appropriate (in terms of items/thematic proposed)?,"Internal evaluation: It is expected that a system of indicators was developed and validated by the steering committee. The indicators are exhaustive, address all surveillance steps, are measured according to the planned frequency, and enable an effective monitoring of the functioning of the OH surveillance system.",N/A,N/A,Are effective internal evaluations of the functioning of the OH surveillance system conducted (regularly)?,"External evaluation: External evaluations of the OH surveillance system are expected to be conducted regularly (every 3-4 years), according to a well-known and complete methodology. The evaluations should consider actors' expectations and experience regarding the functioning of the OH surveillance system.",N/A,N/A,Are effective external evaluations of the OH surveillance system conducted?,Corrective measures,N/A,N/A,Have corrective measures been taken based on the results of a previous evaluation of the OH surveillance system?,Adaptability to changes,N/A,N/A,"Regarding previous experiences, can the OH surveillance system adapt to internal and external changes and to critical situations within appropriate timelines?",Protocol design,N/A,N/A,What level of cross-sectoral collaboration occurs when designing surveillance protocols?,Data collection,N/A,N/A,What level of cross-sectoral collaboration occurs for surveillance data collection?,"Laboratory techniques: The existence of procedures and protocols for conversion of laboratory results across multiple sectors is a prerequisite for data interoperability between sectors.If sectors use different laboratory tests or interpret results with different standards, it might impact the flow and use of information.",N/A,N/A,Are laboratory techniques and procedures harmonized across sectors?,Data warehouse: A data warehouse is a central repository of integrated data from one or more sources in a single place. It stores current and historical data that is used for query and analysis.,N/A,N/A,Is there a common data warehouse?,Sharing agreement,N/A,N/A,"Are data sharing agreements (specifying issues related to data management, data storage, data ownership and confidentiality) between relevant sectors are implemented?","Data quality: Some examples of data quality indicators: completeness, accuracy, consistency, integrity, validity, timeliness etc.",N/A,N/A,Is the evaluation of data quality conducted systematically (using relevant indicators of data quality) and results/findings shared between sectors?,Usefulness,N/A,N/A,Do the shared data serve their purpose in the context of OH surveillance?,"FAIR data follow four principles: findability, accessibility, interoperability and reusability.",N/A,N/A,Are the data produced being handled within the OH surveillance system according to the FAIR principles?,Joint analysis,N/A,N/A,Are the data collected by the OH surveillance system (originating from multiple sources) jointly analyzed?,Sharing techniques,N/A,N/A,"Are statistical analyses, and visualization procedures shared across networks/sectors (e.g. syndromic surveillance scripts)?",Sharing expertise,N/A,N/A,Is scientific expertise shared between actors from different sectors to interpret the results?,"Indicators: Some examples of indicators: ratio, proportion, incidence, prevalence etc.",N/A,N/A,Are the harmonized and common indicators/metrics used across sectors to analyze and interpret the data?,N/A,N/A,N/A,N/A,"Internal communication: can include seminar reports, official letters, meeting minutes, or emails shared between actors of surveillance sectors.",N/A,N/A,Is an organized/formal internal communication system established between actors/sectors?,"External communication: includes scientific articles on OH surveillance results, seminar reports, regular publication of surveillance results in the form of newsletters, reports, web platforms/Shiny interfaces, etc.",N/A,N/A,Is joint external communication established?,Dissemination,N/A,N/A,Is joint information dissemination to decision-makers conducted?,"Emergence - The definition of a case suspicion and detection (e.g. suspected case, clinical case, possible case, probable case, confirmed case, etc.) is specific to the surveillance programs of the studied OH system.",N/A,N/A,"In the event of a suspected or detected case, is information sharing to other sectors conducted in real-time?","Emergence detection - Hazard emergence may be defined as a rapid increase in number of cases (incidence, prevalence) or geographical range. This definition should be adapted to the specificities of the hazard, the epidemiological situation and the objectives of the surveillance system under study.",N/A,N/A,"Does the detection of hazard emergence based on OH surveillance data occur within appropriate timeframes (for implementation of preventive, surveillance and control measures)?","Improved knowledge - OH surveillance systems have the capacity to integrate large, multi-sectoral, quantities of information and data to produce new data, knowledge and methods. This can be evidenced by reports, scientific publications, seminars, conferences, specific training courses and reinvestment of new knowledge to improve the surveillance system.",N/A,N/A,"Has the OH surveillance system improved the knowledge of the epidemiological situation of the targeted hazard, as evidenced by the following outputs?","Effectiveness - Some examples of indicators: timeliness, sensitivity, specificity, positive predictive value, precision, robustness, etc.",N/A,N/A,Has the implementation of the OH surveillance system improved the overall effectiveness of surveillance for the hazard?,Operational cost,N/A,N/A,"Has the implementation of the OH surveillance system reduced the operational costs (human, material, financial resources) of surveillance activities?","A OH team (formal or informal) consists of members of different disciplines, working collaboratively to set goals, make decisions and share resources and responsibilities to achieve better health outcomes (it could be formal or informal).",N/A,N/A,N/A,The OH network is defined as an engagement between two or more discrete stakeholders/actors with at least two of the sectors represented.,N/A,N/A,Has the network of stakeholders been strengthened (to become a solid network across all stakeholders) due to the existence of the OH surveillance system?,"International collaboration; Strategic plan; Preparedness corresponds to the set of actions that are taken as precautionary measures in the face of potential hazard-related issues. These actions can include written procedures, the resources available and training for emergency action; Interventions evidence-based interventions are practices or programs that have peer-reviewed, documented empirical evidence of effectiveness; Advocacy includes activities and publications (media, legislative, and grassroots efforts) to influence public policy, laws and budgets, and to educate target groups (government officials, students in public, animal and environmental health education, and the public) about the mitigation of the hazard risk based on the information obtained from the OH surveillance system; Awareness; Research; Policy changes; Behavioral changes include attitude, lifestyle changes; Health outcome include reduction of incidence, prevalence, case fatality, mortality, etc.",N/A,N/A,"Is international collaboration for the OH surveillance system (among countries or/and with international agencies) established? Is a common strategic plan that defines actions to set up or strengthen OH collaborations and the major steps or milestones needed to be reached by all stakeholders developed? Has better preparedness been developed from OH surveillance results? Have interventions been developed and implemented in a timely manner based on the evidence provided by the OH surveillance system (e.g. data from human sector feeding interventions in the animal sector)? Is effective advocacy being conducted by the OH surveillance system or by another stakeholder (not directly involved in the OH surveillance system) using information produced by the OH surveillance system? Does the OH surveillance system contribute to an increase in the level of awareness among stakeholders about the epidemiological situation (distribution, patterns, and determinants of the hazard of interest in defined human and animal populations as well as on the environment) of the hazard? Does the existing OH surveillance system create opportunities to develop and conduct new multi-sectoral collaborative research? Have policy (e.g. regulations, public interventions) changes been made based on, or informed by, evidence or recommendations from the OH surveillance system? Have behavioral changes been observed in the population at risk based on or informed by the OH surveillance system? Have the health outcomes among human and animal populations and ecosystems improved and achieved the goals set by decision-makers, as a result of the implementation of interventions informed by the OH surveillance?","Besides identifying areas that could lead to improvements in existing OH epidemiological surveillance capacities, the tool was designed to allow benchmarking (i.e., comparisons) with results from previous evaluations of that surveillance system, or other relevant systems, for example in other countries.",N/A,N/A,"16. Hénaux V, Henok T, Bogaardt C, Lailler R, Collineau L, Prada J. Deliverable D-JIP-MATRIX-WP4.2 OH-EpiCap tool and tutorial. (2022). Available online at: https://zenodo.org/record/7006654 (accessed September 23, 2022).","IMPORTANT: Complete framework with indicators and evaluation critera are available at: https://zenodo.org/records/7006654 - attached as supplemental file.

The relationship between targets and indicators is still somewhat unclear - have classified targets as domains and indicators as themes for extraction. There were more than 40 indicators therefore there are multiple indicators listed in the ""Additional Theme 40"" fields. 

OH-EpiCap is a generic (i.e., applicable to multi-sectoral surveillance systems of any hazard), interactive (facilitating and supporting discussions among stakeholders from diverse sectors and disciplines), and standalone (thanks to the user-friendly web application) tool developed to conduct macro-level evaluation of epidemiological national capacities and capabilities for OH surveillance. It supports the diagnostic of strengths and weaknesses in multi-sectoral collaborations and helps to identify concrete and direct actions to improve collaborative activities at all steps of surveillance. Besides, this evaluation framework strengthens trust between stakeholders across the systems, building a foundation for professional networks, acculturation to practices in other health sectors and disciplines, and long-term collaborations. The tool was designed to enable representatives of any surveillance system to conduct an evaluation of the multiple aspects of OH surveillance, in a short time and without requiring an external evaluation team.

Three dimensions of evaluation were considered in our tool: the organization of the collaborative system, the nature and functioning of collaborations for operational activities, and the impact of collaborations on surveillance (Figure 1). Each dimension was then divided into four targets focusing on specific features of multi-sectoral collaborations, building from the existing evaluation frameworks. Finally, we established standardized indicators defining more accurately each target and we singled out the necessary criteria to support their evaluation. The definition of indicators in each target is available in Hénaux et al. (16).

A questionnaire was developed to facilitate the collection of information for the scoring of the indicators, with one question per indicator. A semi-quantitative scale was defined with four levels, describing the level of compliance of the system under examination compared to an ideal situation: higher values suggest better adherence to the OH principle targeted by the indicator (i.e., better integration of sectors) and lower values indicate improvements may be beneficial. The standardized scoring guide, detailing for each individual score, the situation in which that score should be awarded, is available in Hénaux et al. (16).

One Health (OH): Multisectoral and multidisciplinary approach ensuring communication, collaboration, and coordination among all relevant ministries, agencies, stakeholders, sectors, and disciplines working locally, nationally, and globally to attain optimal health for people, animals, and our environment (https://extranet.who.int/sph/one-health-operations).

One Health surveillance / Integrated surveillance: The systematic collection, validation, analysis, interpretation of data, and dissemination of information collected on humans, animals, and the environment to inform decisions for more effective evidence- and system-based health interventions (Aenishaenslin et al 2021; Stark et al 2015).

One Health surveillance system: System in which collaborative efforts exist across at least two sectors (among human health, animal health, food safety and environment) in the surveillance process to produce and disseminate information with a purpose to improve any of human, animal or environmental health (Dufour et al 2009; https://aginfra.d4science.org/web/orionknowledgehub/catalogue).

Actors: An individual or organization that operates with a primary intent to improve health of people, animals and the environment.

End user: The person who receives and ultimately uses a product (WHO, 2021).

Stakeholders: the ultimate beneficiaries (i.e. animals, people and the environment) and the organisations that work to protect them (i.e. research institutes, government ministries, international organisations and professional bodies) (Dufour et al 2009).",
thackerMethodEvaluatingSystems1988,5678,Thacker 1988,A method for evaluating systems of epidemiological surveillance,A METHOD FOR EVALUATING SYSTEMS OF EPIDEMIOLOGICAL SURVEILLANCE,1988,Stephen B. Thacker,unknown,United States of America,Guidance for evaluating epidemiological surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Acceptability is measured by the willingness of persons conducting surveillance and those providing data to generate accurate, consistent and timely data.","The quantitative assessment of acceptability of a surveillance system has never been carefully conducted. 

Because refusal to participate and incompleteness are not sufficient evidence of the unacceptability of a surveillance system, more careful evaluation of this attribute should be developed.","The acceptability of a particular system - especially one that is voluntary - is dependent upon the perceived public health importance of the health event under surveillance, recognition of the individual's contribution to the system as it relates to control and prevention, and the time burden relative to available time. Surveillance methods must also be acceptable to those who provide the data. 

The individuals working at each step in the surveillance system must be willing to collect and handle the relevant data in a prescribed manner. As new systems are developed, the burden on data handlers must be ascertained and the impact of modifications In surveillance must be taken into account.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The cost of a system includes indirect as well as direct costs. and should be measured in relation to the benefits obtained.,N/A,"Surveillance can be costly, particularly in the development of new systems or the enhancement of current ones. One can assess current systems in terms of costs and benefits and can apply the lessons from these efforts to further surveillance activities. The economic analysis of surveillance systems has received little methodical attention apart from the accounting of direct costs to health agencies. To assess direct and indirect costs, all elements of a surveillance system, including data collection, analysis and dissemination, must be identified and costs assigned to them. To calculate a benefit/cost ratio, the benefits such as illness prevented can be estimated, including the reduction of medical-care costs and of time lost from school or work.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Flexibility is a measure of the ability of a surveillance system to be easily adapted to new reporting needs in response to changes in the nature or the importance of the health event, the population monitored, or the available resources.",This flexibility Is a desirable feature of a surveillance system and is best assessed as new health problems emerge or alternative Intervention strategies are adopted. The flexibility of a surveillance system can be assessed by the additional costs involved in modifying the system in some way.,Flexibility can also be observed at another level. A surveillance system that can be used for monitoring new or emerging problems can be seen as flexible.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,A surveillance system that is representative accurately observes both the occurrence of e health event over time and the distribution by person and place of that event in the population at any point time.,"To measure representativeness one can compare surveillance data covering pan of a population to a sample assumed to be complete (e.g. death certificates for selected fatal events) or a random sample of the population at risk (e.g. the Health lnterview Survey of the National Center for Health Statistics) 
","If a surveillance system collects reports on essentially all occurrences of a health event (e g. total deaths to a vital registrar) then the system is by definition representative and further assessment of this attribute is not necessary.

The importance of the degree of representativeness depends on its possible effect on the public health response. The report of a few cases of a disease may trigger appropriate control efforts ; non-representative reports may focus prevention activities away from populations at high risk. A precise assessment of representativeness requires carefully designed studies to obtain complete and accurate data for the health event in question.",N/A,N/A,N/A,N/A,N/A,"Sensitivity is defined as the ability of a surveillance system to detect true health events. Health events may be defined as 
(a) instances in which persons have a particular health problem or risk factor ; 
(b) a more narrowly defined subset of (a) (e.g. fatal events); or more broadly, as 
(c) an epidemic of a particular health event.","Quantitatively, sensitivity is the ratio of the total number of health events detected by the system over the total number of true health events as determined by an independent and more complete means of ascertainment (Fig. 1).","In published reports, sensitivity has been termed completeness of reporting and has been studied more than the other six attributes.

A variety of activities and circumstances will have an impact on sensitivity. 

The level of sensitivity can also vary to address specific programme goals. When control activities are contingent upon the identification and reporting of every case (e.g. the late stages of the international smallpox eradication campaign and the United States Measles Elimination 
Program) sensitivity is the critical criterion for assessing a surveillance system.",N/A,Simplicity in a system means it is easy to understand and implement.,N/A,"Simplicity should be a guiding principle for epidemiological surveillance. Simple systems are easy to understand and implement, cost less than complex systems, and provide flexibility. At the same time. surveillance systems should not be so simple that they provide data that are not useful or may even be misleading. The impact that an Increase In the complexity of a surveillance system would have on effective use of the system must be weighted against its Increased cost. In a voluntary system, Increased reporting burden might have a deleterious effect on the level of cooperation and productivity of those who report data. If the addition of information to a surveillance form compromises data quality or causes delays in data collection, the public health value of that system will diminish. Before asking for additional information, the impact of this added burden on these health departments should first be assessed in terms of data quality and reporter acceptance (see below).",N/A,Specificity is a measure of how infrequently a system detects false-positive health events.,"Quantitatively, it is the number of individuals identified by the system as not being diseased or not having a risk factor divided by the number of all parsons who truly do not have the disease or risk factor of interest (Fig. 1).

Given these difficulties in ascertainment, determination of the number of misclassified cases or false positives can be used as a measure of tho failure of the system to correctly classify health events In Fig. 1 the false-positive rate is B/ A + B.","When applied to surveillance, specificity can be difficult to determine if the total population at risk Is unknown. General population data may be available, but if a large portion of the population is not at risk (e.g. immune) the use of the total population as a denominator will provide an overestimate of specificity. Use of the true population at risk provides a more accurate estimate. 

A high rate of false positivity suggests that the system may be too sensitive (ie. the case definition in use is too permissive). While resources may be wasted in tracking these Incorrectly classified reports. the system may still be useful if the risk to public heath of a missed case is great (e.g. parathion contamination of a commercial food product).

Specificity, like sensitivity, can be applied to epidemics. Pseudo-epidemics (false positives) ore not common, but recognition of such situations is important to avoid unnecessary concern of the lay and medical community, to identify previously unrecognized laboratory problems, and to minimize the misuse of resources.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Timeliness is the Interval between the occurrence of an adverse health event and (i) the report of the event to the appropriate public health agency, (ii) the identification by that agency of trends or outbreaks, or (iii) the implementation of control measures.",N/A,"Timeliness is related both to the incubation or latency period of the health event and to the efficiency of the preventative Intervention. Because these parameters very according to the health event in question, timeliness must be interpreted from the stand-point of the user. 

Timeliness is particularly important for acute diseases that may occur in epidemic form.",N/A,A surveillance system is useful if it generates a public health response leading to the control and prevention of adverse health events or to a better understanding of the process leading to an adverse outcome.,"The usefulness of a surveillance system is measured by whether it leads to prevention or control or a better understanding of adverse health events. The measure can be qualitative, in terms of the subjective views of those using the system, or quantitative in terms of the impact of surveillance data on policies, interventions or the occurrence of a health event. 

The simplest way to assess usefulness is to ask those involved in public health practice. Surveys of public health officials at the state and local level, for example, have indicated that routine notifiable disease reports for viral hepatitis and measles are useful for disease prevention and control (18~ 19), A more rigorous approach to defining usefulness is through assessment of the impact of surveillance data on policies and interventions, and ultimately their impact on the occurrence of a health event. While policy analyses have been conducted elsewhere in the health field (20), there are no such studies of surveillance systems. Such policy analysis requires both observation and understanding of the decision-making process and quantification of the impact of surveillance information on the measures of interest (i.e.  morbidity, mortality, disability and quality of life). The latter can be accomplished by a quantifiable score such as the Disease Impact Score, which expresses as a single index the estimated impact of prevention on morbidity, mortality and cost, and attributes a portion of that score to surveillance (21). Although surveillance data may be important to health decision making and policy formation, decisions affecting surveillance are often based on changes in more general programme directions rather than detailed analysis of a particular system (e.g. directing resources away from routine contact tracing for gonorrhoea control to programmes for the prevention and control of acquired immunodeficiency syndrome) . 
","An additional consideration is the extent to which the knowledge obtained from surveillance data about the epidemiology of a health event leads to better understanding of a health problem (e.g. the identification of foreign travel as a risk factor in disease transmission), Even a very crude system of surveillance may be useful to public health practitioners (e.g. counting the total number of deaths seen by a medical examiner during a heat wave). 

The usefulness of a surveillance system should be reviewed periodically as illness patterns change and new priorities emerge. If a system is not directed towards high-priority health events and used as a tool to drive public health activities, either efforts must be made to 
improve the surveillance system or these resources should be directed elsewhere.","We recommend that the evaluation of the usefulness of a surveillance system be based on answers to the following questions. Does the system : 
* detect trends signalling new problems and lead to control and prevention activities? 
* detect epidemics leading to control and prevention activities? 
* provide quantitative estimates of the magnitude of morbidity and mortalitY related to the health event under surveillance? 
* identify factors involved in disease occurrence? 
* facilitate research likely to lead to control or prevention? 
* permit assessment of the effects of control measures?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The attributes of surveillance discussed in this article are interdependent, and the improvement of one may improve or compromise another. Increasing the sensitivity of a system to detect a greater proportion of a given health event in a population may also improve representativeness and usefulness yet lead to greater cost, lower specificity and more false-positive events.

Similarly, efforts to increase timeliness may lead to increased cost and a loss of specificity as more resources are expended and incomplete, less accurate diagnostic information is collected. The incidence of a health event also affects the interaction of sensitivity. specificity and timeliness of surveillance activities. 

Some aspects of evaluation are not addressed in this article. The proposed evaluation of both sensitivity and representativeness. for example. does not address the epidemiology of undiagnosed cases or problems associated with detection bias.",N/A,N/A,N/A,"Epidemiological surveillance is the systematic collection, analysis, interpretation and timely dissemination of health data for the planning, implementation and evaluation of public health programmes. The application of these data to disease-prevention and health-promotion  programmes completes a surveillance cycle in public health. 

The primary question to be addressed in the assessment of a surveillance system is whether or not the information produced by the system is useful. Does the system contribute to understanding a public health problem or prompt action that leads to the reduction of morbidity and mortality or the promotion of health? If not. is the health event under surveillance of sufficient importance to warrant a more effective surveillance system? If the system is useful, can it be improved or maintained at less expense? In either event, the quality of epidemiological surveillance systems can be assessed using the evaluation criteria based on seven attributes of surveillance systems formulated in this article.

Deficiencies detected in the evaluation of a surveillance system may relate to any part of the surveillance process-collection, analysis, dissemination or application of results to prevention. For example, the validity and reliability of surveillance reports are serious concerns for  anyone using surveillance data. 

Deficiencies in quality control within a surveillance system may adversely affect its effectiveness and efficiency as reflected in the measures of the usefulness, cost and quality of such systems. 

Assessment of both ongoing and developing systems of epidemiological surveillance will help to make them more efficient and more effective.",
thackerPublicHealthSurveillance1988,2749,Thacker 1988,Public health surveillance in the United States.,PUBLIC HEALTH SURVEILLANCE IN THE UNITED STATES,1988,STEPHEN B. THACKER,unknown,United States of America,A review of public health surveillance in the United States,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"CDC 1988 [""Acceptability reflects the willingness of individuals and organizations to participate in the system""]",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 1988,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 1988,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 1988,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 1988,N/A,N/A,N/A,CDC 1988,N/A,N/A,N/A,CDC 1988,N/A,"Increasing the sensitivity of a system to detect a greater proportion of a given health event in a population may also improve representativeness and usefulness of the system, yet may lead to greater cost, lower specificity, and more false positive events.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 1988,N/A,N/A,N/A,A surveillance system is useful if it can be applied to a public health program to control and prevent adverse health events or to better understand the process leading to an adverse outcome.,"The simplest way to assess usefulness is to ask those involved in public health practice by means of interviews or surveys. A more rigorous approach to defining usefulness is through the assessment of the impact of surveillance data on policies and interventions, but there are no published studies of this kind.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Other perspectives limit the potential scope of public health surveillance. The most common is that surveillance is limited to data collection and collation. It is important for a system of public health surveillance to include analysis and interpretation of data, as well as dissemination of those data to the relevant persons. Finally, to be complete, a public health surveillance system requires linkage to programs. When this broad perspective is not understood, the practice of surveillance and of epidemiology in public health is constrained short of its potential.",
vasconcelosgioiaInformingResilienceBuilding2021,120,VasconcelosGioia 2021,Informing resilience building: FAO's Surveillance Evaluation Tool (SET) Biothreat Detection Module will help assess national capacities to detect agro-terrorism and agro-crime.,Informing resilience building: FAO's Surveillance Evaluation Tool (SET) Biothreat Detection Module will help assess national capacities to detect agro-terrorism and agro-crime,2021,Gisela Vasconcelos Gioia,gisela.gioia@fao.org,Italy,"The development of the new SET Biothreat Detection Module and how it will be used to
evaluate surveillance for agro-terrorism and agro-crime animal disease threat","a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Biothreat reduction,N/A,N/A,N/A,Surveillance,N/A,N/A,N/A,Investigation,N/A,N/A,N/A,Emergency,N/A,N/A,N/A,Laboratory,N/A,N/A,N/A,Wildlife,N/A,N/A,N/A,Public health,N/A,N/A,N/A,Law enforcement,N/A,N/A,N/A,Military,N/A,none provided,Institutional organization,"Existence of agro-terrorism and agro-crime committee; Existence of formal documents on the organization and operation of agro-terrorism and agro-crime surveillance; Existence of focal points and mechanisms for national and international collaboration between animal health, law enforcement and other relevant sectors; and Adequacy of resources for surveillance of agro-terrorism and agro-crime.",5 indicators,Laboratory,"Mechanisms in place to meet laboratory epidemiologic and forensic needs; Existence of guidelines for sampling in joint epidemiologic and criminal investigations; Adequacy of resources and existence of laboratory information management system (LIMS) in laboratories involved in joint investigations; and Capacity of the country to differ endemic, foreign, emerging and potentially manipulated pathogens.",6 indicators,Surveillance activities,Existence and quality of a list of pathogens of concern for agro-terrorism and agro-crime; Knowledge of epidemiological situation of pathogens of concern; Existence of awareness campaigns on exotic and eradicated diseases; Existence and implementation of triggers and mechanisms for secure information sharing between veterinary services and law enforcement; Cross-border animal disease surveillance capacity; and Existence and quality of guidelines on joint epidemiological and criminal investigations.,11 indicators,Risk assessment,"Implementation, quality and use of threat/risk assessments to guide agro-terrorism and agro-crime surveillance activities.",2 indicators,Workforce,"Existence of staff planning, roster of investigators, background checks and trainings on detection, reporting and joint epidemiological and criminal investigations of potential agro-terrorism or agro-crime animal health events.",5 indicators,Data management,"Existence and implementation of mechanisms to secure surveillance data and sensitive information from theft, loss or misuse.",1 indicator,Evaluation,Implementation and use of joint simulation exercises and after action reviews for improvement of agro-terrorism and agro-crime surveillance.,2 indicators,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,24. Food and Agriculture Organization of the United Nations (FAO): Surveil lance Evaluation Tool (SET). http://www.fao.org/ag/againfo/programmes/en/ empres/tools_SET.html. Accessed 4 Jan 2020.,"Article does not provide a detailed list of all indicators related to category - there is also no supplemental file provided.

Once all 32 indicators are scored, the module will automatically generate a spider graph of the country's strengths and weaknesses in the detection of biological threats (Fig.3). This graphical output may then be used to develop recommendations to improve national surveillance of agro-terrorism and agro-crime events. Similar to SET, recommendations will be developed using the SMART approach (Specific, Measurable, Achievable, Relevant and Time-bound). For this, the recommendations will be prioritized into short, medium and long-term and detailed in an action plan for improvement of animal health agro-terrorism and agro-crime surveillance.

Therefore, a specific Biothreat Detection Module was developed to be used within SET to assess the capacity of countries to detect unusual animal health events that are indicative of agro-terrorism or agro-crime.",
velasovaEvaluationUsefulnessNational2015,1071,Velasova 2015,Evaluation of the usefulness at national level of the dairy cattle health and production recording systems in Great Britain.,Evaluation of the usefulness at national level of the dairy cattle health and production recording systems in Great Britain,2015,M. Velasova,mvelasova@rvc.ac.uk,not reported,Formally evaluate the usefulness (reliability and accuracy) of the dairy cattle health recording systems in Great Britain,"b. Formal evaluation of public health, environmental, or One Health surveillance systems",e. Other,Great Britain,g. SERVAL: a new framework for the evaluation of animal health surveillance (Drewe 2015); k. Other,"Adaptation of the SERVAL framework, attributes were grouped according to the ""proposed terms and concepts for describing and evaluating animal-health surveillance systems"" (Hoinville 2013).",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Government agencies,N/A,N/A,"Experts were selected because of their knowledge of the dairy industry, cattle health or disease surveillance.",Government advisory groups,N/A,N/A,"Experts were selected because of their knowledge of the dairy industry, cattle health or disease surveillance.",Practising dairy cattle veterinarians,N/A,N/A,"Experts were selected because of their knowledge of the dairy industry, cattle health or disease surveillance.",Dairy farmers organisations,N/A,N/A,"Experts were selected because of their knowledge of the dairy industry, cattle health or disease surveillance.",Universities (veterinary schools),N/A,N/A,"Experts were selected because of their knowledge of the dairy industry, cattle health or disease surveillance.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,System processes,Data collection; Data recording and management; Data analysis; Communication;,Stage 1 of the evaluation involved a web-based questionnaire. Stage 2 of the evaluation involved conducting a structured telephone interview.,Inclusion,Representativeness; Coverage; Multiple utility,Stage 1 of the evaluation involved a web-based questionnaire. Stage 2 of the evaluation involved conducting a structured telephone interview.,System performance,Benefit,Stage 1 of the evaluation involved a web-based questionnaire. Stage 2 of the evaluation involved conducting a structured telephone interview.,System function,Flexibility; Stability and sustainability,Stage 1 of the evaluation involved a web-based questionnaire. Stage 2 of the evaluation involved conducting a structured telephone interview.,Evidence quality,Bias,Stage 1 of the evaluation involved a web-based questionnaire. Stage 2 of the evaluation involved conducting a structured telephone interview.,Data quality,Data completeness and correctness,Stage 1 of the evaluation involved a web-based questionnaire. Stage 2 of the evaluation involved conducting a structured telephone interview.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Ability of the system to adapt to changes and to continue working in long term,"How easily can it adapt to changes in case definition, variation in funding, staff availability, etc.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Extent to which features of the population of the interest are reflected in the surveillance data that are collected,"Information on geographic location, herd size, production type, age, sex",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Data collection: The use of appropriate data sources and data collection methods, protocols and the existence of a case definition","Use of protocols, standard procedures when collecting data
 Consistent, continuous collection
 Active v passive collection
 Paper v electronic collection
 Use of trained personnel
 Use of clear definitions for diseases/conditions",N/A,N/A,Data recording and management: Appropriate use of data management systems and protocols and quality control of data,"*Manual data entry v electronic; 
*Central recording; 
*Using bespoke spread sheet/databases; 
*Use of unique identifier for individual animal/farm; 
*Checking for errors, duplicates; 
* Data manipulation/collation",N/A,N/A,Data analysis: Use of appropriate methods for analysis and interpretation of results,"*At animal/farm level; 
*Prevalence/incidence estimates, descriptive; 
*Who is involved in the analysis; 
*How often data are analysed",N/A,N/A,"Communication: Assessment of methods and ease of reporting, including type of outputs reported","* To individual farmer, producers, industry, government, veterinarian, consumer; 
* Use of standard format of reporting; 
* Regular reports; 
* Ways of reporting—use of website, over the phone, etc.",N/A,N/A,Coverage: Proportion of the population of interest that is included in the surveillance activity,*Number and geographic coverage of farms/animals included in the database,N/A,N/A,Multiple utility: The ability of a surveillance system to capture information on several diseases or health conditions; measure of how generic the system is,"*Type of data recorded in the system; 
*Specific health conditions recorded in the system",N/A,N/A,Benefit: Direct and indirect advantages produced by the surveillance system,"*Reason for recording: legal requirement, reduction in disease occurrence, improved animal health on farm, identification of research needs, improved genetics, providing advice; 
*Who benefits: individual farmers, producers, government, consumer, industry",N/A,N/A,"Stability and sustainability: The ability to function without failure (reliability), the ability to be operational when needed (availability) and the robustness, and the ability of the system to be ongoing in the long term (sustainability)","* Use of protocols, standard procedures when collecting data; 
*Consistent, continuous collection; 
*Quality control; 
*Staff availability, funding",N/A,N/A,Bias: The extent to which prevalence estimate produced by the surveillance system deviates from the true prevalence value. One way to reduce bias would be to increase representativeness,"Assessed in terms of methodological flaws:
* Selection of farms (implication for selection bias); 
* Data collection (implication for information bias); 
* Use of case definitions, laboratory testing (implication for misclassification bias)",N/A,N/A,"Data completeness and correctness: Proportion of the data that was intended to be collected that actually was (data completeness), and the proportion of data entries that correctly reflect the true value of the data collected (data correctness)","* Number of individual animals/herds recorded in the database (information for data completeness); 
* Check on the completeness of disease recording (i.e. whether particular health conditions are recorded for all of the animals or herds in the database)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"In the authors' evaluation, they prioritised attributes in order to identify recording systems that can produce reliable and accurate estimates of important health conditions at national level and the same attributes were assessed for all the systems as opposed to the attribute selection based on the objectives of the individual recording systems as it is described in the SERVAL framework.

Qualitative assessment of the individual attributes as green, orange or red has an element of subjectivity, and thus, the assessment of the attributes by a single person could have introduced some bias.",N/A,N/A,N/A,"Animal health surveillance definition: he systematic, continuous or repeated measurement, collection, collation, analysis, interpretation and timely dissemination of animal health and welfare related data from defined population

For these systems to be effective at national level, the data need to be reliable and accurate; reliability can be defined as the ability to function without failure and accuracy in terms of completeness and correctness.

Information on individual attributes was summarised qualitatively, and the attributes were assessed using a coloured traffic light system as (1) green—excellent or very good; (2) orange— good, though room for improvement; and (3) red—poor, in need of attention.

The aspects (and respective attributes) of the recording systems used for the assessment of the reliability included system processes, system performance and system function; and for the assessment of accuracy: system processes, inclusion and evidence quality. 

All the recording systems were fully electronic with data quality control in place and standard procedures for data collection. Voluntary participation, lack of completeness, coverage and standardisation were common weaknesses of the systems.",
worldhealthorganizationOverviewWHOFramework2004,10973,WorldHealthOrganization 2004,Overview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases.,Overview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases,2004,World Health Organization,unknown,not reported,Conceptual framework of surveillance and response systems for communicable diseases,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Plan for the monitoring and evaluation activities,N/A,N/A,N/A,"Details of each step are given in the WHO toolkit for monitoring and evaluating surveillance and response systems to communicable diseases, currently being finalized by WHO.",Prepare for the monitoring and evaluation,N/A,N/A,N/A,"Details of each step are given in the WHO toolkit for monitoring and evaluating surveillance and response systems to communicable diseases, currently being finalized by WHO.",Conduct the monitoring and evaluation,N/A,N/A,N/A,"Details of each step are given in the WHO toolkit for monitoring and evaluating surveillance and response systems to communicable diseases, currently being finalized by WHO.",Follow up on the recommendations from the monitoring and evaluation activities,N/A,N/A,N/A,"Details of each step are given in the WHO toolkit for monitoring and evaluating surveillance and response systems to communicable diseases, currently being finalized by WHO.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Surveillance structure,"- Laws, legislation, regulations
- IHRa compliance
- Surveillance strategy
- Data flow between levels
- Networking/partnership",N/A,Core functions,"- Case detection
- Registration
- Confirmation
- Reporting
- Data analysis/interpretation
- Epidemic preparedness
- Response and control
- Feedback",N/A,Support functions,"- Standards and guidelines
- Training
- Supervision
- Communication
- Resources (including logistics)
- Coordination",N/A,Surveillance quality,"- Timeless
- Completeness
- Usefulness
- Sensitivity
- Specificity
- Simplicity
- Flexibility
- Acceptability
- Reliability
- Positive predictive value
- Representativeness",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"To pull final WHO guidance document (I believe this is it): 

World Health Organization, 2006. Communicable disease surveillance and response systems: guide to monitoring and evaluating. Lyon: WHO Lyon Office for National Preparedness and Response

Conceptual framework for public health surveillance and action and its application  in health sector reform. BMC Public Health, 2002, 2:2  (http://www.biomedcentral.com/1471-2458/2/2)","Public health practitioners need to review constantly their performance in detecting and responding to communicable diseases. At the same time, they should remain accountable for their activities and policies to a variety of stakeholders. People at different levels of surveillance need to report accurate, timely and reliable data to national authorities, to ensure timely and effective responses to contain communicable disease outbreaks, and also to donors, to secure funding to strengthen surveillance and response activities to communicable diseases. Most importantly, all surveillance levels in countries should be able to utilize the surveillance information locally to address and resolve problems related to control of communicable diseases.

Monitoring is the routine (continuous) tracking of the performance of the surveillance and response systems. Evaluating is the periodic assessment of changes in targeted results (objectives) that can be attributed to the surveillance and response system. Evaluation attempts to attribute changes in outputs, outcomes and impacts (negative or positive, targeted or non-targeted) of the surveillance and response system.

Evaluation fosters accountability while ensuring that the surveillance and response systems meet the objectives for which they were developed.

Monitoring surveillance quality - most importantly, routine monitoring of timeliness and completeness - is essential, regardless of the surveillance strategy.

Evaluation should include process (and resulting outputs) evaluation, outcome evaluation and impact evaluation of the surveillance and response system.

The selection of indicators for monitoring and evaluating should be guided by the usefulness of the information generated, availability of data, ease of accessing the data, feasibility and cost-effectiveness of generating the required data. Additional criteria to consider include validity, sensitivity and reliability of the indicators.

WHO recommends the logical framework model and the toolkit for monitoring and evaluating surveillance and response systems to communicable diseases (currently being finalized) contains a list of indicators categorized as input, process, output, outcome and impact indicators, which are defined below. Their use by Member States for monitoring and evaluating surveillance and response systems at national and subnational levels is recommended.

Input indicators refer to the resources needed to establish and implement surveillance and response activities. They include trained personnel, finances, standards and guidelines, communication facilities, relevant forms for surveil- lance, etc.

Process indicators are used to monitor and track activities such as training, supervision, developing guidelines, and development of core surveillance functions.

Output indicators are used to measure the results of the activities conducted, e.g. reports and interpretation of surveillance data, feedback provided, proportion of health staff trained in surveillance and response, and whether supervision was conducted according to plan.

Outcome indicators are used to measure the extent to which the surveillance objectives are being achieved and include the quality of the surveillance systems, appropriateness of any outbreak response and usefulness of the systems.

Impact indicators are used to measure the extent to which the overall goal of the surveillance and response systems is being achieved, e.g. reduction in the case-fatality rate of epidemic-prone diseases, changes in the morbidity pattern of targeted communicable diseases or changes in behaviours of health staff and of the general population.

Framework was built upon work from McNabb 2022 and CDC 2001.",
yangUnderstandingOccupationalSafety2022,189,Yang 2022,"Understanding occupational safety and health surveillance: expert consensus on components, attributes and example measures for an evaluation framework.","Understanding occupational safety and health surveillance: expert consensus on components, attributes and example measures for an evaluation framework",2022,Liu Yang,yangliu@lifetime.oregonstate.edu,United States of America,Development of a preliminary evaluation framework for occupational health surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Inputs,"Surveillance Components: 
- Infrastructure (legislation and regulations; standards and guidelines; funding resources; organizational structure and human resources; material resources); 
- Surveillance Strategy (surveillance objectives; events under surveillance; surveillance technologies; surveillance protocols); 
- Data Sources (mandatory reports; administrative data; registry data; census data; survey data; other data); 
- Stakeholders (federal agencies, state agencies; employers and employees; medical care providers; professionals and professional organizations; other stakeholders)","Assessed by the following attributes:
- Infrastructure (legislative support, compliance, sustainability)
- Surveillance Strategy (confidentiality, significance, feasibility, transparency)
- Data Sources (data quality related attributes: validity, sensitivity, specificity, PVP, representativeness, consistency, completeness, accuracy, clarity)
Stakeholder (acceptability, mutual understanding, mutual benefit)",N/A,N/A,Activities,"Surveillance Components:
- Data Processing [Core Functions] (data collection; case investigation, data analysis; data interpretation)
- Early Detection [Core Functions] (provide timely data; detect clusters and unusual events; guide immediate actions)
- Ongoing Monitoring [Core Functions] (track burdens and trends; identify populations at risk; detect workplace hazards)
- Data Dissemination [Core Functions] (produce dissemination materials; dissemination timing; dissemination channels/mechanisms)
- Supporting Functions (supervision; management; training; communication and coordination; surveillance evaluation)","Assessed by the following attributes:
- Relevance
- Adherence
",N/A,N/A,Outputs,"Surveillance Components:
- Surveillance Publications (technical reports; media reports; conference presentations; peer-reviewed publications; educational materials)
- Datasets
- Other Outputs","Assessed by the following attributes:
- Accessibility
- Usability
- Data quality related attributes: validity, sensitivity, specificity, PVP, representativeness, consistency, completeness, accuracy, clarity",N/A,N/A,Outcomes,"Surveillance Components:
- Short and Mid-Term Outcomes (support research; guide intervention programs; increase awareness and knowledge)
- Long-Term Outcomes (policy change at national/state/local level; safer workplace; reduced work-related injuries; illnesses and diseases)","Assessed by the following attributes:
- Usefulness",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Experts involved in the operation of OSH surveillance systems in the US,"Experts needed to meet at least three of the following criteria to be included in the Delphi study:
- OSH surveillance experience (more than one year's experience working as a key staff in OSH surveillance systems in the U.S)
- Evaluation experience (Experience in evaluating OSH surveillance systems)
- Education (Bachelor's degree or higher in public health, safety, or related fields)
- Publications (More than three peer-reviewed publications/book or book chapter on occupational safety and health topics in the past five years, among which at least one focusing on OSH surveillance)
- Conference presentation (than three national level conference presentations on occupational safety and health topics in the past five years, among which at least one focusing on OSH surveillance)
- Professional involvement (Current member or committee in professional organizations of occupational safety and health, public health surveillance, or program evaluation)",N/A,N/A,Experts involved in the evaluation of OSH surveillance systems,"Experts needed to meet at least three of the following criteria to be included in the Delphi study:
- OSH surveillance experience (more than one year's experience working as a key staff in OSH surveillance systems in the U.S)
- Evaluation experience (Experience in evaluating OSH surveillance systems)
- Education (Bachelor's degree or higher in public health, safety, or related fields)
- Publications (More than three peer-reviewed publications/book or book chapter on occupational safety and health topics in the past five years, among which at least one focusing on OSH surveillance)
- Conference presentation (than three national level conference presentations on occupational safety and health topics in the past five years, among which at least one focusing on OSH surveillance)
- Professional involvement (Current member or committee in professional organizations of occupational safety and health, public health surveillance, or program evaluation)",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,"1. Infrastructure

2. Surveillance strategy

3. Data sources

4. Stakeholders","1. Basic structure and foundations for establishing and maintaining a surveillance system. It should be flexible and able to change/evolve as the system grows and as needed

2. Guiding standards, methodologies and procedures for the establishment and maintenance of a surveillance system, including surveillance objectives, events under surveillance and case definitions, available data sources and surveillance techniques.

3. Instead of being a single, comprehensive surveillance system, current OSH surveillance systems make use of a variety of data sources which are collected by different organizations with different surveillance objectives, strengths and weaknesses.

4.Those who provide data, funding or technical support; or are involved in the surveillance activities such as survey participants; or impacted by surveillance activities and results; or surveillance data users.","Sub-domains are provided in the framework section.

For sub-domain definitions see Table 3 in the supplement materials.","1. Data processing

2. Early detection

3. Ongoing monitoring

4. Data dissemination

5. Supporting activities","1. The function of system to synthesize and analyze data at individual and aggregated levels and produce interpretable results. Protocols should be in place specifying data collection methods & procedures.

2. Timely data processing, analysis and dissemination to guide immediate actions to stop workplace hazards and possible diseases clusters. Early detection may not be a critical function in current OSH surveillance practice. However, there is the need for more timely case detection and investigation to guide effective intervention action.

3. Ongoing surveillance activities with an emphasis on identifying burdens and trends over time and population. 

4.The function to routinely and actively disseminate data and information to the public to guide actions on improving occupational safety and health.

5. Functions that facilitate implementation of the core functions","Sub-domains are provided in the framework section.

For sub-domain definitions see Table 3 in the supplement materials.","1. Publications

2. Datastes

3. Other outputs","1. Data (e.g. summary statistics, case investigation, trend analysis, etc.) and interpretable information generated routinely and on demand need to be reported in various forms, depending on the surveillance purposes and dissemination methods.

2. Individual level and aggregated data records released by the surveillance system to the public and interested organizations/individuals for research and other purposes.

3. Other outputs in the surveillance system may include research and outreach, intervention prevention guidance, strategic policy recommendations, etc., depending on the surveillance system's objectives and resources available","Sub-domains are provided in the framework section.

For sub-domain definitions see Table 3 in the supplement materials.","1. Short & mid-term outcomes

2. Long-term outcomes",No domain definitions provided.,"Sub-domains are provided in the framework section.

For sub-domain definitions see Table 3 in the supplement materials.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Stakeholders understand the purpose of the surveillance system, advocate the system, feel the system is useful, and/or are willing to participate in surveillance activities.",N/A,N/A,"Are stakeholders aware of the existence of legal and mandatory requirements for the surveillance activities?Do stakeholders actively communicate with the system staff?
Participation rate/responding speed of stakeholders in a certain surveillance activity (e.g. meeting, data request, survey).
The level of willingness of stakeholders to collaborate with the surveillance system.
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Required variables recorded in the surveillance datasets are complete without missing data.,N/A,N/A,"Proportion of missing or blank data?
What is the reason for missing data?
What is the impact of missing data?
","Compliance:Degree to which the surveillance system complies with all relevant legislation, regulations and policies, including ethics and confidentiality requirements.",N/A,N/A,Is the system in compliance with all legal and regulatory requirements?,"Data have the same meanings (e.g. case definition, diagnosis standards) to allow for consistent interpretation. This includes internal consistency (within a dataset) and external consistency (across different data sources), as well as consistency over time.",N/A,N/A,"Are data collected by different entities within the system following consistent and rigorous formats?Are data collected from different sources share common methodology (e.g. case definition, coding systems, and classifications)?
Is data coded the same way over time to track trends?
",N/A,N/A,N/A,N/A,"Goes beyond effectiveness by bringing in a reference to the amount of resources involved. A surveillance system is cost effective if it identifies data with the biggest impact on improving worker safety and health while minimizing the cost of collecting the data. Cost-effectiveness analysis should consider the societal costs associated with the occurrence of events under surveillance, i.e., the costs associated with the health and productivity consequences of occupational exposures, injuries, illnesses, and mortality on workers, their families, and society, including both direct and indirect costs.",N/A,N/A,"What are the costs (direct and indirect, individual and societal) for injuries/illnesses/events under surveillance?
Is cost-effectiveness (financial and social) a consideration in decision-making for objectives and priorities, and the selection of surveillance methodologies?
Is there up-to-date cost-effectiveness analysis done for the system?
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Ability of a surveillance system to achieve its intended objectives.,N/A,N/A,"Is the system effective in accomplishing its stated objectives?
Are various methods used to increase effectiveness, such as shared efforts on data collection/processing/dissemination through internal and external collaboration?
Percentage of planned tasks (e.g. obtaining source data, outbreak detection & case investigation, data analysis, producing data reports) accomplished by due dates.
What are the costs (fixed and variable) associated with each surveillance activity in the system?
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Surveillance strategies and methods are suitable and applicable to the surveillance objectives and available resources.,N/A,N/A,"Do the system strategies correspond to objectives and priorities?
Do necessary outside resources exist (e.g. steering committee, technical committee, government affiliation)?
Do the staff have the required knowledge, skills and experience to operate and maintain the system? Multidisciplinary expertise may be needed for modern day surveillance.
Are the surveillance events/cases trackable over time given the data sources available?
Do the resources available match the strategies and processes (data collection, data analysis, and data dissemination, etc.)?
","Ability of the system to adapt to changes in operating conditions, technologies or information with little additional time, personnel, or funds.",N/A,N/A,"Can the system respond to event/case definition changes?
Can the system respond to changes and/or variations across existing data sources?
Can the system easily incorporate new data sources?
Can the system respond to new data standards (e.g. ICD-9 to ICD-10)?Can the system respond to changing surveillance technologies (e.g. online data sharing, machine learning techniques for data coding)?
Can the system adjust surveillance objectives and strategies as needed (e.g. respond to new hazards/conditions)?
Is there funding/personnel/material redundancy to support flexibility?
","Ability of the surveillance system or components in the system to integrate/connect with other surveillance or public health systems to enhance interoperability, effectiveness and/or to reduce cost.",N/A,N/A,"Is the system connected with other public health systems within or outside the same organization (in terms of data collection/processing/sharing)?Does the system follow standardized data collection and sharing for integration ease?
Are problems/opportunities identified with functions as they relate to each other?
Are potential issues addressed for a successful integration (e.g. to avoid annexation)? 
Are there data sharing mechanisms among different surveillance functions, which includes information to share, to whom the information being communicated, and data sharing platform?
",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The proportion of reported cases/events that are actually true cases/events.,N/A,N/A,"The proportion/number of cases/events captured by the surveillance system that are confirmed as true cases/events.
Is there active approach used to verify cases/events?
",N/A,N/A,N/A,N/A,"The extent to which data adequately represent the population under surveillance and relevant sub-populations by time, place, population demographics and socio-demographics.",N/A,N/A,"Does the system reflect the characteristics of working populations under surveillance?
Does the system reflect the change of population characteristics over time?
Are there sub-populations of interest excluded or under-reported?
",N/A,N/A,N/A,N/A,The ability of the surveillance system to capture true cases/events or outbreaks/clusters.,N/A,N/A,"The likelihood/percentage that workers will seek medical care or compensation and be reported/captured to the surveillance system?
Sensitivity of the screening/diagnosis procedure.
The proportion/number of cases/events are captured by the surveillance system compared to certain standard OSH data source(s)?
Is there any active approach used to help to detect true cases/events?
Can the system accurately detect clusters, outbreaks or usual events in an appropriate time frame?
","A guiding principle in designing and implementing the surveillance system, including the organizational structure, the surveillance strategies, information flow from data providers to data users, coordination of various surveillance activities. Simplicity is conductive to the effectiveness and efficiency. All different components in the surveillance system should be designed to avoid unnecessary complexity.",N/A,N/A,"Is the case definition of events/conditions under surveillance simple and easy to understand?
Does the system rely on sophisticated data collection methods, multiple data sources and/or multiple collaborators?
Does the system involve active surveillance activities?
Are system protocols easy to follow?
Is the organizational structure simple but sufficiently effective to meet the surveillance needs?
Does the system use accepted standards for data coding and data sharing so that merging and comparison within/outside the system is easy?
Are processes and platforms (e.g. software, database) for data reporting, entry, coding, merging, and sharing streamlined and easy to use?
Is there any part of the system unnecessarily complicated? Is there a better way to streamline the system?
",The proportion of individuals not having the occupational health related event identified by the system as not having the event.,N/A,N/A,"Specificity of the screening/diagnosis procedure.
The proportion/number of non-cases/events correctly determined by the surveillance methodology/algorithm (e.g. by comparing two methodologies identifying work-related cases).
",Ability of the surveillance system to be operational and provide surveillance products reliably and stably (without failure).,N/A,N/A,"Can the system continue its planned activities with staff turnover or other resource problems?
Are data sources and data collection collaboration stable to ensure ongoing surveillance?
Can the system maintain its activities under changing situations such as coding system changes, technological updating, switching technical platforms?
",N/A,N/A,N/A,N/A,Capability of the system to finish working steps and fulfills its objectives with a speed that's quick and appropriate.,N/A,N/A,"Time required for collaborating agencies to process data before it is transferred to the system.
Time needed to investigate and analyze the data for mortality/morbidity, trends, outbreak, risk factors.
Time needed for the surveillance system to release warning alerts (outbreak, unusual events) and/or data/statistics reports.
Time needed for the system to respond to requests (e.g. data request, regular/urgent work needs).
Overall time spent from events (exposure, seeking health information, medical care, and/or medicine) to data dissemination and eventually to public health actions.
Are the time spent appropriate for the objectives of the system?
",Ability of the surveillance system to directly and indirectly contribute to the prevention and control of adverse occupational health conditions and improve workers' safety and health.,N/A,N/A,"Does the system provide timely data to detect outbreaks/clusters/unusual events? Calculate the number/percentage of events detected.
Does the surveillance data allow for investigation of clusters, outbreaks, and/or unusual events to guide timely mitigation action? Calculate the number/percentage of the investigated/actionable.
Does the system measure the burden of work-related injuries or illnesses and monitor trends over time and space?
Can the surveillance data guide identification of worker populations at risk?
Does system track leading indicators of occupational safety and health (e.g. workplace hazards)?
Can the system detect new/emerging diseases and/or workplace hazards?
Has the data dissemination helped to increase the workers' and employers' safety and health awareness?Does the system provide data to support epidemiological studies and applied research/practices?
Can surveillance data guide the planning, implementation, and evaluation of interventions or programs intended to prevent and control work-related injuries, illnesses, and diseases?
Has the surveillance data lead to policy/regulation changes at national/state/local level?
",Degree to which information correctly describe the health event it was designed to measure.,N/A,N/A,"Is their standard scientific evidence that the event under surveillance is work-related, or significantly associated with occupational factors.
Validity of the survey constructs.
Are the data of sufficient quality to generate a valid estimate?
Are biases introduced in data collection process (e.g. case reporting, data coding, method to identify work-relatedness) that affect the validity of measurements?",Legislative support: Existence of legal and regulatory requirements to support the establishment and maintenance of the surveillance system and its activities.,N/A,N/A,"Are there mandatory requirements on the establishment of the system?
Are there mandatory requirements on data reporting/collection for the events/cases under surveillance?","Sustainability:The system is able to sustain itself with adequate financial, human and material resources.",N/A,N/A,"Is funding secure for short-term (e.g. 3-5 years) and long-term (e.g. more than 5 years) future?; 
Are the necessary human resources (e.g. staffing) sustainable for the short-term and long-term future?; 
Are the necessary material resources (e.g. technical infrastructure) sustainable for the short-term and long-term future?; 
Can the system maintain and expand collaborations in the future (e.g. for data collection, analysis and dissemination)?; 
Can financial, human and material resources support the system to adapt to envisioned changes and/or to expand activities?","Confidentiality: Privacy and data confidentiality requirements for the collection, storage, backup, transport and retrieval of information (especially over the internet), based on relevant standards and guidelines.",N/A,N/A,"Are privacy and confidentiality requirements clearly specified in protocols/documentation?;
Are the requirements reviewed regularly to be updated as necessary?; 
Are well-established methodologies in place to secure confidentiality in the data collection and transport, especially over the internet?; 
Is there a process to check for and document deviations and corrective actions when privacy or confidentiality is breached?","Significance: Objectives, priorities and events under surveillance in the system reflect significant occupational safety and health concerns.",N/A,N/A,"Does the system identify significant OSH issues (i.e. potentially catastrophic, associated with big economic and/or social impacts, or concerns among the public or industries)?; 
Once identified, is there a process to set objectives and prioritize events to surveil? e.g. with advisory board or stakeholders, through consensus, through grant peer review.; 
How does the system adjust its objectives and priorities based on emerging OSH issues?; 
Are there past examples of the system reflecting significant occupational safety and health concerns?; 
Are populations at risk (defined by age, ethnicity, size, spatial distribution, etc.) identified and tracked in the system on an ongoing basis?","Transparency: Surveillance strategies, methodologies and activities are planned and revised following a well-established, sound and transparent approach and process.",N/A,N/A,"Are important details (e.g. surveillance strategies, planned activities, methodologies for data collection and analysis, changes) clearly documented in system protocols/documentation on a regular basis?","Mutual understanding:Relevant information is shared among stakeholders, including surveillance objectives and requirements (such as privacy and confidentiality requirements), the flow of surveillance data and process, and the methodologies of information dissemination and utilization. This helps to achieve mutual understanding and expectations among stakeholders.",N/A,N/A,"Are responsibilities clearly specified for staff and collaborators in the surveillance system?; 
Is there a mutual understanding of security, confidentiality and privacy process between the system and stakeholders (e.g. data providers, data users)?; 
Has a trusted relationship been established between the surveillance system and its collaborators?",Mutual benefit:The capability of the surveillance system to create opportunities where collaborations can benefit both the system and its partners/collaborators,N/A,Availability of a joint database or the ease of data exchange favours collaboration.,Are opportunities created for collaborators to benefit from the system?,Relevance: Degree to which functions and activities in the surveillance system are relevant to its objectives and priorities as per occupational safety and health needs.,N/A,N/A,"Is there an up-to-date logic model/flowchart that links the system's functions and objectives?; 
Is each function/activity necessary to achieve objective/meet priorities?; 
Are performance indicators specified in the surveillance system? Example indicators include expected frequency of case reporting, data analysis and dissemination, or frequency of work meetings?
","Adherence: Degree to which the surveillance system follows guidelines, standards, protocols in its core and supporting functions.",N/A,N/A,"Is there auditing process to track how function protocols are followed?; 
Are methods established for data collection and processing to ensure high-quality data?
",Accessibility: Ability of the surveillance system to make data and information accessible to those who need it and when they need it.,N/A,N/A,"Is there an appropriate plan for dissemination to increase accessibility, including channels and formats? Is the system able to respond to internal and external data requests? Balance between confidentiality requirements and benefits of feeding data to researchers and the public may be a challenge.",Usability: Data and products produced by the surveillance system should be tailored to meet the needs of intended users.,N/A,N/A,"Are useful data interpretations provided to the audience beyond the data (e.g. statistics)?; Are products tailored to the need of the end users (e.g. reading level, knowledge level, language, industry/occupation, disability needs, culture and formats of communication)?; Can statistics be stratified by factors of interest, such as sex, age, ethnicity, socioeconomic status, geography, etc?; Does the system seek feedback on usability by stakeholders to guide improvement?","Accuracy: Data, statistics, and information produced in the surveillance datasets are accurate without errors.",N/A,N/A,"Are there proper quality control measures to identify and correct errors in place? Is there data corruption due to incorrect data merging or conversion?
","Clarity: Data, statistics, and information is coded/presented clearly without ambiguity. For example, variables are named appropriately. Data dictionary is clear and easy to follow.",N/A,N/A,"Are variables coded clearly and consistently? Does the surveillance system keep a clear and easy-to-follow, up-to-date data dictionary? Are data provided by the system in formats easy to understand and provided with accurate data dictionaries? Are educational materials and other materials for dissemination formatted clearly and precisely?",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"36. Yang L, Weston C, Cude C, Kincl L. Evaluating Oregon's occupational  public health surveil lance system based on the CDC updated guidelines.  Am J Ind Med. 2020;63(8):713-25. https://doi.org/10.1002/ajim.23139

Relevant references taken from Table 1 of the supplement materials.

Holder Y, Peden M, Krug E, et al (Eds). Injury  Surveillance Guidelines. Geneva, World Health  Organization; 2001.

World Health Organization (WHO). Communicable  Disease Surveillance and Response Systems: Guide to  Monitoring and Evaluating. Geneva: World Health  Organization (WHO); 2006.

World Health Organization (WHO). Assessing the  National Health Information System: An Assessment Tool  (v4.0). Geneva: World Health Organization; 2008.

Spreeuwers D, de Boer AG, Verbeek JH, van Dijk FJ.  Characteristics of national registries for occupational  diseases: international development and validation of an  audit tool (ODIT). BMC Health Serv Res. 2009;9:194.

UNAIDS/WHO working group on global HIV/AIDS and  STI surveillance. Evaluating a National Surveillance  System. Geneva: World Health Organization; 2013.

Centers for Disease Control and Prevention (CDC).  Evaluating an NCD-Related Surveillance System. Atlanta,  GA: Centers for Disease Control and Prevention; 2013.

Hoinville L. Animal Health Surveillance Terminology  Final Report from Pre-ICAHS Workshop. In: International  Conference on Animal Health Surveillance; Vol 17. 2013:1-27.

Calba C, Cameron A, Goutard F, et al. The EVA Tool: An  Integrated Approach for Evaluation of Animal Health  Surveillance Systems. RISKSUR Project; 2013.

European Center for Disease Prevention and Control  (ECDC). Data Quality Monitoring and Surveillance  System Evaluation - A Handbook of Methods and  Applications. Stockholm: ECDC: European Center for  Disease Prevention and Control; 2014.

Hoffman S, Dekraai M. Brief Evaluation Protocol for  Public Health Surveillance Systems. the Public Policy  Center, University of Nebraska; 2016.","System related attributes: Simplicity, flexibility, timeliness, stability, integration, effectiveness, cost-effectiveness Data quality related attributes: Validity, sensitivity, specificity, predictive value positive (PVP), representativeness, consistency, completeness, accuracy, clarity

Their framework followed a logic model and was broken down into components, attributes, and measures.

Components and attributes tend to  appear more often in existing evaluation guidelines with  relatively finite definitions and connotations, while measures, which represent the operationalization of attributes into measurable indicators, tend to be more flexible  and selected/developed at the evaluator's discretion.

Since different measures may be geared towards different  aspects of the attributes, the development of a standard  yet flexible guiding framework can further test the comprehensiveness and applicability of selected measures,  including any customization of evaluation metrics.

Further  research is needed to comprehensively understand interactions among OSH surveillance components and attributes and to investigate weights for elements based their  interactions.

OSH surveillance components, attributes and example measures identified in this study can serve as a  preliminary guide for evaluating OSH surveillance systems. The evaluators could choose components and  attributes that are appropriate to their systems and  use example measures to develop their own evaluation metrics. 

The research team is further developing a more detailed  evaluation framework based on the study findings to  provide standard yet flexible guidance on how to select  and prioritize these elements for evaluating different  types and stages of OSH surveillance systems.",
peyrePrinciplesEvaluationOne2022,13689,Peyre 2022,Principles for evaluation of one health surveillance: The EVA book,Principles for evaluation of one health surveillance: The EVA book,2022,Marisa Peyre,unknown,France,One Health surveillance system evaluation principles,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",d. One Health,N/A,h. The RISKSUR EVA tool (Survtool): A tool for the integrated evaluation of animal health surveillance systems (Peyre 2019); k. Other,Reviews multiples tools and frameworks but if largely centred around The RISKSUR EVA tool (Survtool): A tool for the integrated evaluation of animal health surveillance systems (Peyre 2019).,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,None provided,None provided,None provided,None provided,Early detection and early warning activities with the aim to reduce the impact of underlying animal diseases,Monitoring and verification of disease events in their natural environment to mitigate the specific levels of these events as they occur.,Evaluation and ranking of disease events to assign priority for plan of action according to the collected data.,Assessing the various mitigation strategies for effectiveness with the aim to implement these strategies assessing? With the required modifications and/or policy to the surveillance system.,N/A,N/A,Book provides the objectives for animal surveillance systems. Long-term success of a comprehensive surveillance system depends on inclusion of all the above objectives (those listed in Q13). See Fig. 1.9 for the list/diagram of the multiple objectives of animal health surveillance evaluations.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,Organizational,Risk-based criteria definition; Surveillance system organization,N/A,Functional,"Availability and sustainability; Acceptability and engagement; Simplicity; Flexibility, adaptability; Compatibility; Multiple hazard",N/A,Effectiveness,Coverage; Representativeness; False alarm rate (inverse of specificity); Bias = accuracy; Precision; Timeliness; Sensitivity (detection probability and detection fraction); PPV; NPV; Robustness,N/A,Value,Cost; Benefit,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The concept of economic cost includes (1) the losses due to disease (e.g., reduced milk yield, mortality) and (2) the resources required to detect the disease by a system (e.g., time, services, consumables for surveillance). In economic evaluation, the resources used to detect disease are compared with the disease losses with the aim to identify an optimal balance where a higher economic efficiency is achieved. Estimation of the total economic cost stemming from losses and expenditures is called a disease impact assessment. Estimation of the resource expenditures only is called a cost analysis.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Flexibility, adaptability: The ability to adapt to changing information needs or operating conditions with little additional time, personnel, or allocated funds. The extent to which the system can accommodate collection of information about new health hazards or additional/alternative types of data; changes in case definitions or technology; and variations in funding sources or reporting methods should be assessed.",N/A,"Stability, flexibility, and adaptability: Stability of the system in terms of its flexibility and adaptability related to unexpected health and/or political events should be assessed prior to and during the implementation of the program. Prior to implementation, the evaluators can provide a hypothetical scenario with a scoring sheet to determine the response and accommodation of the system to event such as emerging diseases or unexpected adverse health events. The scenario should be related to the specific aim of the surveillance system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The probability that no health event is present given that no health event is detected.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,The probability that health event is present given that health event is detected.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The extent to which the features of the population of interest are reflected by the population included in the surveillance activity; these features may include herd size, production type, age, sex, or geographical location or time of sampling (important for some systems, e.g., for vector-borne disease).",N/A,Representativeness of the system: Complete documentation of the sampling design and its validation should be available for review by evaluators to ensure that the inclusion of animals and their premises are representative of the reference population and the functional and organizational aspects of the system that may influence its representativeness should be assessed. The plan should include the appropriate statistical adjustments so that inference to the reference population can be done.,N/A,N/A,N/A,N/A,N/A,"Sensitivity (detection probability and detection fraction): Sensitivity of a surveillance system can be considered on three levels.
  Surveillance sensitivity (case detection probability) refers to the proportion of individual animals or herds in the population of interest that have the health-related condition of interest that the surveillance system is able to detect. Sensitivity could be measured in terms of detection fraction (number of cases detected divided by the coverage level) in a context of nonexhaustive coverage.
  Surveillance sensitivity (outbreak detection) refers to the probability that the surveillance system will detect a significant increase (outbreak) of disease. This may be an increase in the level of a disease that is not currently present in the population or the occurrence of any cases of disease that are not currently present.
  Surveillance sensitivity (presence) refers to the probability that disease will be detected if present at a certain level (prevalence) in the population.",N/A,"Overall sensitivity of system: Most systems require an overall high sensitivity particularly when their priority is for early detection of cases. Thus, the overall proportion of non-detected cases (i.e., the proportion of false negatives) of the system should be as low as possible. The evaluators should be able to estimate the overall sensitivity of the surveillance system by considering all the steps in the diagnosis of cases following either a conventional decision tree or the formula for estimating herd sensitivity with the adjustments for the various objectives in the final diagnosis and all the organizational and functional aspects of the system that are likely to influence its sensitivity.",N/A,"Refers to the surveillance system structure, ease of operation, and flow of data through the system.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Stability, flexibility, and adaptability: Stability of the system in terms of its flexibility and adaptability related to unexpected health and/or political events should be assessed prior to and during the implementation of the program. Prior to implementation, the evaluators can provide a hypothetical scenario with a scoring sheet to determine the response and accommodation of the system to event such as emerging diseases or unexpected adverse health events. The scenario should be related to the specific aim of the surveillance system.",N/A,N/A,N/A,N/A,N/A,"Timeliness can be defined in various ways:
  This is usually defined as the time between any two defined steps in a surveillance system; the time points chosen are likely to vary depending on the purpose of the surveillance activity.
  For planning purposes, timeliness can also be defined as whether surveillance detects changes in time for risk mitigation measures to reduce the likelihood of further spread.
The precise definition of timeliness chosen should be stated as part of the evaluation process. Some suggested definitions for the RISKSUR project are For early detection and demonstrating freedom
  Measured using time‚Time between introduction of infection and detection of outbreak or presence by surveillance system
  Measured using case numbers‚Number of animals/farms infected when outbreak or infection detected
For case detection to facilitate control
  Measured using time‚Time between infection of animal (or farm) and their detection
  Measured using case numbers‚Number of other animals/farms infected before case detected
For detecting a change in prevalence
  Measured using time‚Time between increase in prevalence and detection of increase
  Measured using case numbers‚Number of additional animals/farms infected when prevalence increase is identified",N/A,"Timeliness in measuring health events including the response time: The system should include a documented plan with various response options according to the expected outcomes from the system. The responses should be as much as possible comprehensive to include all the potential expected outcomes with scientific justifications and time periods. These responses are usually specific to the health events that are included in the system, but they are also linked to regulations and authorities. The evaluators should be able to review these responses with both scientific knowledge and regulations of the underlying the health events in the system. For instance, a surveillance stream for national brucellosis control program may include mitigation options when animals are serologically positive but with no history of clinical signs of the disease in contrast to a different mitigation option when the serologically positive animals are associated with farms that have a known history of events and/or clinical signs of the disease.",N/A,N/A,N/A,Usefulness of the system: The usefulness of the system will vary according the different stakeholders‚ needs but could be measured in terms of its impact and/or added value to reach its objectives and address those needs. The utility of the system could be measured by looking at its economic value and by considering all the organizational and functional aspects that will influence this aspect.,N/A,N/A,N/A,N/A,N/A,Risk-based criteria definition: Validity and relevance of the risk criteria selected and the approach/method used for their identification.,N/A,N/A,N/A,"Surveillance system organization: An assessment of the organizational structures and management of the surveillance system including the existence of clear, relevant objectives, the existence of steering and technical committees whose members have relevant expertise and clearly defined roles and responsibilities, stakeholder involvement, and the existence of effective processes for data management and dissemination of information.",N/A,N/A,N/A,Availability and sustainability: The ability to be operational when needed (availability) and the robustness and ability of system to be ongoing in the long term (sustainability).,N/A,N/A,N/A,"Acceptability and engagement: Willingness of persons and organizations to participate in the surveillance system, the degree to which each of these users is involved in the surveillance. Could also assess their beliefs about the benefits or adverse consequences of their participation in the system including the provision of compensation for the consequence of disease detection.",N/A,"Cultural sensitivity: The system and its activities should be acceptable to the community in which it is applied. A social and cultural checklist that is used for assessing the evaluation of adaptability can be used both during the planning of the system and the evaluation as well. The Australian Institute of Health and Welfare has highlighted several great issues to be considered in the evaluation to account for those cultural aspects, for example, during the avian influenza outbreak in Indonesia in 2005‚ 2006, leaders of mosques and villages were consulted on implementation of specific objectives of a surveillance system with the aim to enhance the reliability of the system [15]. Delabouglise et al. [4] have shown the importance of cultural and socioeconomic factors in the performances of avian influenza surveillance system performances in Thailand and Vietnam [4] (see Parts IV and VI).

Acceptability of a surveillance system should consider the importance of economic impact, trust, and cultural issues.",N/A,"Compatibility: Compatibility with and ability to integrate data from other sources and surveillance components, e.g., one health surveillance (part of data collection and data management).",N/A,N/A,N/A,Multiple hazard: Whether the system captures information about more than one hazard.,N/A,N/A,N/A,Coverage: The proportion of the population of interest (target population) that is included in the surveillance activity.,N/A,N/A,N/A,"False alarm rate (inverse of specificity): Proportion of negative events (e.g., non-outbreak periods) incorrectly classified as events (outbreaks). This is the inverse of the specificity but is more easily understood than specificity.",N/A,"Overall specificity of the final disease diagnosis: Similar to the above item of estimation of the overall sensitivity of the surveillance system, the overall specificity should be estimated using the same procedure. The overall proportion of false alarms (i.e., false positives) should be assessed with the aim to link it to the overall sensitivity. The implementers should be encouraged to have a reasonable proportion of false alarms; otherwise, the overall sensitivity will suffer and the resources will be poorly used.",N/A,Bias = accuracy: The extent to which a prevalence estimate produced by the surveillance system deviates from the true prevalence value. Bias is reduced as representativeness is increased.,N/A,N/A,N/A,"Precision: How closely defined a numerical estimate is. A precise estimate has a narrow confidence interval. Precision is influenced by prevalence, sample size, and surveillance approach used.",N/A,N/A,N/A,Robustness: The ability of the surveillance system to produce acceptable outcomes over a range of assumptions about uncertainty by maximizing the reliability of an adequate outcome. Robustness can be assessed using info-gap models.,N/A,N/A,N/A,"Benefit: The benefit of surveillance quantifies the monetary and nonmonetary positive direct and indirect consequences produced by the surveillance system and assesses whether users are satisfied that their requirements have been met. This includes financial savings, better use of resources, and any losses avoided due to the existence of the system and the information it provides. These avoided losses may include the avoidance of
  animal production losses
  human mortality and morbidity
  decrease in consumer confidence
  threatened livelihoods
  harmed ecosystems
  utility loss
Often, the benefit of surveillance estimated as losses avoided can only be realized by implementing an intervention. Hence, it is necessary to also assess the effect of the intervention and look at surveillance, intervention, and loss avoidance as a three-variable relationship. Further benefits of surveillance include maintained or increased trade, improved ability to react in case of an outbreak of disease, maintaining a structured network of professionals able to react appropriately against a (future) threat, maintaining a critical level of infrastructure for disease control, increased understanding about a disease, and improved ability to react in case of an outbreak of disease.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"A review of the evaluation methods of surveillance systems and current practices performed by Calba [20] highlighted the importance and need to develop an integrated evaluation approach including not only the epidemiological aspects of the evaluation but also the social and economic aspects (Part III, Chap. 6) [20]. This review showed that:
(i) Most of the evaluation frameworks and guidelines have been so far developed based on empirical situation, on an ad hoc basis, each providing different levels of detail for implementation and usually targeting only partial aspects of the surveillance system characteristics; specific evaluation of surveillance (as opposed to the evaluation of disease interventions) has been performed only on limited occasions and a variety of approaches and methods are used without a generally agreed protocol [21].
(ii) A set of generic guidelines were available (CDC, WHO) but covered also partial aspects each and were highly complementary.
(iii) The terminology used was not standardized, generating some confusion for the users.
(iv) There was no rationale in the use of evaluation attributes and often a lack of methods or information on the methods to assess them; more than 25 attributes have been described for the evaluation of animal health surveillance systems, making a complete evaluation f all attributes are used time-consuming and expensive. In some cases, no methods have been described for the measurement of these attributes and only a fraction of these evaluation attributes are included in the evaluation guidelines and applied in case studies ([21‚23], RISKSUR D1.2).
(v) Economic evaluation activities currently focus mainly on disease control pro- grams and economic impact of diseases in populations and only a small pro- portion of published studies focused on economic evaluation of surveillance.
(vi) There is no standardized gold standards or effectiveness targets for animal health surveillance; in animal health, there is no index of an effectiveness mea- sure available as it exists in the human health system evaluation process [e.g., disability-adjusted life-years (DALYs) and quality-adjusted life-years (QALYs)] [24].",N/A,N/A,Review Table 3.1 on page 46 to ensure that all listed evaluation guides have already been identified in this scoping review.,"Although the book is titles ""Principles for Evaluation of One Health Surveillance"", the book is largely centred/from the perspective of animal health surveillance. The book is also fairly duplicative of The RISKSUR EVA tool (Survtool): A tool for the integrated evaluation of animal health surveillance systems (Peyre 2019) and associated resources.

A lot of content from this book is also duplicative of other work published by thr CIRAD group that has already been included in this scoping review, therefore those elements were not extracted here.

Evaluation is the determination of the merit of a surveillance system/component, by confronting the results of the assessment with standards targets, criteria or a counterfactual system. This process shall be transparent, objective and evidence-based. The outcome of an evaluation is a judgement and/or recommendations placed in the overall surveillance context. An evaluation can be performed at any development stage of the surveillance system. Ideally, an evaluation is conducted in regular intervals in line with the policy cycle, by internal and/or external evaluators. One, several or all components in the surveillance system and any number of attributes and/or criteria can be considered, depending on the evaluation question and the context.

The merit of a surveillance system represents its ability to perform and address its objective (i.e., the system is able to detect sufficient number of cases to control the disease; the system is able to prove disease freedom status with sufficient robustness). The performance of a surveillance system could be assessed at different levels, looking at Technical effectiveness: Looking at specific aspects of the system such as sensitivity, timeliness (cf. Part III).
 Process effectiveness: Looking at the system organization (e.g., data management, acceptability, cf. Part III) and its impact on its technical efficacy.
 Efficiency: Looking at the added value of the system versus a situation without any surveillance or another type of surveillance. This could be done by assessing economic criteria (e.g., cost-effectiveness or cost‚ benefit) (cf. Part III) or looking at the system impact (cf. Part VI).

Animal health surveillance (AHS) is the ongoing systematic collection, analysis, and interpretation of data and the dissemination of information to those who need to know in order to take action [6]. This definition comprises important notions about sustainability and long-term action, communication to relevant stakeholders, and perspectives for action.

Surveillance systems are complex and need to consider the principles of epidemiology driven by epidemiological, economic, social (including political, cultural), and environmental factors in interactive ways. To allow for the design of cost-effective systems, the plan needs to consider practical and affordable assessment frameworks for timely evaluation of the benefits and costs of the system. Additionally, the assessment must be accepted by the local users and providers of the system.

The terms assessment and evaluation are interrelated. Assessment is the systematic process of documenting and using empirical data on the knowledge, skills, attitudes, and beliefs of the users and providers of the system. Evaluation, on the other hand, focuses on the output and performance of a system in relation to achieving its stated aim. Evaluation is a comprehensive or a quality review of the system. Evaluation processes normally involve some standards, criteria, measures of performance, or objectives that describe the value of the system outcome. Evaluation can identify criteria for success, lessons learned, things to achieve, ways to improve the work, and the means to move forward. Thus, evaluation is product-oriented specifically to respond to the question: Whats been achieved or impacted? The aim of evaluation is to help the decision makers and reviewers of the progress determine the success or effectiveness of a system. It provides a comprehensive description of a system including insight into its operation. The evaluation may be subjective or objective depending on the performance indices or the matrices that are used in the evaluation.

The main recommendations of the review were (i) the need for a structured evaluation process for animal surveillance systems that allows for flexibility in the selection of evaluation attributes and attribute assessment methods to make it con- text specific (this has been developed as part of the Survtool framework (see Chap. 4); (ii) the need to design a glossary of evaluation terms (to complement the existing ‚surveillance glossary‚ [10])‚such a glossary is available at the end of this book and here: https://www.fp7-risksur.eu/terminology/glossary; and (iii) to develop a set of internationally recognized and standardized effectiveness metrics for economic evaluation of animal health surveillance (see Sect. 3.3).

The first step in the evaluation process is to plan the evaluation and define the object and context of the evaluation. This involves engaging with the decision makers via a stakeholder mapping and workshop to identify, with them, the gaps and needs required to frame the evaluation plan. This will contribute to ensuring uptake of the recommendations by the people that implement and therefore impact the evaluation activity (see Part VI).

Determine the stakeholders: Data collection is the main activity of a surveillance system. Providers of the data are essential streams to ensure both reliability and accuracy of the data. The collected data should, as much as possible, serve the aim of the system including the users of the findings. Both providers and users are involved in making decisions, participating in program activities, or are affected by those activities. The program may have both primary and secondary stakeholders. The primary stakeholders are those who are directly involved in or directly affected by the programs outcomes. Secondary stakeholders are those who are less involved and less affected by the program but may have some either short- or long-term involvement or could influence the program outcomes, which could still be important to include (e.g., the Ministry of Health for surveillance programs not related to zoonotic diseases). The implementers of the program will be the starting point to determine a list of stakeholders.

When engaging with stakeholders, needs and resources for the evaluation must be identified. The following list of essential items can be used to determine the resources and needs including gaps in the system (Table 3.2):
 The official name/title of the system and its program. The program is usually the official public designation of the system, and the system is the technical procedure or the protocol to be administrated by the program.
  The list of the people and their credentials that are involved in the execution of the protocol. This list may include previous and currently involved people if there is a long history of the ongoing surveillance system.
  The aim(s) of the program in both technical and governance format (e.g., all the legislative documents that formalize the program or specify its framing).
  Outputs, or at least some recent results of the program, particularly communi-ques with users and providers of the program.
  The proposed protocol to meet the expected outcomes.

See Table 3.4.1.1 on page 49 for the list of essential elements of context to frame the evaluation process.

Stakeholder communication: The method of communication of a surveillance evaluation will depend on the different stakeholders, their familiarity with the details of the surveillance system, and their anticipated or intended actions. How, when, and why stakeholders will be communicated with is an appropriate activity to undertake during the planning stages of the evaluation‚so that the appropriate data is gathered at the outset and the appropriate method of distribution considered. The evaluation must be clear, action oriented, and easily distributed. It should also be geared to the particular stakeholder. Stakeholders who are directly involved in the surveillance, its design, and activities may require little need for interpretation of evaluation findings. Because they have significant knowledge of the system and underlying processes, details on the background, etc., will be less necessary. The evaluation report will be result oriented, allowing for interpretation. Evaluation reports intended for stakeholders who may not be as familiar with the surveillance system may require more information, including background, data collection methods, and analysis. Interpretation of the findings will need to be elaborated upon. Interpretive reports do not just provide the results of data collection, but put the results in context including, if appropriate, changes over time. When necessary, evaluation reports can also take the form of information sheets for lay audiences for those who may not have a high level of knowledge on the surveillance topic [1]. Depending on the surveillance system being evaluated, other means of communication of findings may be appropriate including peer reviewed journal articles, abstracts or posters given at professional meetings, lay press news items, books, book chapters, and web-based publications [1].

Economic evaluation of surveillance systems/components should be required as an aid to decision-making in surveillance to inform the allocation of scarce resources. It shows the consequences of alternatives and helps to identify which of these are to be preferred from an economic point of view.

Technical (or effectiveness) evaluation: Is about assessing the performances of a surveillance system (e.g., sensitivity, timeliness) to evaluate its capacity to reach its objective (e.g., disease control).

Process (or functional) evaluation: Is about assessing the conditions in which the system is performing and the elements of the system organisation and function that will affect its performances to make corrective actions to improve the system performances. Evaluation of the system process will allow to better understand the reasons behind limited performances. This will allow meaningful, adapted, and therefore more sustainable recommendations for effectiveness improvement, linked to the specific context of the system itself (see Part VI). Process evaluation will also allow to identify direct or indirect impact of a change in the surveillance activities, which will inform a cost-analysis (see Sect. 2.3).

Comprehensive or integrated evaluation: Is about integrating evaluation of system effectiveness and process to ensure all elements affecting the system performances are considered; this will improve sustainability and impact of the actions (e.g., assessing the system sensitivity and the acceptability of the actors of the system, which impacts the sensitivity level in order to promote changes to improve reporting and increase sensitivity) and could include economics (understanding decision-making in resource allocation by the system actors to improve its efficiency).

The single most important conclusion is that to proceed beyond cost-effectiveness analysis, which provides information about the implications for monetary expenditure on resources aimed at achieving a technical objective, two conditions must be fulfilled. First, the benefits accruing to surveillance must be defined in economic, not technical, terms and measured in equivalent monetary units; second, recognition that benefits do not accrue exclusively to surveillance but also to interventions made in the light of surveillance information. Thus any standard social cost benefit approach to evaluation, should it be contemplated, must incorporate both surveillance and intervention resources, and address the challenging task of expressing the benefits of mitigating disease effects in monetary units. See Sections 5 and 6 of the book for more details or formulas relating to economic evaluations of surveillance systems.",
ribeiroOvercomingChallengesDesigning2019,7631,Ribeiro 2019,Overcoming challenges for designing and implementing the One Health approach: a systematic review of the literature.,Overcoming challenges for designing and implementing the One Health approach: A systematic review of the literature,2019,Carolina dos S. Ribeiro,"ribeirocds@hotmail.com, carolina.dos.santos.ribeiro@rivm.nl",Netherlands,Systematic review of issues relating to the implementation of One Health approaches,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Despite the consensual OH definition that emerged in recent years, the level of collaboration required in the OH approach is not yet agreed upon. Most of the OH initiatives are based on interdisciplinary (ID) collaborations, implying the integration of different disciplines and cooperation between diverse experts, creating possibilities for knowledge co-creation. More recent initiatives, however, advocate for taking a whole society approach, which implies a transdisciplinary (TD) level of collaboration, with the inclusion of stakeholders beyond the academic domain. Some authors advocate that taking a TD approach can better address complex global health challenges, due to the consideration of local contexts and the inclusion of community stakeholders, which contribute to the adoption and sustainability of OH initiatives.

The inclusion of diverse stakeholders under the OH approach, however, can lead to conflicts due to their manifold interests and priorities. Examples of collaborative conflicts are power imbalances, conflicts of interest and coordination gaps that can occur at an ID level but especially at a cross-sectoral, participatory TD level. 

Policy support, access to funds, and trained professionals, able to understand and implement the OH approach, are basic conditions to facilitate the start and smooth execution of OH initiatives. Therefore, addressing condition challenges is considered an important first step towards the successful design and implementation of OH initiatives. Some authors also elaborate on the interdependency of these themes. While on the one hand, without policy support and funding, educational and training programs cannot be enhanced; on the other hand, educated and trained personnel are necessary for improving and increasing OH advocacy and message development for policy-makers and the public, and therefore enhancing policy support and funding.

In order to generate a paradigm shift for solving global health problems, a merely multidisciplinary team of experts is not sufficient. Stakeholders should work at an ID and TD level through the integration of academic and real world expertise for knowledge co-creation to address OH challenges in an innovative way.

See Tables 1-3 for challenges related to conducting OH initiatives. See Tables 4-6 for associated proposed solutions.

Challenges for acquiring conditions for starting OH initiatives:
-Policy and funding: Lack of resources and funding for OH initiatives; Lack of overall awareness about OH; Lack of commitment of policy-makers with OH
-Education and training: Lack of competence from OH practitioners; Insufficient and inefficient OH training programs; Lack of academic and institutional support for OH

Challenges for executing OH initiatives:
-Surveillance: Hard to perform OH surveillance; Problems with access to and quality of OH data and information; Lack of surveillance capacity; Fragmented surveillance systems
-Multi-actor collaborations: Difficulties to promote and sustain OH collaborations; Unequal power/representation of actors; Lack of facilitated collaborative process; Disciplinary and cultural silo thinking
-Multi-domain collaborations: Lack of facilitated collaborative process; Difficulties in promoting the engagement of multiple actors across domains; Difficulties to include context-specific factors in OH initiatives
-Multi-level collaborations: Institutional and academic fragmentation; Geographic and cultural fragmentation

Challenges for monitoring and evaluating OH initiatives:
-Monitoring & evaluation: Lack of OH evaluation studies and reporting of outcomes; Lack of guidelines and metrics for OH monitoring and evaluation",
meynardProposalFrameworkEvaluating2008,1912,Meynard 2008,Proposal of a framework for evaluating military surveillance systems for early detection of outbreaks on duty areas.,Proposal of a framework for evaluating military surveillance systems for early detection of outbreaks on duty areas,2008,Jean-Baptiste Meynard,jbmeynard@pasteur-cayenne.fr,French Guiana,Evaluation framework for military surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,d. Frameworks and Tools for Evaluating Health Surveillance Systems (Health Canada 2004); k. Other,"Additional methods were also used to evaluate British and French military syndromic surveillance systems. From this experience conducting these evaluations, a proposal for a framework for military surveillance systems was developed.",Initial Evaluation,"Parameters: 
Global coherence, pertinence, acceptability, feasibility, interoperability",Survey of peripheral actors; multinational exercise,N/A,"Production:
Evaluation program",Intermediate Evaluations,"Parameters:
Current dynamic, intermediary efficacy, timeliness, sensitivity, specificity, operationability, coherence, interoperability",KAP survey; simulation; technical audits; ergonomic studies; multinational exercise,N/A,"Production: 
Proposals for corrections of the system",Final Evaluations,"Parameters:
Timeliness, validity, sensibility, specificity, data quality, reliability, usefulness, portability, stability, costs, efficacy, efficiency, impact, interoperability",CDC framework; simulation; multinational exercise,N/A,"Production:
Conclusions and final recommendations",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The early detection of potential epidemics, evaluation of their potential impact on operational capacity and the provision of information to facilitate the medical response.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Civilians,N/A,N/A,"The actors of the evaluation were some actors of the system, university or institutional partners or came from external organisms. They were military and civilian. They were specialists in epidemiological surveillance or its evaluation.",Military personnel,N/A,N/A,"The actors of the evaluation were some actors of the system, university or institutional partners or came from external organisms. They were military and civilian. They were specialists in epidemiological surveillance or its evaluation.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Assessing the willingness of users to be involved in the operation of the system.,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,The link between the different components and the development stages.,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Financial assessment: dealing with installation and running costs and the calculation of cost-efficacy and cost-benefit ratios.,See Figure 3,N/A,N/A,Providing information about the completeness of recorded data.,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,The extent to which the initial objectives are achieved.,See Figure 3,N/A,N/A,The link between the resources implemented and the results.,See Figure 3,N/A,N/A,The extent to which the available means meet needs.,See Figure 3,N/A,N/A,"Measuring the system's ability to adapt to a change in environmental conditions, such as the emergence of a disease causing an epidemic (emergent disease) or significant changes in the population. Not listed as a attribute in the proposed framework but is used/listed elsewhere.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,CDC 2004,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Evaluating the possible use of the system in other circumstances or at a different location.,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,Unclear - potentially CDC 2004,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,Unclear - potentially CDC 2004. Not listed as a attribute in the proposed framework but is used/listed elsewhere.,N/A,N/A,N/A,Unclear - potentially CDC 2004,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,Unclear - potentially CDC 2004,See Figure 3,N/A,N/A,Reflecting the reaction of the system to a change in the variables recorded.,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,Assessing the time taken to detect a potential epidemic and to provide commanders with the relevant information.,See Figure 3,N/A,N/A,Measuring the contribution of the system to the early detection of an epidemic and its ability to provide information to facilitate efficient intervention.,See Figure 3,N/A,N/A,Assessing the system's ability to detect real outbreaks.,See Figure 3,N/A,N/A,Pertinence: the link between objectives and the preliminary assessment.,See Figure 3,N/A,N/A,Operationality: functioning conditions in the field.,See Figure 3,N/A,N/A,Impact: all effects other than the results.,See Figure 3,N/A,N/A,Current dynamic: no definition provided - unclear if this should be considered an attribute of the framework.,See Figure 3,N/A,N/A,Sensibility: no definition provided,See Figure 3,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"7. Jefferson H, Dupuy B, Chaudet H, Texier G, Green A, Barnish G, Boutin JP, Meynard JB: Evaluation of syndromic surveillance for the early detection of outbreaks among military personnel in a tropical country. J Public Health 2008 in press.

19. Lombardo JS, Burkom H, Pavlin J, Centers for Disease Control and Prevention (CDC): ESSENCE II and the framework for evaluating syndromic surveillance systems. MMWR Morb Mortal Wkly Rep 2004, 53 Suppl:159-165.","See Figure 3 for a schematic representation of the proposed framework for evaluating military surveillance systems.

This evaluation also showed that the CDC framework was not entirely appropriate for the evaluation of military systems because it did not assess all the factors specifically important in a military context (e.g. interoperability, security, population turnover, high mobility, etc.). The proposed evaluation assesses these factors through other specific methods (figure 4).

Our proposed new evaluation framework is summarised in figure 3. An initial evaluation is essential before or during the first deployment of a system or its prototype. At this point, coherence, pertinence, immediate acceptability, feasibility, and interoperability should be assessed. Those responsible for this evaluation must be deployed simultaneously with the system. The methods used in our evaluation framework are mostly surveys, with face-to-face interviews based on questionnaires and participation in a multinational exercise. This initial evaluation should be used to correct any problems identified and to create a formal evaluation program, with a detailed agenda.

Several intermediate evaluations should then be performed and any abnormalities should be rapidly corrected, to ensure continuous improvement. At this point, the dynamics of functioning, intermediate efficacy, operationality and coherence should be assessed. Various methods can be used for this assessment. A specific evaluation is required, focusing on those responsible for data recording, for which KAP surveys are ideal. Simulation exercises can be used to evaluate timeliness, sensitivity and specificity. Regular technical audits are required to check the functioning and back-up of the system and to ensure that the highest levels of security are maintained. Studies of ergonomics should focus on the enhancement of humancomputer interfaces to improve their acceptability. At this point, participation in a multinational exercise would also be useful, for the assessment of interoperability. Military or civilian experts may be responsible for these evaluations.

The final evaluation is essential. It should be carried out at the end of a prototype phase (as with 2SE FAG), at the end of deployment in a theatre of action or when a system ceases to be used (as with PRISM). At this point, efficacy, timeliness, validity, sensitivity, specificity, data quality, usefulness, portability, stability and reliability should be assessed. A study of costs, efficiency, impact and interoperability should also be carried out. The reference method for the final evaluation is the CDC framework, adapted to the specific characteristics of the military environment. If a deployment or mission is too long, this method could also be used after several months or years of functioning. A multinational exercise could again be useful at this stage. The final evaluation is expected to generate conclusions and recommendations allowing the generalisation of the system or allowing its use for another deployment, following adoption of the proposed corrections and improvements.

For military systems, maximum flexibility must be combined with the highest level of security. It must also be possible to adapt the capacity of the system to demand, maintaining some redundancy so that the system can be modified whilst still operational. Technical audits, based on quality assurance methods[9], were used to study functioning and security. The permanence of the system is a key requirement and evaluation.",
margeviciusAdvancingFrameworkEnable2014,1290,Margevicius 2014,Advancing a framework to enable characterization and evaluation of data streams useful for biosurveillance.,Advancing a Framework to Enable Characterization and Evaluation of Data Streams Useful for Biosurveillance,2014,Kristen J. Margevicius,kmargevicius@lanl.gov,United States of America,A framework for evaluating data streams to be used in a biosurveillance system,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Scope,"Process: The process of gathering, integrating, interpreting, and communicating

Knowledge: Essential information related to all-hazards threats or disease activity affecting human, animal, or plant health

Purpose: To achieve early detection and warning, contribute to overall situational awareness of the health aspects of an incident, and to enable better decision making at all levels",N/A,N/A,N/A,Biosurveillance Goals,See objectives listed in Q13.,N/A,N/A,N/A,Data Stream Characterization,"Data Stream Context (Disease, Population, Type):
-Infectious Disease(s) of Interest
-Human, Animal, Plant, Pathogen, Pest
-Diagnostic (Data that leads to identification of a pathogen, or confirmed diagnosis of disease)
-Syndromic (Health-related data that may precede or substitute for formal diagnosis)
-Environmental (Non-health related data associated with the social, natural, and/or built environment)

Data Stream Categories:
-Ambulance / EMT Records
-Clinic/Health Care Provider Records
-ED / Hospital Records
-Employment / School Records
Established Databases
-Financial Records
-Help Lines
-Internet Search Queries
-Laboratory Records
-News Aggregators
-Official Reports
-Police / Fire Department Records
-Personal Communication
-Prediction Markets
-Sales
-Social Media

Data Stream Details:
-Algorithms
-Collection Method
-Data Accuracy
-Data Processing Before Analysis
-Data Quality
-Data Reporting
-Data Security
-Data Structure
-Data Transmission
-Geospatial Characteristics
-Metadata Collected
-Population Characteristics
-Stakeholders",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"Early Warning of Health Threats: Surveillance that enables identification of potential threats including emerging and re-emerging diseases that may be undefined or unexpected.
","Early Detection of Health Events: Surveillance that enables identification of disease, outbreaks (either natural or intentional in origin), or events that have occurred, before they become significant.","Situational Awareness: Surveillance that monitors the location, magnitude, and spread of an outbreak or event once it has occurred.",Consequence Management: Surveillance that assesses impacts and informs response to an outbreak or an event.,"Baseline Awareness: Information that can inform and facilitate the achievement of the above surveillance goals and can be related to population demographics and health, the natural, social, and built environment, and underlying disease patterns and characteristics.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,See Figure 2 for further elaboration of surveillance system objectives.,N/A,N/A,N/A,Experts involved in animal biosurveillance activities,"An SME panel was established representing experts involved in animal, plant, and human infectious disease biosurveillance activities or development from U.S. federal government agencies, national laboratories, and academic institutions (Table 1). The panel consisted primarily of research-based individuals (.75%), although individuals working in operational biosurveillance were also included. Details of the development of this panel can be found in Deshpande et al[29]. 
",N/A,N/A,Experts involved in plant biosurveillance activities,"An SME panel was established representing experts involved in animal, plant, and human infectious disease biosurveillance activities or development from U.S. federal government agencies, national laboratories, and academic institutions (Table 1). The panel consisted primarily of research-based individuals (.75%), although individuals working in operational biosurveillance were also included. Details of the development of this panel can be found in Deshpande et al[29].",N/A,N/A,Experts involved in human infectious disease biosurveillance activities,"An SME panel was established representing experts involved in animal, plant, and human infectious disease biosurveillance activities or development from U.S. federal government agencies, national laboratories, and academic institutions (Table 1). The panel consisted primarily of research-based individuals (.75%), although individuals working in operational biosurveillance were also included. Details of the development of this panel can be found in Deshpande et al[29].",N/A,N/A,Experts from US federal government agencies,"An SME panel was established representing experts involved in animal, plant, and human infectious disease biosurveillance activities or development from U.S. federal government agencies, national laboratories, and academic institutions (Table 1). The panel consisted primarily of research-based individuals (.75%), although individuals working in operational biosurveillance were also included. Details of the development of this panel can be found in Deshpande et al[29].",N/A,N/A,Experts from national laboratories,"An SME panel was established representing experts involved in animal, plant, and human infectious disease biosurveillance activities or development from U.S. federal government agencies, national laboratories, and academic institutions (Table 1). The panel consisted primarily of research-based individuals (.75%), although individuals working in operational biosurveillance were also included. Details of the development of this panel can be found in Deshpande et al[29].",N/A,N/A,Experts from academic institutions,"An SME panel was established representing experts involved in animal, plant, and human infectious disease biosurveillance activities or development from U.S. federal government agencies, national laboratories, and academic institutions (Table 1). The panel consisted primarily of research-based individuals (.75%), although individuals working in operational biosurveillance were also included. Details of the development of this panel can be found in Deshpande et al[29].",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"4. Morse SS, Mazet JA, Woolhouse M, Parrish CR, Carroll D, et al. (2012) Prediction and prevention of the next pandemic zoonosis. The Lancet 380: 1956‚1965. doi:10.1016/S0140-6736(12)61684-5.

5. Bravata DM, McDonald KM, Smith WM, Rydzak C, Szeto H, et al. (2004) Systematic review: Surveillance systems for early detection of bioterrorismrelated diseases. Ann Intern Med 140: 910‚ 922

24. Malecki KC, Resnick B, Burke TA (2008) Effective Environmental Public Health Surveillance Programs: A Framework for Identifying and Evaluating Data Resources and Indicators. J Public Health Manag Pract 14: 543‚551. doi:10.1097/01.PHH.0000338366.74327.c9.

32. Buehler JW, Berkelman RL, Hartley DM, Peters CJ (2003) Syndromic surveillance and bioterrorism-related epidemics. Emerg Infect Dis 9: 11971204. doi:10.3201/eid0910.030231.","Within the context of biosurveillance systems, data streams are inextricably linked to the system in which they are deployed and are usually evaluated in the context of system capabilities (such as timeliness and sensitivity)[23,27,28]. As part of a larger project to provide a systematic evaluation of data streams for integrated global biosurveillance, we required concrete terminology to enable the cataloging, characterization, and classification of diverse data sources and systems that exist or are being developed for use in infectious disease biosurveillance.

Evaluation of data streams as opposed to evaluation of surveillance systems requires a characteristic set of attributes and metrics that are related to, but are not the same as, system attributes and metrics. Because biosurveillance systems can include one or many types of data streams, a data stream-centric framework can also be used in biosurveillance system evaluation and discourse if the framework is based on cogent classification schemes and definitions.

An SME panel was established representing experts involved in animal, plant, and human infectious disease biosurveillance activities or development from U.S. federal government agencies, national laboratories, and academic institutions (Table 1). The panel consisted primarily of research-based individuals (.75%), although individuals working in operational biosurveillance were also included. Details of the development of this panel can be found in Deshpande et al[29]. 

Sixteen data stream categories emerged from the iterative development process (Table 6). Table 6 provides definitions and examples of these categories and examples of how the data stream categories can be sub-categorized as needed such as clinic/health care provider records being subcategorized into physician provided or veterinary provided records. Of significance is the fact that we were able to bin any data stream into one of the 16 major categories, and are continually refining the sub-categories to enable comprehensive characterization. This table also illustrates how commonly referenced data streams could be binned into the 16 broad categories.

Finally, the choice and effectiveness of types of data streams should be informed by the specific goal(s) of the biosurveillance system, and by the diseases being monitored. These categories complete the framework for understanding data stream relevance that is shown in Figure 3.",
hitzigerSystemThinkingCitizen2021,259,Hitziger 2021,System Thinking and Citizen Participation Is Still Missing in One Health Initiatives - Lessons From Fifteen Evaluations.,System Thinking and Citizen Participation Is Still Missing in One Health Initiatives ‚ Lessons From Fifteen Evaluations,2021,Simon R. Ruegg,srueegg@vetclinics.uzh.ch,Switzerland,Review of One Health evaluation approaches,"c. Provides domains, themes, and/or criteria or recommendations for evaluating public health and/or environmental surveillance systems",d. One Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,none provided,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"The NEOH tool assesses the One Health-ness of initiatives with a catalogue of 80 semi-quantitative questions about knowledge integration. The second tool was developed in collaboration with experts from transdisciplinary research, sustainability sciences and international development research: Evaluating knOwLedge Integration Capacity in multi-stakeholder governance (EVOLvINC). 

The tools provide two different perspectives using similar data: while the NEOH tool compares operational aspects (working, thinking, planning) and infrastructural aspects (learning, sharing, organisation) in a OH ratio, EVOLvINC links the aspects to the project life cycle. Thus, the NEOH representation facilitates reflection about investments in the system operations or infrastructure, and the EVOLvINC too conveys the contribution of these aspects to the project life cycle and the capacity to evolve.

It illustrates that sharing and learning are the least developed aspects, both linked to the evaluation stage of the policy or project life cycle. The strongest scores were achieved for the thinking and organisation aspects.

The most positively evaluated criteria of the formulation phase were leverage potential (B, F), competences and methods,(E, F) and resource allocation (C, F).

The weakest criterion was the consideration of system characteristics (C‚E). For example, initiative E was identified to be working at the level of population patterns of zoonoses in Kenya rather than at the level of transmission structures, and activities during project formulation did not explicitly consider time delays, feedback loops, and causal interactions between different processes.

The most positively evaluated criteria for the implementation phase were internal team structure (A, B, D, E, F), power distribution (B, E, F, G), and conflict resolution (A, D, E) processes.

The poorest scores were achieved for external actor and stakeholder network (C, D) and bridging knowledge (C, G). 

The strongest evaluation scores for the evaluation phase were achieved for the sharing of methods and results (C, E, G) and the direct learning environment (A, F). 

All initiatives appreciated the evaluation process, theoretical approach, and questionnaires. Each initiative experienced the evaluation as a trigger for important reflections that they intend to apply in the future. The lessons learnt were derived from all phases of the evaluation process, and the conceptual background. Insights that were singled out as particularly relevant or thought-provoking included each of the six aspects, and the criteria inclusive design process, identification and engagement of sectors, actors and stakeholders, reflectivityinternal team structure, external stakeholder network, power distribution, leadership, and conflict resolution. Several initiatives realised the importance of additional systemic and environmental factors of relevance to their OH focus.

Knowledge integration seems to be emphasised by most OH initiatives primarily during the implementation phase, but there are opportunities to enhance participation and knowledge integration in all three phases of the project life cycle. In the formulation phase, a strong baseline was provided through the leverage potential and a diversity of competencies. This was endorsed by the attention given to power distribution and conflict resolution during implementation, and the willingness to share data. The main challenges in adopting a systems perspective were rooted in a lack of consideration of systemic characteristics. This is amplified by the lack of external stakeholder engagement, the poor bridging of knowledge in the implementation phase, and the limited attention given to an initiative or policy as a learning organisation with evolutionary features.

A final note should be made regarding the timing of an evaluation within an initiatives life cycle. Both tools are easily adapted to prospective, formative or retrospective evaluations with only minor rephrasing. Fonseca et al. (29) recommend prospective and repeated formative evaluations at early stages of the initiative, since they allow for anticipation of subsequent aspects and enhancement of knowledge integration capacity in the future. 

In the present study, prospective evaluation of the learning aspect was found challenging (G, I) since many learning opportunities develop spontaneously during implementation stages, and many questions relate to actual lessons learnt, rather than mere opportunities to learn. At the other end of the cycle, retrospective evaluations may be limited by data availability if collaborators are hard to contact (K), and because process-oriented information is usually scarce in academic or grey literature. To redress this gap, we believe that such data should be required in the Checklist for One Health Epidemiological Reporting of Evidence (COHERE) guidelines (10).",N/A,N/A,"13. Hitziger M, Aragrande M, Berezowski JA, Canali M, Del Rio Vilas V, Hoffmann S, et al. EVOLvINC: EValuating knOwLedge INtegration Capacity in multistakeholder governance. Ecol Soc. (2019) 24:art36. doi: 10.5751/ES-10935-240236

Network for Evaluation of One Health (NEOH) COST Action TD1404","The paper is primarily a comparision of the EVOLvINC and NEOH evaluation frameworks - to pull each framework to include in scoping review.

A key element of the OH approach is the integration of knowledge across sectors, disciplines and stakeholders.

Reporting knowledge integration processes should be included in the COHERE guidelines (10).",
ngetichDevelopmentValidationFramework2021,223,Ng'etich 2021,Development and validation of a framework to improve neglected tropical diseases surveillance and response at sub-national levels in Kenya.,Development and validation of a framework to improve neglected tropical diseases surveillance and response at sub-national levels in Kenya,2021,Arthur K. S. Ng‚ etich,arthursaitabau@yahoo.com,South Africa,Development of an evaluation framework for PC-NTD surveillance systems,"a. Provides guidance or a descriptive framework (i.e., outlines specific standards, principles, criteria, characteristics, or properties) for evaluating public health, environmental, or One Health surveillance systems",a. Public Health,N/A,m. Not applicable (i.e. a formal evaluation was not conducted),N/A,Inputs & Processes,N/A,N/A,N/A,"Used a logic framework to map the literature organize surveillance themes, attributes, and criteria into a matrix (see Table 1.) Final validated framework is shown in Fig 5.","Intended Results (Outputs, Outcomes & Impact)",N/A,N/A,N/A,"Used a logic framework to map the literature organize surveillance themes, attributes, and criteria into a matrix (see Table 1.) Final validated framework is shown in Fig 5.",N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Identified outcome themes that could be used as objecitves: early detection and effective response action; improved data accuracy and quality; efficient surveillance data transmission.,N/A,N/A,N/A,Directors of health,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,Disease surveillance coordinators,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,Epidemiologists,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,Health information and records officers,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,NTD coordinators,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,Public health officers,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,Other key sub-national health stakeholders,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,Stakeholders from the national disease surveillance unit,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,N/A,N/A,Stakeholders from the national NTD programme in Kenya,Stakeholders constituted individuals that regularly utilise information generated by the surveillance system to take appropriate actions or make decisions influencing implementation of interventions and policy-making processes.,none provided,Core Functions,"Case confirmation; reporting; data analysis; feedback
",N/A,Support Functions,Supervision; training; resources,N/A,Surveillance Attributes,Simplicity; acceptability; stability; flexibility; usefulness; data quality and accuracy; timeliness and completeness,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Willingness of persons to be involved in activities within the surveillance system.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Expected essential data requirements compared to actual reporting.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Accuracy of data collected within the surveillance system.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,,Ease of surveillance system to adapt to change of information needs and operating conditions with minimal additional resources.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Ease of operation of the surveillance system.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,,N/A,N/A,N/A,Stability of surveillance system to be available and reliable when required.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,,N/A,N/A,N/A,N/A,N/A,N/A,N/A,Surveillance system contribution to control and prevention of adverse health-related conditions.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,,N/A,N/A,N/A,Case confirmation: Improved specimen handling; Strengthened laboratory support. (Note: described as a theme of surveillance functions).,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Reporting: Improved reporting quality; Adequate reporting forms provision. (Note: described as a theme of surveillance functions).,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Data analysis: Increased surveillance performance monitoring; Improved data accuracy. (Note: described as a theme of surveillance functions).,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Feedback: Improved health workers' attitudes; Enhanced feedback from higher to lower levels. (Note: described as a theme of surveillance functions).,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Supervision: Strengthened implementation of surveillance systems; Utilisation of up-to-date information; Identification of correct reporting channels. (Note: described as a theme of surveillance functions).,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Training: Improved performance of the surveillance system; Improved surveillance data quality; Enhanced knowledge on surveillance systems. (Note: described as a theme of surveillance functions).,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,"Resources: Financial resources; Human resources; Technical, material and logistical resources; Equipment and infrastructure. (Note: described as a theme of surveillance functions).",N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Data quality and accuracy: Unclear - potentially a merging of CDC 2001 definitions,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Timeliness and completeness: Unclear - potentially a merging of CDC 2001 definitions,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,Surveillance data timeliness: How quick information is conveyed across levels of the surveillance system.,N/A,N/A,See S1 File. Data Collection Tools for list of stakeholder survey questions.,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,"A multi-phased approach was utilised to validate the proposed framework using: (i) consultative meetings with stakeholders at the sub-national and national levels and (ii) presentation of the draft framework in a conference meeting constituted of NTD researchers and policy experts. The aim of the consultative discussions was to review the draft framework components based on the expertise and experiences of healthcare stakeholders and decision makers. In addition, presentation of the draft framework in a scientific forum was intended to obtain further inputs to improve the framework components and assess scalability and adoptability of the framework especially at the sub-national level based on NTD research experts opinions. The validation process presented an opportunity to ascertain the accuracy of information underpinning the draft framework and identified key points for framework refinement. The process allowed participants to comment freely on the framework components in an open forum, which allowed for extensive discussions and drew out diverse stakeholder and expert opinions.

Encouraging involvement of the community levels in surveillance activities isdeemed to increase ownership and sustainability of the processes. This corresponds to efforts to empower communities living in NTD endemic regions through their participation in control interventions and formalizing the roles of community health workers",
