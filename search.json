[
  {
    "objectID": "figures.html#table1",
    "href": "figures.html#table1",
    "title": "Figures",
    "section": "Table 1 — Study characteristics",
    "text": "Table 1 — Study characteristics\n\n\n\n\n\n\n\n\nTable 1. Study characteristics\n\n\nStudy ID\nStudy title\nCorresponding author country\nStudy design type\nSurveillance Type\nEvaluation Framework Used\n\n\n\n\nKlaucke 1988\nGuidelines for Evaluating Surveillance Systems\nnot reported\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nAenishaenslin 2021\nEvaluating the Integration of One Health in Surveillance Systems for Antimicrobial Use and Resistance: A Conceptual Framework\nCanada\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nAlbali 2023\nComparative Performance Evaluation of the Public Health Surveillance Systems in 6 Gulf Cooperation Countries: Cross-sectional Study\nSaudi Arabia\nFormal evaluation\nPublic Health\nCDC 2001; CDC 2004\n\n\nAmato 2023\nEvaluation of the pilot wastewater surveillance for SARS-CoV-2 in Norway, June 2022 - March 2023\nNorway\nFormal evaluation\nWastewater\nCDC 2001; ECDC 2014\n\n\nAnonymous 2001\nUpdated Guidelines for Evaluating Public Health Surveillance Systems\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nArinik 2023\nAn Evaluation Framework For Comparing Epidemic Intelligence Systems\nFrance\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nAuer 2001\nCanadian Aboriginal communities: a framework for injury surveillance\nCanada\nGuidance or a descriptive framework\nPublic Health\nNo framework(s) or guidance document(s) were discussed\n\n\nAuer 2011\nThe relevance of WHO injury surveillance guidelines for evaluation: learning from the Aboriginal Community-Centered Injury Surveillance System (ACCISS) and two institution-based systems\nSweden\nGuidance or a descriptive framework\nPublic Health\nOther\n\n\nAzofeifa 2018\nEvaluating Behavioral Health Surveillance Systems\nN/A\nGuidance or a descriptive framework\nPublic Health\nNo framework(s) or guidance document(s) were discussed\n\n\nBabaie 2015\nPerformance Assessment of Communicable Disease Surveillance in Disasters: A Systematic Review\nIran\nDomains, themes\nPublic Health\nNot applicable\n\n\nBaboMartins 2017\nEconomics of zoonoses surveillance in a One Health context: an assessment of Campylobacter surveillance in Switzerland\nUnited Kingdom\nFormal evaluation\nOne Health\nOther\n\n\nBaker 2006\nGlobal Public Health Surveillance under New International Health Regulations\nNew Zealand\nFormal evaluation\nPublic Health\nCDC 2001\n\n\nBennani 2021\nEvaluating Integrated Surveillance for Antimicrobial Use and Resistance in England: A Qualitative Study\nUnited Kingdom\nFormal evaluation\nOne Health\nOther\n\n\nBingle 2005\nAn Evaluation of the Ontario Rapid Risk Factor Surveillance System\nCanada\nGuidance or a descriptive framework\nPublic Health\nCDC 2001\n\n\nBordier 2019\nOne Health Surveillance: A Matrix to Evaluate Multisectoral Collaboration\nVietnam\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nBordier 2020\nCharacteristics of One Health surveillance systems: A systematic literature review\nVietnam\nDomains, themes\nOne Health\nNot applicable\n\n\nBordier 2022\nEvaluation of Collaboration in a Multisectoral Surveillance System: The ECoSur Tool\nVietnam\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nBravata 2004\nEvaluating Detection and Diagnostic Decision Support Systems for Bioterrorism Response\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nBuehler 2004\nFramework for Evaluating Public Health Surveillance Systems for Early Detection of Outbreaks: Recommendations from the CDC Working Group\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nBuehler 2008\nEvaluation of surveillance systems for early epidemic detection\nunknown\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nCalba 2015\nSurveillance systems evaluation: a systematic review of the existing approaches\nFrance\nDomains, themes\nOther\nNot applicable\n\n\nCalba 2015\nApplying participatory approaches in the evaluation of surveillance systems: A pilot study on African swine fever surveillance in Corsica\nBelgium\nFormal evaluation\nOther\nOASIS; Other\n\n\nCalba 2016\nThe Added-Value of Using Participatory Approaches to Assess the Acceptability of Surveillance Systems: The Case of Bovine Tuberculosis in Belgium\nFrance\nFormal evaluation\nOther\nOASIS; Other\n\n\nCameron 2020\nQuantification of the sensitivity of early detection surveillance\nFrance\nDomains, themes\nPublic Health\nNot applicable\n\n\nChoi 2008\nEnhancing global capacity in the surveillance, prevention, and control of chronic diseases: seven themes to consider and build upon\nCanada\nDomains, themes\nPublic Health\nNot applicable\n\n\nClara 2020\nDeveloping monitoring and evaluation tools for event-based surveillance: experience from Vietnam\nUnited States of America\nDomains, themes\nPublic Health\nNo framework(s) or guidance document(s) were discussed\n\n\nCollineau 2022\nEvaluation of the French surveillance system for epidemiological surveillance of antimicrobial resistance in the community and nursing homes\nFrance\nFormal evaluation\nOne Health\nOASIS\n\n\nCorley 2012\nAssessing the Continuum of Event-Based Biosurveillance Through an Operational Lens\nUnited States of America\nGuidance or a descriptive framework\nOther\nNot applicable\n\n\nCrawley 2021\nUsing Timeliness Metrics to Track Progress and Identify Gaps in Disease Surveillance\nUnited States of America\nDomains, themes\nPublic Health\nNot applicable\n\n\nCutts 1993\nSurveillance for the Expanded Programme on Immunization\nUnited Kingdom\nDomains, themes\nPublic Health\nNot applicable\n\n\nDeclich 1994\nPublic health surveillance: historical origins, methods and evaluation\nCanada\nDomains, themes\nPublic Health\nNot applicable\n\n\nDelRioVilas 2022\nHealth Surveillance Evaluation in the Policy Cycle\nFrance\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nDente 2018\nIntegrated surveillance and risk assessment for arbovirus infections: recommendations for enhancing One Health in the Mediterranean Region: MediLabSecure Strategic Document 2018\nnot reported\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nDrewe 2012\nEvaluation of animal and public health surveillance systems: a systematic review\nUnited Kingdom\nDomains, themes\nOther\nNot applicable\n\n\nDrewe 2015\nSERVAL: A New Framework for the Evaluation of Animal Health Surveillance\nUnited Kingdom\nGuidance or a descriptive framework\nOther\nNot applicable\n\n\nElAllaki 2013\nConceptual evaluation of population health surveillance programs: Method and example\nCanada\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nFord 2021\nAdequacy of Existing Surveillance Systems to Monitor Racism, Social Stigma and COVID Inequities: A Detailed Assessment and Recommendations\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nCDC 2001; Other\n\n\nGarcia-Vozmediano 2022\nA One Health Evaluation of the Surveillance Systems on Tick-Borne Diseases in the Netherlands, Spain and Italy\nItaly\nFormal evaluation\nOne Health\nOther\n\n\nGoutard 2022\nTHE USE OF PARTICIPATORY METHODS IN THE EVALUATION OF HEALTH SURVEILLANCE SYSTEMS\nFrance\nGuidance or a descriptive framework\nOther\nNot applicable\n\n\nGroseclose 2010\nEvaluating Public Health Surveillance\nnot reported\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nGroseclose 2013\nEvaluation of syndromic surveillance systems that use healthcare data\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nGroseclose 2017\nPublic Health Surveillance Systems: Recent Advances in Their Use and Evaluation\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nHall 2007\nSetting Standards and an Evaluation Framework for Human Immunodeficiency Virus/Acquired Immunodeficiency Syndrome Surveillance\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nHarper 2011\nImproving Aboriginal health data capture: evidence from a health registry evaluation\nCanada\nFormal evaluation\nPublic Health\nCDC 2001\n\n\nHaworth-Brockman 2021\nOne Health Evaluation of Antimicrobial Use and Resistance Surveillance: A Novel Tool for Evaluating Integrated, One Health Antimicrobial Resistance and Antimicrobial Use Surveillance Programs\nCanada\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nHendrikx 2011\nOASIS: an assessment tool of epidemiological surveillance systems in animal health and food safety\nFrance\nGuidance or a descriptive framework\nOther\nNot applicable\n\n\nHerida 2016\nEconomic Evaluations of Public Health Surveillance Systems: a Systematic Review\nFrance\nDomains, themes\nPublic Health\nNot applicable\n\n\nHoinville 2013\nProposed terms and concepts for describing and evaluating animal-health surveillance systems\nUnited Kingdom\nDomains, themes\nOther\nNot applicable\n\n\nInnes 2022\nEnhancing global health security in Thailand: Strengths and challenges of initiating a One Health approach to avian influenza surveillance\nUnited States of America\nFormal evaluation\nOne Health\nCDC 2001; Other\n\n\nJajosky 2004\nEvaluation of reporting timeliness of public health surveillance systems for infectious diseases\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNo framework(s) or guidance document(s) were discussed\n\n\nLucero-Obusan 2022\nPublic health surveillance in the U.S. Department of Veterans Affairs: evaluation of the Praedico surveillance system\nUnited States of America\nFormal evaluation\nPublic Health\nCDC 2001\n\n\nMader 2021\nOASIS evaluation of the French surveillance network for antimicrobial resistance in diseased animals (RESAPATH): success factors underpinning a well-performing voluntary system\nFrance\nFormal evaluation\nOne Health\nOASIS\n\n\nMarbus 2020\nExperience of establishing severe acute respiratory surveillance in the Netherlands: Evaluation and challenges\nNetherlands\nFormal evaluation\nPublic Health\nCDC 2001; ECDC 2014; Other\n\n\nMitchell 2009\nThe development of an evaluation framework for injury surveillance systems\nAustralia\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nMorbey 2021\nEvaluating multi-purpose syndromic surveillance systems - a complex problem\nUnited Kingdom\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nMuellner 2018\nSurF: an innovative framework in biosecurity and animal health surveillance evaluation\nNew Zealand\nGuidance or a descriptive framework\nOther\nNot applicable\n\n\nPaternoster 2017\nThe degree of One Health implementation in the west nile virus integrated surveillance in Northern Italy, 2016\nItaly\nFormal evaluation\nOne Health\nOther\n\n\nPavlin 2013\nSyndromic surveillance for infectious diseases\nUnited States of America\nDomains, themes\nPublic Health\nNot applicable\n\n\nPelican 2019\nSynergising tools for capacity assessment and One Health operationalisation\nUnited States of America\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nPeyre 2019\nThe RISKSUR EVA tool (Survtool): A tool for the integrated evaluation of animal health surveillance systems\nFrance\nGuidance or a descriptive framework\nOther\nNot applicable\n\n\nPeyre 2022\nSynthesis-evaluate to better inform: A way to strengthening health surveillance systems\nFrance\nOther\nOne Health\nNot applicable\n\n\nReintjes 2007\nBenchmarking national surveillance systems: a new tool for the comparison of communicable disease surveillance and control in Europe\nGermany\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nRomano 2022\nAn Evaluation of Syndromic Surveillance-Related Practices Among Selected State and Local Health Agencies\nUnited States of America\nDomains, themes\nPublic Health\nNo framework(s) or guidance document(s) were discussed\n\n\nRüegg 2022\nGuidance for evaluating integrated surveillance of antimicrobial use and resistance\nSwitzerland\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nSahal 2009\nCommunicable diseases surveillance lessons learned from developed and developing countries: Literature review\nDenmark\nDomains, themes\nPublic Health\nNot applicable\n\n\nSandberg 2021\nAssessment of Evaluation Tools for Integrated Surveillance of Antimicrobial Use and Resistance Based on Selected Case Studies\nDenmark\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nSosin 2003\nDraft Framework for Evaluating Syndromic Surveillance Systems\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nTegegne 2023\nOH-EpiCap: a semi-quantitative tool for the evaluation of One Health epidemiological surveillance capacities and capabilities\nFrance\nGuidance or a descriptive framework\nOne Health\nNot applicable\n\n\nThacker 1988\nA METHOD FOR EVALUATING SYSTEMS OF EPIDEMIOLOGICAL SURVEILLANCE\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nThacker 1988\nPUBLIC HEALTH SURVEILLANCE IN THE UNITED STATES\nUnited States of America\nDomains, themes\nPublic Health\nNot applicable\n\n\nVasconcelosGioia 2021\nInforming resilience building: FAO's Surveillance Evaluation Tool (SET) Biothreat Detection Module will help assess national capacities to detect agro-terrorism and agro-crime\nItaly\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nVelasova 2015\nEvaluation of the usefulness at national level of the dairy cattle health and production recording systems in Great Britain\nnot reported\nFormal evaluation\nOther\nSERVAL; Other\n\n\nWorldHealthOrganization 2004\nOverview of the WHO framework for monitoring and evaluating surveillance and response systems for communicable diseases\nnot reported\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nYang 2022\nUnderstanding occupational safety and health surveillance: expert consensus on components, attributes and example measures for an evaluation framework\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nPeyre 2022\nPrinciples for evaluation of one health surveillance: The EVA book\nFrance\nGuidance or a descriptive framework\nOne Health\nThe RISKSUR EVA tool (Survtool); Other\n\n\nRibeiro 2019\nOvercoming challenges for designing and implementing the One Health approach: A systematic review of the literature\nNetherlands\nDomains, themes\nOne Health\nNot applicable\n\n\nMeynard 2008\nProposal of a framework for evaluating military surveillance systems for early detection of outbreaks on duty areas\nFrench Guiana\nGuidance or a descriptive framework\nPublic Health\nHealth Canada 2004; Other\n\n\nMargevicius 2014\nAdvancing a Framework to Enable Characterization and Evaluation of Data Streams Useful for Biosurveillance\nUnited States of America\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\nHitziger 2021\nSystem Thinking and Citizen Participation Is Still Missing in One Health Initiatives ‚ Lessons From Fifteen Evaluations\nSwitzerland\nDomains, themes\nOne Health\nNot applicable\n\n\nNg'etich 2021\nDevelopment and validation of a framework to improve neglected tropical diseases surveillance and response at sub-national levels in Kenya\nSouth Africa\nGuidance or a descriptive framework\nPublic Health\nNot applicable\n\n\n\n\n\n\n\n\n↑ Back to top"
  },
  {
    "objectID": "figures.html#upset-plot",
    "href": "figures.html#upset-plot",
    "title": "Figures",
    "section": "Upset Plot",
    "text": "Upset Plot\n\n\n\n\n\n\n\n\n\n\n↑ Back to top"
  },
  {
    "objectID": "figures.html#framework-used",
    "href": "figures.html#framework-used",
    "title": "Figures",
    "section": "Framework used to evaluate surveillance systems",
    "text": "Framework used to evaluate surveillance systems\n\n\n\n\n\n\n\n\n\n\n↑ Back to top"
  },
  {
    "objectID": "figures.html#surv-system",
    "href": "figures.html#surv-system",
    "title": "Figures",
    "section": "Type of surveillance system",
    "text": "Type of surveillance system\n\n\n\n\n\n\n\n\n\n\n↑ Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHES EF",
    "section": "",
    "text": "This site contains: - Dictionary – the term dictionary and documentation. - Figures – Upset plot and bar graphs.\n\nOpen Dictionary → Open Figures →\n\n\n\n\n\nDictionary\nFigures"
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "PHES EF",
    "section": "",
    "text": "Dictionary\nFigures"
  },
  {
    "objectID": "dictionary_documentation.html",
    "href": "dictionary_documentation.html",
    "title": "dictionary documentation",
    "section": "",
    "text": "ID: N/A See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#validity-data",
    "href": "dictionary_documentation.html#validity-data",
    "title": "dictionary documentation",
    "section": "",
    "text": "ID: N/A See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#b",
    "href": "dictionary_documentation.html#b",
    "title": "dictionary documentation",
    "section": "b",
    "text": "b\nID: abilityToContinueTrackingAnEvent See also: N/A\nDefinition The ability of the surveillance system to continue tracking an event throughout the event life cycle.\nDescription An event-based biosurveillance may be quite successful in detecting or forecasting an outbreak of disease, but it may lose its sensitivity as the event progresses (e.g., due to a high background level of indicators following a media announcement).\nBackground This reported concept was only identified by Corley 2012 in the context of biosurveillance models and systems.\nSynonyms\n\nExact: stability (reliability)\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#acceptability",
    "href": "dictionary_documentation.html#acceptability",
    "title": "dictionary documentation",
    "section": "Acceptability",
    "text": "Acceptability\nID: acceptability See also: engagement; collaboration\nDefinition The willingness of persons and organizations to participate in the surveillance system.\nDescription Acceptability reflects stakeholders’ perceptions and attitudes toward the surveillance system, including their willingness to participate. It encompasses recognition of the system’s importance, satisfaction with processes, trust in data management, perceived reporting burden, and alignment with ethical and cultural expectations. High acceptability is supported by clear communication, demonstrated value, privacy protections, and responsiveness to user needs.\nBackground Acceptability was identified as a foundational concept in the evaluation of public health surveillance, being identified on 34 occassions. In our review, the concept was identified as early as 1988, to reflect \"the willingness of individuals and organizations to participate in the surveillance system\". Overall, definitions have remained largely congruent with the one introduced in 1988. However, the concept has evolved through the incorporation of new elements such as trust and engagement.\nSynonyms\n\nExact: N/A\nBroad: participation"
  },
  {
    "objectID": "dictionary_documentation.html#acceptability-and-engagement",
    "href": "dictionary_documentation.html#acceptability-and-engagement",
    "title": "dictionary documentation",
    "section": "Acceptability and engagement",
    "text": "Acceptability and engagement\nID: acceptabilityAndEngagement See also: acceptability; engagement; collaboration\nDefinition N/A\nDescription Acceptability and engagement reflect the willingness to participate in and the degree of involvement with a surveillance system. They are shaped by system design (e.g., simplicity, timeliness), perceived value (e.g., importance, relevance, trust), and social context (e.g., cultural fit, stigma, privacy concerns). High levels of acceptability and engagement improve data quality, sustainability, and stakeholder collaboration but may be limited by political will, resource constraints, and communication barriers.\nBackground Acceptability as a surveillance system attribute has evolved since its initial conceptualization. The original CDC 1988 definition focused on willingness of individuals and organizations to participate in surveillance activities. The 2001 CDC guidelines maintained this core concept while expanding factors that influence acceptability. Calba et al. (2015) broadened the concept to include not just willingness but \"the degree to which each of these users is involved in the surveillance.\" Contemporary understanding has further expanded to encompass community engagment, participation, and trust—reflecting a shift from traditional, top-down surveillance approaches to more collaborative models. This evolution acknowledges that modern surveillance systems must be acceptable to a wider range of stakeholders beyond traditional public health departments, including affected communities, healthcare providers, private sector entities, and various levels of government. The concept now implicitly recognizes cultural appropriateness, and ethical considerations as components of acceptability.\nSynonyms\n\nExact: N/A\nBroad: participation"
  },
  {
    "objectID": "dictionary_documentation.html#accessibility-data",
    "href": "dictionary_documentation.html#accessibility-data",
    "title": "dictionary documentation",
    "section": "Accessibility (data)",
    "text": "Accessibility (data)\nID: accessibilityData See also: data management and storage; interoperability\nDefinition The ease with which authorized users can retrieve surveillance data and metadata using standardized protocols.\nDescription [To incoporate FAIR in description]. Accessibility in public health surveillance refers to how readily and consistently surveillance outputs (such as alerts, reports, or predictive model results) and input data (such as raw surveillance data or supporting information) are available to end-users, decision-makers, and planners. This includes availability through standardized and sustainable protocols, user-friendly dissemination mechanisms, and manageable data formats. Accessible systems reduce technical, administrative, logistical, and practical barriers, enabling timely decision-making and effective public health responses.\nBackground FAIR data concepts, introduced by Yang et al. in 2022, have become increasingly prominent. Definitions of accessibility commonly include providing data “when and how users need them,” although these elements overlap with system availability and communication and dissemination. Accessibility involves both output accessibility (ease of disseminating surveillance results to users) and input accessibility (consistent availability and usability of source data). Effective accessibility also requires sufficient human and technological resources, clear authorization balancing openness with privacy and security, and robust infrastructure for reliable data flow.\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#accuracy",
    "href": "dictionary_documentation.html#accuracy",
    "title": "dictionary documentation",
    "section": "Accuracy",
    "text": "Accuracy\nID: accuracy See also: precision; bias\nDefinition The proportion of data entries that correctly reflect the true value of the data collected.\nDescription [Comparison to the reference standard, ISO,varying definitions]. Accuracy is influenced by several factors, including the sensitivity and specificity of case definitions, the clairty of surveillance forms (whether hardcopy or electronic), the technical competence and training of staff, and the care exercised in data management. It is positively correlated with several other data quality attributes/terms, including representativeness, precision, completeness, and consistency, and is negatively correlated with bias. System acceptability can influence how accurately data are captured and recorded.\nBackground\n\nAccuracy was identified as an independent concept on eight occassions, distinct from the definitions of \"data quality\" or \"data completeness and correctness\". However, this concept has been defined inconsistently across the literature, with terminology varying by discipline - often referred to as validity, accuracy, or data correctness. The definition of accuracy that we have adopted aligns with the DQO and ISO/IEC 25012 definition.\n\n\nThe definition aligns with established international standards, including ISO 8000-2:2020, which defines accuracy as the correctness of data relative to real-world conditions. It also corresponds to definitions in the Data Quality Ontology (DQO), which emphasizes accuracy as the correctness and precision with which data represent reality. Accuracy assessment often involves validation procedures, comparisons against reference standards, or independent verification processes.\n\nSynonyms\n\nExact: validity, data correctness, bias (Peyre 2019, 2022), comparability\nBroad: data quality?"
  },
  {
    "objectID": "dictionary_documentation.html#adaptability",
    "href": "dictionary_documentation.html#adaptability",
    "title": "dictionary documentation",
    "section": "Adaptability",
    "text": "Adaptability\nID: adaptability See also: N/A\nDefinition N/A\nDescription N/A\nBackground –\nSynonyms\n\nExact: Flexibility\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#adherence-suggest-change-to-standards-use-or-standards-adherence",
    "href": "dictionary_documentation.html#adherence-suggest-change-to-standards-use-or-standards-adherence",
    "title": "dictionary documentation",
    "section": "Adherence — suggest change to “Standards use” or “Standards adherence”",
    "text": "Adherence — suggest change to “Standards use” or “Standards adherence”\nID: adherence See also: compliance\nDefinition The degree to which a surveillance system follows and implements established guidelines, protocols, classification systems, and data exchange standards in its core and supporting functions.\nDescription Standardization encompasses adherence to recognized guidelines across multiple dimensions of surveillance systems, including methodological protocols, data structures, classification systems, and exchange formats. This attribute covers both technical standards (data formats, interoperability frameworks) and operational standards (case definitions, reporting procedures). Standards use is closely related to compliance, but differs in focus. While standards use focuses on internal consistency in following best practices and operational protocols, compliance is centred around relevant legislation, regulations and policies, including ethics and security. Beyond compliance, standards use is also tied to other data quality attributes/terms, and is positively correlated with consistency ans technical competence and training.\nBackground\n\nThe concept of adherence was identified six times in our scoping review. However, the overarching concept referred to here was only identified by Yang et al., (2022), with elements of this definition being referenced multiple times throughout the literature (e.g., standards use, transparency).\n\n\nHigh adherence is essential for the consistent functioning of the system, as it reduces errors, ensures uniformity, and facilitates the accurate tracking of health-related events or environmental changes. A system with high adherence is more likely to produce accurate and high-quality data, as following established protocols reduces errors and inconsistencies. It also enhances consistency by ensuring uniform application of procedures across time and by different personnel. Furthermore, training and supervision play a critical role in maintaining adherence, as they ensure that individuals are well-equipped to follow protocols correctly and consistently.\n\nSynonyms\n\nExact: N/A\nBroad: standards use"
  },
  {
    "objectID": "dictionary_documentation.html#availability-system",
    "href": "dictionary_documentation.html#availability-system",
    "title": "dictionary documentation",
    "section": "Availability (system)",
    "text": "Availability (system)\nID: availablity See also: Accessibility (data); N/A\nDefinition The ability to be operational when needed (Groseclose 2017; Peyre 2019, Peyre 2022; Muellner 2018; Hoinville 2013; Yang 2022; Albali 2023; Amato 2023; Anonymous 2001; Azofeifa 2018; Babaie 2015; Baker 2006; Buehler 2004, 2008; Calba 2015; Drewe 2012, 2015; Harper 2011; Innes 2022; Lucero-Obusan 2022; Marbus 2020; Meynard 2008; Ng’etich 2021; Sosin 2003; Bordier 2019; Velasova 2015).\nDescription Availability reflects a system’s readiness to reliably collect, process, and disseminate surveillance data when required. It encompasses the continuous functioning of essential components, including infrastructure, skilled personnel, and communication channels, ensuring timely public health responses.\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#benefit",
    "href": "dictionary_documentation.html#benefit",
    "title": "dictionary documentation",
    "section": "Benefit",
    "text": "Benefit\nID: benefit See also: costs; impact\nDefinition The direct and indirect advantages produced by the surveillance system.\nDescription [Carol’s + time horizon component]. The benefit term is influenced by several factors, including the scope of surveillance objectives, the effectiveness of data use in decision-making, and the capacity for early detection and response. It encompasses direct and indirect outcomes such as cost savings, improved public and animal health, enhanced trade, and prevention of losses in productivity, morbidity, and mortality. Benefits are positively correlated with terms such as timeliness, usefulness, and stability, and are shaped by stakeholder engagement and collaboration. The distribution of benefits across sectors also informs the overall value of the surveillance system.\nBackground Benefit was identified as an independent concept nine times in our scoping review, distinct from related concepts such as costs, impact, and efficiency. The concept was first introduced by Hoinville et al., in 2013 and was consistently included in animal health surveillance system evaluation frameworks thereafter. The definition has remained largely unchanged with the execption of Calba et al., 2015 introducing the idea of assessing whether users are satisfied that their requirements have been met in their definition. Their paper also focused solely on non-monetary benefits. However, despite the alignment of this definition across animal health surveillance evaluation frameworks, benefit was not identified as a standalone concept in the context of public health surveillance.\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#bias-ascertainment-performance",
    "href": "dictionary_documentation.html#bias-ascertainment-performance",
    "title": "dictionary documentation",
    "section": "Bias (ascertainment performance)",
    "text": "Bias (ascertainment performance)\nID: biasAscertainmentPerformance See also: accuracy; precision; sensitivity; specificity; representativeness; data quality; predictive value positive; false detection rate\nDefinition The extent to which a prevalence estimate produced by the surveillance system deviates from the true prevalence value.\nDescription Case detection bias occurs when systematic measurement errors cause surveillance data to systematically differ from the true occurrence of the health event in the target population. Bias can arise from multiple sources including diagnostic test characteristics, reporting practices, population coverage, sampling methods, case definitions, and temporal factors. The magnitude and impact of bias depends on surveillance objectives. For general population surveillance, bias can distort prevalence estimates and trend analysis, leading to incorrect public health conclusions.\nBackground\n\nBias was identified as a reported concept six times in our scoping review. The concept was first introduced by Hoinville et al., in 2013 and was consistently included in animal health surveillance system evaluation frameworks thereafter. The definition has remained largely unchanged with the execption of Peyre 2019 & 2022 incorporating the idea of \"bias=accuracy\" in their definition. Despite its frequent application in evaluating animal health surveillance systems, the term \"bias\" was not identified in the context of public health surveillance.\n\n\nEvaluating bias in surveillance systems is essential for accurately monitoring endemic diseases.\n\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#case-definition",
    "href": "dictionary_documentation.html#case-definition",
    "title": "dictionary documentation",
    "section": "Case definition",
    "text": "Case definition\nID: caseDefinition See also: bias (case detection)\nDefinition The standard set of criteria used to identify and classify cases or events for consistent reporting and analyses within a surveillance system.\nDescription The case definition affects surveillance system performance by determining how accurately and consistently cases are identified and classified. A well-designed case definition supports accurate and consistent detection, improving the quality of the data collected. It directly influences terms like sensitivity, specificity, representativeness, and coverage, and plays a role in determining the system’s cost, acceptability, and flexibility. Clear defined definition may also improve consistency across sites and over time.\nBackground The concept of case definition was identifed five times throughout our scoping review.\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#collaboration",
    "href": "dictionary_documentation.html#collaboration",
    "title": "dictionary documentation",
    "section": "Collaboration",
    "text": "Collaboration\nID: collaboration See also: acceptability and engagement; governance\nDefinition The active engagement and coordination among diverse partners and end-users to facilitate exchange of data, information, and knowledge, sharing of capacities, and collaborative implementation of surveillance activities.\nDescription Collaboration in surveillance systems relies on clear roles, strong legal frameworks, and established inter-sectoral mechanisms. It occurs in four main areas: governance across sectors (health, animal, environment), decision-making at all levels (local to international), interdisciplinary efforts (biosciences, social sciences, engineering), and public-private partnerships (e.g., veterinary companies in antimicrobial resistance). Effective data exchange and a shared databases enhance collaboration. [still working on this one somewhat since multiple terms are being folded into this].\nBackground TBD\nSynonyms\n\nExact: partnerships\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#communication-and-dissemination",
    "href": "dictionary_documentation.html#communication-and-dissemination",
    "title": "dictionary documentation",
    "section": "Communication and dissemination",
    "text": "Communication and dissemination\nID: communicationAndDissemination See also: collaboration\nDefinition The ability of the system to deliver information and data in a clear and distinct manner to relevant stakeholders inside and outside of the surveillance system.\nDescription Effective communication and dissemination in surveillance systems involve sharing clear, relevant, and timely information with all stakeholders, actors, and end-users (both internally and externally). Surveillance data outputs must meet the needs of diverse users, including data providers, analysts, decision-makers, and the public. Outputs should be accessible, frequent, and based on up-to-date, high-quality data with clear explanations of limitations and biases. Communication and disseminationis is also closely linked to acceptability, timeliness, impact, and collaboration.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#compatability",
    "href": "dictionary_documentation.html#compatability",
    "title": "dictionary documentation",
    "section": "Compatability",
    "text": "Compatability\nID: compatibility See also: Coherence; interoperability\nDefinition Compatibility with and ability to integrate data from other sources and surveillance components, e.g., one health surveillance (part of data collection and data management) (Peyre 2019, Peyre 2022).\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: Integration"
  },
  {
    "objectID": "dictionary_documentation.html#compliance",
    "href": "dictionary_documentation.html#compliance",
    "title": "dictionary documentation",
    "section": "Compliance",
    "text": "Compliance\nID: compliance See also: adherence\nDefinition The degree to which the surveillance system complies with all relevant legislation, regulations and policies, including ethics and confidentiality requirements.\nDescription Compliance refers to meeting required legal or regulatory requirements, often with external oversight. It is closely related to adherence, but differs in focus. While compliance focuses on relevant legislation, regulations and policies, including ethics and security, adherence is centred around internal consistency in following best practices and operational protocols. Beyond adherence, compliance is also tied to other data quality attributes/terms, and is positively correlated with consistency ans technical competence and training.\nBackground The concept of compliance was identified twice in our scoping review. However, the overarching concept referred to here was only identified by Yang et al., (2022), with components of this definition being referenced multiple times throughout the literature (e.g., legislative support, security, ethical considerations).\nSynonyms\n\nExact: N/A\nBroad: legislative support"
  },
  {
    "objectID": "dictionary_documentation.html#consistency",
    "href": "dictionary_documentation.html#consistency",
    "title": "dictionary documentation",
    "section": "Consistency",
    "text": "Consistency\nID: consistency See also: N/A\nDefinition Data have the same meanings (e.g. case definition, diagnosis standards) to allow for consistent interpretation. This includes internal consistency (within a dataset) and external consistency (across different data sources), as well as consistency over time.\nDescription Consistency refers to the uniformity and reliability of data across time and sources within the surveillance system. It ensures that data remain unchanged when replicated, transferred, or integrated between partners. Consistent data collection methods, coding systems, case definitions, and documentation of transformations are essential for comparability and trend analysis.\nBackground Consistency was identified five times in our scoping review.\nSynonyms\n\nExact: N/A\nBroad: repeatability, precision"
  },
  {
    "objectID": "dictionary_documentation.html#cost-benefit",
    "href": "dictionary_documentation.html#cost-benefit",
    "title": "dictionary documentation",
    "section": "Cost-benefit",
    "text": "Cost-benefit\nID: costBenefit See also: cost minimization; costs; cost-effectiveness; cost-utility; benefit\nDefinition An analysis where all costs and outcomes are expressed in monetary terms, calculating the net gain or loss by measuring both the costs of an intervention and the monetary value of its outcomes.\nDescription Cost-benefit analysis quantifies both the costs and outcomes of a surveillance system in monetary terms to assess its net economic value. This allows comparison of investments against financial benefits such as reduced disease burden, healthcare savings, or productivity gains. It supports decision-making by highlighting the economic return of surveillance activities relative to their expense. Accurate valuation of outcomes and comprehensive cost accounting—including direct, indirect, fixed, and variable costs—are essential. This term complements cost-effectiveness and cost-minimization analyses by providing a broader economic perspective on surveillance system value.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#cost-effectiveness",
    "href": "dictionary_documentation.html#cost-effectiveness",
    "title": "dictionary documentation",
    "section": "Cost-effectiveness",
    "text": "Cost-effectiveness\nID: costEffectiveness See also: cost minimization; cost-benefit; costs; cost-utility; benefit\nDefinition Relationship between the expected outcomes and the costs of surveillance to achieve these outcomes. Surveillance system costs include direct costs (personnel and material resources), indirect costs (resulting from preparedness and response to surveillance findings), and prevention benefits or costs from a societal perspective (e.g., effects of the information generated on decision making and population health). Refers to the relative expenditures (costs) and outcomes (effects) of different surveillance strategies, determining whether the improved health outcomes or surveillance capabilities justify the associated costs to help inform efficient resource allocation decisions (kirsh 2008 adpated for surveillance).\nDescription The costs of obtaining surveillance information needs to be balanced against the benefits derived. Assessment of surveillance resources typically focuses on direct costs. Because of the complexity of surveillance and response processes, it is usually difficult to define indirect costs. For some infectious disease surveillance systems, investigators have modeled the expected future costs of strategies for continued vaccination, surveillance, and other public health activities. Efforts to improve sensitivity, positive predictive value, representativeness, timeliness, and stability can increase the cost of a surveillance system.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#cost-minimization",
    "href": "dictionary_documentation.html#cost-minimization",
    "title": "dictionary documentation",
    "section": "Cost minimization",
    "text": "Cost minimization\nID: costMinimization See also: costs; cost-benefit; cost-effectiveness; cost-utility; benefit\nDefinition The comparison of costs between alternatives with identical outcomes, used to determine the most economical option when no additional benefits are present (often applied to demonstrate the dominance of one strategy over another).\nDescription Cost-minimization compares the expenses of alternative surveillance strategies that achieve identical outcomes to identify the most economical option. It helps prioritize resource allocation by demonstrating which approach delivers the same public health impact at the lowest cost. This term is closely linked to cost-effectiveness and efficiency, but unlike those, it assumes equivalent benefits across options. Accurate cost data—including fixed and variable costs—are essential. Considering operational, personnel, and infrastructure expenses ensures a comprehensive evaluation, supporting sustainable and affordable surveillance system design without compromising performance.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#cost-utility",
    "href": "dictionary_documentation.html#cost-utility",
    "title": "dictionary documentation",
    "section": "Cost-utility",
    "text": "Cost-utility\nID: costUtility See also: cost minimization; cost-benefit; cost-effectiveness; costs; benefit\nDefinition An evaluation that compares the system’s interventions or strategies by measuring outcomes in terms of utility gained, using a ratio scale to assess the value of different health states or surveillance outcomes, allowing for comparison across various surveillance approaches and their impact on public health.\nDescription Cost-utility analysis compares surveillance strategies by measuring outcomes in terms of utility, often using quality-adjusted life years (QALYs) or disability-adjusted life years (DALYs). This allows valuation of health benefits considering both quantity and quality of life gained from interventions. It facilitates comparison across diverse surveillance approaches with different health impacts, integrating effectiveness and economic costs into a single metric. Accurate utility measurement requires reliable health state valuation and comprehensive cost data. This term complements cost-benefit and cost-effectiveness analyses by focusing on health-related quality of life, supporting informed resource allocation in public health surveillance.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#costs",
    "href": "dictionary_documentation.html#costs",
    "title": "dictionary documentation",
    "section": "Costs",
    "text": "Costs\nID: costs See also: cost minimization; cost-benefit; cost-effectiveness; cost-utility; benefit\nDefinition All expenses associated with the surveillance system, including direct costs (e.g., equipment, personnel) and indirect costs (e.g., training, data management infrastructure).\nDescription Cost is a key consideration in evaluating surveillance systems, reflecting their value and efficiency. Costs are both direct (e.g., personnel, data collection, laboratory services, infrastructure) and indirect (e.g., follow-up efforts for false alarms, impact on agency credibility). New or improved systems incur start-up (e.g., software, equipment) and ongoing operational costs (e.g., staff, maintenance). Economic analyses should balance these costs with the public health benefits, such as early outbreak detection and disease prevention, to assess overall value. Direct and indirect costs are usually collected and reported separately.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#coverage",
    "href": "dictionary_documentation.html#coverage",
    "title": "dictionary documentation",
    "section": "Coverage",
    "text": "Coverage\nID: coverage See also: representativeness\nDefinition Proportion of the population of interest (target population) or proportion of areas of interest (e.g. specific habitats or high- risk sites) that is included in the surveillance activity.\nDescription Coverage indicates the extent to which the target population or geographic areas are included in surveillance. High coverage enhances representativeness, sensitivity, and early detection—especially for emerging threats. It is related to sampling strategy, reporting completeness, and access to high-risk populations. Mathematically, coverage is the proportion the same represents divided by the total target population size.\nBackground Coverage was identified as a reported concept six times in our scoping review. The concept was first introduced by Hoinville et al., in 2013 and has since been consistently included in animal health surveillance system evaluation frameworks. The definition has remained highly consistent within animal health surveillance, aligning with the concept of \"population coverage\" in public health surveillance.\nSynonyms\n\nExact: N/A\nBroad: representativeness?"
  },
  {
    "objectID": "dictionary_documentation.html#credibility-collaboration",
    "href": "dictionary_documentation.html#credibility-collaboration",
    "title": "dictionary documentation",
    "section": "Credibility (collaboration)",
    "text": "Credibility (collaboration)\nID: credibilityCollaboration See also: N/A\nDefinition N/A\nDescription TBD\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#credibility-data",
    "href": "dictionary_documentation.html#credibility-data",
    "title": "dictionary documentation",
    "section": "Credibility (data)",
    "text": "Credibility (data)\nID: credibilityData See also: N/A\nDefinition N/A\nDescription TBD\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#data-accessibility",
    "href": "dictionary_documentation.html#data-accessibility",
    "title": "dictionary documentation",
    "section": "Data accessibility",
    "text": "Data accessibility\nID: dataAccessibility See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: Accessibility (data)\nBroad: –"
  },
  {
    "objectID": "dictionary_documentation.html#data-analysis",
    "href": "dictionary_documentation.html#data-analysis",
    "title": "dictionary documentation",
    "section": "Data analysis",
    "text": "Data analysis\nID: dataAnalysis See also: data collection; data management and storage\nDefinition The use of appropriate methods for the analysis and interpretation of data.\nDescription &lt;+ Data analysis applies scientific methods to process surveillance data to generate insights such as detecting unusual patterns (i.e. outbreaks, signal levels beyond expected). Methods range from basic descriptive statistics and trend monitoring to more sophisticated approaches like time series, spatial analysis, and automated aberration detection algorithms. +&gt; assesses how effectively surveillance data are processed and interpreted to generate insights. High-performing systems apply appropriate, context-specific analytical methods and ensure findings are actionable.\nBackground Data analysis was cited as a concept in surveillance system evaluation nine times in the literature, spanning public health, animal health, and One Health surveillance system evaluation frameworks. The definition remains largely consistent, &lt;+ relfecting uniformity across disciplines, with refinment over time, to emphasize the use of contextual information (e.g., prior likelihood of disease) in risk-based analysis and the need for analysis/interpretation to be performed timely to support decision-making and action. +&gt;\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#data-collection",
    "href": "dictionary_documentation.html#data-collection",
    "title": "dictionary documentation",
    "section": "Data collection",
    "text": "Data collection\nID: dataCollection See also: data analysis; data management and storage\nDefinition The use of appropriate data sources and collection methods, including a clear a case definition and a data collection protocol.\nDescription Effective data collection relies on clearly defined and complete case definitions or risk organism descriptions, including case signalment, clinical and pathological signs, and epidemiological information, and, where relevant, laboratory or taxonomic identification. Diagnostic methods must align with the case definition and be assessed for sensitivity and specificity. A written protocol should guide data and sample collection, with mechanisms to ensure adherence. Data collection methods should be clearly documented, and collection methods should minimize redundancy, address data gaps, and employ appropriate sampling strategies (e.g., risk-based or pooled).\nBackground Data collection is a fundamental surveillance activity consistently recognized in evaluation frameworks across public, animal, and One Health systems (five instances within the literature review). Data collection was explicitly mentioned as a concept in the evaluation of surveillance systems in five instances within the literature, including a clear definition and integration into the animal health surveillance field. It is commonly cited as the most costly and difficult component of a surveillance system to implement (Chaudron, 2010; Peyre et al. 2022).(1)\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#data-completeness",
    "href": "dictionary_documentation.html#data-completeness",
    "title": "dictionary documentation",
    "section": "Data completeness",
    "text": "Data completeness\nID: dataCompleteness See also: coverage; accuracy\nDefinition The proportion of data that were intended to be collected that actually was collected.\nDescription Completeness refers to the extent to which all required data are captured, reported, and available for analysis. A system with high completeness allows for more reliable decision-making and enhances the system’s usefulness. Incomplete data may result from issues with data collection, management, or communication, undermining the system’s effectiveness. Regular submission from all contributors and strong data management practices help improve completeness. Ensuring completeness strengthens data quality.\nBackground Completeness was identified as an independent concept on 12 occassions, distinct from the definitions of \"data quality\" or \"data completeness and correctness\". The concept was first introduced by Thacker et al., in 1988 (A method for evaluating systems of epidemiological surveillance), however it was not indentified as an evaluation concept until 1993 by Cutts et al. The definition of completeness has remained largely unchanged over the years, maintaining consistency across disciplines. It is primarily regarded as a key aspect of data quality and continues to be one of the most frequently used concepts for evaluating surveillance systems.\nSynonyms\n\nExact: data completeness and correctness (completeness)\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#data-correctness",
    "href": "dictionary_documentation.html#data-correctness",
    "title": "dictionary documentation",
    "section": "Data correctness",
    "text": "Data correctness\nID: dataCorrectness See also: N/A\nDefinition The proportion of data entries that correctly reflect the true value of the data collected.\nDescription N/A - data completeness and correctness is an exact synonym for data quality.\nBackground TBD\nSynonyms\n\nExact: accuracy (correctness), completeness, data quality\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#data-management",
    "href": "dictionary_documentation.html#data-management",
    "title": "dictionary documentation",
    "section": "Data management",
    "text": "Data management\nID: dataManagement See also: N/A\nDefinition –\nDescription –\nBackground –\nSynonyms\n\nExact: –\nBroad: –"
  },
  {
    "objectID": "dictionary_documentation.html#data-management-and-storage",
    "href": "dictionary_documentation.html#data-management-and-storage",
    "title": "dictionary documentation",
    "section": "Data management and storage",
    "text": "Data management and storage\nID: dataManagementAndStorage See also: historical data\nDefinition Appropriate use and documentation of data management systems for processing information, including data processing protocols, and effective use of data verification procedures and of data storage and back-up procedures.\nDescription\n\nAppropriate use and documentation of data management systems for processing information, including data processing protocols and effective use of data verification procedures, data storage and back-up protocols. Measures taken to assure authorised computer system access and to maintain confidentiality where needed. Is there a dedicated custodian? Data management is a broad area concerning the collation, storage and maintenance of data, including but not limited to matters of data quality, accessibility, usefulness and security. Assessing this attribute will require an intimate understanding of the data storage and management systems employed by the surveillance activity.\n\n\nData management is a broad area concerning the collation, storage and maintenance of data, including but not limited to matters of data quality, accessibility, usefulness and security. Assessing this attribute will require an intimate understanding of the data systems employed by the surveillance activity.\n\n\nData management and storage involve the systematic handling, processing, and safeguarding of data throughout its lifecycle. This includes ensuring data quality, accessibility, and security. Effective data management requires robust protocols for processing, verification, storage, and backup, as well as measures to control access and maintain confidentiality where necessary. An essential consideration is the appointment of a dedicated custodian responsible for overseeing these activities.\n\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#data-quality",
    "href": "dictionary_documentation.html#data-quality",
    "title": "dictionary documentation",
    "section": "Data quality",
    "text": "Data quality\nID: dataQuality See also: N/A\nDefinition The completeness and validity of the data recorded in the public health surveillance system.\nDescription &lt;+ Data quality measures the inherent correctness and sufficiency of the data gathered by the surveillance system. +&gt; Data quality reflects the completeness and validity of recorded data and is essential for accurate surveillance outputs. &lt;+ Poor data quality can undermine reliability, introduce bias that limits representativeness, and make the system less acceptable to participants. Conversely, high-quality data are essential for accurate analysis and improving the system’s overall usefulness for decision-making and public health action. +&gt; High-quality data improve system acceptability and representativeness, while Poor-quality data—often due to manual entry errors in paper-based systems—can undermine reliability and may indicate problems in data collection or data management and storage. Electronic systems can enhance data quality by improving accuracy, timeliness, and accessibility. Data quality is linked to terms such as timeliness, acceptability, representativeness, and usefulness, and directly affects the reliability and usability of system outputs for decision-making and public health response.\nBackground\n\nData quality has historically been defined by the core attributes of completeness and validity. It is routinely recognized as essential across public health, animal health, and emerging One Health surveillance frameworks. In the context of animal health, the term \"data completeness and correctness\" is used as an exact synonym for data quality.\n\n\nIn more recent years, data quality includes the concept of fit-for-purpose, with sufficeint quality to meet the need of the data’s intended purpose. As surveillance systems evolve, particularly through the use of informatics and electronic systems, data quality is enhanced and expanded. Electronic systems can improve data quality by facilitating accuracy, timeliness, accessibility, and reducing the potential for manual entry errors. As data systems evolve, data quality has been enhanced and expanded with the use of robust data management systems and automated data flow processes. The concept is highly interrelated with other performance metrics; for instance, poor quality data reduces system acceptability and representativeness.\n\nSynonyms\n\nExact: data completeness and correctness\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#detection-mode",
    "href": "dictionary_documentation.html#detection-mode",
    "title": "dictionary documentation",
    "section": "Detection mode",
    "text": "Detection mode\nID: detectionMode See also: Sensitivity; Specificity; Predictive Value Positive; False-alarm rate; Timeliness; Data analysis\nDefinition The operational capability of the surveillance system to identify or forecast an event (e.g., event detection, establish baseline, or event detection expected with no baseline).(Corley_AEC_2012?)\nDescription Detection mode characterizes how a surveillance system operationally identifies health events and determines whether detected events represent deviations from an established baseline in terms of frequency and/or magnitude (Corley_AEC_2012?). Systems may be configured to detect events against an established baseline, to first establish baseline patterns before detection can occur, or to detect events when no baseline is available (such as for exotic or novel diseases). Any excess or anomalous occurrence identified through the system’s detection mode should be statistically characterized and include a measure of abnormality or confidence (Corley_AEC_2012?). It should be recognized that baselines fluctuate over time, requiring appropriate statistical methods for pattern recognition and aberration detection (Buehler_ESSEDa_2004?,Groseclose_ESS_2013?). The chosen detection mode directly influences how system attributes such as sensitivity (probability of detection) and timeliness (speed of detection) are defined and measured, and ultimately determines the system’s utility for public health intervention (2,Morbey_OJP_2021?,Corley_AEC_2012?).\nBackground Detection mode provides a foundational characterization of the operational capability of a surveillance system, specifically concerning its approach to early warning and event detection (Corley_AEC_2012?). The attribute was identified and defined within the context of evaluating event-based biosurveillance systems, models, and constructs, which frequently rely on analyzing qualitative or quantitative variables to infer population health status (Corley_AEC_2012?). Within biosurveillance evaluation frameworks, detection mode falls under the broader Event Attribute Family and describes the type of operational outcome anticipated from the system (Corley_AEC_2012?). While detection mode represents a distinct operational design characteristic, it overlaps considerably with classic case detection and ascertainment metrics. The performance of a surveillance system’s detection mode is fundamentally measured through traditional epidemiological attributes including sensitivity (the probability and proportion of true events detected), specificity (the ability to correctly identify non-events), predictive value positive (the proportion of detected events that are true events), and timeliness (the speed of detection) (2,Morbey_OJP_2021?,Corley_AEC_2012?,Buehler_ESSEDa_2004?). This attribute is closely connected to syndromic surveillance methods, which heavily rely on statistical tools for pattern recognition and aberration detection applied to data streams to screen for patterns requiring investigation (Buehler_ESSEDa_2004?,Groseclose_ESS_2013?). The chosen detection mode directly determines how these classic ascertainment metrics are operationalized, defined, and measured within the surveillance system context, while balancing detection capability against false-alarm rates to ensure efficient resource utilization (3,Corley_AEC_2012?).\nSynonyms\n\nExact: N/A\nBroad: event detection, early detection/warning, surveillance sensitivity (outbreak detection), signal detection, case detection capability"
  },
  {
    "objectID": "dictionary_documentation.html#effectiveness",
    "href": "dictionary_documentation.html#effectiveness",
    "title": "dictionary documentation",
    "section": "Effectiveness",
    "text": "Effectiveness\nID: effectiveness See also: usefulness\nDefinition The extent to which a surveillance system is able to achieve its intended objectives. (4,Drewe_EoAaPHS_2012?,WorldHealthOrganization_OtWF_2004?,Peyre_TRVA_2019?).\nDescription Effectiveness reflects how well the surveillance system achieves its intended objectives and meets the needs of stakeholders. It represents the capability of producing a desired result and encompasses the system’s technical performance in reaching its objectives, such as disease control or early detection (4,Drewe_EoAaPHS_2012?). The measurement of effectiveness considers multiple underlying attributes including timeliness, sensitivity, specificity, predictive value, and robustness, with the specific attributes of greatest relevance determined by the surveillance system’s objectives (Grosbois_ARtUMoE_2015?,Yang_UOaHS_2022?). Sensitivity (probability of detection) and timeliness are frequently assessed attributes related to effectiveness, particularly for systems focused on early detection. Systems should use collaborative approaches to improve effectiveness across data collection, processing, and dissemination, as integrated surveillance can enhance effectiveness compared to systems operating in isolation (Yang_UOaHS_2022?). Effectiveness is evaluated through indicators that measure processes, outputs, outcomes, and impacts against stated objectives. These indicators may include task completion rates, timeliness metrics, and measurable public health impact, such as whether the system leads to prevention, control, or better understanding of adverse health events (Muellner_SiFAiB_2018?,Peyre_TRVA_2019?). This term is closely related to system usefulness (the tangible benefits and outcomes attributed to the system) and efficiency (the relationship between resources implemented and results obtained) (4,Peyre_TRVA_2019?).\nBackground Effectiveness emerged as a core evaluation criterion through the adaptation of general program evaluation principles to public health surveillance. The concept gained prominence in surveillance evaluation frameworks during the late 20th and early 21st centuries, particularly through influential guidance documents from the Centers for Disease Control and Prevention (CDC) and the World Health Organization (WHO), which established effectiveness as a central measure for assessing surveillance system quality (4,WorldHealthOrganization_OtWF_2004?). These frameworks positioned effectiveness as one of three core criteria for assessing public policies and programs, alongside relevance and efficiency, reflecting broader trends in public sector performance evaluation (4). The operationalization of effectiveness in surveillance contexts evolved from general notions of \"achieving objectives\" to more specific technical performance measures. In surveillance evaluation, effectiveness became understood as the technical performance of the system—the capacity to reach its objective (such as disease control or early detection) through appropriate use of inputs to produce desired outputs (4,Drewe_EoAaPHS_2012?). This conceptualization linked effectiveness to measurable attributes such as sensitivity, timeliness, and specificity, allowing evaluators to quantify technical performance. The development of economic evaluation frameworks, particularly cost-effectiveness analysis (CEA), further formalized effectiveness as a measurable construct, using performance indicators as proxies for benefit when comparing surveillance investments (4,Grosbois_ARtUMoE_2015?). From a policy perspective, this evolution enabled effectiveness to measure the effects (outcomes and impacts) directly attributable to surveillance system implementation, establishing the principle that surveillance systems must be regularly evaluated to ensure they remain both effective and efficient in meeting evolving public health needs.\nSynonyms\n\nExact: efficacy\nBroad: Impact, usefulness"
  },
  {
    "objectID": "dictionary_documentation.html#efficiency",
    "href": "dictionary_documentation.html#efficiency",
    "title": "dictionary documentation",
    "section": "Efficiency",
    "text": "Efficiency\nID: efficiency See also: N/A\nDefinition The link between the resources implemented and the results obtained.\nDescription An efficient system will accomplish a job with minimum expenditure of time, human effort and cost. Conducting surveillance incurs costs such as salaries, consumables, and travel. These costs can be compared against the outputs from surveillance such as reports, disease or organism detections and notifications, or other signals. A surveillance system can be considered efficient if there is an optimal balance between economic investments and its outputs, the latter achieving the desired quality attributes (e.g. precision, timeliness). Risk-based surveillance can - where appropriate in terms of the surveillance objective - provide efficiency gains in surveillance systems.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: cost-effectiveness"
  },
  {
    "objectID": "dictionary_documentation.html#engagement",
    "href": "dictionary_documentation.html#engagement",
    "title": "dictionary documentation",
    "section": "Engagement",
    "text": "Engagement\nID: engagement See also: acceptability; collaboration\nDefinition The active involvement of stakeholders, including partners and communities, in the design, operation, interpretation, and use of the surveillance system.\nDescription Engagement reflects the depth and quality of participation in surveillance activities. It encompasses contributions to data collection, system design, analysis interpretation, and application of surveillance outputs. Effective engagement is characterized by meaningful interaction, shared responsibility, and mutual benefit among all partners.\nBackground The concept of engagement has evolved in surveillance practice, particularly in emphasizing community involvement. Engaged communities participate in various aspects of surveillance, from identifying priorities to collecting data and using results. Evidence of engagement includes consistent participation, valuable feedback, system adaptation based on community input, and local ownership of activities. Modern approaches recognize that engagement should include diverse communities, especially those most affected by health conditions under surveillance. This shift values equitable partnerships where communities are active collaborators rather than simply sources of data.\nSynonyms\n\nExact: participation\nBroad: –"
  },
  {
    "objectID": "dictionary_documentation.html#equity-data",
    "href": "dictionary_documentation.html#equity-data",
    "title": "dictionary documentation",
    "section": "Equity data",
    "text": "Equity data\nID: equityData See also: representativeness; acceptability; data quality; usefulness; coverage\nDefinition The surveillance system’s data content necessary to capture population characteristics and contextual factors that enable analysis of differential health impacts across demographic and socioeconomic groups.\nDescription Equity-relevant data ensures the system collects information necessary to analyze how disease burden, exposure, or surveillance outcomes vary across populations. For environmental surveillance systems, this requires data that can be spatially or demographically linked to affected communities, stratified by indicators of vulnerability such as socioeconomic status, age distribution, or geographic marginalization. For human health surveillance, this extends to demographic attributes (race/ethnicity, gender, age), and in specialized frameworks, may include measures of structural determinants such as racism or stigma. For animal health surveillance, relevant factors include producer characteristics, economic constraints, and cultural factors (e.g., livestock’s role in local economies) that influence disease reporting and system participation. The attribute assesses whether the system’s data infrastructure enables identification of which populations are disproportionately affected and supports development of targeted, equitable interventions. This directly influences representativeness (ensuring no groups are systematically excluded) and acceptability (ensuring culturally appropriate engagement).\nBackground The concept of equity-relevant data in surveillance evaluation has three distinct but converging lineages. Traditional Public Health Surveillance (1990s-2000s): Foundational CDC guidelines from the 1990s required surveillance evaluation to consider disparities or inequities and assess data distribution by population demographics (race, ethnicity, age, socioeconomic status). This was traditionally addressed within the attribute of representativeness, which required collecting demographic characteristics and identifying systematically excluded population subgroups. One Health and Animal Health Frameworks (2013-present): Animal health and One Health evaluation frameworks identified that traditional approaches, focused on technical attributes like sensitivity, failed to capture the social and economic aspects influencing system performance. These frameworks required characterizing socioeconomic context, including local value systems, cultural importance of livestock, and economic constraints—factors that fundamentally shape surveillance effectiveness through their influence on acceptability and data quality. Health Equity and Anti-Racism Frameworks (2021-present): Public Health Critical Race Praxis (PHCRP) evaluation frameworks identified a critical gap: even systems collecting race/ethnicity data often fail to capture structural drivers of health inequities. PHCRP explicitly requires assessing whether systems capture measures of racism (such as residential segregation or discriminatory policies) and validated stigma indicators, moving beyond demographic categories to measure mechanisms producing inequitable outcomes. Convergence: These lineages converge in recognizing that adequate evaluation requires assessing whether systems collect data sufficient to identify who is disproportionately affected (demographics), why disparities exist (structural and contextual factors), and whether the system engages populations equitably (cultural appropriateness). Specific data elements vary by surveillance type, but the principle is consistent: equity-relevant data collection addresses not only demographic completeness but also the social, economic, and structural determinants shaping health outcomes and surveillance performance. This concept intersects with multiple traditional evaluation attributes including representativeness, acceptability, data quality, and usefulness.\nSynonyms\n\nExact: equity-relevant data, health equity data, disparities data\nBroad: social determinants data, demographic data, stratification variables, population characteristic data, vulnerability indicators"
  },
  {
    "objectID": "dictionary_documentation.html#false-alarm-rate",
    "href": "dictionary_documentation.html#false-alarm-rate",
    "title": "dictionary documentation",
    "section": "False-alarm rate",
    "text": "False-alarm rate\nID: falseAlarmRate See also: specificity\nDefinition The proportion of negative events (e.g. non-outbreak periods) incorrectly classified as events (outbreaks) (3,5).\nDescription The false-alarm rate is the proportion of non-events incorrectly flagged as events and represents the inverse of specificity (3,5,6). While some false positives are expected in surveillance systems, a high false-alarm rate can lead to wasted resources through misdirected investigations of non-events (anonymous.2001?,Buehler_EOPHS_2004?,Groseclose_EOSH_2008?). Conversely, efforts to minimize false alarms by raising detection thresholds may compromise sensitivity, increasing the risk of missed outbreaks (Buehler_EOPHS_2004?,Groseclose_SSEDSHD_2013?). This trade-off is particularly critical in early detection and syndromic surveillance systems, where high data volumes and low event prevalence often generate elevated false-positive rates (Groseclose_SSEDSHD_2013?). Excessive false alerts can lead to alert fatigue among users, potentially causing genuine events to be missed, and may erode credibility of public health agencies (Lucero-Obusan_BMC_2022?,Groseclose_SSEDSHD_2013?). System designers should specify desired sensitivity and false-alarm rate thresholds, explicitly balancing the risk of missed outbreaks against the cost of investigating false alarms (Buehler_EOPHS_2004?). The false-alarm rate is closely related to predictive value positive (PVP), as a low PVP directly reflects a high false-alarm rate; both metrics quantify the quality of positive signals in a surveillance system (Buehler_EOPHS_2004?,anonymous.2001?).\nBackground The term \"false-alarm rate\" was proposed and adopted in animal health surveillance evaluation frameworks as an alternative to \"specificity\" because it was considered more easily understood by non-epidemiologists, including surveillance planners and policy makers (3,5). The concept gained prominence as a key metric within the Evidence Quality or Effectiveness domain of surveillance evaluation frameworks, particularly for systems designed to detect early outbreaks or unexpected events (5,icahs-workshop-report?). In biosurveillance and outbreak detection systems, quantifying the false-alarm rate has been identified as essential for economic evaluations, with stakeholders demonstrating willingness-to-pay for improvements in this attribute (delRioVilas_PfEoOHSTEB_2022?,Amato_EPI_2023?).\nSynonyms\n\nExact: Inverse of specificity, False positive rate (FPR)\nBroad: Predictive value positive (PVP) - related inverse concept; low PVP indicates high false-alarm rate"
  },
  {
    "objectID": "dictionary_documentation.html#feasibility",
    "href": "dictionary_documentation.html#feasibility",
    "title": "dictionary documentation",
    "section": "Feasibility",
    "text": "Feasibility\nID: feasibility See also: sustainability; stability; efficiency; effectiveness\nDefinition The extent to which available means (resources, expertise, infrastructure) meet the surveillance system’s needs, ensuring that strategies and methods are suitable and applicable to the surveillance objectives (Yang_UOaHS_2022?,Drewe_EoAaPHS_2012?).\nDescription Feasibility evaluates whether a surveillance system is realistic and sustainable given available resources, expertise, and objectives (Yang_UOaHS_2022?). It addresses the fundamental question of whether the means necessary to run the system are available and whether system strategies correspond to public health priorities (Drewe_EoAaPHS_2012?,Yang_UOaHS_2022?). Key components of feasibility assessment include staff capability and multidisciplinary expertise essential for system operation and maintenance, as well as whether personnel have the required knowledge, skills, and experience (Yang_UOaHS_2022?). Feasibility also considers the availability of necessary external resources, such as steering committees, technical committees, and government affiliations that support system implementation. The ability to track surveillance events over time using available data sources represents another critical feasibility consideration (Yang_UOaHS_2022?). Ultimately, feasibility assesses whether available resources are sufficient to support all system components—including data collection, analysis, and dissemination—effectively and efficiently. Limited resources pose significant constraints on achieving ideal surveillance criteria, making feasibility a primary consideration when setting evaluation objectives and determining system design (Yang_UOaHS_2022?).\nBackground Feasibility emerged as a fundamental organizational constraint in surveillance evaluation frameworks, routinely assessed alongside other organizational and performance measures to determine whether surveillance systems can realistically operate given resource limitations (Yang_UOaHS_2022?,Drewe_EoAaPHS_2012?). The attribute gained particular importance in the context of resource-constrained settings and programs with limited technical capacity, where conceptual evaluation methods focusing on feasibility were recognized as more appropriate than purely quantitative, effectiveness-based metrics that might penalize such programs (Yang_UOaHS_2022?). The practical application of feasibility assessment was formalized in evaluation guidance that positioned it as a necessary early step in surveillance system development. When deciding whether to start a new system or conduct detailed evaluation, assessing feasibility and cost became established as essential steps following the determination of public health importance (Drewe_EoAaPHS_2012?). This framework recognized that even well-designed systems cannot succeed without adequate means to support their operation. The concept gained additional prominence with the rise of One Health and integrated surveillance initiatives, where challenges are often caused by poor availability of resources and personnel, underscoring the necessity of rigorous feasibility assessment before committing to complex, multisectoral surveillance efforts (4,Yang_UOaHS_2022?). Feasibility’s relationship to other evaluation attributes reflects its role as a foundational constraint that shapes what can be achieved. The relationship between feasibility and sustainability is immediate and critical, as feasibility explicitly evaluates whether a system is sustainable given available resources, while sustainability assesses the system’s ability to continue in the long term (Drewe_EoAaPHS_2012?). A system deemed unfeasible lacks the necessary means for operation, directly undermining sustainability. Feasibility constraints also determine what ideal evaluation criteria can realistically be pursued—when resources are limited, evaluators must consider feasibility when setting objectives and criteria, recognizing that many desirable attributes may not be readily achievable (Yang_UOaHS_2022?). This creates direct linkages to stability (the reliability of system operation), as adequate resources and staff capability underpin both feasibility and stability. The attribute also influences effectiveness and efficiency, since resource adequacy determines both whether objectives can be achieved and whether they can be achieved optimally. The overall goal of evaluation—to ensure the design of efficient and sustainable surveillance systems—depends fundamentally on initial feasibility assessment, making this attribute a critical gate through which all other system qualities must pass\nSynonyms\n\nExact: N/A\nBroad: Practicality (ease of operation and administration), Resource adequacy, Implementability"
  },
  {
    "objectID": "dictionary_documentation.html#flexibility",
    "href": "dictionary_documentation.html#flexibility",
    "title": "dictionary documentation",
    "section": "Flexibility",
    "text": "Flexibility\nID: flexibility See also: portability; simplicity; sustainability; acceptability\nDefinition The ability of the system to adapt to changing information needs or operating conditions, including scaling up or down as necessary, with little additional time, personnel, or funds (Drewe_EoAaPHS_2012?,Groseclose_EPHS_2010?,Azofeifa_EBHS_2018?,Hoinville_TRVA_2013?).\nDescription Flexibility is the system’s ability to adapt to new information needs, emerging threats, or changing resources with minimal disruption. Flexible systems must accommodate diverse changes including new health-related events or hazards, modifications to case definitions or technologies, and variations in funding or reporting sources (Groseclose_EPHS_2010?,Amato_E_2023?). Examples of such adaptations include responding to changes in data standards (e.g., ICD-9 to ICD-10), incorporating new data sources and technologies (e.g., online data sharing or machine learning techniques), or adjusting case definitions to reflect evolving understanding of health conditions (Groseclose_EPHS_2010?). Standardized formats and modular designs support flexibility by providing robust, adaptable infrastructure. Systems utilizing standard vocabularies or standardized formats (such as PHIN standards) provide flexible code structures that can accommodate changing information needs. Centralized data processing can enhance flexibility by reducing the need for widespread system and operator behavior changes when adaptations are required. Flexibility is generally higher in simpler systems, as fewer components require modification when adapting (Thacker_MEES_1988?). Flexibility is closely related to sustainability, resilience, and system responsiveness. Flexible systems are vital for long-term maintenance, especially when facing external factors such as funding variations or personnel cuts, with infrastructure that can evolve as the system grows. Flexibility also supports acceptability and usefulness, as systems that can be tailored to meet the evolving needs and interests of staff and stakeholders foster greater participation and sustained engagement.\nBackground Flexibility emerged as one of the seven original surveillance system attributes identified by Thacker et al. in 1988, establishing it as a foundational evaluation criterion (Thacker_MEES_1988?,Groseclose_EPHS_2010?). The attribute has been consistently included in surveillance evaluation frameworks across public health, animal health, and One Health systems, reflecting its status as a core performance measure. It was retained as one of nine core metrics in the modernized US CDC Evaluation Guidelines and continues to appear in contemporary evaluation tools (Groseclose_EPHS_2010?,Peyre_TRVA_2019?). The definition of flexibility has remained highly consistent since its introduction, emphasizing low-cost adaptation to changing conditions with minimal additional resources (Drewe_EoAaPHS_2012?,Groseclose_EPHS_2010?,Hoinville_TRVA_2013?). The term is often used interchangeably with \"adaptability\" or referenced as \"adaptability to changes,\" and some evaluation tools formally list the attribute as \"Flexibility, adaptability\" (Peyre_TRVA_2019?). Recent applications have expanded the concept to explicitly include the system’s ability to scale up, scale down, or expand as necessary, particularly relevant for emerging surveillance contexts such as wastewater surveillance (Amato_E_2023?). Flexibility’s relationship to other evaluation attributes reveals its interconnected role in system performance. The attribute demonstrates a bidirectional relationship with simplicity—simpler systems exhibit greater flexibility because fewer components require modification during adaptation (Thacker_MEES_1988?). Flexibility also supports sustainability by enabling systems to persist despite changing external factors such as funding variations or staffing changes, while simultaneously contributing to acceptability and usefulness by allowing systems to be tailored to stakeholder needs. The relative importance of flexibility may vary across system development stages, with some evidence suggesting it holds particular relevance during initial development and pilot testing, while attributes like reliability and stability assume greater significance during operational maturity (Auer_R_2011?).\nSynonyms\n\nExact: adaptability\nBroad: scalability"
  },
  {
    "objectID": "dictionary_documentation.html#governance",
    "href": "dictionary_documentation.html#governance",
    "title": "dictionary documentation",
    "section": "Governance",
    "text": "Governance\nID: governance See also: N/A\nDefinition The coordination, leadership, and operational effectiveness of surveillance systems, encompassing the legislative framework, steering mechanisms, and organizational structures that ensure clear roles, shared responsibilities, and inclusive decision-making to achieve surveillance objectives (Sandberg_AoEFTfIS_2021?,Figuie_AHSFCtRG_2022?).\nDescription Governance refers to the coordination, leadership, and operational effectiveness of a surveillance system, encompassing how the system is organized, steered, and operationally managed (Groseclose_APHS_2017?,Sandberg_AoEFTfIS_2021?). Strong governance ensures clear roles and responsibilities of actors involved in the system, shared responsibilities across partners, inclusive decision-making, and formalized collaboration across sectors and disciplines (Rüegg_GfEiS_2022?,Bordier_EoCiaMSS_2022?). Effective governance involves defined strategic goals, operational structures such as steering committees and coordination mechanisms, and documented agreements between institutions through regulations, charters, or formal agreements (Hendrikx_OAToESS_2011?,Collineau_EoftFS_2022?,Bordier_EoCiaMSS_2022?). It requires systems to define how to prioritize objectives and organize the allocation of costs and benefits, ensuring appropriate mobilization of resources across sectors (Figuie_AHSFCtRG_2022?,Pelican_STfCA_2019?). Good governance is characterized by integration of different areas of knowledge, inclusion of public values and social concerns in decision-making, and rules promoting transparency, inclusiveness, and accountability (Figuie_AHSFCtRG_2022?). Governance mechanisms should also assess and manage the system’s compliance with legal and regulatory requirements, including ethics and confidentiality considerations. Governance is closely linked to collaboration, as governance mechanisms define the structure and quality of collaborative modalities in multisectoral systems (Bordier_EoCiaMSS_2022?,Bordier_COHSS_2020?). It is particularly critical for implementing One Health approaches, where collaborative strategies must be planned and organized at both policy and institutional levels to be functional and sustainable (Bordier_EoCiaMSS_2022?). Governance contrasts with traditional hierarchical \"government\" authority and purely technical \"management\" approaches by implying more flexible forms of power where public and non-public stakeholders interact (Figuie_AHSFCtRG_2022?). Good governance is considered a condition for greater stakeholder involvement and surveillance effectiveness, with understanding of real governance—how systems actually function in practice—serving as a powerful tool for designing more effective systems overall (Peyre_PfEoOHS_2022?,Figuie_AHSFCtRG_2022?).\nBackground Governance represents a relatively recent and conceptually diverse addition to surveillance evaluation frameworks, appearing with increasing frequency in One Health and integrated surveillance contexts without a clear, unified evolutionary path (Sandberg_AoEFTfIS_2021?,Rüegg_TNEOF_2018?). Unlike classical surveillance attributes (such as sensitivity or timeliness) that emerged from foundational epidemiological frameworks and maintained consistent definitions across decades, governance appears variably across evaluation tools with context-dependent conceptualizations. Early recognition of governance-related obstacles—such as managerial and administrative weaknesses—highlighted gaps in traditional surveillance evaluation, but did not immediately produce standardized governance assessment approaches (Baker_GPHSU_2006?). Several evaluation tools developed for integrated and multisectoral surveillance have incorporated governance as a distinct domain, though with varying emphases and operationalizations. The NEOH tool, ATLASS framework, and PMP-AMR each assess governance-related dimensions, while the ECoSur tool was specifically designed to evaluate the organization and governance of collaboration in multisectoral systems (Sandberg_AoEFTfIS_2021?,Bordier_EoCiaMSS_2022?,Bordier_EoCiaMSS_2019?,Rüegg_TNEOF_2018?,Garcia-Vozmediano_AOHES_2022?). These tools reflect governance’s particular salience in One Health contexts where multiple sectors, disciplines, and institutions must coordinate, yet they do not represent a convergence toward a single standardized governance construct. Some frameworks emphasize structural elements (steering committees, documented agreements), while others focus on functional aspects (decision-making processes, resource allocation) or social dimensions (stakeholder representation, real versus official governance practices) (Figuie_AHSFCtRG_2022?,Peyre_PfEoOHS_2022?,Bordier_EoCiaMSS_2022?). The varied conceptualizations of governance reflect its complex nature as both an organizational input and a determinant of system performance. Governance overlaps with concepts like organizational structure and system organization, which appear in earlier frameworks, yet extends beyond them to encompass power dynamics, stakeholder interactions, and the distinction between formal rules and actual practices (Figuie_AHSFCtRG_2022?,Hendrikx_OAToESS_2011?). Poor early engagement of field staff in system design—a governance failure—often leads to poor acceptability and implementation challenges, demonstrating governance’s cascading effects on other attributes (DelRioVilas_HSEitPC_2022?). Governance directly enables collaboration by providing structures for multisectoral interaction, supports sustainability through resource allocation and strategic planning, and enhances effectiveness through stakeholder involvement and accountability (Bordier_EoCiaMSS_2019?,Bordier_EoCiaMSS_2022?,Peyre_PfEoOHS_2022?). Despite these recognized relationships, governance remains a less standardized evaluation attribute compared to classical metrics, with its assessment varying substantially based on surveillance context, institutional complexity, and evaluator perspective.\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#granularity",
    "href": "dictionary_documentation.html#granularity",
    "title": "dictionary documentation",
    "section": "Granularity",
    "text": "Granularity\nID: granularity See also: completeness\nDefinition The level of detail provided in input sources and output data of the surveillance system.\nDescription Granularity refers to the level of detail in both input and output data within a surveillance system. Input granularity indicates how detailed the data sources are, such as individual data points or aggregated tables. Mismatched granularity between the required input for event-based biosurveillance and available data can impact the accuracy of results. For output, granularity reflects how detailed the results are, whether presented as a single data field, a table, or a graphic. Higher granularity in output can help identify specific trends, populations, or infection regions, but lower-detail outputs may not always be able to represent high-detail data.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#historical-data",
    "href": "dictionary_documentation.html#historical-data",
    "title": "dictionary documentation",
    "section": "Historical data",
    "text": "Historical data\nID: historicalData See also: accessibility (data); data quality; data management and storage\nDefinition Refers to the quality and accessibility of archived data.\nDescription Historical data refers to the quality, completeness, and accessibility of archived surveillance information. It is especially important for demonstrating disease freedom, monitoring trends in endemic diseases, and supporting epidemiological research. This term is closely linked to data management and storage, and repeatability. Key considerations include the number of years stored, data reliability, ease of access and analysis, and availability of metadata explaining changes over time. Effective use of historical data enhances surveillance value and enables long-term analysis and planning.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#impact",
    "href": "dictionary_documentation.html#impact",
    "title": "dictionary documentation",
    "section": "Impact",
    "text": "Impact\nID: impact See also: Effectiveness; Benefit\nDefinition The measure of changes that have been made based on surveillance results in relation to the system’s aims, including the actions taken and outcomes achieved as a result of the information provided (4,icahs-workshop-report?,Drewe_SERVAL_2015?).\nDescription Impact measures the tangible benefits a surveillance system provides by assessing the changes and consequences that result from surveillance outputs. It reflects how surveillance data and information influence decisions, policy, and interventions, including changes in behavior, protocols, or disease control measures (Declich_PHS_1994?,Thacker_MEES_1988?,DelRioVilas_HSEitPC_2022?). The measurement of impact includes details of actions taken as a result of the information provided by the system, such as changes in protocols or behavior, modifications in mitigation actions, or implementation of interventions (4,Drewe_SERVAL_2015?). Evaluation measures the extent to which the overall goal is achieved through ultimate outcomes such as policy changes, behavioral changes, and better health outcomes directly attributed to the surveillance system (Tegegne_OECatET_2023?,WorldHealthOrganization_OtWF_2004?). High-impact systems provide timely, complete, and representative data aligned with stakeholder and policy needs. Impact is strengthened by underlying attributes such as sensitivity, timeliness, data completeness, and representativeness, which together determine the quality of surveillance data and enhance the system’s value in guiding effective responses (anonymous.2001?). For example, improved timeliness allows control and prevention activities to be initiated earlier, contributing to greater overall impact. Impact is ultimately realized through the translation of surveillance information into practice to reduce unnecessary variation and increase effectiveness, with integrated evaluation frameworks assessing how surveillance information informs the implementation of interventions (DelRioVilas_HSEitPC_2022?,Groseclose_APHS_2017?,Bennani_EISA_2021?).\nBackground Impact and usefulness represent closely related concepts that measure the ultimate value of surveillance systems, with their relationship reflecting different evaluation traditions and contexts rather than fundamental conceptual differences. Historically, evaluating surveillance systems included assessing usefulness by asking practitioners about system value, but more rigorous approaches involved assessing the impact of surveillance data on policies and interventions (Thacker_MEES_1988?,Thacker_PPHS_1988?). The term \"impact\" gained particular prominence in animal health surveillance, economic evaluation, and One Health contexts, where it became the preferred terminology in frameworks like SERVAL and EVA Survtool that assess ultimate value and benefits achieved (4,Hoinville_TRVA_2013?,Drewe_SERVAL_2015?). Impact is often defined specifically as the changes made based on surveillance results or the consequences beyond immediate effectiveness, relating to societal benefits of loss avoidance (Drewe_SERVAL_2015?,Meynard_PFAFM_2008?). This framing connects impact directly to economic evaluation methodologies, linking performance (effectiveness) to monetary benefit (cost-benefit analysis) or non-monetary benefit (cost-effectiveness analysis) (Peyre_TRVA_2019?,Drewe_SERVAL_2015?). Impact evaluation methods seek to answer cause-and-effect questions by comparing outcomes to counterfactuals—what would have happened without the surveillance intervention. In integrated surveillance frameworks like the Integrated Surveillance System Evaluation Project (ISSEP), impact represents a specific evaluation level (Level 5: Contribution to Desirable Outcomes), where ultimate outcomes include improved animal, human, and environmental health, along with associated socioeconomic benefits (Bennani_EISA_2021?,Sandberg_AoEFTfIS_2021?). Modern surveillance evaluation increasingly emphasizes impact assessment, driven by both donor accountability requirements and social accountability demands (4,Peyre_AITAEoPHS_2022?). Workshop participants assessing evaluation attribute importance have generally considered impact alongside costs as highly relevant attributes for system performance, sometimes viewing it as conceptually distinct from organizational benefits (Hoinville_TRVA_2013?). While impact and usefulness are explicitly recognized as synonyms in evaluation literature, impact tends to be emphasized in contexts requiring quantifiable evidence of return on investment and in integrated or One Health systems where demonstrating the value of cross-sectoral collaboration is essential. The attribute’s dependence on virtually all other surveillance qualities (sensitivity, timeliness, representativeness, acceptability, stability) reflects its role as a summary measure of whether the entire surveillance enterprise achieves its intended purpose of improving health outcomes.\nSynonyms\n\nExact: usefulness, utility\nBroad: benefit, value"
  },
  {
    "objectID": "dictionary_documentation.html#interoperability",
    "href": "dictionary_documentation.html#interoperability",
    "title": "dictionary documentation",
    "section": "Interoperability",
    "text": "Interoperability\nID: interoperability See also: accessibility (data); data management and storage\nDefinition Compatibility with and ability to integrate data from other sources and surveillance components.\nDescription Interoperability helps ensure timely, efficient data exchange across sectors, disciplines, and administrative entities. Interoperability supports joint analysis, enhances flexibility, and improves sustainability. Effective interoprability requires standardized data formats, unique identifiers (e.g., sample or location IDs), and reliable data-sharing mechanisms. Challenges include fragmented or duplicative systems, lack of digital integration, or a lack of formal communication pathways. The importance of interoperability may depend on how essential inter-system data exchange is to the overall usefulness and effectiveness of the surveillance system.\nBackground TBD\nSynonyms\n\nExact: compatibility, integration\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#laboratory-and-sample-management",
    "href": "dictionary_documentation.html#laboratory-and-sample-management",
    "title": "dictionary documentation",
    "section": "Laboratory and sample management",
    "text": "Laboratory and sample management\nID: laboratoryAndSampleManagement See also: technical competence and training\nDefinition Whether testing is carried out using appropriate methods with quality assurance scheme and timely and accurate delivery of results.\nDescription Laboratory and sample management evaluates the integration, reliability, and quality of diagnostic laboratory functions within the surveillance system. Key considerations include the implementation of systematic quality management practices, participation in proficiency testing, and adherence to international standards (e.g., ISO 9001, ISO 17025). Effective sample handling, timely analysis, and standardized protocols and harmonization of techniques across laboratories support data comparability. Laboratory and sample management is also closely related to technical competence and training.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#likelihood-ratio-of-a-positive-test",
    "href": "dictionary_documentation.html#likelihood-ratio-of-a-positive-test",
    "title": "dictionary documentation",
    "section": "Likelihood ratio of a positive test",
    "text": "Likelihood ratio of a positive test\nID: likelihoodRatioOfAPositiveTest See also: TBD\nDefinition Ratio of the probability of a surveillance system detecting an infected individual to the probability of the system incorrectly identifying them as infected when they are in fact not.\nDescription Likelihood ratios do not vary with disease prevalence and so are stable expressions of system performance.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#multiple-utility",
    "href": "dictionary_documentation.html#multiple-utility",
    "title": "dictionary documentation",
    "section": "Multiple utility",
    "text": "Multiple utility\nID: multipleUtility See also: flexibility; portability\nDefinition The ability of a surveillance system to capture information on several hazards; measure of how generic the system is.\nDescription Multiple utility describes a surveillance system’s capacity to collect information on several hazards, reflecting how generic and adaptable it is. Systems with high multiple utility can support various surveillance objectives, improving cost-effectiveness and overall value. This term is positively linked to acceptability, sustainability, flexibility, and cos. Both realised and potential multiple utility should be assessed to identify opportunities for improvement. Systems with broad, representative designs generally offer greater multiple utility than those narrowly focused on specific risks.\nBackground TBD\nSynonyms\n\nExact: multiple hazard\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#mutual-benefit",
    "href": "dictionary_documentation.html#mutual-benefit",
    "title": "dictionary documentation",
    "section": "Mutual benefit",
    "text": "Mutual benefit\nID: mutualBenefit See also: collaboration\nDefinition The capability of the surveillance system to create opportunities where collaborations can benefit both the system and its partners/collaborators.\nDescription Mutual Benefit refers to the extent to which all collaborators gain value from participating in the surveillance system. This includes the availability of shared data infrastructure, clarity in roles and responsibilities, and the fostering of trusted relationships. Mutual understanding of privacy, confidentiality, and security processes supports sustained cooperation. Systems that enable data exchange and define partner benefits are more likely to promote long-term collaboration and stakeholder engagement.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#negative-predictive-value-npv",
    "href": "dictionary_documentation.html#negative-predictive-value-npv",
    "title": "dictionary documentation",
    "section": "Negative predictive value (NPV)",
    "text": "Negative predictive value (NPV)\nID: negativePredictiveValue See also: positive predictive value\nDefinition The probability that no health event is present given that no health event is detected.\nDescription Negative predictive value (NPV) reflects the likelihood that a negative surveillance result truly indicates absence of condition, hazard, or event under surveillance. A high NPV suggests few false negatives and supports confidence in the system’s ability to rule out threats when no signal is detected. NPV is influenced by the system’s sensitivity, specificity, and the prevalence of the condition in the population. IIt applies acros various public health surveillance modalities, including lagroatory, syndomic, environmental, and even-based approaches, and should be considered alongside sensitivity and positive predictive value.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#performance-monitoring-and-evaluation",
    "href": "dictionary_documentation.html#performance-monitoring-and-evaluation",
    "title": "dictionary documentation",
    "section": "Performance monitoring and evaluation",
    "text": "Performance monitoring and evaluation\nID: performanceMonitoringAndEvaluation See also: N/A\nDefinition The routine use of performance indicators to monitor surveillance system performance, and the periodic use of internal or external evaluations to assess system outputs in relation to stated objectives.\nDescription Performance monitoring and evaluation assesses the extent to which the surveillance system uses performance indicators and scheduled evaluations to track progress, measure effectiveness, and ensure accountability. This includes regular internal monitoring and external assessments of system components, including data quality, timeliness, sensitivity, and stakeholder collaboration. Performance monitoring and evaluation supports system transparency, enables corrective actions, and contributes to long-term improvement. It is closely linked to effectiveness, efficiency, impact, and sustainability.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#portability",
    "href": "dictionary_documentation.html#portability",
    "title": "dictionary documentation",
    "section": "Portability",
    "text": "Portability\nID: portability See also: flexibility\nDefinition The ease with which a surveillance system can be replicated or implemented in a different context or setting.\nDescription Portability describes how easily a surveillance system can be adopted or adapted in other settings or jurisdictions. High portability is supported by standardized formats, clear documentation, modular design, and minimal dependence on local infrastructure or specialized personnel. Systems that are portable enable broader uptake, facilitate scalability, and enhance knowledge sharing. Portability is positively associated with attributes such as simplicity, flexibility, and sustainability.\nBackground TBD\nSynonyms\n\nExact: generalizability\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#positive-predictive-value-ppv",
    "href": "dictionary_documentation.html#positive-predictive-value-ppv",
    "title": "dictionary documentation",
    "section": "Positive predictive value (PPV)",
    "text": "Positive predictive value (PPV)\nID: positivePredicitiveValue See also: negative predictive value\nDefinition The proportion of reported cases that actually have the health-related event under surveillance.\nDescription Positive Predictive Value (PPV) is the proportion of cases identified by a surveillance system that are true cases. A high PPV indicates fewer false positives, which helps minimize unnecessary investigtations and conserves resources. PPV is influenced by the specificity and sensitivity of case definitions, as well as the prevalence of the condition in the population. As sensitivity and PPV approach 100%, a system is more likely to be representative of the population with the event under surveillance. However, as sensitivity increases, PPV may decrease; therefore, a balance should be maintained between prioritizing early detection and accuracy. PPV may also influenced by data quality, communication, and reporting practices.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: sensitivity"
  },
  {
    "objectID": "dictionary_documentation.html#precision",
    "href": "dictionary_documentation.html#precision",
    "title": "dictionary documentation",
    "section": "Precision",
    "text": "Precision\nID: precision See also: accuracy; bias\nDefinition The degree to which a numerical estimate is narrowly defined, typically indicated by the tightness of its confidence interval.\nDescription Precision reflects the level of statistical uncertainty around an estimate, with narrower confidence intervals indicating higher precision. It is influenced by sample size, confidence level, variability in the data, and overall data quality. Precision is important for interpreting the reliability of surveillance indicators and comparing system performance over time or across regions.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: repeatability, consistency"
  },
  {
    "objectID": "dictionary_documentation.html#preparedness",
    "href": "dictionary_documentation.html#preparedness",
    "title": "dictionary documentation",
    "section": "Preparedness",
    "text": "Preparedness\nID: preparedness See also: N/A\nDefinition Preparedness corresponds to the set of actions that are taken as precautionary measures in the face of potential hazard-related issues.\nDescription Preparedness refers to the extent to which a surveillance system is equipped to respond effectively to public health emergencies. This includes having written procedures, emergency trained personnel, and readily available resources to support timely action. A well-prepared system can detect, report, and respond to emerging threats quickly and efficiently. The preparedness term is closely linked to timeliness, stability, and sustainability, as it depends on ongoing capacity, planning, and coordination.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#redundancy",
    "href": "dictionary_documentation.html#redundancy",
    "title": "dictionary documentation",
    "section": "Redundancy",
    "text": "Redundancy\nID: redundancy See also: N/A\nDefinition The ability of the surveillance system to operate in the face of component loss or degradation.\nDescription Redundancy refers to the presence of backup systems or components—such as staff, IT infrastructure, data sources, or interagency agreements—that ensure continued surveillance operations if one part fails. It supports system stability and resilience, allowing for uninterrupted performance during disruptions. Without redundancy, the failure of a single component can compromise data collection, analysis, or reporting. Redundancy is closely related to stability, robustness, and sustainability, as it enhances the system’s ability to maintain functionality and deliver reliable outputs under various conditions.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#relevance",
    "href": "dictionary_documentation.html#relevance",
    "title": "dictionary documentation",
    "section": "Relevance",
    "text": "Relevance\nID: relevance See also: effectivness; usefulness\nDefinition The degree to which functions and activities in the surveillance system are relevant to its objectives and priorities.\nDescription Relevance assesses how well a surveillance system’s functions, activities, and data align with its objectives, priorities, and user needs. It examines whether the system addresses key data gaps, supports decision-making, and reflects epidemiological, socio-political, and economic contexts. Relevance also involves ensuring collaborative activities (e.g., sampling, lab testing, data sharing) match the system’s goals and stakeholder expectations. High relevance enhances system usefulness, acceptability, and sustainability by focusing resources on priority surveillance needs.\nBackground TBD\nSynonyms\n\nExact: pertienence\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#repeatability",
    "href": "dictionary_documentation.html#repeatability",
    "title": "dictionary documentation",
    "section": "Repeatability",
    "text": "Repeatability\nID: repeatability See also: N/A\nDefinition How consistently the study results can be reproduced over time.\nDescription Repeatability is a key concept in validating diagnostic tests and is closely tied to precision. In the context of a surveillance system, it also relates to the terms/attributes of historical data, stability, and sustainability. A surveillance system that excels in repeatability generates data that can be consistently compared across years, with clear documentation of any changes in data collection methods or variables over time. This ensures that variations in the data are well-understood and attributable to actual trends rather than inconsistencies in data collection, facilitating accurate longitudinal analysis and comparison.\nBackground TBD\nSynonyms\n\nExact: –\nBroad: consistency, precision"
  },
  {
    "objectID": "dictionary_documentation.html#representativeness",
    "href": "dictionary_documentation.html#representativeness",
    "title": "dictionary documentation",
    "section": "Representativeness",
    "text": "Representativeness\nID: representativeness See also: coverage\nDefinition The extent to which data adequately represent the population under surveillance and relevant sub-populations by time, place, population demographics and socio-demographics.\nDescription Representativeness refers to how well surveillance data reflect the characteristics of the population of interest, allowing findings to be generalized without systematic bias. It considers factors like geography, demographics, and clinical presentation. While sensitivity focuses on detecting cases, representativeness ensures that the distribution of cases mirrors reality. High coverage across regions and groups supports inclusivity, while limited or uneven data can lead to selection or ascertainment bias. The representativeness of a surveillance system is related to both coverage and bias. Representativeness is also closely linked to terms such as sensitivity, precision, and data quality, and is essential for drawing accurate conclusions and informing effective public health planning.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: coverage?"
  },
  {
    "objectID": "dictionary_documentation.html#responsiveness-processes",
    "href": "dictionary_documentation.html#responsiveness-processes",
    "title": "dictionary documentation",
    "section": "Responsiveness (processes)",
    "text": "Responsiveness (processes)\nID: responsiveness See also: N/A\nDefinition Responsiveness refers to the system’s ability to promptly address user requests and the willingness of support staff to assist with inquiries and provide necessary services.\nDescription Responsiveness measures how quickly and effectively a surveillance system addresses user requests and support needs. It reflects the willingness and ability of staff to assist with inquiries, troubleshoot issues, and provide necessary services. High responsiveness supports timely data reporting, improves user satisfaction, and enhances system acceptability. Responsiveness is closely linked to timeliness and acceptability, ensuring the system remains user-friendly and operationally efficient.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: –"
  },
  {
    "objectID": "dictionary_documentation.html#robustness",
    "href": "dictionary_documentation.html#robustness",
    "title": "dictionary documentation",
    "section": "Robustness",
    "text": "Robustness\nID: robustness See also: N/A\nDefinition The ability of the surveillance system to produce acceptable outcomes over a range of assumptions about uncertainty by maximising the reliability of an adequate outcome.\nDescription Robustness refers to a surveillance system’s ability to consistently generate reliable results over time, even under varying conditions and uncertainties. It ensures stable, accurate outcomes regardless of environmental or data changes. Robust systems are closely linked to precision, as both require dependable results. Additionally, robustness ties into consistency, flexibility, and portability, allowing the system to adapt to diverse contexts. A robust surveillance system is crucial for providing reliable data that supports long-term public health decisions and interventions, making it vital for effective and sustainable public health responses.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#security",
    "href": "dictionary_documentation.html#security",
    "title": "dictionary documentation",
    "section": "Security",
    "text": "Security\nID: security See also: N/A\nDefinition The privacy and data confidentiality measures required to prevent surveillance data compromise, based on relevant standards and guidelines.\nDescription Security in a surveillance system involves safeguarding the privacy and confidentiality of data to prevent unauthorized access or breaches. Security measures should be reviewed regularly and adapted to emerging threats. Strong security practices ensures data integrity and builds trust between actors/stakeholders of the surveillance system.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#sensitivity",
    "href": "dictionary_documentation.html#sensitivity",
    "title": "dictionary documentation",
    "section": "Sensitivity",
    "text": "Sensitivity\nID: sensitivity See also: specificity\nDefinition The system’s ability to accurately identify and capture all true cases or events of interest within the target population\nDescription Sensitivity can be assessed at three levels: Case detection sensitivity – the proportion of actual cases (individuals or herds) with the condition that are correctly identified by the system; Outbreak detection sensitivity – the likelihood that the system will detect a significant increase in disease incidence, provided a clear definition of an outbreak exists; and Presence detection sensitivity – the probability that the system will detect the disease if it is present at or above a specified prevalence level in the population.\nBackground TBD\nSynonyms\n\nExact: recall (Morbey 2021), completeness (Groseclose 2010)\nBroad: positive predictive value"
  },
  {
    "objectID": "dictionary_documentation.html#simplicity",
    "href": "dictionary_documentation.html#simplicity",
    "title": "dictionary documentation",
    "section": "Simplicity",
    "text": "Simplicity\nID: simplicity See also: N/A\nDefinition Refers to the surveillance system structure, ease of operation, and flow of data through the system.\nDescription Simplicity should be inherent in the system as a whole, as well as each component (case definition, reporting procedures, etc.), to make it easy to understand and implement. In general, a surveillance system should be as simple as possible while still meeting its objectives. A simple system typically enhances flexibility, reduces resource requirements, and contributes to better timeliness. Simplicity also positively influences acceptability and engagement, as actors/stakeholders are more likely to adopt and participate in a system that is easy to use and understand. Simplicity also supports sustainability by easing training, maintenance, and management, ultimately leading to more accurate and comprehensive data.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#specificity",
    "href": "dictionary_documentation.html#specificity",
    "title": "dictionary documentation",
    "section": "Specificity",
    "text": "Specificity\nID: specificity See also: false-alarm rate; sensitivity\nDefinition The proportion of cases correctly identified by the system as not having the health-related event under surveillance.\nDescription Specificity refers to a surveillance system’s ability to correctly identify non-cases, minimizing false positives. It complements sensitivity by ensuring that resources are not wasted on investigating non-events. High specificity is especially important in outbreak detection and in systems monitoring rare or high-impact conditions. It reduces false alarms, conserving time and funding. Specificity is influenced by factors such as case definitions and population denominators. In some contexts, a trade-off with sensitivity may be acceptable to avoid missing critical threats.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#stability",
    "href": "dictionary_documentation.html#stability",
    "title": "dictionary documentation",
    "section": "Stability",
    "text": "Stability\nID: stability See also: sustainability\nDefinition Stability refers to the reliability (ie, the ability to collect,manage, and provide data without failure) and availability (the ability to operate when needed) of the public health surveillancesystem.\nDescription Stability refers to the system’s ability to consistently operate and deliver results over time, even under stress or changing conditions. It includes reliability, availability, and resilience to disruptions. Stability depends on factors such as workforce capacity, secure funding, legal frameworks, and continuity plans. It is positively correlated with sustainability and acceptability.\nBackground TBD\nSynonyms\n\nExact: ability to contrinue tracking an event (sub-attribute), reliability, availability\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#sustainability",
    "href": "dictionary_documentation.html#sustainability",
    "title": "dictionary documentation",
    "section": "Sustainability",
    "text": "Sustainability\nID: sustainability See also: stability; feasability; N/A\nDefinition The ability of the surveillance system to be ongoing in the long term.\nDescription Sustainability refers to the system’s ability to operate effectively over time with consistent support. This includes having skilled personnel, sufficient laboratory capacity for timely sample processing, and clearly defined responsibilities for resource provision. Resources should align with current operational needs. Sustainability is closely linked to usefulness and timeliness, emphasizing practical procedures, adequate budgeting, and long-term system maintenance. It is dependednt on the continued engagement from stakeholders/actors involved in core surveillance functions, as well as the acceptability of end-users of the surveillance system.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#system-description",
    "href": "dictionary_documentation.html#system-description",
    "title": "dictionary documentation",
    "section": "System description",
    "text": "System description\nID: systemDescription See also: N/A\nDefinition TBD\nDescription N/A\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#technical-competence-and-training",
    "href": "dictionary_documentation.html#technical-competence-and-training",
    "title": "dictionary documentation",
    "section": "Technical competence and training",
    "text": "Technical competence and training\nID: technicalCompetenceAndTraining See also: laboratory and sample management\nDefinition Refers to the technical skills of the personnel involved in the surveillance system, including access to relevant training.\nDescription The combination of the technical skills, knowledge, and capacities required by personnel to effectively implement and sustain a surveillance system, supported by access to appropriate initial and ongoing training programs. It encompasses the ability to perform system functions accurately, ensure data quality, and engage in collaborative activities, thereby enhancing the overall performance and reliability of the surveillance system\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#timeliness",
    "href": "dictionary_documentation.html#timeliness",
    "title": "dictionary documentation",
    "section": "Timeliness",
    "text": "Timeliness\nID: timeliness See also: N/A\nDefinition The time between any two steps in the surveillance process.\nDescription Timeliness refers to the speed at which data are collected, reported, analyzed, and used to guide public health action. The required level of timeliness depends on the health event—rapid reporting is critical for acute, highly transmissible diseases, while less urgent conditions may allow for slower reporting. Timeliness is influenced by surveillance system design, resource availability, and event complexity. Delays in lab results or data flow can hinder timely response, especially in resource-limited settings. It must be balanced with accuracy and completeness and aligned with surveillance goals such as outbreak detection, trend monitoring, or long-term planning.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#traceability-data",
    "href": "dictionary_documentation.html#traceability-data",
    "title": "dictionary documentation",
    "section": "Traceability (data)",
    "text": "Traceability (data)\nID: traceabilityData See also: N/A\nDefinition N/A\nDescription TBD\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#transparency",
    "href": "dictionary_documentation.html#transparency",
    "title": "dictionary documentation",
    "section": "Transparency",
    "text": "Transparency\nID: transparency See also: N/A\nDefinition The extent to which information can be and is shared across member agencies.\nDescription Transparency refers to how openly the surveillance system shares information about its data collection methods, analysis processes, and limitations with stakeholders and end-users. High transparency builds trust, supports data interpretation, and facilitates informed decision-making. Challenges include inconsistent or delayed data sharing, which can reduce stakeholder confidence and limit timely responses. Transparency is linked to terms like acceptability and usefulness, as clear communication of methods and constraints helps users understand system strengths and weaknesses.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#usablity",
    "href": "dictionary_documentation.html#usablity",
    "title": "dictionary documentation",
    "section": "Usablity",
    "text": "Usablity\nID: usability See also: usefulness; communication dissemination\nDefinition Data and products produced by the surveillance system should be tailored to meet the needs of intended users.\nDescription Usability assesses whether surveillance data and products are tailored to meet the needs of intended users. High usability involves clear documentation (data dictionaries, manuals), minimal training requirements, and system workflows that align with user practices. It also considers how well data interpretations (e.g., statistics) are communicated, including accessibility features like language, cultural relevance, and format. The ability to stratify data by relevant factors (age, sex, geography) enhances usefulness. Regular user feedback guides system improvements. Usability links closely with acceptability and usefulness, influencing how effectively data informs public health actions.\nBackground TBD\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#usefulness",
    "href": "dictionary_documentation.html#usefulness",
    "title": "dictionary documentation",
    "section": "Usefulness",
    "text": "Usefulness\nID: usefulness See also: effectiveness; benefit\nDefinition The extent to which the surveillance system contributes to prevention and control of health-related events by providing practical value that supports public health actions and policy decisions (4,anonymous.2001?,Azofeifa_EBHS_2018?,WorldBank_PPH_2006?).\nDescription Usefulness encompasses two complementary facets: the system’s contribution to preventing or controlling health events (the direct public health outcome) and the practical value of surveillance outputs for decision-makers (the mechanism through which impact occurs). It is demonstrated through real-world outcomes such as policy changes, early outbreak detection, targeted interventions, or improved understanding of health threats that guide evidence-based responses (Groseclose_APHS_2017?,Peyre_TRVA_2019?). A surveillance system is considered useful when it provides value to stakeholders and society by enabling meaningful actions that would not otherwise occur (4,DelRioVilas_HSEitPC_2022?). The assessment of usefulness should begin with a review of system objectives and involves measuring how well surveillance outputs meet stakeholder needs and influence decision-making (anonymous.2001?,Azofeifa_EBHS_2018?). Both qualitative approaches (subjective views of users) and quantitative approaches (measuring impact on policies, interventions, or disease occurrence) can assess usefulness, though measurement is often considered inexact (Thacker_MEES_1988?,Declich_PHS_1994?). Retrospective analysis and stakeholder input help assess whether the system aligns with health priorities and produces information that stakeholders find valuable and actionable. Usefulness is closely tied to—and affected by—virtually all other surveillance attributes including sensitivity, timeliness, predictive value positive, representativeness, simplicity, flexibility, acceptability, and stability. For example, improved timeliness allows control and prevention activities to be initiated earlier, directly enhancing overall usefulness (anonymous.2001?). The quality of data determined by these underlying attributes ultimately shapes the system’s value in guiding effective, evidence-based responses and demonstrating that surveillance efforts justify their investment.\nBackground Usefulness represents one of the seven original core attributes established for evaluating public health surveillance systems, with foundational definition and emphasis provided by Thacker et al. beginning in 1988 and subsequently codified in CDC evaluation guidelines (Thacker_MEES_1988?,anonymous.2001?,Groseclose_EPHS_2010?). This provenance establishes usefulness as a cornerstone concept in public health surveillance evaluation, reflecting the fundamental question of whether surveillance systems achieve their intended purpose of improving population health. The attribute has been consistently included in evaluations of diverse surveillance contexts including behavioral health systems, wastewater surveillance, and global public health surveillance under International Health Regulations (IHR 2005) (Azofeifa_EBHS_2018?,Amato_E_2023?). Usefulness encompasses two distinct but complementary facets identified in surveillance evaluation literature. The first represents the direct purpose of surveillance—the public health outcome itself, measured by the system’s contribution to disease reduction, control, or improved understanding (anonymous.2001?,Thacker_MEES_1988?). The second represents the mechanism of impact—how surveillance data translates into policy and action, reflecting the system’s demonstrable utility for stakeholders and decision-makers (WorldBank_PPH_2006?,DelRioVilas_HSEitPC_2022?). Both facets are essential: a system must both achieve public health outcomes and provide practical value to end-users to be considered truly useful. This dual nature is reflected in assessment approaches that combine both qualitative measures (subjective views of users regarding practical value) and quantitative measures (documented impacts on policies, interventions, or disease occurrence) (Thacker_MEES_1988?,Declich_PHS_1994?). Usefulness is explicitly recognized as synonymous with impact in evaluation literature, yet the terms reflect distinct emphasis and measurement traditions (dictionary_documentation?). While usefulness is typically framed around contributions to prevention and control or informing public health policy decisions, impact is often defined more specifically as the changes made based on surveillance results, frequently appearing in animal health, economic evaluation, and One Health frameworks (anonymous.2001?,Azofeifa_EBHS_2018?,Drewe_SERVAL_2015?,Meynard_PFAFM_2008?). The term \"usefulness\" emphasizes the practical, stakeholder-centered perspective of public health practice—whether the system provides value to those who use it and leads to meaningful action. This contrasts subtly with \"impact,\" which tends to emphasize measurable outcomes and return on investment, particularly in contexts requiring economic evaluation or demonstrating the value of integrated surveillance across sectors. The conceptual alignment between usefulness and impact is substantial: both measure the ultimate value of surveillance by assessing tangible benefits, both focus on how surveillance influences decisions and interventions, both depend on the same underlying technical attributes, and both are highly relevant to stakeholders and decision-makers who need evidence that systems justify investment (4,Groseclose_APHS_2017?,Peyre_TRVA_2019?,DelRioVilas_HSEitPC_2022?). The choice between terms often reflects evaluation context and audience rather than fundamental conceptual difference—public health surveillance evaluations rooted in CDC traditions typically emphasize usefulness, while One Health and economic evaluations frequently emphasize impact. Regardless of terminology, the attribute represents a summary measure of whether the surveillance system achieves its ultimate purpose: improving health outcomes through informed action. Modern surveillance evaluation increasingly demands rigorous assessment of this attribute for both donor accountability and social accountability, requiring demonstration that surveillance efforts produce measurable value (4,Peyre_AITAEoPHS_2022?).\nSynonyms\n\nExact: impact\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#coherence",
    "href": "dictionary_documentation.html#coherence",
    "title": "dictionary documentation",
    "section": "Coherence",
    "text": "Coherence\nID: – See also: Compatibility; integration; interoperability\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#confidence",
    "href": "dictionary_documentation.html#confidence",
    "title": "dictionary documentation",
    "section": "Confidence",
    "text": "Confidence\nID: – See also: Accuracy\nDefinition Output confidence relates to the accuracy of the event-based biosurveillance results. It is used to evaluate the likelihood that the confidence interval contains the true result. This attribute helps evaluate whether the event-based biosurveillance generates estimates at specific intervals with some degree of probability. Confidence also facilitates the evaluation of estimates for frequency and probability distributions (Corley 2012). Reliability - (Confidence in data) Confidence in the reliability of the information (Auer 2011).\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#confidentiality",
    "href": "dictionary_documentation.html#confidentiality",
    "title": "dictionary documentation",
    "section": "Confidentiality",
    "text": "Confidentiality\nID: – See also: N/A\nDefinition Privacy and data confidentiality requirements for the collection, storage, backup, transport and retrieval of information (especially over the internet), based on relevant standards and guidelines (Yang 2022).\nDescription N/A\nBackground –\nSynonyms\n\nExact: –\nBroad: –"
  },
  {
    "objectID": "dictionary_documentation.html#content",
    "href": "dictionary_documentation.html#content",
    "title": "dictionary documentation",
    "section": "Content",
    "text": "Content\nID: – See also: N/A\nDefinition Input data content is the data specification required by the event-based biosurveillance, such as the quantity and class of data needed to produce meaningful results. The content attribute also spans the quantity and class of other data required of the event-based biosurveillance (eg, demographic, behavioral, and exposure information for the acute emergent event). Additionally, the dependence of the data on other systems or constructs may be included (Corley 2012). The output content attribute defines what the event- based biosurveillance generates as a product. The output may be qualitative or quantitative and may include probabilities, forecasts, digests, counts, warnings, or lists of outlying observations. The content attribute also spans the quantity and class of data produced by the event-based biosurveillance. If the event-based biosurveillance output lends guidance to other systems, this should be included (Corley 2012).\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#data-sharing",
    "href": "dictionary_documentation.html#data-sharing",
    "title": "dictionary documentation",
    "section": "Data sharing",
    "text": "Data sharing\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: Transparency\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#decision-making",
    "href": "dictionary_documentation.html#decision-making",
    "title": "dictionary documentation",
    "section": "Decision-making",
    "text": "Decision-making\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#efficacy",
    "href": "dictionary_documentation.html#efficacy",
    "title": "dictionary documentation",
    "section": "Efficacy",
    "text": "Efficacy\nID: – See also: Impact; usability; usefulness\nDefinition Extent to which the system objectives are achieved (Drewe 2012, Meynard 2008).\nDescription N/A\nBackground –\nSynonyms\n\nExact: Effectiveness\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#equity-assessment",
    "href": "dictionary_documentation.html#equity-assessment",
    "title": "dictionary documentation",
    "section": "Equity assessment",
    "text": "Equity assessment\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: –\nBroad: –"
  },
  {
    "objectID": "dictionary_documentation.html#integration",
    "href": "dictionary_documentation.html#integration",
    "title": "dictionary documentation",
    "section": "Integration",
    "text": "Integration\nID: – See also: Coherence; interoperability\nDefinition Ability of the surveillance system or components in the system to integrate/connect with other surveillance or public health systems to enhance interoperability, effectiveness and/or to reduce cost (Yang 2022).\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: Compatibility"
  },
  {
    "objectID": "dictionary_documentation.html#informatics-capabilities",
    "href": "dictionary_documentation.html#informatics-capabilities",
    "title": "dictionary documentation",
    "section": "Informatics capabilities",
    "text": "Informatics capabilities\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#legislative-support",
    "href": "dictionary_documentation.html#legislative-support",
    "title": "dictionary documentation",
    "section": "Legislative support",
    "text": "Legislative support\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: Compliance"
  },
  {
    "objectID": "dictionary_documentation.html#many-separate-attributes",
    "href": "dictionary_documentation.html#many-separate-attributes",
    "title": "dictionary documentation",
    "section": "Many separate attributes",
    "text": "Many separate attributes\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: –\nBroad: –"
  },
  {
    "objectID": "dictionary_documentation.html#operational-plan",
    "href": "dictionary_documentation.html#operational-plan",
    "title": "dictionary documentation",
    "section": "Operational plan",
    "text": "Operational plan\nID: – See also: Governance\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#partnerships",
    "href": "dictionary_documentation.html#partnerships",
    "title": "dictionary documentation",
    "section": "Partnerships",
    "text": "Partnerships\nID: – See also: N/A\nDefinition Whether long-term formal connections are in place (Haworth-Brockman 2021, Bingle 2005).\nDescription N/A\nBackground –\nSynonyms\n\nExact: collaboration\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#privacy",
    "href": "dictionary_documentation.html#privacy",
    "title": "dictionary documentation",
    "section": "Privacy",
    "text": "Privacy\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: Confidentiality"
  },
  {
    "objectID": "dictionary_documentation.html#qa-qi-intensity",
    "href": "dictionary_documentation.html#qa-qi-intensity",
    "title": "dictionary documentation",
    "section": "QA/QI intensity",
    "text": "QA/QI intensity\nID: – See also: N/A\nDefinition –\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#reliability",
    "href": "dictionary_documentation.html#reliability",
    "title": "dictionary documentation",
    "section": "Reliability",
    "text": "Reliability\nID: – See also: N/A\nDefinition The ability to collect, manage, and provide data without failure (Azofeifa 2018, Groseclose 2010, Groseclose 2013, Groseclose 2017, Marbus 2020).\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: N/A"
  },
  {
    "objectID": "dictionary_documentation.html#standards-use",
    "href": "dictionary_documentation.html#standards-use",
    "title": "dictionary documentation",
    "section": "Standards use",
    "text": "Standards use\nID: – See also: N/A\nDefinition Use of data exchange, messaging, or other information technology standards by a surveillance system that enhances the ability of the system and its software applications to communicate, exchange data, and use the information that has been exchanged (Groseclose 2017).\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: Adherence"
  },
  {
    "objectID": "dictionary_documentation.html#utility",
    "href": "dictionary_documentation.html#utility",
    "title": "dictionary documentation",
    "section": "Utility",
    "text": "Utility\nID: – See also: Usefulness; effectiveness; impact\nDefinition Describes how useful, profitable, or beneficial surveillance is in relation to its objectives and describes the changes that have been made based on the outputs provided by the surveillance system (Muellner 2018).\nDescription N/A\nBackground –\nSynonyms\n\nExact: N/A\nBroad: Impact, usefulness"
  },
  {
    "objectID": "dictionary_documentation.html#markdown-rendering-issues",
    "href": "dictionary_documentation.html#markdown-rendering-issues",
    "title": "dictionary documentation",
    "section": "Markdown Rendering Issues",
    "text": "Markdown Rendering Issues\nThe following fields had issues rendering markdown:\n\ndataQuality (term_background): Unclosed change tracking markup found"
  }
]